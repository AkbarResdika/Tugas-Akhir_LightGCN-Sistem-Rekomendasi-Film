{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "79tZQQsGyhuL",
        "_scBRfZ0fnX9",
        "KFaWYCQmkw5u",
        "-Hy1o4t6GjqT"
      ],
      "gpuType": "T4",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AkbarResdika/Tugas-Akhir_LightGCN-Sistem-Rekomendasi-Film/blob/main/Modifikasi_Tugas_Akhir.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pip Recommenders"
      ],
      "metadata": {
        "id": "ulJnRZUXc2hb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install recommenders"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWQI-BE7E4Wh",
        "outputId": "8091a237-2810-434b-d1d8-d79f4d3c8df4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: recommenders in /usr/local/lib/python3.11/dist-packages (1.2.1)\n",
            "Requirement already satisfied: category-encoders<3,>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from recommenders) (2.8.1)\n",
            "Requirement already satisfied: cornac<3,>=1.15.2 in /usr/local/lib/python3.11/dist-packages (from recommenders) (2.3.3)\n",
            "Requirement already satisfied: hyperopt<1,>=0.2.7 in /usr/local/lib/python3.11/dist-packages (from recommenders) (0.2.7)\n",
            "Requirement already satisfied: lightgbm<5,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from recommenders) (4.5.0)\n",
            "Requirement already satisfied: locust<3,>=2.12.2 in /usr/local/lib/python3.11/dist-packages (from recommenders) (2.37.10)\n",
            "Requirement already satisfied: memory-profiler<1,>=0.61.0 in /usr/local/lib/python3.11/dist-packages (from recommenders) (0.61.0)\n",
            "Requirement already satisfied: nltk<4,>=3.8.1 in /usr/local/lib/python3.11/dist-packages (from recommenders) (3.9.1)\n",
            "Requirement already satisfied: notebook<8,>=6.5.5 in /usr/local/lib/python3.11/dist-packages (from recommenders) (6.5.7)\n",
            "Requirement already satisfied: numba<1,>=0.57.0 in /usr/local/lib/python3.11/dist-packages (from recommenders) (0.60.0)\n",
            "Requirement already satisfied: pandas<3.0.0,>2.0.0 in /usr/local/lib/python3.11/dist-packages (from recommenders) (2.2.2)\n",
            "Requirement already satisfied: retrying<2,>=1.3.4 in /usr/local/lib/python3.11/dist-packages (from recommenders) (1.3.4)\n",
            "Requirement already satisfied: scikit-learn<2,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from recommenders) (1.6.1)\n",
            "Requirement already satisfied: scikit-surprise>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from recommenders) (1.1.4)\n",
            "Requirement already satisfied: seaborn<1,>=0.13.0 in /usr/local/lib/python3.11/dist-packages (from recommenders) (0.13.2)\n",
            "Requirement already satisfied: transformers<5,>=4.27.0 in /usr/local/lib/python3.11/dist-packages (from recommenders) (4.52.4)\n",
            "Requirement already satisfied: pandera>=0.15.0 in /usr/local/lib/python3.11/dist-packages (from pandera[strategies]>=0.15.0; python_version >= \"3.9\"->recommenders) (0.24.0)\n",
            "Requirement already satisfied: statsmodels>=0.14.4 in /usr/local/lib/python3.11/dist-packages (from recommenders) (0.14.4)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from category-encoders<3,>=2.6.0->recommenders) (2.0.2)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from category-encoders<3,>=2.6.0->recommenders) (1.0.1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from category-encoders<3,>=2.6.0->recommenders) (1.15.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from cornac<3,>=1.15.2->recommenders) (4.67.1)\n",
            "Requirement already satisfied: powerlaw in /usr/local/lib/python3.11/dist-packages (from cornac<3,>=1.15.2->recommenders) (1.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from hyperopt<1,>=0.2.7->recommenders) (1.17.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.11/dist-packages (from hyperopt<1,>=0.2.7->recommenders) (3.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from hyperopt<1,>=0.2.7->recommenders) (1.0.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from hyperopt<1,>=0.2.7->recommenders) (3.1.1)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.11/dist-packages (from hyperopt<1,>=0.2.7->recommenders) (0.10.9.7)\n",
            "Requirement already satisfied: configargparse>=1.7.1 in /usr/local/lib/python3.11/dist-packages (from locust<3,>=2.12.2->recommenders) (1.7.1)\n",
            "Requirement already satisfied: flask-cors>=3.0.10 in /usr/local/lib/python3.11/dist-packages (from locust<3,>=2.12.2->recommenders) (6.0.1)\n",
            "Requirement already satisfied: flask-login>=0.6.3 in /usr/local/lib/python3.11/dist-packages (from locust<3,>=2.12.2->recommenders) (0.6.3)\n",
            "Requirement already satisfied: flask>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from locust<3,>=2.12.2->recommenders) (3.1.1)\n",
            "Requirement already satisfied: gevent<26.0.0,>=24.10.1 in /usr/local/lib/python3.11/dist-packages (from locust<3,>=2.12.2->recommenders) (25.5.1)\n",
            "Requirement already satisfied: geventhttpclient>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from locust<3,>=2.12.2->recommenders) (2.3.4)\n",
            "Requirement already satisfied: locust-cloud>=1.23.1 in /usr/local/lib/python3.11/dist-packages (from locust<3,>=2.12.2->recommenders) (1.23.1)\n",
            "Requirement already satisfied: msgpack>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from locust<3,>=2.12.2->recommenders) (1.1.0)\n",
            "Requirement already satisfied: psutil>=5.9.1 in /usr/local/lib/python3.11/dist-packages (from locust<3,>=2.12.2->recommenders) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=25.0.0 in /usr/local/lib/python3.11/dist-packages (from locust<3,>=2.12.2->recommenders) (27.0.0)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from locust<3,>=2.12.2->recommenders) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=70.0.0 in /usr/local/lib/python3.11/dist-packages (from locust<3,>=2.12.2->recommenders) (75.2.0)\n",
            "Requirement already satisfied: werkzeug>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from locust<3,>=2.12.2->recommenders) (3.1.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk<4,>=3.8.1->recommenders) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk<4,>=3.8.1->recommenders) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk<4,>=3.8.1->recommenders) (2024.11.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from notebook<8,>=6.5.5->recommenders) (3.1.6)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from notebook<8,>=6.5.5->recommenders) (6.4.2)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook<8,>=6.5.5->recommenders) (25.1.0)\n",
            "Requirement already satisfied: traitlets>=4.2.1 in /usr/local/lib/python3.11/dist-packages (from notebook<8,>=6.5.5->recommenders) (5.7.1)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.11/dist-packages (from notebook<8,>=6.5.5->recommenders) (5.8.1)\n",
            "Requirement already satisfied: jupyter-client<8,>=5.3.4 in /usr/local/lib/python3.11/dist-packages (from notebook<8,>=6.5.5->recommenders) (6.1.12)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.11/dist-packages (from notebook<8,>=6.5.5->recommenders) (0.2.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.11/dist-packages (from notebook<8,>=6.5.5->recommenders) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.11/dist-packages (from notebook<8,>=6.5.5->recommenders) (7.16.6)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.11/dist-packages (from notebook<8,>=6.5.5->recommenders) (1.6.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.11/dist-packages (from notebook<8,>=6.5.5->recommenders) (6.17.1)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook<8,>=6.5.5->recommenders) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook<8,>=6.5.5->recommenders) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook<8,>=6.5.5->recommenders) (0.22.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook<8,>=6.5.5->recommenders) (1.3.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba<1,>=0.57.0->recommenders) (0.43.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>2.0.0->recommenders) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>2.0.0->recommenders) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>2.0.0->recommenders) (2025.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from pandera>=0.15.0->pandera[strategies]>=0.15.0; python_version >= \"3.9\"->recommenders) (24.2)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from pandera>=0.15.0->pandera[strategies]>=0.15.0; python_version >= \"3.9\"->recommenders) (2.11.5)\n",
            "Requirement already satisfied: typeguard in /usr/local/lib/python3.11/dist-packages (from pandera>=0.15.0->pandera[strategies]>=0.15.0; python_version >= \"3.9\"->recommenders) (4.4.3)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from pandera>=0.15.0->pandera[strategies]>=0.15.0; python_version >= \"3.9\"->recommenders) (4.14.0)\n",
            "Requirement already satisfied: typing_inspect>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pandera>=0.15.0->pandera[strategies]>=0.15.0; python_version >= \"3.9\"->recommenders) (0.9.0)\n",
            "Requirement already satisfied: hypothesis>=6.92.7 in /usr/local/lib/python3.11/dist-packages (from pandera[strategies]>=0.15.0; python_version >= \"3.9\"->recommenders) (6.135.10)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2,>=1.2.0->recommenders) (3.6.0)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.11/dist-packages (from seaborn<1,>=0.13.0->recommenders) (3.10.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers<5,>=4.27.0->recommenders) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers<5,>=4.27.0->recommenders) (0.33.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers<5,>=4.27.0->recommenders) (6.0.2)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5,>=4.27.0->recommenders) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5,>=4.27.0->recommenders) (0.5.3)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from flask>=2.0.0->locust<3,>=2.12.2->recommenders) (1.9.0)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from flask>=2.0.0->locust<3,>=2.12.2->recommenders) (2.2.0)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from flask>=2.0.0->locust<3,>=2.12.2->recommenders) (3.0.2)\n",
            "Requirement already satisfied: greenlet>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from gevent<26.0.0,>=24.10.1->locust<3,>=2.12.2->recommenders) (3.2.3)\n",
            "Requirement already satisfied: zope.event in /usr/local/lib/python3.11/dist-packages (from gevent<26.0.0,>=24.10.1->locust<3,>=2.12.2->recommenders) (5.0)\n",
            "Requirement already satisfied: zope.interface in /usr/local/lib/python3.11/dist-packages (from gevent<26.0.0,>=24.10.1->locust<3,>=2.12.2->recommenders) (7.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from geventhttpclient>=2.3.1->locust<3,>=2.12.2->recommenders) (2025.4.26)\n",
            "Requirement already satisfied: brotli in /usr/local/lib/python3.11/dist-packages (from geventhttpclient>=2.3.1->locust<3,>=2.12.2->recommenders) (1.1.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.11/dist-packages (from geventhttpclient>=2.3.1->locust<3,>=2.12.2->recommenders) (2.4.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers<5,>=4.27.0->recommenders) (2025.3.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers<5,>=4.27.0->recommenders) (1.1.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from hypothesis>=6.92.7->pandera[strategies]>=0.15.0; python_version >= \"3.9\"->recommenders) (25.3.0)\n",
            "Requirement already satisfied: sortedcontainers<3.0.0,>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from hypothesis>=6.92.7->pandera[strategies]>=0.15.0; python_version >= \"3.9\"->recommenders) (2.4.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core>=4.6.1->notebook<8,>=6.5.5->recommenders) (4.3.8)\n",
            "Requirement already satisfied: python-engineio>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from locust-cloud>=1.23.1->locust<3,>=2.12.2->recommenders) (4.12.2)\n",
            "Requirement already satisfied: python-socketio==5.13.0 in /usr/local/lib/python3.11/dist-packages (from python-socketio[client]==5.13.0->locust-cloud>=1.23.1->locust<3,>=2.12.2->recommenders) (5.13.0)\n",
            "Requirement already satisfied: bidict>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from python-socketio==5.13.0->python-socketio[client]==5.13.0->locust-cloud>=1.23.1->locust<3,>=2.12.2->recommenders) (0.23.1)\n",
            "Requirement already satisfied: websocket-client>=0.54.0 in /usr/local/lib/python3.11/dist-packages (from python-socketio[client]==5.13.0->locust-cloud>=1.23.1->locust<3,>=2.12.2->recommenders) (1.8.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn<1,>=0.13.0->recommenders) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn<1,>=0.13.0->recommenders) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn<1,>=0.13.0->recommenders) (4.58.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn<1,>=0.13.0->recommenders) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn<1,>=0.13.0->recommenders) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn<1,>=0.13.0->recommenders) (3.2.3)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from nbclassic>=0.4.7->notebook<8,>=6.5.5->recommenders) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook<8,>=6.5.5->recommenders) (4.13.4)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook<8,>=6.5.5->recommenders) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook<8,>=6.5.5->recommenders) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook<8,>=6.5.5->recommenders) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook<8,>=6.5.5->recommenders) (3.1.3)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook<8,>=6.5.5->recommenders) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook<8,>=6.5.5->recommenders) (1.5.1)\n",
            "Requirement already satisfied: pygments>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook<8,>=6.5.5->recommenders) (2.19.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook<8,>=6.5.5->recommenders) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook<8,>=6.5.5->recommenders) (4.24.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->locust<3,>=2.12.2->recommenders) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->locust<3,>=2.12.2->recommenders) (3.10)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.11/dist-packages (from terminado>=0.8.3->notebook<8,>=6.5.5->recommenders) (0.7.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing_inspect>=0.6.0->pandera>=0.15.0->pandera[strategies]>=0.15.0; python_version >= \"3.9\"->recommenders) (1.1.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook<8,>=6.5.5->recommenders) (21.2.0)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel->notebook<8,>=6.5.5->recommenders) (1.8.0)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->notebook<8,>=6.5.5->recommenders) (7.34.0)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->notebook<8,>=6.5.5->recommenders) (0.1.7)\n",
            "Requirement already satisfied: mpmath in /usr/local/lib/python3.11/dist-packages (from powerlaw->cornac<3,>=1.15.2->recommenders) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->pandera>=0.15.0->pandera[strategies]>=0.15.0; python_version >= \"3.9\"->recommenders) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->pandera>=0.15.0->pandera[strategies]>=0.15.0; python_version >= \"3.9\"->recommenders) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->pandera>=0.15.0->pandera[strategies]>=0.15.0; python_version >= \"3.9\"->recommenders) (0.4.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->notebook<8,>=6.5.5->recommenders) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook<8,>=6.5.5->recommenders) (1.4.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->notebook<8,>=6.5.5->recommenders) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->notebook<8,>=6.5.5->recommenders) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->notebook<8,>=6.5.5->recommenders) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->notebook<8,>=6.5.5->recommenders) (3.0.51)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->notebook<8,>=6.5.5->recommenders) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->notebook<8,>=6.5.5->recommenders) (4.9.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook<8,>=6.5.5->recommenders) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook<8,>=6.5.5->recommenders) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook<8,>=6.5.5->recommenders) (0.25.1)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.11/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook<8,>=6.5.5->recommenders) (1.16.0)\n",
            "Requirement already satisfied: simple-websocket>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from python-engineio>=4.12.2->locust-cloud>=1.23.1->locust<3,>=2.12.2->recommenders) (1.1.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook<8,>=6.5.5->recommenders) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=5->notebook<8,>=6.5.5->recommenders) (2.7)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook<8,>=6.5.5->recommenders) (2.22)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->notebook<8,>=6.5.5->recommenders) (0.8.4)\n",
            "Requirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook<8,>=6.5.5->recommenders) (4.9.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel->notebook<8,>=6.5.5->recommenders) (0.2.13)\n",
            "Requirement already satisfied: wsproto in /usr/local/lib/python3.11/dist-packages (from simple-websocket>=0.10.0->python-engineio>=4.12.2->locust-cloud>=1.23.1->locust<3,>=2.12.2->recommenders) (1.2.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook<8,>=6.5.5->recommenders) (1.3.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from wsproto->simple-websocket>=0.10.0->python-engineio>=4.12.2->locust-cloud>=1.23.1->locust<3,>=2.12.2->recommenders) (0.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from recommenders.models.deeprec.deeprec_utils import prepare_hparams"
      ],
      "metadata": {
        "id": "vLoVx41LE8mf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Understanding"
      ],
      "metadata": {
        "id": "79tZQQsGyhuL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sys\n",
        "import os\n",
        "import tensorflow as tf\n",
        "tf.get_logger().setLevel('ERROR')"
      ],
      "metadata": {
        "id": "WPH4gLUGyz4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEFAULT_USER_COL = \"userId\"\n",
        "DEFAULT_ITEM_COL = \"movieId\"\n",
        "DEFAULT_RATING_COL = \"rating\"\n",
        "DEFAULT_TIMESTAMP_COL = \"timestamp\"\n",
        "DEFAULT_PREDICTION_COL = \"prediction\"\n",
        "DEFAULT_GENRE_COL = \"genreId\"\n",
        "\n",
        "DEFAULT_HEADER = (\n",
        "    DEFAULT_USER_COL,\n",
        "    DEFAULT_ITEM_COL,\n",
        "    DEFAULT_RATING_COL,\n",
        "    DEFAULT_GENRE_COL,\n",
        "    DEFAULT_TIMESTAMP_COL,\n",
        ")\n",
        "\n",
        "COL_DICT = {\n",
        "    \"col_user\": DEFAULT_USER_COL,\n",
        "    \"col_item\": DEFAULT_ITEM_COL,\n",
        "    \"col_rating\": DEFAULT_RATING_COL,\n",
        "    \"col_genre\": DEFAULT_GENRE_COL,\n",
        "    \"col_prediction\": DEFAULT_PREDICTION_COL,\n",
        "}\n",
        "\n",
        "DEFAULT_K = 50\n",
        "DEFAULT_THRESHOLD = 10\n",
        "\n",
        "# Other\n",
        "SEED = 42\n"
      ],
      "metadata": {
        "id": "yAzrhl6vC1Xh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Import Data"
      ],
      "metadata": {
        "id": "Y_w9NC_Iyt2t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ratings = pd.read_csv('/content/ratings.csv')\n",
        "movies = pd.read_csv('/content/movies.csv')"
      ],
      "metadata": {
        "id": "rl9YDvdHM35K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings.head()"
      ],
      "metadata": {
        "id": "Z72t8Vey9oBr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "a323d089-fe5c-4760-d223-803512d0d97e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   userId  movieId  rating  timestamp\n",
              "0       1        1     4.0  964982703\n",
              "1       1        3     4.0  964981247\n",
              "2       1        6     4.0  964982224\n",
              "3       1       47     5.0  964983815\n",
              "4       1       50     5.0  964982931"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-67f8660f-bbb7-40f1-bf48-d6f4e1063340\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964982703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964981247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964982224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>47</td>\n",
              "      <td>5.0</td>\n",
              "      <td>964983815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>5.0</td>\n",
              "      <td>964982931</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-67f8660f-bbb7-40f1-bf48-d6f4e1063340')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-67f8660f-bbb7-40f1-bf48-d6f4e1063340 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-67f8660f-bbb7-40f1-bf48-d6f4e1063340');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-5fc86653-969d-4ac0-8fbb-f3cfd3766bc7\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5fc86653-969d-4ac0-8fbb-f3cfd3766bc7')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-5fc86653-969d-4ac0-8fbb-f3cfd3766bc7 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "ratings"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "movies.head()"
      ],
      "metadata": {
        "id": "CjoVhJDw9jwb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "19cbd0e0-e805-4f50-a82c-a44cdd9e4a3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   movieId                               title  \\\n",
              "0        1                    Toy Story (1995)   \n",
              "1        2                      Jumanji (1995)   \n",
              "2        3             Grumpier Old Men (1995)   \n",
              "3        4            Waiting to Exhale (1995)   \n",
              "4        5  Father of the Bride Part II (1995)   \n",
              "\n",
              "                                        genres  \n",
              "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
              "1                   Adventure|Children|Fantasy  \n",
              "2                               Comedy|Romance  \n",
              "3                         Comedy|Drama|Romance  \n",
              "4                                       Comedy  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-28f2f9e2-df83-44a0-98b6-c385b295348f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movieId</th>\n",
              "      <th>title</th>\n",
              "      <th>genres</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Toy Story (1995)</td>\n",
              "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Jumanji (1995)</td>\n",
              "      <td>Adventure|Children|Fantasy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Grumpier Old Men (1995)</td>\n",
              "      <td>Comedy|Romance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Waiting to Exhale (1995)</td>\n",
              "      <td>Comedy|Drama|Romance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Father of the Bride Part II (1995)</td>\n",
              "      <td>Comedy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-28f2f9e2-df83-44a0-98b6-c385b295348f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-28f2f9e2-df83-44a0-98b6-c385b295348f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-28f2f9e2-df83-44a0-98b6-c385b295348f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-0fd9cf99-4f7f-4f06-a468-f9e896644aa4\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0fd9cf99-4f7f-4f06-a468-f9e896644aa4')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-0fd9cf99-4f7f-4f06-a468-f9e896644aa4 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "movies",
              "summary": "{\n  \"name\": \"movies\",\n  \"rows\": 9742,\n  \"fields\": [\n    {\n      \"column\": \"movieId\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 52160,\n        \"min\": 1,\n        \"max\": 193609,\n        \"num_unique_values\": 9742,\n        \"samples\": [\n          45635,\n          1373,\n          7325\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9737,\n        \"samples\": [\n          \"Teenage Mutant Ninja Turtles (2014)\",\n          \"America's Sweethearts (2001)\",\n          \"Cast Away (2000)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"genres\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 951,\n        \"samples\": [\n          \"Crime|Mystery|Romance|Thriller\",\n          \"Action|Adventure|Comedy|Western\",\n          \"Crime|Drama|Musical\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "movie_ratings = ratings.merge(movies, on='movieId', how='inner')\n",
        "movie_ratings.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "7yMJCgpTnNgC",
        "outputId": "bee004ec-8804-428f-892a-48f3602e373d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   userId  movieId  rating  timestamp                        title  \\\n",
              "0       1        1     4.0  964982703             Toy Story (1995)   \n",
              "1       1        3     4.0  964981247      Grumpier Old Men (1995)   \n",
              "2       1        6     4.0  964982224                  Heat (1995)   \n",
              "3       1       47     5.0  964983815  Seven (a.k.a. Se7en) (1995)   \n",
              "4       1       50     5.0  964982931   Usual Suspects, The (1995)   \n",
              "\n",
              "                                        genres  \n",
              "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
              "1                               Comedy|Romance  \n",
              "2                        Action|Crime|Thriller  \n",
              "3                             Mystery|Thriller  \n",
              "4                       Crime|Mystery|Thriller  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5f92286e-0103-4902-8648-0f9a8e18aa5f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>title</th>\n",
              "      <th>genres</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964982703</td>\n",
              "      <td>Toy Story (1995)</td>\n",
              "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964981247</td>\n",
              "      <td>Grumpier Old Men (1995)</td>\n",
              "      <td>Comedy|Romance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964982224</td>\n",
              "      <td>Heat (1995)</td>\n",
              "      <td>Action|Crime|Thriller</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>47</td>\n",
              "      <td>5.0</td>\n",
              "      <td>964983815</td>\n",
              "      <td>Seven (a.k.a. Se7en) (1995)</td>\n",
              "      <td>Mystery|Thriller</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>5.0</td>\n",
              "      <td>964982931</td>\n",
              "      <td>Usual Suspects, The (1995)</td>\n",
              "      <td>Crime|Mystery|Thriller</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5f92286e-0103-4902-8648-0f9a8e18aa5f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5f92286e-0103-4902-8648-0f9a8e18aa5f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5f92286e-0103-4902-8648-0f9a8e18aa5f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-aca96606-fa14-4ad4-898c-8b7f817b993c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-aca96606-fa14-4ad4-898c-8b7f817b993c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-aca96606-fa14-4ad4-898c-8b7f817b993c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "movie_ratings"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "movie_ratings = movie_ratings.drop(columns=['title'])"
      ],
      "metadata": {
        "id": "lSb3yt2Z2utL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movie_genres = movie_ratings.copy()\n",
        "movie_genres['genres'] = movie_genres['genres'].str.split('|')\n",
        "movie_genres_exploded = movie_genres.explode('genres')\n",
        "\n",
        "print(\"DataFrame setelah explode genres:\")\n",
        "display(movie_genres_exploded.head())\n",
        "\n",
        "unique_genres = movie_genres_exploded['genres'].unique()\n",
        "\n",
        "# Menampilkan daftar genre unik\n",
        "print(\"\\nDaftar genre unik:\")\n",
        "print(unique_genres)\n",
        "\n",
        "genre_to_id = {genre: id for id, genre in enumerate(unique_genres)}\n",
        "\n",
        "print(\"\\nPemetaan Genre ke ID:\")\n",
        "print(genre_to_id)\n",
        "\n",
        "# Membuat DataFrame dari pemetaan untuk penggabungan\n",
        "genre_id_map_df = pd.DataFrame(list(genre_to_id.items()), columns=['genres', 'genreId'])\n",
        "\n",
        "\n",
        "movie_ratings_with_genre_id = pd.merge(\n",
        "    movie_genres_exploded,\n",
        "    genre_id_map_df,\n",
        "    on='genres',\n",
        "    how='left' #\n",
        ")\n",
        "\n",
        "# Menampilkan beberapa baris pertama dari DataFrame akhir\n",
        "print(\"\\nDataFrame akhir dengan genreId:\")\n",
        "display(movie_ratings_with_genre_id.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "id": "UQJudmpn2GpK",
        "outputId": "4f4c2a7d-3b3a-45ff-89f3-85bce82e607b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame setelah explode genres:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   userId  movieId  rating  timestamp     genres\n",
              "0       1        1     4.0  964982703  Adventure\n",
              "0       1        1     4.0  964982703  Animation\n",
              "0       1        1     4.0  964982703   Children\n",
              "0       1        1     4.0  964982703     Comedy\n",
              "0       1        1     4.0  964982703    Fantasy"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1445e018-5fcf-4aba-9e19-5198423ac1d0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>genres</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964982703</td>\n",
              "      <td>Adventure</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964982703</td>\n",
              "      <td>Animation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964982703</td>\n",
              "      <td>Children</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964982703</td>\n",
              "      <td>Comedy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964982703</td>\n",
              "      <td>Fantasy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1445e018-5fcf-4aba-9e19-5198423ac1d0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1445e018-5fcf-4aba-9e19-5198423ac1d0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1445e018-5fcf-4aba-9e19-5198423ac1d0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-46e89760-98ea-4250-9156-a8fcfe9c900f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-46e89760-98ea-4250-9156-a8fcfe9c900f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-46e89760-98ea-4250-9156-a8fcfe9c900f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(movie_ratings_with_genre_id\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"userId\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"movieId\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 4.0,\n        \"max\": 4.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          4.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"timestamp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 964982703,\n        \"max\": 964982703,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          964982703\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"genres\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Animation\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Daftar genre unik:\n",
            "['Adventure' 'Animation' 'Children' 'Comedy' 'Fantasy' 'Romance' 'Action'\n",
            " 'Crime' 'Thriller' 'Mystery' 'Horror' 'Drama' 'War' 'Western' 'Sci-Fi'\n",
            " 'Musical' 'Film-Noir' 'IMAX' 'Documentary' '(no genres listed)']\n",
            "\n",
            "Pemetaan Genre ke ID:\n",
            "{'Adventure': 0, 'Animation': 1, 'Children': 2, 'Comedy': 3, 'Fantasy': 4, 'Romance': 5, 'Action': 6, 'Crime': 7, 'Thriller': 8, 'Mystery': 9, 'Horror': 10, 'Drama': 11, 'War': 12, 'Western': 13, 'Sci-Fi': 14, 'Musical': 15, 'Film-Noir': 16, 'IMAX': 17, 'Documentary': 18, '(no genres listed)': 19}\n",
            "\n",
            "DataFrame akhir dengan genreId:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   userId  movieId  rating  timestamp     genres  genreId\n",
              "0       1        1     4.0  964982703  Adventure        0\n",
              "1       1        1     4.0  964982703  Animation        1\n",
              "2       1        1     4.0  964982703   Children        2\n",
              "3       1        1     4.0  964982703     Comedy        3\n",
              "4       1        1     4.0  964982703    Fantasy        4"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8d752e59-df35-47a8-a5b4-ccd7589e166f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>genres</th>\n",
              "      <th>genreId</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964982703</td>\n",
              "      <td>Adventure</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964982703</td>\n",
              "      <td>Animation</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964982703</td>\n",
              "      <td>Children</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964982703</td>\n",
              "      <td>Comedy</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964982703</td>\n",
              "      <td>Fantasy</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8d752e59-df35-47a8-a5b4-ccd7589e166f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8d752e59-df35-47a8-a5b4-ccd7589e166f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8d752e59-df35-47a8-a5b4-ccd7589e166f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-6f3a720c-235d-4ba2-bcd4-241cc4937f7d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6f3a720c-235d-4ba2-bcd4-241cc4937f7d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-6f3a720c-235d-4ba2-bcd4-241cc4937f7d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(movie_ratings_with_genre_id\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"userId\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"movieId\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 4.0,\n        \"max\": 4.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          4.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"timestamp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 964982703,\n        \"max\": 964982703,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          964982703\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"genres\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Animation\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"genreId\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "movie_ratings = movie_ratings_with_genre_id\n",
        "movie_ratings = movie_ratings.drop(columns=['genres'])\n",
        "movie_ratings.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "17aLvDOn2wmt",
        "outputId": "fb67fc86-ae88-49a4-f7a6-834bffbad3c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   userId  movieId  rating  timestamp  genreId\n",
              "0       1        1     4.0  964982703        0\n",
              "1       1        1     4.0  964982703        1\n",
              "2       1        1     4.0  964982703        2\n",
              "3       1        1     4.0  964982703        3\n",
              "4       1        1     4.0  964982703        4"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3cca91f5-ecbf-4992-aa0f-7890aaf37f49\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>genreId</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964982703</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964982703</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964982703</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964982703</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964982703</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3cca91f5-ecbf-4992-aa0f-7890aaf37f49')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3cca91f5-ecbf-4992-aa0f-7890aaf37f49 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3cca91f5-ecbf-4992-aa0f-7890aaf37f49');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-6ea04604-8000-4feb-921c-5366b90f7206\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6ea04604-8000-4feb-921c-5366b90f7206')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-6ea04604-8000-4feb-921c-5366b90f7206 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "movie_ratings"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "COL_USER = \"userId\"\n",
        "COL_ITEM = \"movieId\"\n",
        "COL_RATING = \"rating\"\n",
        "COL_PREDICTION = \"prediction\"\n",
        "COL_GENRE = \"genreId\"\n",
        "COL_TIMESTAMP = \"timestamp\""
      ],
      "metadata": {
        "id": "XmZZD2a6r1Df"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = movie_ratings.rename(\n",
        "    columns={\n",
        "        \"userId\": COL_USER,\n",
        "        \"movieId\": COL_ITEM,\n",
        "        \"rating\": COL_RATING,\n",
        "        \"timestamp\": COL_TIMESTAMP,\n",
        "        \"genreId\": COL_GENRE,\n",
        "        \"prediction\": COL_PREDICTION,\n",
        "    }\n",
        ")\n",
        "\n",
        "data.head()"
      ],
      "metadata": {
        "id": "eqRs_tyfiHL8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "f09bec76-e4e3-45f3-d5ee-9164f3defa31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   userId  movieId  rating  timestamp  genreId\n",
              "0       1        1     4.0  964982703        0\n",
              "1       1        1     4.0  964982703        1\n",
              "2       1        1     4.0  964982703        2\n",
              "3       1        1     4.0  964982703        3\n",
              "4       1        1     4.0  964982703        4"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-94ed2206-f62c-400d-ad4f-0df2bb7e0d8d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>genreId</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964982703</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964982703</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964982703</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964982703</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>964982703</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-94ed2206-f62c-400d-ad4f-0df2bb7e0d8d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-94ed2206-f62c-400d-ad4f-0df2bb7e0d8d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-94ed2206-f62c-400d-ad4f-0df2bb7e0d8d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-3007b011-7ada-40f0-b3be-1ea7d7fa1be8\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3007b011-7ada-40f0-b3be-1ea7d7fa1be8')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-3007b011-7ada-40f0-b3be-1ea7d7fa1be8 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.describe()"
      ],
      "metadata": {
        "id": "YUzSnZeGgmgN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "1244ac86-ea59-490f-e070-945dc1e5788a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              userId        movieId         rating     timestamp  \\\n",
              "count  274480.000000  274480.000000  274480.000000  2.744800e+05   \n",
              "mean      324.707607   20302.543398       3.517797  1.213584e+09   \n",
              "std       182.550241   35369.990843       1.034705  2.167614e+08   \n",
              "min         1.000000       1.000000       0.500000  8.281246e+08   \n",
              "25%       177.000000    1198.000000       3.000000  1.030475e+09   \n",
              "50%       323.000000    3037.000000       3.500000  1.196131e+09   \n",
              "75%       477.000000    8961.000000       4.000000  1.442154e+09   \n",
              "max       610.000000  193609.000000       5.000000  1.537799e+09   \n",
              "\n",
              "             genreId  \n",
              "count  274480.000000  \n",
              "mean        6.885697  \n",
              "std         4.365163  \n",
              "min         0.000000  \n",
              "25%         3.000000  \n",
              "50%         6.000000  \n",
              "75%        11.000000  \n",
              "max        19.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b277297e-6b90-485a-90c0-c0ecfb6866ee\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>genreId</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>274480.000000</td>\n",
              "      <td>274480.000000</td>\n",
              "      <td>274480.000000</td>\n",
              "      <td>2.744800e+05</td>\n",
              "      <td>274480.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>324.707607</td>\n",
              "      <td>20302.543398</td>\n",
              "      <td>3.517797</td>\n",
              "      <td>1.213584e+09</td>\n",
              "      <td>6.885697</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>182.550241</td>\n",
              "      <td>35369.990843</td>\n",
              "      <td>1.034705</td>\n",
              "      <td>2.167614e+08</td>\n",
              "      <td>4.365163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>8.281246e+08</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>177.000000</td>\n",
              "      <td>1198.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.030475e+09</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>323.000000</td>\n",
              "      <td>3037.000000</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>1.196131e+09</td>\n",
              "      <td>6.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>477.000000</td>\n",
              "      <td>8961.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.442154e+09</td>\n",
              "      <td>11.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>610.000000</td>\n",
              "      <td>193609.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.537799e+09</td>\n",
              "      <td>19.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b277297e-6b90-485a-90c0-c0ecfb6866ee')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b277297e-6b90-485a-90c0-c0ecfb6866ee button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b277297e-6b90-485a-90c0-c0ecfb6866ee');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-2a459781-3c4f-4b00-ae29-a11074472f6b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2a459781-3c4f-4b00-ae29-a11074472f6b')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-2a459781-3c4f-4b00-ae29-a11074472f6b button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"userId\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 96937.69006864067,\n        \"min\": 1.0,\n        \"max\": 274480.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          324.7076071116293,\n          323.0,\n          274480.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"movieId\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 105922.71067681276,\n        \"min\": 1.0,\n        \"max\": 274480.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          20302.543398426114,\n          3037.0,\n          274480.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 97042.29660341208,\n        \"min\": 0.5,\n        \"max\": 274480.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          3.517797289419994,\n          3.5,\n          274480.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"timestamp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 557604611.4483496,\n        \"min\": 274480.0,\n        \"max\": 1537799250.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          1213584453.9389317,\n          1196131286.5,\n          274480.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"genreId\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 97040.7967696407,\n        \"min\": 0.0,\n        \"max\": 274480.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          6.885696589915477,\n          6.0,\n          274480.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(x=\"rating\", data=data, palette=\"viridis\")\n",
        "plt.title(\"Distribution of movie ratings\", fontsize=14)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pC33vRpih-l-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 584
        },
        "outputId": "a35bab6b-7003-4dc5-8bf4-5518c93fa5ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-37-3377034991>:1: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.countplot(x=\"rating\", data=data, palette=\"viridis\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Mean global rating: {round(ratings['rating'].mean(),2)}.\")\n",
        "\n",
        "mean_ratings = ratings.groupby('userId')['rating'].mean()\n",
        "print(f\"Mean rating per user: {round(mean_ratings.mean(),2)}.\")"
      ],
      "metadata": {
        "id": "uCoVyBWpiOQe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c09740d-9381-4548-a4ef-83ce25f4d53f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean global rating: 3.5.\n",
            "Mean rating per user: 3.66.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Menghitung total interaksi antar user dan item\n",
        "total_interactions = data.shape[0]\n",
        "\n",
        "# Menghitung total jumlah pengguna dan item\n",
        "num_users = data[COL_USER].nunique()\n",
        "num_items = data[COL_ITEM].nunique()\n",
        "num_genres = data[COL_GENRE].nunique()\n",
        "\n",
        "# Menghitung densitas interaksi\n",
        "interaction_density = (total_interactions / (num_users * num_items)) * 100\n",
        "interaction_density_genre = (total_interactions / (num_items * num_genres)) * 100\n",
        "\n",
        "print(\n",
        "    f\"Total Interactions: {total_interactions}\",\n",
        "    f\"Number of Users: {num_users}\",\n",
        "    f\"Number of Items: {num_items}\",\n",
        "    f\"Number of Genres: {num_genres}\",\n",
        "    sep=\"\\n\"\n",
        ")"
      ],
      "metadata": {
        "id": "8Q-htasejSWB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36ca869a-8101-4b3d-96de-9efd553df4a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Interactions: 274480\n",
            "Number of Users: 610\n",
            "Number of Items: 9724\n",
            "Number of Genres: 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Preparation"
      ],
      "metadata": {
        "id": "_scBRfZ0fnX9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Transformation"
      ],
      "metadata": {
        "id": "9kgxgqrSs0Hx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime, timedelta\n",
        "\n",
        "data[COL_TIMESTAMP]= data.apply(\n",
        "    lambda x: datetime.strftime(datetime(1970, 1, 1, 0, 0, 0) + timedelta(seconds=x[COL_TIMESTAMP].item()), \"%Y-%m-%d %H:%M:%S\"),\n",
        "    axis=1\n",
        ")\n",
        "data.head()"
      ],
      "metadata": {
        "id": "s2bMgUeesTXp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3d38df7-436b-4d81-defd-3c4daa408e3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   userId  movieId  rating            timestamp  genreId\n",
              "0       1        1     4.0  2000-07-30 18:45:03        0\n",
              "1       1        1     4.0  2000-07-30 18:45:03        1\n",
              "2       1        1     4.0  2000-07-30 18:45:03        2\n",
              "3       1        1     4.0  2000-07-30 18:45:03        3\n",
              "4       1        1     4.0  2000-07-30 18:45:03        4"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-62de8844-7e7e-436d-b5ab-461b119d5c7c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>genreId</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2000-07-30 18:45:03</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2000-07-30 18:45:03</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2000-07-30 18:45:03</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2000-07-30 18:45:03</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2000-07-30 18:45:03</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-62de8844-7e7e-436d-b5ab-461b119d5c7c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-62de8844-7e7e-436d-b5ab-461b119d5c7c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-62de8844-7e7e-436d-b5ab-461b119d5c7c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a4f87782-dd68-4326-b53c-1ae2b3d5f005\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a4f87782-dd68-4326-b53c-1ae2b3d5f005')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a4f87782-dd68-4326-b53c-1ae2b3d5f005 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train Test Split Data"
      ],
      "metadata": {
        "id": "KFaWYCQmkw5u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# top k items to recommend\n",
        "TOP_K = 50\n",
        "\n",
        "# Model parameters\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE = 1024\n",
        "\n",
        "SEED = 42\n",
        "\n",
        "yaml3_file = \"/content/lightgcn3.yaml\"\n",
        "yaml4_file = \"/content/lightgcn4.yaml\"\n",
        "yaml5_file = \"/content/lightgcn5.yaml\"\n",
        "user_file = \"/content/user_embeddings.csv\"\n",
        "item_file = \"/content/item_embeddings.csv\"\n"
      ],
      "metadata": {
        "id": "kXw1CTTNdJML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def process_split_ratio(ratio):\n",
        "    \"\"\".Menghasilkan daftar rasio pembagian.\n",
        "\n",
        "    Argumen:\n",
        "        ratio (float atau list): Sebuah angka desimal (float) yang menunjukkan rasio pembagian atau sebuah daftar angka desimal (list) yang menunjukkan rasio pembagian\n",
        "                                 (jika pembagian dilakukan dalam beberapa bagian atau multi-split).\n",
        "\n",
        "    Mengembalikan:\n",
        "        tuple:\n",
        "        - bool: Sebuah variabel boolean `multi` yang menunjukkan apakah pembagian dilakukan\n",
        "          dalam beberapa bagian (multi-split) atau satu bagian (single-split).\n",
        "        - list: Daftar rasio pembagian yang telah dinormalisasi.\n",
        "    \"\"\"\n",
        "    #ketika data pembagian hanya data latih dan uji (float)\n",
        "    if isinstance(ratio, float):\n",
        "        if ratio <= 0 or ratio >= 1:\n",
        "            raise ValueError(\"Split ratio has to be between 0 and 1\")\n",
        "\n",
        "        multi = False\n",
        "    #ketika data bentuk list\n",
        "    elif isinstance(ratio, list):\n",
        "        if any([x <= 0 for x in ratio]):\n",
        "            raise ValueError(\n",
        "                \"All split ratios in the ratio list should be larger than 0.\"\n",
        "            )\n",
        "\n",
        "        # normalize split ratios if they are not summed to 1\n",
        "        if math.fsum(ratio) != 1.0:\n",
        "            ratio = [x / math.fsum(ratio) for x in ratio]\n",
        "\n",
        "        multi = True\n",
        "    else:\n",
        "        raise TypeError(\"Split ratio should be either float or a list of floats.\")\n",
        "\n",
        "    return multi, ratio\n",
        "\n",
        "def _get_column_name(name, col_user, col_item):\n",
        "    if name == \"user\":\n",
        "        return col_user\n",
        "    elif name == \"item\":\n",
        "        return col_item\n",
        "    else:\n",
        "        raise ValueError(\"name should be either 'user' or 'item'.\")\n",
        "\n",
        "def min_rating_filter_pandas(\n",
        "    data,\n",
        "    min_rating=1,\n",
        "    filter_by=\"user\",\n",
        "    col_user=DEFAULT_USER_COL,\n",
        "    col_item=DEFAULT_ITEM_COL,\n",
        "):\n",
        "    \"\"\"Memfilter DataFrame rating untuk setiap pengguna dengan jumlah rating minimum.\n",
        "\n",
        "      Memfilter data frame rating dengan jumlah rating minimum untuk pengguna/item biasanya berguna untuk menghasilkan data frame baru dengan pengguna/item hangat. Kehangatan didefinisikan oleh\n",
        "      argumen min_rating. Sebagai contoh, seorang pengguna disebut hangat jika dia telah memberikan rating pada setidaknya 4 item.\n",
        "\n",
        "      Argumen:\n",
        "          data (pandas.DataFrame): DataFrame dari pasangan user-item. Kolom untuk pengguna dan item harus ada dalam DataFrame, sedangkan kolom lain seperti rating bersifat opsional.\n",
        "          min_rating (int): Jumlah minimum rating untuk pengguna atau item.\n",
        "          filter_by (str): Pilihan \"user\" atau \"item\", tergantung pada mana yang akan difilter berdasarkan min_rating.\n",
        "          col_user (str): Nama kolom untuk ID pengguna.\n",
        "          col_item (str): Nama kolom untuk ID item.\n",
        "\n",
        "      Mengembalikan:\n",
        "          pandas.DataFrame: DataFrame dengan setidaknya kolom pengguna dan item yang telah difilter berdasarkan spesifikasi yang diberikan.\n",
        "    \"\"\"\n",
        "    split_by_column = _get_column_name(filter_by, col_user, col_item)\n",
        "\n",
        "    if min_rating < 1:\n",
        "        raise ValueError(\"min_rating should be integer and larger than or equal to 1.\")\n",
        "\n",
        "    return data.groupby(split_by_column).filter(lambda x: len(x) >= min_rating)\n",
        "\n",
        "def _do_stratification(\n",
        "    data,\n",
        "    ratio=0.75,\n",
        "    min_rating=1,\n",
        "    filter_by=\"user\",\n",
        "    is_random=True,\n",
        "    seed=42,\n",
        "    col_user=DEFAULT_USER_COL,\n",
        "    col_item=DEFAULT_ITEM_COL,\n",
        "    col_timestamp=DEFAULT_TIMESTAMP_COL,\n",
        "):\n",
        "    # A few preliminary checks.\n",
        "    if not (filter_by == \"user\" or filter_by == \"item\"):\n",
        "        raise ValueError(\"filter_by should be either 'user' or 'item'.\")\n",
        "\n",
        "    if min_rating < 1:\n",
        "        raise ValueError(\"min_rating should be integer and larger than or equal to 1.\")\n",
        "\n",
        "    if col_user not in data.columns:\n",
        "        raise ValueError(\"Schema of data not valid. Missing User Col\")\n",
        "\n",
        "    if col_item not in data.columns:\n",
        "        raise ValueError(\"Schema of data not valid. Missing Item Col\")\n",
        "\n",
        "    if not is_random:\n",
        "        if col_timestamp not in data.columns:\n",
        "            raise ValueError(\"Schema of data not valid. Missing Timestamp Col\")\n",
        "\n",
        "    multi_split, ratio = process_split_ratio(ratio)\n",
        "\n",
        "    split_by_column = col_user if filter_by == \"user\" else col_item\n",
        "\n",
        "    ratio = ratio if multi_split else [ratio, 1 - ratio]\n",
        "\n",
        "    if min_rating > 1:\n",
        "        data = min_rating_filter_pandas(\n",
        "            data,\n",
        "            min_rating=min_rating,\n",
        "            filter_by=filter_by,\n",
        "            col_user=col_user,\n",
        "            col_item=col_item,\n",
        "        )\n",
        "\n",
        "    if is_random:\n",
        "        np.random.seed(seed)\n",
        "        data[\"random\"] = np.random.rand(data.shape[0])\n",
        "        order_by = \"random\"\n",
        "    else:\n",
        "        order_by = col_timestamp\n",
        "\n",
        "    data = data.sort_values([split_by_column, order_by])\n",
        "\n",
        "    groups = data.groupby(split_by_column)\n",
        "\n",
        "    data[\"count\"] = groups[split_by_column].transform(\"count\")\n",
        "    data[\"rank\"] = groups.cumcount() + 1\n",
        "\n",
        "    if is_random:\n",
        "        data = data.drop(\"random\", axis=1)\n",
        "\n",
        "    splits = []\n",
        "    prev_threshold = None\n",
        "    for threshold in np.cumsum(ratio):\n",
        "        condition = data[\"rank\"] <= round(threshold * data[\"count\"])\n",
        "        if prev_threshold is not None:\n",
        "            condition &= data[\"rank\"] > round(prev_threshold * data[\"count\"])\n",
        "        splits.append(data[condition].drop([\"rank\", \"count\"], axis=1))\n",
        "        prev_threshold = threshold\n",
        "\n",
        "    return splits\n",
        "\n",
        "def python_stratified_split(\n",
        "    data,\n",
        "    ratio=0.75,\n",
        "    min_rating=1,\n",
        "    filter_by=\"user\",\n",
        "    col_user=DEFAULT_USER_COL,\n",
        "    col_item=DEFAULT_ITEM_COL,\n",
        "    seed=42,\n",
        "):\n",
        "    \"\"\"\"Pembagi stratifikasi Pandas.\n",
        "\n",
        "        Untuk setiap pengguna/item, fungsi split mengambil proporsi rating yang ditentukan oleh rasio pembagian (split ratio). Pembagian dilakukan secara stratifikasi.\n",
        "\n",
        "        Argumen:\n",
        "            data (pandas.DataFrame): DataFrame Pandas yang akan dibagi.\n",
        "            ratio (float atau list): Rasio untuk membagi data. Jika merupakan angka float tunggal, data dibagi menjadi dua bagian dan argumen rasio menunjukkan proporsi data pelatihan;\n",
        "                                     jika merupakan daftar angka float, pembagi membagi data menjadi beberapa bagian yang sesuai dengan rasio pembagian. Jika daftar diberikan dan\n",
        "                                     rasio tidak dijumlahkan menjadi 1, rasio akan dinormalisasi.\n",
        "            seed (int): Seed.\n",
        "            min_rating (int): Jumlah minimum rating untuk pengguna atau item.\n",
        "            filter_by (str): Pilihan \"user\" atau \"item\", tergantung pada mana yang akan difilter\n",
        "                berdasarkan min_rating.\n",
        "            col_user (str): Nama kolom untuk ID pengguna.\n",
        "            col_item (str): Nama kolom untuk ID item.\n",
        "\n",
        "        Mengembalikan:\n",
        "            list: Pembagian data input sebagai pandas.DataFrame.\n",
        "    \"\"\"\n",
        "    return _do_stratification(\n",
        "        data,\n",
        "        ratio=ratio,\n",
        "        min_rating=min_rating,\n",
        "        filter_by=filter_by,\n",
        "        col_user=col_user,\n",
        "        col_item=col_item,\n",
        "        is_random=True,\n",
        "        seed=seed,\n",
        "    )"
      ],
      "metadata": {
        "id": "WifnFT2fDNNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = python_stratified_split(data, ratio=0.75)"
      ],
      "metadata": {
        "id": "fork3dV9dKVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model LightGCN"
      ],
      "metadata": {
        "id": "0X2ogiVzhKJ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Proses Data"
      ],
      "metadata": {
        "id": "8eyelZAxnaec"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ImplicitCF"
      ],
      "metadata": {
        "id": "q6QNVwjxCjvG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Licensed under the MIT License.\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.sparse as sp\n",
        "from scipy import sparse\n",
        "import math\n",
        "\n",
        "\n",
        "class ImplicitCF(object):\n",
        "    \"\"\"Kelas pemrosesan data untuk model GCN yang menggunakan umpan balik implisit.\n",
        "\n",
        "      Menginisialisasi set pelatihan dan pengujian, membuat normalized adjacency matrix,\n",
        "      dan mengambil sampel data untuk epoch pelatihan.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        train,\n",
        "        test=None,\n",
        "        adj_dir=None,\n",
        "        col_user=DEFAULT_USER_COL,\n",
        "        col_item=DEFAULT_ITEM_COL,\n",
        "        col_rating=DEFAULT_RATING_COL,\n",
        "        col_prediction=DEFAULT_PREDICTION_COL,\n",
        "        col_genre =DEFAULT_GENRE_COL,\n",
        "        seed=None,\n",
        "    ):\n",
        "        \"\"\"Konstruktor\n",
        "\n",
        "          Argumen:\n",
        "              adj_dir (str): Direktori untuk menyimpan/memuat adjacency matrices. Jika None, adjacency matrices akan dibuat dan tidak disimpan.\n",
        "              train (pandas.DataFrame): Data pelatihan dengan setidaknya kolom (col_user, col_item, col_rating).\n",
        "              test (pandas.DataFrame): Data pengujian dengan setidaknya kolom (col_user, col_item, col_rating). Test dapat bernilai None, jika demikian, hanya data pelatihan yang akan diproses.\n",
        "              col_user (str): Nama kolom untuk ID pengguna.\n",
        "              col_item (str): Nama kolom untuk ID item.\n",
        "              col_rating (str): Nama kolom untuk rating.\n",
        "              seed (int): Seed.\n",
        "\n",
        "        \"\"\"\n",
        "        self.user_idx = None\n",
        "        self.item_idx = None\n",
        "        self.genre_idx = None\n",
        "        self.adj_dir = adj_dir\n",
        "        self.col_user = col_user\n",
        "        self.col_item = col_item\n",
        "        self.col_rating = col_rating\n",
        "        self.col_genre = col_genre\n",
        "        self.col_prediction = col_prediction\n",
        "        self.train, self.test = self._data_processing(train, test)\n",
        "        self._init_train_data()\n",
        "\n",
        "        random.seed(seed)\n",
        "\n",
        "    def _data_processing(self, train, test):\n",
        "        \"\"\"Memproses dataset untuk mengindeks ulang userID dan itemID dan hanya menyimpan data dengan rating lebih besar dari 0.\n",
        "\n",
        "            Argumen:\n",
        "                train (pandas.DataFrame): Data pelatihan dengan setidaknya kolom (col_user, col_item, col_rating).\n",
        "                test (pandas.DataFrame): Data pengujian dengan setidaknya kolom (col_user, col_item, col_rating).\n",
        "                    Test dapat bernilai None, jika demikian, hanya data pelatihan yang akan diproses.\n",
        "\n",
        "            Mengembalikan:\n",
        "                list: Dataset train dan test pandas.DataFrame, yang telah diindeks ulang dan difilter.\n",
        "\n",
        "        \"\"\"\n",
        "        df = (\n",
        "            train\n",
        "            if test is None\n",
        "            else pd.concat([train, test], axis=0, ignore_index=True)\n",
        "        )\n",
        "\n",
        "        if self.user_idx is None:\n",
        "            user_idx = df[[self.col_user]].drop_duplicates().reindex()\n",
        "            user_idx[self.col_user + \"_idx\"] = np.arange(len(user_idx))\n",
        "            self.n_users = len(user_idx)\n",
        "            self.n_users_in_train = train[self.col_user].nunique()\n",
        "            self.user_idx = user_idx\n",
        "\n",
        "            self.user2id = dict(\n",
        "                zip(user_idx[self.col_user], user_idx[self.col_user + \"_idx\"])\n",
        "            )\n",
        "            self.id2user = dict(\n",
        "                zip(user_idx[self.col_user + \"_idx\"], user_idx[self.col_user])\n",
        "            )\n",
        "\n",
        "        if self.item_idx is None:\n",
        "            item_idx = df[[self.col_item]].drop_duplicates()\n",
        "            item_idx[self.col_item + \"_idx\"] = np.arange(len(item_idx))\n",
        "            self.n_items = len(item_idx)\n",
        "            self.item_idx = item_idx\n",
        "\n",
        "            self.item2id = dict(\n",
        "                zip(item_idx[self.col_item], item_idx[self.col_item + \"_idx\"])\n",
        "            )\n",
        "            self.id2item = dict(\n",
        "                zip(item_idx[self.col_item + \"_idx\"], item_idx[self.col_item])\n",
        "            )\n",
        "\n",
        "        if self.genre_idx is None:\n",
        "            genre_idx = df[[self.col_genre]].drop_duplicates().reindex()\n",
        "            genre_idx[self.col_genre + \"_idx\"] = np.arange(len(genre_idx))\n",
        "            self.n_genres = len(genre_idx)\n",
        "            self.genre_idx = genre_idx\n",
        "\n",
        "            self.genre2id = dict(\n",
        "                zip(genre_idx[self.col_genre], genre_idx[self.col_genre + \"_idx\"])\n",
        "            )\n",
        "            self.id2genre = dict(\n",
        "                zip(genre_idx[self.col_genre + \"_idx\"], genre_idx[self.col_genre])\n",
        "            )\n",
        "\n",
        "        return self._reindex(train), self._reindex(test)\n",
        "\n",
        "\n",
        "\n",
        "        return self._reindex(train), self._reindex(test)\n",
        "\n",
        "    def _reindex(self, df):\n",
        "\n",
        "        if df is None:\n",
        "            return None\n",
        "\n",
        "        df = pd.merge(df, self.user_idx, on=self.col_user, how=\"left\")\n",
        "        df = pd.merge(df, self.item_idx, on=self.col_item, how=\"left\")\n",
        "        df = pd.merge(df, self.genre_idx, on=self.col_genre, how=\"left\")\n",
        "\n",
        "        df = df[df[self.col_rating] > 0]\n",
        "\n",
        "        df_reindex = df[\n",
        "            [self.col_user + \"_idx\", self.col_item + \"_idx\", self.col_genre + \"_idx\", self.col_rating]\n",
        "        ]\n",
        "        df_reindex.columns = [self.col_user, self.col_item, self.col_genre, self.col_rating]\n",
        "\n",
        "        return df_reindex\n",
        "\n",
        "    def _init_train_data(self):\n",
        "        \"\"\"Mencatat item yang diinteraksikan dengan setiap pengguna, genre yang terkait dengan setiap item,\n",
        "           dan membuat adjacency matrix self.R (user-item) dan self.G (item-genre).\n",
        "\n",
        "        \"\"\"\n",
        "        self.interact_status = (\n",
        "            self.train.groupby(self.col_user)[self.col_item]\n",
        "            .apply(set)\n",
        "            .reset_index()\n",
        "            .rename(columns={self.col_item: self.col_item + \"_interacted\"})\n",
        "        )\n",
        "        self.R = sp.dok_matrix((self.n_users, self.n_items), dtype=np.float32)\n",
        "        self.R[self.train[self.col_user], self.train[self.col_item]] = 1.0\n",
        "\n",
        "        item_genre_data = self.train[[self.col_item, self.col_genre]].drop_duplicates()\n",
        "        self.G = sp.dok_matrix((self.n_items, self.n_genres), dtype=np.float32)\n",
        "        self.G[item_genre_data[self.col_item], item_genre_data[self.col_genre]] = 1.0\n",
        "\n",
        "    def get_norm_adj_mat(self):\n",
        "        \"\"\"Memuat Load normalized adjacency matrix ternormalisasi jika ada, jika tidak, buat (dan simpan) matriks tersebut.\n",
        "\n",
        "            Mengembalikan:\n",
        "                scipy.sparse.csr_matrix: Matriks kedekatan ternormalisasi.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if self.adj_dir is None:\n",
        "                raise FileNotFoundError\n",
        "            norm_adj_mat = sp.load_npz(self.adj_dir + \"/norm_adj_mat_extended.npz\")\n",
        "            print(\"Already load norm adj matrix (extended).\")\n",
        "\n",
        "        except FileNotFoundError:\n",
        "            norm_adj_mat = self.create_norm_adj_mat()\n",
        "            if self.adj_dir is not None:\n",
        "                sp.save_npz(self.adj_dir + \"/norm_adj_mat_extended.npz\", norm_adj_mat)\n",
        "        return norm_adj_mat\n",
        "\n",
        "    def create_norm_adj_mat(self):\n",
        "        \"\"\"Create normalized adjacency matrix.\n",
        "\n",
        "        Returns:\n",
        "            scipy.sparse.csr_matrix: Normalized adjacency matrix.\n",
        "\n",
        "        \"\"\"\n",
        "        total_nodes = self.n_users + self.n_items + self.n_genres\n",
        "        adj_mat = sp.dok_matrix(\n",
        "            (total_nodes, total_nodes), dtype=np.float32\n",
        "        )\n",
        "        adj_mat = adj_mat.tolil()\n",
        "\n",
        "        R = self.R.tolil()\n",
        "\n",
        "        # Tambahkan matriks User-Item dan Item-User\n",
        "        R_lil = self.R.tolil()\n",
        "        adj_mat[: self.n_users, self.n_users : self.n_users + self.n_items] = R_lil\n",
        "        adj_mat[self.n_users : self.n_users + self.n_items, : self.n_users] = R_lil.T\n",
        "\n",
        "        # Tambahkan matriks Item-Genre dan Genre-Item\n",
        "        G_lil = self.G.tolil()\n",
        "        item_start_idx = self.n_users\n",
        "        genre_start_idx = self.n_users + self.n_items\n",
        "        adj_mat[item_start_idx : item_start_idx + self.n_items, genre_start_idx : genre_start_idx + self.n_genres] = G_lil\n",
        "        adj_mat[genre_start_idx : genre_start_idx + self.n_genres, item_start_idx : item_start_idx + self.n_items] = G_lil.T\n",
        "\n",
        "        # Normalisasi matriks ketetanggaan\n",
        "        rowsum = np.array(adj_mat.sum(1))\n",
        "        d_inv = np.power(rowsum + 1e-9, -0.5).flatten()\n",
        "        d_inv[np.isinf(d_inv)] = 0.0\n",
        "        d_mat_inv = sp.diags(d_inv)\n",
        "        norm_adj_mat = d_mat_inv.dot(adj_mat)\n",
        "        norm_adj_mat = norm_adj_mat.dot(d_mat_inv)\n",
        "        print(\"Already normalize adjacency matrix (extended).\")\n",
        "\n",
        "        return norm_adj_mat.tocsr()\n",
        "\n",
        "    def train_loader(self, batch_size):\n",
        "        \"\"\"Mengambil sampel data pelatihan setiap batch. Satu item positif dan satu item negatif diambil untuk setiap pengguna.\n",
        "\n",
        "          Argumen:\n",
        "              batch_size (int): Ukuran batch pengguna.\n",
        "\n",
        "          Mengembalikan:\n",
        "              numpy.ndarray, numpy.ndarray, numpy.ndarray:\n",
        "              - Pengguna yang diambil sampelnya.\n",
        "              - Item positif yang diambil sampelnya.\n",
        "              - Item negatif yang diambil sampelnya.\n",
        "        \"\"\"\n",
        "\n",
        "        def sample_neg(x):\n",
        "            if len(x) >= self.n_items:\n",
        "                raise ValueError(\"A user has voted in every item. Can't find a negative sample.\")\n",
        "            while True:\n",
        "                neg_id = random.randint(0, self.n_items - 1)\n",
        "                if neg_id not in x:\n",
        "                    return neg_id\n",
        "\n",
        "        indices = range(self.n_users_in_train)\n",
        "        if self.n_users < batch_size:\n",
        "            users = [random.choice(indices) for _ in range(batch_size)]\n",
        "        else:\n",
        "            users = random.sample(indices, batch_size)\n",
        "\n",
        "        interact = self.interact_status.iloc[users]\n",
        "        pos_items = interact[self.col_item + \"_interacted\"].apply(\n",
        "            lambda x: random.choice(list(x))\n",
        "        )\n",
        "        neg_items = interact[self.col_item + \"_interacted\"].apply(\n",
        "            lambda x: sample_neg(x)\n",
        "        )\n",
        "\n",
        "        return np.array(users), np.array(pos_items), np.array(neg_items)\n"
      ],
      "metadata": {
        "id": "Le-IjsGRy2fS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = ImplicitCF(train=train, test=test, seed=SEED)"
      ],
      "metadata": {
        "id": "bkIFB2ALmfnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##prepere hyper-parameters"
      ],
      "metadata": {
        "id": "xlVmrTcLoeTg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hparams = prepare_hparams(yaml5_file,\n",
        "                          n_layers=5,\n",
        "                          batch_size=BATCH_SIZE,\n",
        "                          epochs=EPOCHS,\n",
        "                          learning_rate=0.005,\n",
        "                          eval_epoch=5,\n",
        "                          top_k=TOP_K,\n",
        "                         )"
      ],
      "metadata": {
        "id": "RIlh9UfWodYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Create and Train Model"
      ],
      "metadata": {
        "id": "65xDoQPBdgDv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Lightgcn"
      ],
      "metadata": {
        "id": "sp_jLUIuBukx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_top_k_items(\n",
        "    dataframe, col_user=DEFAULT_USER_COL, col_rating=DEFAULT_RATING_COL, k=DEFAULT_K\n",
        "):\n",
        "    \"\"\"Get the input customer-item-rating tuple in the format of Pandas\n",
        "    DataFrame, output a Pandas DataFrame in the dense format of top k items\n",
        "    for each user.\n",
        "\n",
        "    Note:\n",
        "        If it is implicit rating, just append a column of constants to be\n",
        "        ratings.\n",
        "\n",
        "    Args:\n",
        "        dataframe (pandas.DataFrame): DataFrame of rating data (in the format\n",
        "        customerID-itemID-rating)\n",
        "        col_user (str): column name for user\n",
        "        col_rating (str): column name for rating\n",
        "        k (int or None): number of items for each user; None means that the input has already been\n",
        "        filtered out top k items and sorted by ratings and there is no need to do that again.\n",
        "\n",
        "    Returns:\n",
        "        pandas.DataFrame: DataFrame of top k items for each user, sorted by `col_user` and `rank`\n",
        "    \"\"\"\n",
        "    # Sort dataframe by col_user and (top k) col_rating\n",
        "    if k is None:\n",
        "        top_k_items = dataframe\n",
        "    else:\n",
        "        top_k_items = (\n",
        "            dataframe.sort_values([col_user, col_rating], ascending=[True, False])\n",
        "            .groupby(col_user, as_index=False)\n",
        "            .head(k)\n",
        "            .reset_index(drop=True)\n",
        "        )\n",
        "    # Add ranks\n",
        "    top_k_items[\"rank\"] = top_k_items.groupby(col_user, sort=False).cumcount() + 1\n",
        "    return top_k_items"
      ],
      "metadata": {
        "id": "AxJKXatoB7se"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_ranking_true_pred(\n",
        "    rating_true,\n",
        "    rating_pred,\n",
        "    col_user,\n",
        "    col_item,\n",
        "    col_prediction,\n",
        "    relevancy_method,\n",
        "    k=DEFAULT_K,\n",
        "    threshold=DEFAULT_THRESHOLD,\n",
        "    **_,\n",
        "):\n",
        "    \"\"\"Filter truth and prediction data frames on common users\n",
        "\n",
        "    Args:\n",
        "        rating_true (pandas.DataFrame): True DataFrame\n",
        "        rating_pred (pandas.DataFrame): Predicted DataFrame\n",
        "        col_user (str): column name for user\n",
        "        col_item (str): column name for item\n",
        "        col_prediction (str): column name for prediction\n",
        "        relevancy_method (str): method for determining relevancy ['top_k', 'by_threshold', None]. None means that the\n",
        "            top k items are directly provided, so there is no need to compute the relevancy operation.\n",
        "        k (int): number of top k items per user (optional)\n",
        "        threshold (float): threshold of top items per user (optional)\n",
        "\n",
        "    Returns:\n",
        "        pandas.DataFrame, pandas.DataFrame, int: DataFrame of recommendation hits, sorted by `col_user` and `rank`\n",
        "        DataFrame of hit counts vs actual relevant items per user number of unique user ids\n",
        "    \"\"\"\n",
        "\n",
        "    # Make sure the prediction and true data frames have the same set of users\n",
        "    common_users = set(rating_true[col_user]).intersection(set(rating_pred[col_user]))\n",
        "    rating_true_common = rating_true[rating_true[col_user].isin(common_users)]\n",
        "    rating_pred_common = rating_pred[rating_pred[col_user].isin(common_users)]\n",
        "    n_users = len(common_users)\n",
        "\n",
        "    # Return hit items in prediction data frame with ranking information. This is used for calculating NDCG and MAP.\n",
        "    # Use first to generate unique ranking values for each item. This is to align with the implementation in\n",
        "    # Spark evaluation metrics, where index of each recommended items (the indices are unique to items) is used\n",
        "    # to calculate penalized precision of the ordered items.\n",
        "    if relevancy_method == \"top_k\":\n",
        "        top_k = k\n",
        "    elif relevancy_method == \"by_threshold\":\n",
        "        top_k = threshold\n",
        "    elif relevancy_method is None:\n",
        "        top_k = None\n",
        "    else:\n",
        "        raise NotImplementedError(\"Invalid relevancy_method\")\n",
        "    df_hit = get_top_k_items(\n",
        "        dataframe=rating_pred_common,\n",
        "        col_user=col_user,\n",
        "        col_rating=col_prediction,\n",
        "        k=top_k,\n",
        "    )\n",
        "    df_hit = pd.merge(df_hit, rating_true_common, on=[col_user, col_item])[\n",
        "        [col_user, col_item, \"rank\"]\n",
        "    ]\n",
        "\n",
        "    # count the number of hits vs actual relevant items per user\n",
        "    df_hit_count = pd.merge(\n",
        "        df_hit.groupby(col_user, as_index=False)[col_user].agg(hit=\"count\"),\n",
        "        rating_true_common.groupby(col_user, as_index=False)[col_user].agg(\n",
        "            actual=\"count\",\n",
        "        ),\n",
        "        on=col_user,\n",
        "    )\n",
        "\n",
        "    return df_hit, df_hit_count, n_users"
      ],
      "metadata": {
        "id": "D550wHLACBM_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ndcg_at_k(\n",
        "    rating_true,\n",
        "    rating_pred,\n",
        "    col_user=DEFAULT_USER_COL,\n",
        "    col_item=DEFAULT_ITEM_COL,\n",
        "    col_rating=DEFAULT_RATING_COL,\n",
        "    col_prediction=DEFAULT_PREDICTION_COL,\n",
        "    relevancy_method=\"top_k\",\n",
        "    k=DEFAULT_K,\n",
        "    threshold=DEFAULT_THRESHOLD,\n",
        "    score_type=\"binary\",\n",
        "    discfun_type=\"loge\",\n",
        "    **_,\n",
        "):\n",
        "    \"\"\"Normalized Discounted Cumulative Gain (nDCG).\n",
        "\n",
        "    Info: https://en.wikipedia.org/wiki/Discounted_cumulative_gain\n",
        "\n",
        "    Args:\n",
        "        rating_true (pandas.DataFrame): True DataFrame\n",
        "        rating_pred (pandas.DataFrame): Predicted DataFrame\n",
        "        col_user (str): column name for user\n",
        "        col_item (str): column name for item\n",
        "        col_rating (str): column name for rating\n",
        "        col_prediction (str): column name for prediction\n",
        "        relevancy_method (str): method for determining relevancy ['top_k', 'by_threshold', None]. None means that the\n",
        "            top k items are directly provided, so there is no need to compute the relevancy operation.\n",
        "        k (int): number of top k items per user\n",
        "        threshold (float): threshold of top items per user (optional)\n",
        "        score_type (str): type of relevance scores ['binary', 'raw', 'exp']. With the default option 'binary', the\n",
        "            relevance score is reduced to either 1 (hit) or 0 (miss). Option 'raw' uses the raw relevance score.\n",
        "            Option 'exp' uses (2 ** RAW_RELEVANCE - 1) as the relevance score\n",
        "        discfun_type (str): type of discount function ['loge', 'log2'] used to calculate DCG.\n",
        "\n",
        "    Returns:\n",
        "        float: nDCG at k (min=0, max=1).\n",
        "    \"\"\"\n",
        "    df_hit, _, _ = merge_ranking_true_pred(\n",
        "        rating_true=rating_true,\n",
        "        rating_pred=rating_pred,\n",
        "        col_user=col_user,\n",
        "        col_item=col_item,\n",
        "        col_prediction=col_prediction,\n",
        "        relevancy_method=relevancy_method,\n",
        "        k=k,\n",
        "        threshold=threshold,\n",
        "    )\n",
        "\n",
        "    if df_hit.shape[0] == 0:\n",
        "        return 0.0\n",
        "\n",
        "    df_dcg = df_hit.merge(rating_pred, on=[col_user, col_item]).merge(\n",
        "        rating_true, on=[col_user, col_item], how=\"outer\", suffixes=(\"_left\", None)\n",
        "    )\n",
        "\n",
        "    if score_type == \"binary\":\n",
        "        df_dcg[\"rel\"] = 1\n",
        "    elif score_type == \"raw\":\n",
        "        df_dcg[\"rel\"] = df_dcg[col_rating]\n",
        "    elif score_type == \"exp\":\n",
        "        df_dcg[\"rel\"] = 2 ** df_dcg[col_rating] - 1\n",
        "    else:\n",
        "        raise ValueError(\"score_type must be one of 'binary', 'raw', 'exp'\")\n",
        "\n",
        "    if discfun_type == \"loge\":\n",
        "        discfun = np.log\n",
        "    elif discfun_type == \"log2\":\n",
        "        discfun = np.log2\n",
        "    else:\n",
        "        raise ValueError(\"discfun_type must be one of 'loge', 'log2'\")\n",
        "\n",
        "    # Calculate the actual discounted gain for each record\n",
        "    df_dcg[\"dcg\"] = df_dcg[\"rel\"] / discfun(1 + df_dcg[\"rank\"])\n",
        "\n",
        "    # Calculate the ideal discounted gain for each record\n",
        "    df_idcg = df_dcg.sort_values([col_user, col_rating], ascending=False)\n",
        "    df_idcg[\"irank\"] = df_idcg.groupby(col_user, as_index=False, sort=False)[\n",
        "        col_rating\n",
        "    ].rank(\"first\", ascending=False)\n",
        "    df_idcg[\"idcg\"] = df_idcg[\"rel\"] / discfun(1 + df_idcg[\"irank\"])\n",
        "\n",
        "    # Calculate the actual DCG for each user\n",
        "    df_user = df_dcg.groupby(col_user, as_index=False, sort=False).agg({\"dcg\": \"sum\"})\n",
        "\n",
        "    # Calculate the ideal DCG for each user\n",
        "    df_user = df_user.merge(\n",
        "        df_idcg.groupby(col_user, as_index=False, sort=False)\n",
        "        .head(k)\n",
        "        .groupby(col_user, as_index=False, sort=False)\n",
        "        .agg({\"idcg\": \"sum\"}),\n",
        "        on=col_user,\n",
        "    )\n",
        "\n",
        "    # DCG over IDCG is the normalized DCG\n",
        "    df_user[\"ndcg\"] = df_user[\"dcg\"] / df_user[\"idcg\"]\n",
        "    return df_user[\"ndcg\"].mean()"
      ],
      "metadata": {
        "id": "YB2kFe0UHYT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recall_at_k(\n",
        "    rating_true,\n",
        "    rating_pred,\n",
        "    col_user=DEFAULT_USER_COL,\n",
        "    col_item=DEFAULT_ITEM_COL,\n",
        "    col_prediction=DEFAULT_PREDICTION_COL,\n",
        "    relevancy_method=\"top_k\",\n",
        "    k=DEFAULT_K,\n",
        "    threshold=DEFAULT_THRESHOLD,\n",
        "    **_,\n",
        "):\n",
        "    \"\"\"Recall at K.\n",
        "\n",
        "    Args:\n",
        "        rating_true (pandas.DataFrame): True DataFrame\n",
        "        rating_pred (pandas.DataFrame): Predicted DataFrame\n",
        "        col_user (str): column name for user\n",
        "        col_item (str): column name for item\n",
        "        col_prediction (str): column name for prediction\n",
        "        relevancy_method (str): method for determining relevancy ['top_k', 'by_threshold', None]. None means that the\n",
        "            top k items are directly provided, so there is no need to compute the relevancy operation.\n",
        "        k (int): number of top k items per user\n",
        "        threshold (float): threshold of top items per user (optional)\n",
        "\n",
        "    Returns:\n",
        "        float: recall at k (min=0, max=1). The maximum value is 1 even when fewer than\n",
        "        k items exist for a user in rating_true.\n",
        "    \"\"\"\n",
        "    df_hit, df_hit_count, n_users = merge_ranking_true_pred(\n",
        "        rating_true=rating_true,\n",
        "        rating_pred=rating_pred,\n",
        "        col_user=col_user,\n",
        "        col_item=col_item,\n",
        "        col_prediction=col_prediction,\n",
        "        relevancy_method=relevancy_method,\n",
        "        k=k,\n",
        "        threshold=threshold,\n",
        "    )\n",
        "\n",
        "    if df_hit.shape[0] == 0:\n",
        "        return 0.0\n",
        "\n",
        "    return (df_hit_count[\"hit\"] / df_hit_count[\"actual\"]).sum() / n_users"
      ],
      "metadata": {
        "id": "MeMb3SCBHvB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_top_k_scored_items(scores, top_k, sort_top_k=False):\n",
        "    \"\"\"Extract top K items from a matrix of scores for each user-item pair, optionally sort results per user.\n",
        "\n",
        "    Args:\n",
        "        scores (numpy.ndarray): Score matrix (users x items).\n",
        "        top_k (int): Number of top items to recommend.\n",
        "        sort_top_k (bool): Flag to sort top k results.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray, numpy.ndarray:\n",
        "        - Indices into score matrix for each user's top items.\n",
        "        - Scores corresponding to top items.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # ensure we're working with a dense ndarray\n",
        "    if isinstance(scores, sparse.spmatrix):\n",
        "        scores = scores.todense()\n",
        "\n",
        "    if scores.shape[1] < top_k:\n",
        "        logger.warning(\n",
        "            \"Number of items is less than top_k, limiting top_k to number of items\"\n",
        "        )\n",
        "    k = min(top_k, scores.shape[1])\n",
        "\n",
        "    test_user_idx = np.arange(scores.shape[0])[:, None]\n",
        "\n",
        "    # get top K items and scores\n",
        "    # this determines the un-ordered top-k item indices for each user\n",
        "    top_items = np.argpartition(scores, -k, axis=1)[:, -k:]\n",
        "    top_scores = scores[test_user_idx, top_items]\n",
        "\n",
        "    if sort_top_k:\n",
        "        sort_ind = np.argsort(-top_scores)\n",
        "        top_items = top_items[test_user_idx, sort_ind]\n",
        "        top_scores = top_scores[test_user_idx, sort_ind]\n",
        "\n",
        "    return np.array(top_items), np.array(top_scores)\n"
      ],
      "metadata": {
        "id": "Dqm-GkmLIiTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Licensed under the MIT License.\n",
        "\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "tf.compat.v1.disable_eager_execution()  # need to disable eager in TF2.x\n",
        "\n",
        "\n",
        "class LightGCN(object):\n",
        "    \"\"\"LightGCN model\n",
        "\n",
        "    :Citation:\n",
        "\n",
        "        He, Xiangnan, Kuan Deng, Xiang Wang, Yan Li, Yongdong Zhang, and Meng Wang.\n",
        "        \"LightGCN: Simplifying and Powering Graph Convolution Network for Recommendation.\" arXiv\n",
        "        preprint arXiv:2002.02126, 2020.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, hparams, data, seed=None):\n",
        "        \"\"\"Initializing the model. Create parameters, placeholders, embeddings and loss function.\n",
        "\n",
        "        Args:\n",
        "            hparams (HParams): A HParams object, hold the entire set of hyperparameters.\n",
        "            data (object): A recommenders.models.deeprec.DataModel.ImplicitCF object, load and process data.\n",
        "            seed (int): Seed.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        tf.compat.v1.set_random_seed(seed)\n",
        "        np.random.seed(seed)\n",
        "\n",
        "        self.data = data\n",
        "        self.epochs = hparams.epochs\n",
        "        self.lr = hparams.learning_rate\n",
        "        self.emb_dim = hparams.embed_size\n",
        "        self.batch_size = hparams.batch_size\n",
        "        self.n_layers = hparams.n_layers\n",
        "        self.decay = hparams.decay\n",
        "        self.eval_epoch = hparams.eval_epoch\n",
        "        self.top_k = hparams.top_k\n",
        "        self.save_model = hparams.save_model\n",
        "        self.save_epoch = hparams.save_epoch\n",
        "        self.metrics = hparams.metrics\n",
        "        self.model_dir = hparams.MODEL_DIR\n",
        "\n",
        "        valid_metrics = [\"ndcg\", \"recall\"]\n",
        "        self.metrics = [metric for metric in hparams.metrics if metric in valid_metrics]\n",
        "        if not self.metrics:\n",
        "            raise ValueError(\"Please select at least one valid metric: {}\".format(valid_metrics))\n",
        "\n",
        "\n",
        "        self.norm_adj = data.get_norm_adj_mat()\n",
        "\n",
        "        self.n_users = data.n_users\n",
        "        self.n_items = data.n_items\n",
        "        self.n_genres = data.n_genres # Menambahkan jumlah genre\n",
        "\n",
        "        # Placeholder untuk pengguna, item positif, item negatif, dan genre terkait item positif\n",
        "        self.users = tf.compat.v1.placeholder(tf.int32, shape=(None,))\n",
        "        self.pos_items = tf.compat.v1.placeholder(tf.int32, shape=(None,))\n",
        "        self.neg_items = tf.compat.v1.placeholder(tf.int32, shape=(None,))\n",
        "        # Tidak perlu placeholder untuk genre dalam batch sampling standar BPR,\n",
        "        # karena sampling item positif dan negatif sudah dilakukan.\n",
        "        # Namun, kita akan menggunakan embedding genre dalam perhitungan embedding akhir.\n",
        "\n",
        "        self.weights = self._init_weights()\n",
        "        # Embedding gabungan untuk pengguna, item, dan genre\n",
        "        self.ua_embeddings, self.ia_embeddings, self.ga_embeddings = self._create_lightgcn_embed()\n",
        "\n",
        "        self.u_g_embeddings = tf.nn.embedding_lookup(\n",
        "            params=self.ua_embeddings, ids=self.users\n",
        "        )\n",
        "        self.pos_i_g_embeddings = tf.nn.embedding_lookup(\n",
        "            params=self.ia_embeddings, ids=self.pos_items\n",
        "        )\n",
        "        self.neg_i_g_embeddings = tf.nn.embedding_lookup(\n",
        "            params=self.ia_embeddings, ids=self.neg_items\n",
        "        )\n",
        "        self.u_g_embeddings_pre = tf.nn.embedding_lookup(\n",
        "            params=self.weights[\"user_embedding\"], ids=self.users\n",
        "        )\n",
        "        self.pos_i_g_embeddings_pre = tf.nn.embedding_lookup(\n",
        "            params=self.weights[\"item_embedding\"], ids=self.pos_items\n",
        "        )\n",
        "        self.neg_i_g_embeddings_pre = tf.nn.embedding_lookup(\n",
        "            params=self.weights[\"item_embedding\"], ids=self.neg_items\n",
        "        )\n",
        "        # Embedding awal genre (sebelum GCN) untuk regularization loss\n",
        "        self.g_embeddings_pre = self.weights[\"genre_embedding\"]\n",
        "\n",
        "        self.batch_ratings = tf.matmul(\n",
        "            self.u_g_embeddings,\n",
        "            self.pos_i_g_embeddings,\n",
        "            transpose_a=False,\n",
        "            transpose_b=True,\n",
        "        )\n",
        "\n",
        "        # Menghitung BPR loss yang mencakup user, item positif, dan item negatif\n",
        "        self.mf_loss, self.emb_loss = self._create_bpr_loss(\n",
        "            self.u_g_embeddings, self.pos_i_g_embeddings, self.neg_i_g_embeddings\n",
        "        )\n",
        "        # Loss total: MF loss + embedding regularization loss (termasuk genre)\n",
        "        self.loss = self.mf_loss + self.emb_loss\n",
        "\n",
        "        self.opt = tf.compat.v1.train.AdamOptimizer(learning_rate=self.lr).minimize(\n",
        "            self.loss\n",
        "        )\n",
        "        self.saver = tf.compat.v1.train.Saver(max_to_keep=1)\n",
        "\n",
        "        gpu_options = tf.compat.v1.GPUOptions(allow_growth=True)\n",
        "        self.sess = tf.compat.v1.Session(\n",
        "            config=tf.compat.v1.ConfigProto(gpu_options=gpu_options)\n",
        "        )\n",
        "        self.sess.run(tf.compat.v1.global_variables_initializer())\n",
        "\n",
        "    def _init_weights(self):\n",
        "        \"\"\"Initialize user and item embeddings.\n",
        "\n",
        "        Returns:\n",
        "            dict: With keys `user_embedding` and `item_embedding`, embeddings of all users and items.\n",
        "\n",
        "        \"\"\"\n",
        "        all_weights = dict()\n",
        "        initializer = tf.compat.v1.keras.initializers.VarianceScaling(\n",
        "            scale=1.0, mode=\"fan_avg\", distribution=\"uniform\"\n",
        "        )\n",
        "\n",
        "        all_weights[\"user_embedding\"] = tf.Variable(\n",
        "            initializer([self.n_users, self.emb_dim]), name=\"user_embedding\"\n",
        "        )\n",
        "        all_weights[\"item_embedding\"] = tf.Variable(\n",
        "            initializer([self.n_items, self.emb_dim]), name=\"item_embedding\"\n",
        "        )\n",
        "        # Menambahkan inisialisasi embedding genre\n",
        "        all_weights[\"genre_embedding\"] = tf.Variable(\n",
        "            initializer([self.n_genres, self.emb_dim]), name=\"genre_embedding\"\n",
        "        )\n",
        "        print(\"Using xavier initialization for user, item, and genre embeddings.\")\n",
        "\n",
        "        return all_weights\n",
        "\n",
        "    def _create_lightgcn_embed(self):\n",
        "        \"\"\"Calculate the average embeddings of users and items after every layer of the model.\n",
        "\n",
        "        Returns:\n",
        "            tf.Tensor, tf.Tensor: Average user embeddings. Average item embeddings.\n",
        "\n",
        "        \"\"\"\n",
        "        # Matriks adjacency yang diperluas (user-item, item-user, item-genre, genre-item)\n",
        "        A_hat = self._convert_sp_mat_to_sp_tensor(self.norm_adj)\n",
        "\n",
        "        # Menggabungkan embedding awal pengguna, item, dan genre\n",
        "        ego_embeddings = tf.concat(\n",
        "            [self.weights[\"user_embedding\"], self.weights[\"item_embedding\"], self.weights[\"genre_embedding\"]], axis=0\n",
        "        )\n",
        "        all_embeddings = [ego_embeddings]\n",
        "\n",
        "        # Propagasi pesan melalui lapisan GCN\n",
        "        for k in range(0, self.n_layers):\n",
        "            ego_embeddings = tf.sparse.sparse_dense_matmul(A_hat, ego_embeddings)\n",
        "            all_embeddings += [ego_embeddings]\n",
        "\n",
        "        # Menggabungkan embedding dari semua lapisan\n",
        "        all_embeddings = tf.stack(all_embeddings, 1)\n",
        "        # Menghitung embedding rata-rata di seluruh lapisan\n",
        "        all_embeddings = tf.reduce_mean(\n",
        "            input_tensor=all_embeddings, axis=1, keepdims=False\n",
        "        )\n",
        "        # Memisahkan embedding gabungan menjadi embedding pengguna, item, dan genre\n",
        "        u_g_embeddings, i_g_embeddings, g_g_embeddings = tf.split(\n",
        "            all_embeddings, [self.n_users, self.n_items, self.n_genres], 0\n",
        "        )\n",
        "        return u_g_embeddings, i_g_embeddings, g_g_embeddings\n",
        "\n",
        "    def _create_bpr_loss(self, users, pos_items, neg_items):\n",
        "        \"\"\"Calculate BPR loss.\n",
        "\n",
        "        Args:\n",
        "            users (tf.Tensor): User embeddings to calculate loss.\n",
        "            pos_items (tf.Tensor): Positive item embeddings to calculate loss.\n",
        "            neg_items (tf.Tensor): Negative item embeddings to calculate loss.\n",
        "\n",
        "        Returns:\n",
        "            tf.Tensor, tf.Tensor: Matrix factorization loss. Embedding regularization loss.\n",
        "\n",
        "        \"\"\"\n",
        "        # Skor interaksi antara pengguna dan item positif\n",
        "        pos_scores = tf.reduce_sum(input_tensor=tf.multiply(users, pos_items), axis=1)\n",
        "        # Skor interaksi antara pengguna dan item negatif\n",
        "        neg_scores = tf.reduce_sum(input_tensor=tf.multiply(users, neg_items), axis=1)\n",
        "\n",
        "        # Regularisasi L2 pada embedding awal pengguna, item, dan genre\n",
        "        regularizer = (\n",
        "            tf.nn.l2_loss(self.u_g_embeddings_pre)\n",
        "            + tf.nn.l2_loss(self.pos_i_g_embeddings_pre)\n",
        "            + tf.nn.l2_loss(self.neg_i_g_embeddings_pre)\n",
        "            + tf.nn.l2_loss(self.g_embeddings_pre) # Menambahkan regularisasi embedding genre\n",
        "        )\n",
        "        regularizer = regularizer / self.batch_size\n",
        "        # BPR loss: memaksimalkan perbedaan antara skor positif dan negatif\n",
        "        mf_loss = tf.reduce_mean(\n",
        "            input_tensor=tf.nn.softplus(-(pos_scores - neg_scores))\n",
        "        )\n",
        "        # Total embedding regularization loss\n",
        "        emb_loss = self.decay * regularizer\n",
        "        return mf_loss, emb_loss\n",
        "\n",
        "    def _convert_sp_mat_to_sp_tensor(self, X):\n",
        "        \"\"\"Convert a scipy sparse matrix to tf.SparseTensor.\n",
        "\n",
        "        Returns:\n",
        "            tf.SparseTensor: SparseTensor after conversion.\n",
        "\n",
        "        \"\"\"\n",
        "        coo = X.tocoo().astype(np.float32)\n",
        "        indices = np.asmatrix([coo.row, coo.col]).transpose()\n",
        "        return tf.SparseTensor(indices, coo.data, coo.shape)\n",
        "\n",
        "    def fit(self):\n",
        "        \"\"\"Melatih model pada self.data.train. Jika eval_epoch bukan -1, evaluasi model pada\n",
        "        `self.data.test` setiap `eval_epoch` epoch untuk mengamati status pelatihan.\n",
        "\n",
        "        \"\"\"\n",
        "        for epoch in range(1, self.epochs + 1):\n",
        "            train_start = time.time()\n",
        "            loss, mf_loss, emb_loss = 0.0, 0.0, 0.0\n",
        "            n_batch = self.data.train.shape[0] // self.batch_size + 1\n",
        "            for idx in range(n_batch):\n",
        "                # train_loader dari ImplicitCF sudah menyediakan pengguna, item positif, dan item negatif\n",
        "                users, pos_items, neg_items = self.data.train_loader(self.batch_size)\n",
        "                _, batch_loss, batch_mf_loss, batch_emb_loss = self.sess.run(\n",
        "                    [self.opt, self.loss, self.mf_loss, self.emb_loss],\n",
        "                    feed_dict={\n",
        "                        self.users: users,\n",
        "                        self.pos_items: pos_items,\n",
        "                        self.neg_items: neg_items,\n",
        "                    },\n",
        "                )\n",
        "                loss += batch_loss / n_batch\n",
        "                mf_loss += batch_mf_loss / n_batch\n",
        "                emb_loss += batch_emb_loss / n_batch\n",
        "\n",
        "            if np.isnan(loss):\n",
        "                print(\"ERROR: loss is nan.\")\n",
        "                sys.exit()\n",
        "            train_end = time.time()\n",
        "            train_time = train_end - train_start\n",
        "\n",
        "            if self.save_model and epoch % self.save_epoch == 0:\n",
        "                save_path_str = os.path.join(self.model_dir, \"epoch_\" + str(epoch))\n",
        "                if not os.path.exists(save_path_str):\n",
        "                    os.makedirs(save_path_str)\n",
        "                checkpoint_path = self.saver.save(  # noqa: F841\n",
        "                    sess=self.sess, save_path=save_path_str\n",
        "                )\n",
        "                print(\"Save model to path {0}\".format(os.path.abspath(save_path_str)))\n",
        "\n",
        "            if self.eval_epoch == -1 or epoch % self.eval_epoch != 0:\n",
        "                print(\n",
        "                    \"Epoch %d (train)%.1fs: train loss = %.5f = (mf)%.5f + (embed)%.5f\"\n",
        "                    % (epoch, train_time, loss, mf_loss, emb_loss)\n",
        "                )\n",
        "            else:\n",
        "                eval_start = time.time()\n",
        "                ret = self.run_eval()\n",
        "                eval_end = time.time()\n",
        "                eval_time = eval_end - eval_start\n",
        "\n",
        "                print(\n",
        "                    \"Epoch %d (train)%.1fs + (eval)%.1fs: train loss = %.5f = (mf)%.5f + (embed)%.5f, %s\"\n",
        "                    % (\n",
        "                        epoch,\n",
        "                        train_time,\n",
        "                        eval_time,\n",
        "                        loss,\n",
        "                        mf_loss,\n",
        "                        emb_loss,\n",
        "                        \", \".join(\n",
        "                            metric + \" = %.5f\" % (r)\n",
        "                            for metric, r in zip(self.metrics, ret)\n",
        "                        ),\n",
        "                    )\n",
        "                )\n",
        "\n",
        "    def load(self, model_path=None):\n",
        "        \"\"\"Load an existing model.\n",
        "\n",
        "        Args:\n",
        "            model_path: Model path.\n",
        "\n",
        "        Raises:\n",
        "            IOError: if the restore operation failed.\n",
        "\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.saver.restore(self.sess, model_path)\n",
        "        except Exception:\n",
        "            raise IOError(\n",
        "                \"Failed to find any matching files for {0}\".format(model_path)\n",
        "            )\n",
        "\n",
        "    def run_eval(self):\n",
        "        \"\"\"Run evaluation on self.data.test.\n",
        "\n",
        "        Returns:\n",
        "            dict: Results of all metrics in `self.metrics`.\n",
        "        \"\"\"\n",
        "        topk_scores = self.recommend_k_items(\n",
        "            self.data.test, top_k=self.top_k, use_id=True\n",
        "        )\n",
        "        ret = []\n",
        "        for metric in self.metrics:\n",
        "            if metric == \"ndcg\":\n",
        "                ret.append(ndcg_at_k(self.data.test, topk_scores, k=self.top_k))\n",
        "            elif metric == \"recall\":\n",
        "                ret.append(recall_at_k(self.data.test, topk_scores, k=self.top_k))\n",
        "        return ret\n",
        "\n",
        "    def run_eval(self):\n",
        "        \"\"\"Menjalankan evaluasi pada self.data.test.\n",
        "\n",
        "        Mengembalikan:\n",
        "            dict: Hasil dari semua metrik di `self.metrics`.\n",
        "        \"\"\"\n",
        "        topk_scores = self.recommend_k_items(\n",
        "            self.data.test, top_k=self.top_k, use_id=True\n",
        "        )\n",
        "        ret = []\n",
        "        for metric in self.metrics:\n",
        "            if metric == \"ndcg\":\n",
        "                ret.append(ndcg_at_k(self.data.test, topk_scores, k=self.top_k))\n",
        "            elif metric == \"recall\":\n",
        "                ret.append(recall_at_k(self.data.test, topk_scores, k=self.top_k))\n",
        "        return ret\n",
        "\n",
        "    def score(self, user_ids, remove_seen=True):\n",
        "        \"\"\"Menghitung skor semua item untuk pengguna uji.\n",
        "\n",
        "        Argumen:\n",
        "            user_ids (np.array): Pengguna yang akan diuji.\n",
        "            remove_seen (bool): Flag untuk menghapus item yang sudah dilihat dalam pelatihan dari rekomendasi.\n",
        "\n",
        "        Mengembalikan:\n",
        "            numpy.ndarray: Nilai minat semua item untuk pengguna.\n",
        "\n",
        "        \"\"\"\n",
        "        if any(np.isnan(user_ids)):\n",
        "            raise ValueError(\n",
        "                \"LightGCN cannot score users that are not in the training set\"\n",
        "            )\n",
        "        u_batch_size = self.batch_size\n",
        "        n_user_batchs = len(user_ids) // u_batch_size + 1\n",
        "        test_scores = []\n",
        "        for u_batch_id in range(n_user_batchs):\n",
        "            start = u_batch_id * u_batch_size\n",
        "            end = (u_batch_id + 1) * u_batch_size\n",
        "            user_batch = user_ids[start:end]\n",
        "            item_batch = range(self.data.n_items)\n",
        "            # Menggunakan item embedding akhir (hasil propagasi GCN) untuk perhitungan skor\n",
        "            rate_batch = self.sess.run(\n",
        "                self.batch_ratings, {self.users: user_batch, self.pos_items: item_batch}\n",
        "            )\n",
        "            test_scores.append(np.array(rate_batch))\n",
        "        test_scores = np.concatenate(test_scores, axis=0)\n",
        "        if remove_seen:\n",
        "            test_scores += self.data.R.tocsr()[user_ids, :] * -np.inf\n",
        "        return test_scores\n",
        "\n",
        "    def recommend_k_items(\n",
        "        self, test, top_k=10, sort_top_k=True, remove_seen=True, use_id=False\n",
        "    ):\n",
        "        \"\"\"Recommend top K items for all users in the test set.\n",
        "\n",
        "        Args:\n",
        "            test (pandas.DataFrame): Test data.\n",
        "            top_k (int): Number of top items to recommend.\n",
        "            sort_top_k (bool): Flag to sort top k results.\n",
        "            remove_seen (bool): Flag to remove items seen in training from recommendation.\n",
        "\n",
        "        Returns:\n",
        "            pandas.DataFrame: Top k recommendation items for each user.\n",
        "\n",
        "        \"\"\"\n",
        "        data = self.data\n",
        "        if not use_id:\n",
        "            user_ids = np.array([data.user2id[x] for x in test[data.col_user].unique()])\n",
        "        else:\n",
        "            user_ids = np.array(test[data.col_user].unique())\n",
        "\n",
        "        test_scores = self.score(user_ids, remove_seen=remove_seen)\n",
        "\n",
        "        top_items, top_scores = get_top_k_scored_items(\n",
        "            scores=test_scores, top_k=top_k, sort_top_k=sort_top_k\n",
        "        )\n",
        "\n",
        "        df = pd.DataFrame(\n",
        "            {\n",
        "                data.col_user: np.repeat(\n",
        "                    test[data.col_user].drop_duplicates().values, top_items.shape[1]\n",
        "                ),\n",
        "                data.col_item: top_items.flatten()\n",
        "                if use_id\n",
        "                else [data.id2item[item] for item in top_items.flatten()],\n",
        "                data.col_prediction: top_scores.flatten(),\n",
        "            }\n",
        "        )\n",
        "\n",
        "        return df.replace(-np.inf, np.nan).dropna()\n",
        "\n",
        "    def output_embeddings(self, idmapper, n, target, output_file):\n",
        "        embeddings = list(target.eval(session=self.sess))\n",
        "        with open(output_file, \"w\") as wt:\n",
        "            for i in range(n):\n",
        "                wt.write(\n",
        "                    \"{0}\\t{1}\\n\".format(\n",
        "                        idmapper[i], \" \".join([str(a) for a in embeddings[i]])\n",
        "                    )\n",
        "                )\n",
        "\n",
        "    def infer_embedding(self, user_file, item_file, genre_file=None):\n",
        "        \"\"\"Mengekspor embedding pengguna, item, dan genre ke file csv.\n",
        "\n",
        "        Argumen:\n",
        "            user_file (str): Path file untuk menyimpan embedding pengguna.\n",
        "            item_file (str): Path file untuk menyimpan embedding item.\n",
        "            genre_file (str, optional): Path file untuk menyimpan embedding genre. Default None.\n",
        "\n",
        "        \"\"\"\n",
        "        # membuat direktori output jika tidak ada\n",
        "        dirs, _ = os.path.split(user_file)\n",
        "        if not os.path.exists(dirs):\n",
        "            os.makedirs(dirs)\n",
        "        dirs, _ = os.path.split(item_file)\n",
        "        if not os.path.exists(dirs):\n",
        "            os.makedirs(dirs)\n",
        "        if genre_file:\n",
        "             dirs, _ = os.path.split(genre_file)\n",
        "             if not os.path.exists(dirs):\n",
        "                 os.makedirs(dirs)\n",
        "\n",
        "\n",
        "        data = self.data\n",
        "\n",
        "        # Mengekspor embedding pengguna\n",
        "        self.output_embeddings(\n",
        "            data.id2user, self.n_users, self.ua_embeddings, user_file\n",
        "        )\n",
        "        # Mengekspor embedding item\n",
        "        self.output_embeddings(\n",
        "            data.id2item, self.n_items, self.ia_embeddings, item_file\n",
        "        )\n",
        "        # Mengekspor embedding genre jika genre_file disediakan\n",
        "        if genre_file:\n",
        "             self.output_embeddings(\n",
        "                 data.id2genre, self.n_genres, self.ga_embeddings, genre_file\n",
        "             )\n"
      ],
      "metadata": {
        "id": "MDQ618w9AYai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LightGCN(hparams, data, seed=SEED)"
      ],
      "metadata": {
        "id": "ac2nM1o8di4r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf924aaa-5a75-4f60-f528-315c0d10daff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already normalize adjacency matrix (extended).\n",
            "Using xavier initialization for user, item, and genre embeddings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Timer"
      ],
      "metadata": {
        "id": "JT46qlTsADkF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from functools import lru_cache, wraps\n",
        "logger = logging.getLogger(__name__)"
      ],
      "metadata": {
        "id": "V1FAPBRWtefy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _check_column_dtypes(func):\n",
        "    \"\"\"Checks columns of DataFrame inputs\n",
        "\n",
        "    This includes the checks on:\n",
        "\n",
        "    * whether the input columns exist in the input DataFrames\n",
        "    * whether the data types of col_user as well as col_item are matched in the two input DataFrames.\n",
        "\n",
        "    Args:\n",
        "        func (function): function that will be wrapped\n",
        "\n",
        "    Returns:\n",
        "        function: Wrapper function for checking dtypes.\n",
        "    \"\"\"\n",
        "\n",
        "    @wraps(func)\n",
        "    def check_column_dtypes_wrapper(\n",
        "        rating_true,\n",
        "        rating_pred,\n",
        "        col_user=DEFAULT_USER_COL,\n",
        "        col_item=DEFAULT_ITEM_COL,\n",
        "        col_prediction=DEFAULT_PREDICTION_COL,\n",
        "        *args,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        \"\"\"Check columns of DataFrame inputs\n",
        "\n",
        "        Args:\n",
        "            rating_true (pandas.DataFrame): True data\n",
        "            rating_pred (pandas.DataFrame): Predicted data\n",
        "            col_user (str): column name for user\n",
        "            col_item (str): column name for item\n",
        "            col_rating (str): column name for rating\n",
        "            col_prediction (str): column name for prediction\n",
        "        \"\"\"\n",
        "        # Some ranking metrics don't have the rating column, so we don't need to check.\n",
        "        expected_true_columns = {col_user, col_item}\n",
        "        if \"col_rating\" in kwargs:\n",
        "            expected_true_columns.add(kwargs[\"col_rating\"])\n",
        "        if not has_columns(rating_true, expected_true_columns):\n",
        "            raise ColumnMismatchError(\"Missing columns in true rating DataFrame\")\n",
        "\n",
        "        if not has_columns(rating_pred, {col_user, col_item, col_prediction}):\n",
        "            raise ColumnMismatchError(\"Missing columns in predicted rating DataFrame\")\n",
        "\n",
        "        if not has_same_base_dtype(\n",
        "            rating_true, rating_pred, columns=[col_user, col_item]\n",
        "        ):\n",
        "            raise ColumnTypeMismatchError(\n",
        "                \"Columns in provided DataFrames are not the same datatype\"\n",
        "            )\n",
        "\n",
        "        return func(\n",
        "            rating_true=rating_true,\n",
        "            rating_pred=rating_pred,\n",
        "            col_user=col_user,\n",
        "            col_item=col_item,\n",
        "            col_prediction=col_prediction,\n",
        "            *args,\n",
        "            **kwargs,\n",
        "        )\n",
        "\n",
        "    return check_column_dtypes_wrapper"
      ],
      "metadata": {
        "id": "-znoBbp5tCbr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lru_cache_df(maxsize, typed=False):\n",
        "    \"\"\"Least-recently-used cache decorator for pandas Dataframes.\n",
        "\n",
        "    Decorator to wrap a function with a memoizing callable that saves up to the maxsize most recent calls. It can\n",
        "    save time when an expensive or I/O bound function is periodically called with the same arguments.\n",
        "\n",
        "    Inspired in the `lru_cache function <https://docs.python.org/3/library/functools.html#functools.lru_cache>`_.\n",
        "\n",
        "    Args:\n",
        "        maxsize (int|None): max size of cache, if set to None cache is boundless\n",
        "        typed (bool): arguments of different types are cached separately\n",
        "    \"\"\"\n",
        "\n",
        "    def to_pandas_hash(val):\n",
        "        \"\"\"Return PandaHash object if input is a DataFrame otherwise return input unchanged\"\"\"\n",
        "        return PandasHash(val) if isinstance(val, pd.DataFrame) else val\n",
        "\n",
        "    def from_pandas_hash(val):\n",
        "        \"\"\"Extract DataFrame if input is PandaHash object otherwise return input unchanged\"\"\"\n",
        "        return val.pandas_object if isinstance(val, PandasHash) else val\n",
        "\n",
        "    def decorating_function(user_function):\n",
        "        @wraps(user_function)\n",
        "        def wrapper(*args, **kwargs):\n",
        "            # convert DataFrames in args and kwargs to PandaHash objects\n",
        "            args = tuple([to_pandas_hash(a) for a in args])\n",
        "            kwargs = {k: to_pandas_hash(v) for k, v in kwargs.items()}\n",
        "            return cached_wrapper(*args, **kwargs)\n",
        "\n",
        "        @lru_cache(maxsize=maxsize, typed=typed)\n",
        "        def cached_wrapper(*args, **kwargs):\n",
        "            # get DataFrames from PandaHash objects in args and kwargs\n",
        "            args = tuple([from_pandas_hash(a) for a in args])\n",
        "            kwargs = {k: from_pandas_hash(v) for k, v in kwargs.items()}\n",
        "            return user_function(*args, **kwargs)\n",
        "\n",
        "        # retain lru_cache attributes\n",
        "        wrapper.cache_info = cached_wrapper.cache_info\n",
        "        wrapper.cache_clear = cached_wrapper.cache_clear\n",
        "\n",
        "        return wrapper\n",
        "\n",
        "    return decorating_function"
      ],
      "metadata": {
        "id": "XATlE1YBtSQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@_check_column_dtypes\n",
        "@lru_cache_df(maxsize=1)\n",
        "def merge_ranking_true_pred(\n",
        "    rating_true,\n",
        "    rating_pred,\n",
        "    col_user,\n",
        "    col_item,\n",
        "    col_prediction,\n",
        "    relevancy_method,\n",
        "    k=DEFAULT_K,\n",
        "    threshold=DEFAULT_THRESHOLD,\n",
        "    **_,\n",
        "):\n",
        "    \"\"\"Filter truth and prediction data frames on common users\n",
        "\n",
        "    Args:\n",
        "        rating_true (pandas.DataFrame): True DataFrame\n",
        "        rating_pred (pandas.DataFrame): Predicted DataFrame\n",
        "        col_user (str): column name for user\n",
        "        col_item (str): column name for item\n",
        "        col_prediction (str): column name for prediction\n",
        "        relevancy_method (str): method for determining relevancy ['top_k', 'by_threshold', None]. None means that the\n",
        "            top k items are directly provided, so there is no need to compute the relevancy operation.\n",
        "        k (int): number of top k items per user (optional)\n",
        "        threshold (float): threshold of top items per user (optional)\n",
        "\n",
        "    Returns:\n",
        "        pandas.DataFrame, pandas.DataFrame, int: DataFrame of recommendation hits, sorted by `col_user` and `rank`\n",
        "        DataFrame of hit counts vs actual relevant items per user number of unique user ids\n",
        "    \"\"\"\n",
        "\n",
        "    # Make sure the prediction and true data frames have the same set of users\n",
        "    common_users = set(rating_true[col_user]).intersection(set(rating_pred[col_user]))\n",
        "    rating_true_common = rating_true[rating_true[col_user].isin(common_users)]\n",
        "    rating_pred_common = rating_pred[rating_pred[col_user].isin(common_users)]\n",
        "    n_users = len(common_users)\n",
        "\n",
        "    # Return hit items in prediction data frame with ranking information. This is used for calculating NDCG and MAP.\n",
        "    # Use first to generate unique ranking values for each item. This is to align with the implementation in\n",
        "    # Spark evaluation metrics, where index of each recommended items (the indices are unique to items) is used\n",
        "    # to calculate penalized precision of the ordered items.\n",
        "    if relevancy_method == \"top_k\":\n",
        "        top_k = k\n",
        "    elif relevancy_method == \"by_threshold\":\n",
        "        top_k = threshold\n",
        "    elif relevancy_method is None:\n",
        "        top_k = None\n",
        "    else:\n",
        "        raise NotImplementedError(\"Invalid relevancy_method\")\n",
        "    df_hit = get_top_k_items(\n",
        "        dataframe=rating_pred_common,\n",
        "        col_user=col_user,\n",
        "        col_rating=col_prediction,\n",
        "        k=top_k,\n",
        "    )\n",
        "    df_hit = pd.merge(df_hit, rating_true_common, on=[col_user, col_item])[\n",
        "        [col_user, col_item, \"rank\"]\n",
        "    ]\n",
        "\n",
        "    # count the number of hits vs actual relevant items per user\n",
        "    df_hit_count = pd.merge(\n",
        "        df_hit.groupby(col_user, as_index=False)[col_user].agg(hit=\"count\"),\n",
        "        rating_true_common.groupby(col_user, as_index=False)[col_user].agg(\n",
        "            actual=\"count\",\n",
        "        ),\n",
        "        on=col_user,\n",
        "    )\n",
        "\n",
        "    return df_hit, df_hit_count, n_users"
      ],
      "metadata": {
        "id": "PfDT5nEIsX6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def has_columns(df, columns):\n",
        "    \"\"\"Check if DataFrame has necessary columns\n",
        "\n",
        "    Args:\n",
        "        df (pandas.DataFrame): DataFrame\n",
        "        columns (iterable(str)): columns to check for\n",
        "\n",
        "    Returns:\n",
        "        bool: True if DataFrame has specified columns.\n",
        "    \"\"\"\n",
        "    if not isinstance(columns, set):\n",
        "        columns = set(columns)\n",
        "    return columns.issubset(df.columns)"
      ],
      "metadata": {
        "id": "qjCvOEw2uB15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from timeit import default_timer\n",
        "\n",
        "\n",
        "class Timer(object):\n",
        "    \"\"\"Timer class.\n",
        "\n",
        "    `Original code <https://github.com/miguelgfierro/pybase/blob/2298172a13fb4a243754acbc6029a4a2dcf72c20/log_base/timer.py>`_.\n",
        "\n",
        "    Examples:\n",
        "        >>> import time\n",
        "        >>> t = Timer()\n",
        "        >>> t.start()\n",
        "        >>> time.sleep(1)\n",
        "        >>> t.stop()\n",
        "        >>> t.interval < 1\n",
        "        True\n",
        "        >>> with Timer() as t:\n",
        "        ...   time.sleep(1)\n",
        "        >>> t.interval < 1\n",
        "        True\n",
        "        >>> \"Time elapsed {}\".format(t) #doctest: +ELLIPSIS\n",
        "        'Time elapsed 1...'\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self._timer = default_timer\n",
        "        self._interval = 0\n",
        "        self.running = False\n",
        "\n",
        "    def __enter__(self):\n",
        "        self.start()\n",
        "        return self\n",
        "\n",
        "    def __exit__(self, *args):\n",
        "        self.stop()\n",
        "\n",
        "    def __str__(self):\n",
        "        return \"{:0.4f}\".format(self.interval)\n",
        "\n",
        "    def start(self):\n",
        "        \"\"\"Start the timer.\"\"\"\n",
        "        self.init = self._timer()\n",
        "        self.running = True\n",
        "\n",
        "    def stop(self):\n",
        "        \"\"\"Stop the timer. Calculate the interval in seconds.\"\"\"\n",
        "        self.end = self._timer()\n",
        "        try:\n",
        "            self._interval = self.end - self.init\n",
        "            self.running = False\n",
        "        except AttributeError:\n",
        "            raise ValueError(\n",
        "                \"Timer has not been initialized: use start() or the contextual form with Timer() as t:\"\n",
        "            )\n",
        "\n",
        "    @property\n",
        "    def interval(self):\n",
        "        \"\"\"Get time interval in seconds.\n",
        "\n",
        "        Returns:\n",
        "            float: Seconds.\n",
        "        \"\"\"\n",
        "        if self.running:\n",
        "            raise ValueError(\"Timer has not been stopped, please use stop().\")\n",
        "        else:\n",
        "            return self._interval\n"
      ],
      "metadata": {
        "id": "rcY87Mgh9MhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def has_same_base_dtype(df_1, df_2, columns=None):\n",
        "    \"\"\"Check if specified columns have the same base dtypes across both DataFrames\n",
        "\n",
        "    Args:\n",
        "        df_1 (pandas.DataFrame): first DataFrame\n",
        "        df_2 (pandas.DataFrame): second DataFrame\n",
        "        columns (list(str)): columns to check, None checks all columns\n",
        "\n",
        "    Returns:\n",
        "        bool: True if DataFrames columns have the same base dtypes.\n",
        "    \"\"\"\n",
        "\n",
        "    if columns is None:\n",
        "        if any(set(df_1.columns).symmetric_difference(set(df_2.columns))):\n",
        "            logger.error(\n",
        "                \"Cannot test all columns because they are not all shared across DataFrames\"\n",
        "            )\n",
        "            return False\n",
        "        columns = df_1.columns\n",
        "\n",
        "    if not (\n",
        "        has_columns(df=df_1, columns=columns) and has_columns(df=df_2, columns=columns)\n",
        "    ):\n",
        "        return False\n",
        "\n",
        "    result = True\n",
        "    for column in columns:\n",
        "        if df_1[column].dtype.type.__base__ != df_2[column].dtype.type.__base__:\n",
        "            logger.error(\"Columns {} do not have the same base datatype\".format(column))\n",
        "            result = False\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "fJEIDVPOuOeg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PandasHash:\n",
        "    \"\"\"Wrapper class to allow pandas objects (DataFrames or Series) to be hashable\"\"\"\n",
        "\n",
        "    # reserve space just for a single pandas object\n",
        "    __slots__ = \"pandas_object\"\n",
        "\n",
        "    def __init__(self, pandas_object):\n",
        "        \"\"\"Initialize class\n",
        "\n",
        "        Args:\n",
        "            pandas_object (pandas.DataFrame|pandas.Series): pandas object\n",
        "        \"\"\"\n",
        "\n",
        "        if not isinstance(pandas_object, (pd.DataFrame, pd.Series)):\n",
        "            raise TypeError(\"Can only wrap pandas DataFrame or Series objects\")\n",
        "        self.pandas_object = pandas_object\n",
        "\n",
        "    def __eq__(self, other):\n",
        "        \"\"\"Overwrite equality comparison\n",
        "\n",
        "        Args:\n",
        "            other (pandas.DataFrame|pandas.Series): pandas object to compare\n",
        "\n",
        "        Returns:\n",
        "            bool: whether other object is the same as this one\n",
        "        \"\"\"\n",
        "\n",
        "        return hash(self) == hash(other)\n",
        "\n",
        "    def __hash__(self):\n",
        "        \"\"\"Overwrite hash operator for use with pandas objects\n",
        "\n",
        "        Returns:\n",
        "            int: hashed value of object\n",
        "        \"\"\"\n",
        "\n",
        "        hashable = tuple(self.pandas_object.values.tobytes())\n",
        "        if isinstance(self.pandas_object, pd.DataFrame):\n",
        "            hashable += tuple(self.pandas_object.columns)\n",
        "        else:\n",
        "            hashable += tuple(self.pandas_object.name)\n",
        "        return hash(hashable)"
      ],
      "metadata": {
        "id": "iMCP0oIyudNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_top_k_items(\n",
        "    dataframe, col_user=DEFAULT_USER_COL, col_rating=DEFAULT_RATING_COL, k=DEFAULT_K\n",
        "):\n",
        "    \"\"\"Get the input customer-item-rating tuple in the format of Pandas\n",
        "    DataFrame, output a Pandas DataFrame in the dense format of top k items\n",
        "    for each user.\n",
        "\n",
        "    Note:\n",
        "        If it is implicit rating, just append a column of constants to be\n",
        "        ratings.\n",
        "\n",
        "    Args:\n",
        "        dataframe (pandas.DataFrame): DataFrame of rating data (in the format\n",
        "        customerID-itemID-rating)\n",
        "        col_user (str): column name for user\n",
        "        col_rating (str): column name for rating\n",
        "        k (int or None): number of items for each user; None means that the input has already been\n",
        "        filtered out top k items and sorted by ratings and there is no need to do that again.\n",
        "\n",
        "    Returns:\n",
        "        pandas.DataFrame: DataFrame of top k items for each user, sorted by `col_user` and `rank`\n",
        "    \"\"\"\n",
        "    # Sort dataframe by col_user and (top k) col_rating\n",
        "    if k is None:\n",
        "        top_k_items = dataframe\n",
        "    else:\n",
        "        top_k_items = (\n",
        "            dataframe.sort_values([col_user, col_rating], ascending=[True, False])\n",
        "            .groupby(col_user, as_index=False)\n",
        "            .head(k)\n",
        "            .reset_index(drop=True)\n",
        "        )\n",
        "    # Add ranks\n",
        "    top_k_items[\"rank\"] = top_k_items.groupby(col_user, sort=False).cumcount() + 1\n",
        "    return top_k_items"
      ],
      "metadata": {
        "id": "gksfojgpup_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@lru_cache_df(maxsize=1)\n",
        "def _get_reciprocal_rank(\n",
        "    rating_true,\n",
        "    rating_pred,\n",
        "    col_user=DEFAULT_USER_COL,\n",
        "    col_item=DEFAULT_ITEM_COL,\n",
        "    col_prediction=DEFAULT_PREDICTION_COL,\n",
        "    relevancy_method=\"top_k\",\n",
        "    k=DEFAULT_K,\n",
        "    threshold=DEFAULT_THRESHOLD,\n",
        "):\n",
        "    df_hit, df_hit_count, n_users = merge_ranking_true_pred(\n",
        "        rating_true=rating_true,\n",
        "        rating_pred=rating_pred,\n",
        "        col_user=col_user,\n",
        "        col_item=col_item,\n",
        "        col_prediction=col_prediction,\n",
        "        relevancy_method=relevancy_method,\n",
        "        k=k,\n",
        "        threshold=threshold,\n",
        "    )\n",
        "\n",
        "    if df_hit.shape[0] == 0:\n",
        "        return None, n_users\n",
        "\n",
        "    # calculate reciprocal rank of items for each user and sum them up\n",
        "    df_hit_sorted = df_hit.copy()\n",
        "    df_hit_sorted[\"rr\"] = (\n",
        "        df_hit_sorted.groupby(col_user).cumcount() + 1\n",
        "    ) / df_hit_sorted[\"rank\"]\n",
        "    df_hit_sorted = df_hit_sorted.groupby(col_user).agg({\"rr\": \"sum\"}).reset_index()\n",
        "\n",
        "    return pd.merge(df_hit_sorted, df_hit_count, on=col_user), n_users"
      ],
      "metadata": {
        "id": "6EtRegtJvJMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with Timer() as train_time:\n",
        "    model.fit()\n",
        "\n",
        "print(\"Took {} seconds for training.\".format(train_time.interval))"
      ],
      "metadata": {
        "id": "0ZX-LXEodpUj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d63e9c0d-c382-47d1-bf0d-5743e3fc3d4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 (train)4.3s: train loss = 0.29809 = (mf)0.29750 + (embed)0.00059\n",
            "Epoch 2 (train)2.5s: train loss = 0.21461 = (mf)0.21358 + (embed)0.00103\n",
            "Epoch 3 (train)2.4s: train loss = 0.19808 = (mf)0.19664 + (embed)0.00144\n",
            "Epoch 4 (train)2.4s: train loss = 0.18057 = (mf)0.17860 + (embed)0.00197\n",
            "Epoch 5 (train)2.4s + (eval)0.9s: train loss = 0.15456 = (mf)0.15192 + (embed)0.00264, recall = 0.02805, ndcg = 0.12957\n",
            "Epoch 6 (train)3.0s: train loss = 0.13944 = (mf)0.13623 + (embed)0.00321\n",
            "Epoch 7 (train)2.4s: train loss = 0.13240 = (mf)0.12873 + (embed)0.00367\n",
            "Epoch 8 (train)2.4s: train loss = 0.12311 = (mf)0.11899 + (embed)0.00412\n",
            "Epoch 9 (train)2.4s: train loss = 0.11588 = (mf)0.11128 + (embed)0.00460\n",
            "Epoch 10 (train)3.5s + (eval)0.5s: train loss = 0.10702 = (mf)0.10190 + (embed)0.00512, recall = 0.03190, ndcg = 0.15709\n",
            "Epoch 11 (train)2.7s: train loss = 0.10167 = (mf)0.09603 + (embed)0.00564\n",
            "Epoch 12 (train)2.4s: train loss = 0.09471 = (mf)0.08852 + (embed)0.00619\n",
            "Epoch 13 (train)2.4s: train loss = 0.08932 = (mf)0.08260 + (embed)0.00672\n",
            "Epoch 14 (train)2.4s: train loss = 0.08372 = (mf)0.07651 + (embed)0.00721\n",
            "Epoch 15 (train)3.0s + (eval)0.6s: train loss = 0.08200 = (mf)0.07432 + (embed)0.00767, recall = 0.03587, ndcg = 0.17819\n",
            "Epoch 16 (train)2.4s: train loss = 0.07732 = (mf)0.06922 + (embed)0.00809\n",
            "Epoch 17 (train)2.4s: train loss = 0.07471 = (mf)0.06622 + (embed)0.00849\n",
            "Epoch 18 (train)2.4s: train loss = 0.07271 = (mf)0.06390 + (embed)0.00882\n",
            "Epoch 19 (train)2.7s: train loss = 0.06978 = (mf)0.06064 + (embed)0.00914\n",
            "Epoch 20 (train)2.7s + (eval)0.3s: train loss = 0.06861 = (mf)0.05919 + (embed)0.00941, recall = 0.03835, ndcg = 0.18652\n",
            "Epoch 21 (train)2.4s: train loss = 0.06613 = (mf)0.05645 + (embed)0.00968\n",
            "Epoch 22 (train)2.4s: train loss = 0.06470 = (mf)0.05476 + (embed)0.00994\n",
            "Epoch 23 (train)3.6s: train loss = 0.06272 = (mf)0.05256 + (embed)0.01016\n",
            "Epoch 24 (train)3.8s: train loss = 0.06175 = (mf)0.05136 + (embed)0.01039\n",
            "Epoch 25 (train)2.4s + (eval)0.5s: train loss = 0.06026 = (mf)0.04966 + (embed)0.01060, recall = 0.04114, ndcg = 0.19278\n",
            "Epoch 26 (train)2.4s: train loss = 0.05850 = (mf)0.04770 + (embed)0.01080\n",
            "Epoch 27 (train)2.4s: train loss = 0.05618 = (mf)0.04518 + (embed)0.01100\n",
            "Epoch 28 (train)3.0s: train loss = 0.05531 = (mf)0.04412 + (embed)0.01119\n",
            "Epoch 29 (train)2.4s: train loss = 0.05467 = (mf)0.04329 + (embed)0.01138\n",
            "Epoch 30 (train)2.4s + (eval)0.3s: train loss = 0.05300 = (mf)0.04147 + (embed)0.01153, recall = 0.04239, ndcg = 0.19695\n",
            "Epoch 31 (train)2.4s: train loss = 0.05287 = (mf)0.04119 + (embed)0.01169\n",
            "Epoch 32 (train)2.4s: train loss = 0.05149 = (mf)0.03966 + (embed)0.01182\n",
            "Epoch 33 (train)3.0s: train loss = 0.05079 = (mf)0.03880 + (embed)0.01199\n",
            "Epoch 34 (train)2.4s: train loss = 0.04968 = (mf)0.03758 + (embed)0.01210\n",
            "Epoch 35 (train)2.4s + (eval)0.3s: train loss = 0.04844 = (mf)0.03620 + (embed)0.01223, recall = 0.04313, ndcg = 0.20197\n",
            "Epoch 36 (train)2.4s: train loss = 0.04808 = (mf)0.03574 + (embed)0.01234\n",
            "Epoch 37 (train)2.7s: train loss = 0.04639 = (mf)0.03392 + (embed)0.01247\n",
            "Epoch 38 (train)2.7s: train loss = 0.04657 = (mf)0.03402 + (embed)0.01255\n",
            "Epoch 39 (train)2.4s: train loss = 0.04535 = (mf)0.03266 + (embed)0.01269\n",
            "Epoch 40 (train)2.4s + (eval)0.5s: train loss = 0.04467 = (mf)0.03189 + (embed)0.01279, recall = 0.04376, ndcg = 0.20375\n",
            "Epoch 41 (train)2.4s: train loss = 0.04424 = (mf)0.03135 + (embed)0.01289\n",
            "Epoch 42 (train)3.0s: train loss = 0.04352 = (mf)0.03053 + (embed)0.01298\n",
            "Epoch 43 (train)2.4s: train loss = 0.04350 = (mf)0.03044 + (embed)0.01306\n",
            "Epoch 44 (train)2.4s: train loss = 0.04310 = (mf)0.02997 + (embed)0.01313\n",
            "Epoch 45 (train)2.4s + (eval)0.6s: train loss = 0.04152 = (mf)0.02831 + (embed)0.01321, recall = 0.04371, ndcg = 0.20248\n",
            "Epoch 46 (train)2.5s: train loss = 0.04193 = (mf)0.02864 + (embed)0.01329\n",
            "Epoch 47 (train)2.9s: train loss = 0.04112 = (mf)0.02774 + (embed)0.01337\n",
            "Epoch 48 (train)2.4s: train loss = 0.04116 = (mf)0.02773 + (embed)0.01342\n",
            "Epoch 49 (train)2.4s: train loss = 0.04054 = (mf)0.02708 + (embed)0.01346\n",
            "Epoch 50 (train)2.4s + (eval)0.3s: train loss = 0.03971 = (mf)0.02614 + (embed)0.01357, recall = 0.04482, ndcg = 0.20486\n",
            "Epoch 51 (train)2.8s: train loss = 0.03968 = (mf)0.02606 + (embed)0.01362\n",
            "Epoch 52 (train)2.6s: train loss = 0.03909 = (mf)0.02541 + (embed)0.01368\n",
            "Epoch 53 (train)2.4s: train loss = 0.03916 = (mf)0.02540 + (embed)0.01376\n",
            "Epoch 54 (train)2.4s: train loss = 0.03806 = (mf)0.02425 + (embed)0.01381\n",
            "Epoch 55 (train)2.4s + (eval)0.5s: train loss = 0.03837 = (mf)0.02451 + (embed)0.01386, recall = 0.04546, ndcg = 0.20918\n",
            "Epoch 56 (train)3.0s: train loss = 0.03738 = (mf)0.02347 + (embed)0.01391\n",
            "Epoch 57 (train)2.4s: train loss = 0.03684 = (mf)0.02289 + (embed)0.01395\n",
            "Epoch 58 (train)2.4s: train loss = 0.03741 = (mf)0.02342 + (embed)0.01399\n",
            "Epoch 59 (train)2.4s: train loss = 0.03652 = (mf)0.02249 + (embed)0.01403\n",
            "Epoch 60 (train)2.4s + (eval)0.5s: train loss = 0.03673 = (mf)0.02266 + (embed)0.01407, recall = 0.04428, ndcg = 0.20809\n",
            "Epoch 61 (train)2.8s: train loss = 0.03659 = (mf)0.02250 + (embed)0.01410\n",
            "Epoch 62 (train)2.4s: train loss = 0.03558 = (mf)0.02143 + (embed)0.01414\n",
            "Epoch 63 (train)2.4s: train loss = 0.03576 = (mf)0.02156 + (embed)0.01420\n",
            "Epoch 64 (train)2.4s: train loss = 0.03553 = (mf)0.02128 + (embed)0.01424\n",
            "Epoch 65 (train)2.6s + (eval)0.8s: train loss = 0.03448 = (mf)0.02020 + (embed)0.01427, recall = 0.04539, ndcg = 0.20981\n",
            "Epoch 66 (train)2.6s: train loss = 0.03517 = (mf)0.02085 + (embed)0.01432\n",
            "Epoch 67 (train)2.4s: train loss = 0.03568 = (mf)0.02134 + (embed)0.01434\n",
            "Epoch 68 (train)2.4s: train loss = 0.03429 = (mf)0.01991 + (embed)0.01438\n",
            "Epoch 69 (train)2.4s: train loss = 0.03441 = (mf)0.01999 + (embed)0.01442\n",
            "Epoch 70 (train)2.9s + (eval)0.3s: train loss = 0.03423 = (mf)0.01978 + (embed)0.01445, recall = 0.04533, ndcg = 0.20568\n",
            "Epoch 71 (train)2.4s: train loss = 0.03427 = (mf)0.01979 + (embed)0.01448\n",
            "Epoch 72 (train)2.4s: train loss = 0.03395 = (mf)0.01944 + (embed)0.01451\n",
            "Epoch 73 (train)2.4s: train loss = 0.03427 = (mf)0.01972 + (embed)0.01455\n",
            "Epoch 74 (train)2.4s: train loss = 0.03340 = (mf)0.01883 + (embed)0.01457\n",
            "Epoch 75 (train)3.0s + (eval)0.6s: train loss = 0.03348 = (mf)0.01888 + (embed)0.01460, recall = 0.04482, ndcg = 0.20608\n",
            "Epoch 76 (train)2.4s: train loss = 0.03347 = (mf)0.01880 + (embed)0.01467\n",
            "Epoch 77 (train)2.4s: train loss = 0.03320 = (mf)0.01853 + (embed)0.01467\n",
            "Epoch 78 (train)2.4s: train loss = 0.03339 = (mf)0.01871 + (embed)0.01469\n",
            "Epoch 79 (train)2.7s: train loss = 0.03274 = (mf)0.01802 + (embed)0.01472\n",
            "Epoch 80 (train)2.7s + (eval)0.3s: train loss = 0.03255 = (mf)0.01777 + (embed)0.01478, recall = 0.04453, ndcg = 0.20895\n",
            "Epoch 81 (train)2.4s: train loss = 0.03251 = (mf)0.01771 + (embed)0.01480\n",
            "Epoch 82 (train)2.3s: train loss = 0.03198 = (mf)0.01713 + (embed)0.01484\n",
            "Epoch 83 (train)2.4s: train loss = 0.03202 = (mf)0.01716 + (embed)0.01486\n",
            "Epoch 84 (train)2.9s: train loss = 0.03222 = (mf)0.01733 + (embed)0.01489\n",
            "Epoch 85 (train)2.5s + (eval)0.5s: train loss = 0.03197 = (mf)0.01706 + (embed)0.01491, recall = 0.04482, ndcg = 0.21168\n",
            "Epoch 86 (train)2.4s: train loss = 0.03210 = (mf)0.01719 + (embed)0.01491\n",
            "Epoch 87 (train)2.4s: train loss = 0.03209 = (mf)0.01713 + (embed)0.01496\n",
            "Epoch 88 (train)2.4s: train loss = 0.03106 = (mf)0.01608 + (embed)0.01499\n",
            "Epoch 89 (train)3.0s: train loss = 0.03106 = (mf)0.01603 + (embed)0.01503\n",
            "Epoch 90 (train)2.4s + (eval)0.3s: train loss = 0.03143 = (mf)0.01637 + (embed)0.01505, recall = 0.04553, ndcg = 0.21402\n",
            "Epoch 91 (train)2.4s: train loss = 0.03125 = (mf)0.01619 + (embed)0.01506\n",
            "Epoch 92 (train)2.4s: train loss = 0.03066 = (mf)0.01557 + (embed)0.01509\n",
            "Epoch 93 (train)2.6s: train loss = 0.03109 = (mf)0.01595 + (embed)0.01514\n",
            "Epoch 94 (train)2.7s: train loss = 0.03145 = (mf)0.01631 + (embed)0.01514\n",
            "Epoch 95 (train)2.4s + (eval)0.5s: train loss = 0.03069 = (mf)0.01551 + (embed)0.01518, recall = 0.04516, ndcg = 0.21369\n",
            "Epoch 96 (train)2.4s: train loss = 0.03088 = (mf)0.01568 + (embed)0.01520\n",
            "Epoch 97 (train)2.4s: train loss = 0.03070 = (mf)0.01549 + (embed)0.01521\n",
            "Epoch 98 (train)2.9s: train loss = 0.03053 = (mf)0.01529 + (embed)0.01523\n",
            "Epoch 99 (train)2.4s: train loss = 0.03082 = (mf)0.01555 + (embed)0.01527\n",
            "Epoch 100 (train)2.4s + (eval)0.3s: train loss = 0.03056 = (mf)0.01528 + (embed)0.01528, recall = 0.04611, ndcg = 0.21180\n",
            "Took 265.31044300300005 seconds for training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Rekomendasi"
      ],
      "metadata": {
        "id": "wCKxTv8dYjvF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topk_scores = model.recommend_k_items(test, top_k=TOP_K, remove_seen=True)\n",
        "\n",
        "topk_scores.head(50)"
      ],
      "metadata": {
        "id": "Zb_V8MZiYml6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ed56cc04-fcb3-4753-9750-74f992ba089d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    userId  movieId  prediction\n",
              "0        1     1200    9.712413\n",
              "1        1     1215    9.565120\n",
              "2        1     1036    8.949173\n",
              "3        1     1387    8.680443\n",
              "4        1      924    8.668243\n",
              "5        1      858    8.497039\n",
              "6        1      589    8.324872\n",
              "7        1     1562    8.295771\n",
              "8        1      610    8.233351\n",
              "9        1     3175    8.214261\n",
              "10       1     2288    8.089562\n",
              "11       1     1356    8.028523\n",
              "12       1     1259    8.027637\n",
              "13       1      380    7.916318\n",
              "14       1     3396    7.891645\n",
              "15       1     1022    7.869342\n",
              "16       1     1391    7.841421\n",
              "17       1     1287    7.808260\n",
              "18       1     1909    7.803876\n",
              "19       1     2081    7.788218\n",
              "20       1     2294    7.784133\n",
              "21       1     2746    7.780013\n",
              "22       1     2355    7.769999\n",
              "23       1     1304    7.749008\n",
              "24       1      849    7.745828\n",
              "25       1     2762    7.729729\n",
              "26       1     1610    7.709579\n",
              "27       1     1125    7.655711\n",
              "28       1     1923    7.654776\n",
              "29       1     2968    7.612978\n",
              "30       1     2723    7.593167\n",
              "31       1     2710    7.573452\n",
              "32       1     4571    7.565423\n",
              "33       1     1407    7.533757\n",
              "34       1     1221    7.526453\n",
              "35       1     3210    7.499311\n",
              "36       1      671    7.486251\n",
              "37       1     1370    7.477342\n",
              "38       1       34    7.456740\n",
              "39       1     1748    7.451847\n",
              "40       1     1374    7.435513\n",
              "41       1     3421    7.396968\n",
              "42       1      594    7.379936\n",
              "43       1      541    7.370810\n",
              "44       1     2890    7.369243\n",
              "45       1       10    7.365650\n",
              "46       1     2471    7.365357\n",
              "47       1     1876    7.353664\n",
              "48       1      457    7.347206\n",
              "49       1      588    7.344885"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6d8ca08f-4898-49a3-9ba3-7bfd3b7eedf1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1200</td>\n",
              "      <td>9.712413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1215</td>\n",
              "      <td>9.565120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1036</td>\n",
              "      <td>8.949173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1387</td>\n",
              "      <td>8.680443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>924</td>\n",
              "      <td>8.668243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>858</td>\n",
              "      <td>8.497039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>589</td>\n",
              "      <td>8.324872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>1562</td>\n",
              "      <td>8.295771</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>610</td>\n",
              "      <td>8.233351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>3175</td>\n",
              "      <td>8.214261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1</td>\n",
              "      <td>2288</td>\n",
              "      <td>8.089562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1</td>\n",
              "      <td>1356</td>\n",
              "      <td>8.028523</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1</td>\n",
              "      <td>1259</td>\n",
              "      <td>8.027637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1</td>\n",
              "      <td>380</td>\n",
              "      <td>7.916318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1</td>\n",
              "      <td>3396</td>\n",
              "      <td>7.891645</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1</td>\n",
              "      <td>1022</td>\n",
              "      <td>7.869342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1</td>\n",
              "      <td>1391</td>\n",
              "      <td>7.841421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1</td>\n",
              "      <td>1287</td>\n",
              "      <td>7.808260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1</td>\n",
              "      <td>1909</td>\n",
              "      <td>7.803876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1</td>\n",
              "      <td>2081</td>\n",
              "      <td>7.788218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>1</td>\n",
              "      <td>2294</td>\n",
              "      <td>7.784133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>1</td>\n",
              "      <td>2746</td>\n",
              "      <td>7.780013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>1</td>\n",
              "      <td>2355</td>\n",
              "      <td>7.769999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>1</td>\n",
              "      <td>1304</td>\n",
              "      <td>7.749008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>1</td>\n",
              "      <td>849</td>\n",
              "      <td>7.745828</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>1</td>\n",
              "      <td>2762</td>\n",
              "      <td>7.729729</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>1</td>\n",
              "      <td>1610</td>\n",
              "      <td>7.709579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>1</td>\n",
              "      <td>1125</td>\n",
              "      <td>7.655711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>1</td>\n",
              "      <td>1923</td>\n",
              "      <td>7.654776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>1</td>\n",
              "      <td>2968</td>\n",
              "      <td>7.612978</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>1</td>\n",
              "      <td>2723</td>\n",
              "      <td>7.593167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>1</td>\n",
              "      <td>2710</td>\n",
              "      <td>7.573452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>1</td>\n",
              "      <td>4571</td>\n",
              "      <td>7.565423</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>1</td>\n",
              "      <td>1407</td>\n",
              "      <td>7.533757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>1</td>\n",
              "      <td>1221</td>\n",
              "      <td>7.526453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>1</td>\n",
              "      <td>3210</td>\n",
              "      <td>7.499311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>1</td>\n",
              "      <td>671</td>\n",
              "      <td>7.486251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>1</td>\n",
              "      <td>1370</td>\n",
              "      <td>7.477342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>1</td>\n",
              "      <td>34</td>\n",
              "      <td>7.456740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>1</td>\n",
              "      <td>1748</td>\n",
              "      <td>7.451847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>1</td>\n",
              "      <td>1374</td>\n",
              "      <td>7.435513</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>1</td>\n",
              "      <td>3421</td>\n",
              "      <td>7.396968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>1</td>\n",
              "      <td>594</td>\n",
              "      <td>7.379936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>1</td>\n",
              "      <td>541</td>\n",
              "      <td>7.370810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>1</td>\n",
              "      <td>2890</td>\n",
              "      <td>7.369243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>7.365650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>1</td>\n",
              "      <td>2471</td>\n",
              "      <td>7.365357</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>1</td>\n",
              "      <td>1876</td>\n",
              "      <td>7.353664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>1</td>\n",
              "      <td>457</td>\n",
              "      <td>7.347206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>1</td>\n",
              "      <td>588</td>\n",
              "      <td>7.344885</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6d8ca08f-4898-49a3-9ba3-7bfd3b7eedf1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6d8ca08f-4898-49a3-9ba3-7bfd3b7eedf1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6d8ca08f-4898-49a3-9ba3-7bfd3b7eedf1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-8d59c87a-5046-4e0a-a242-43fa38e46bcb\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8d59c87a-5046-4e0a-a242-43fa38e46bcb')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-8d59c87a-5046-4e0a-a242-43fa38e46bcb button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "topk_scores",
              "summary": "{\n  \"name\": \"topk_scores\",\n  \"rows\": 30500,\n  \"fields\": [\n    {\n      \"column\": \"userId\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 176,\n        \"min\": 1,\n        \"max\": 610,\n        \"num_unique_values\": 610,\n        \"samples\": [\n          82,\n          219,\n          56\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"movieId\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 27099,\n        \"min\": 1,\n        \"max\": 187593,\n        \"num_unique_values\": 2069,\n        \"samples\": [\n          137857,\n          5952,\n          4638\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prediction\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 30451,\n        \"samples\": [\n          6.42027473449707,\n          9.273921966552734,\n          5.652397155761719\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Evaluasi"
      ],
      "metadata": {
        "id": "MbBLhhxBYnCE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval_ndcg = ndcg_at_k(test, topk_scores, k=TOP_K)\n",
        "eval_recall = recall_at_k(test, topk_scores, k=TOP_K)\n",
        "\n",
        "print(\"NDCG:\\t%f\" % eval_ndcg,\n",
        "      \"Recall@K:\\t%f\" % eval_recall, sep='\\n')"
      ],
      "metadata": {
        "id": "YatNsY1PYotH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28909f9c-718d-478b-99d6-71ea8ab4e033"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NDCG:\t0.211797\n",
            "Recall@K:\t0.046109\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright (c) Recommenders contributors.\n",
        "# Licensed under the MIT License.\n",
        "\n",
        "import os\n",
        "import re\n",
        "import nbformat\n",
        "from nbconvert.preprocessors import ExecutePreprocessor\n",
        "from IPython.display import display\n",
        "\n",
        "\n",
        "NOTEBOOK_OUTPUT_CONTENT_TYPE = \"application/notebook_utils.json+json\"\n",
        "def store_metadata(name, value):\n",
        "    \"\"\"Store data in the notebook's output source code.\n",
        "\n",
        "    Args:\n",
        "        name (str): Name of the data.\n",
        "        value (int,float,str): Value of the data.\n",
        "    \"\"\"\n",
        "\n",
        "    metadata = {\"notebook_utils\": {\"name\": name, \"data\": True, \"display\": False}}\n",
        "    data_json = {\n",
        "        \"application/notebook_utils.json+json\": {\n",
        "            \"name\": name,\n",
        "            \"data\": value,\n",
        "            \"encoder\": \"json\",\n",
        "        }\n",
        "    }\n",
        "    display(data_json, metadata=metadata, raw=True)"
      ],
      "metadata": {
        "id": "Zuu_Rjqml3lR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Record results for tests - ignore this cell\n",
        "store_metadata(\"ndcg\", eval_ndcg)\n",
        "store_metadata(\"recall\", eval_recall)"
      ],
      "metadata": {
        "id": "RKSpYWoul4j_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83e65c1e-d0c4-4a3c-90ad-fb547ef4155e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/notebook_utils.json+json": {
              "name": "ndcg",
              "data": 0.21179685910664497,
              "encoder": "json"
            }
          },
          "metadata": {
            "notebook_utils": {
              "name": "ndcg",
              "data": true,
              "display": false
            }
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/notebook_utils.json+json": {
              "name": "recall",
              "data": 0.04610884582053135,
              "encoder": "json"
            }
          },
          "metadata": {
            "notebook_utils": {
              "name": "recall",
              "data": true,
              "display": false
            }
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Infer Embedding"
      ],
      "metadata": {
        "id": "4cwf58nRY4IN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.infer_embedding(user_file, item_file)"
      ],
      "metadata": {
        "id": "qr0aAfOoY59R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Kombinasi Hyperparameter terbaik"
      ],
      "metadata": {
        "id": "-Hy1o4t6GjqT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definisikan daftar nilai yang ingin Anda coba untuk setiap hyperparameter\n",
        "epochs_to_try = [25, 50, 100] # Contoh nilai, sesuaikan sesuai kebutuhan Anda\n",
        "topks_to_try = [10, 20, 50]   # Contoh nilai\n",
        "learning_rates_to_try = [0.005, 0.05, 0.5] # Contoh nilai\n",
        "n_layers_to_try = [3, 4, 5] # Contoh nilai untuk jumlah layer\n",
        "\n",
        "# Dictionary untuk menyimpan hasil evaluasi dari setiap kombinasi\n",
        "evaluation_results = {}\n",
        "\n",
        "# Mapping n_layers ke file YAML yang sesuai\n",
        "yaml_file_mapping = {\n",
        "    3: yaml3_file,\n",
        "    4: yaml4_file,\n",
        "    5: yaml5_file\n",
        "}\n",
        "\n",
        "# Mulai pencarian grid\n",
        "for epoch_val in epochs_to_try:\n",
        "    for topk_val in topks_to_try:\n",
        "        for lr_val in learning_rates_to_try:\n",
        "            for layers_val in n_layers_to_try:\n",
        "\n",
        "                print(f\"--- Trying combination: Epochs={epoch_val}, TopK={topk_val}, LearningRate={lr_val}, Layers={layers_val} ---\")\n",
        "\n",
        "                # Dapatkan yaml_file yang sesuai berdasarkan layers_val\n",
        "                current_yaml_file = yaml_file_mapping.get(layers_val)\n",
        "                if current_yaml_file is None:\n",
        "                    print(f\"Warning: No YAML file defined for {layers_val} layers. Skipping this combination.\")\n",
        "                    continue # Lewati kombinasi ini jika tidak ada file YAML yang sesuai\n",
        "\n",
        "                # Persiapkan hparams dengan kombinasi saat ini\n",
        "                current_hparams = prepare_hparams(current_yaml_file, # Gunakan yaml_file yang sesuai\n",
        "                                                  n_layers=layers_val,\n",
        "                                                  batch_size=BATCH_SIZE,\n",
        "                                                  epochs=epoch_val,\n",
        "                                                  learning_rate=lr_val,\n",
        "                                                  eval_epoch=5,\n",
        "                                                  top_k=topk_val\n",
        "                                                 )\n",
        "\n",
        "                # Inisialisasi model LightGCN dengan hparams baru\n",
        "                model = LightGCN(current_hparams, data, seed=SEED)\n",
        "\n",
        "                # Latih model\n",
        "                with Timer() as train_time:\n",
        "                    model.fit()\n",
        "\n",
        "                print(f\"Training finished in {train_time.interval:.2f} seconds.\")\n",
        "\n",
        "                # Evaluasi model pada dataset test\n",
        "                topk_scores = model.recommend_k_items(test, top_k=topk_val, remove_seen=True)\n",
        "\n",
        "                eval_ndcg = ndcg_at_k(test, topk_scores, k=topk_val)\n",
        "                eval_recall = recall_at_k(test, topk_scores, k=topk_val)\n",
        "\n",
        "                print(f\"Evaluation results for this combination: NDCG@{topk_val}: {eval_ndcg:.5f}, Recall@{topk_val}: {eval_recall:.5f}\")\n",
        "\n",
        "                # Simpan hasil evaluasi\n",
        "                combination_key = f\"Epochs={epoch_val}_TopK={topk_val}_LR={lr_val}_Layers={layers_val}\"\n",
        "                evaluation_results[combination_key] = {\n",
        "                    'ndcg': eval_ndcg,\n",
        "                    'recall': eval_recall,\n",
        "                    'train_time': train_time.interval\n",
        "                }\n",
        "\n",
        "# Setelah semua kombinasi diuji, cetak ringkasan hasil\n",
        "print(\"\\n===== Hyperparameter Tuning Summary =====\")\n",
        "for combo, metrics in evaluation_results.items():\n",
        "    print(f\"{combo}: NDCG={metrics['ndcg']:.5f}, Recall={metrics['recall']:.5f}, TrainTime={metrics['train_time']:.2f}s\")\n",
        "\n",
        "# Anda dapat menganalisis 'evaluation_results' dictionary untuk menemukan kombinasi terbaik\n",
        "best_combination = max(evaluation_results, key=lambda k: evaluation_results[k]['ndcg'])\n",
        "print(f\"\\nBest combination based on NDCG: {best_combination}\")\n",
        "print(f\"NDCG: {evaluation_results[best_combination]['ndcg']:.5f}\")\n",
        "print(f\"Recall: {evaluation_results[best_combination]['recall']:.5f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96mIUSE8-eMJ",
        "outputId": "c548f024-6cef-42b8-f531-ea83c22f1db5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mOutput streaming akan dipotong hingga 5000 baris terakhir.\u001b[0m\n",
            "Epoch 5 (train)2.3s + (eval)0.5s: train loss = 2.31665 = (mf)1.34408 + (embed)0.97257, recall = 0.00781, ndcg = 0.15178\n",
            "Epoch 6 (train)2.9s: train loss = 2.42049 = (mf)1.34321 + (embed)1.07728\n",
            "Epoch 7 (train)2.3s: train loss = 2.63196 = (mf)1.46021 + (embed)1.17175\n",
            "Epoch 8 (train)2.3s: train loss = 2.71630 = (mf)1.46606 + (embed)1.25023\n",
            "Epoch 9 (train)2.3s: train loss = 2.76217 = (mf)1.45020 + (embed)1.31197\n",
            "Epoch 10 (train)2.4s + (eval)0.6s: train loss = 2.75561 = (mf)1.39844 + (embed)1.35717, recall = 0.00810, ndcg = 0.13781\n",
            "Epoch 11 (train)2.7s: train loss = 2.87546 = (mf)1.46445 + (embed)1.41101\n",
            "Epoch 12 (train)2.3s: train loss = 2.86540 = (mf)1.41492 + (embed)1.45048\n",
            "Epoch 13 (train)2.3s: train loss = 2.84148 = (mf)1.35913 + (embed)1.48235\n",
            "Epoch 14 (train)2.3s: train loss = 2.83239 = (mf)1.32561 + (embed)1.50678\n",
            "Epoch 15 (train)2.6s + (eval)0.4s: train loss = 2.90723 = (mf)1.37486 + (embed)1.53237, recall = 0.00748, ndcg = 0.13339\n",
            "Epoch 16 (train)2.6s: train loss = 2.93445 = (mf)1.37012 + (embed)1.56432\n",
            "Epoch 17 (train)2.3s: train loss = 3.01337 = (mf)1.41653 + (embed)1.59684\n",
            "Epoch 18 (train)2.3s: train loss = 2.96085 = (mf)1.33700 + (embed)1.62385\n",
            "Epoch 19 (train)2.3s: train loss = 2.93110 = (mf)1.29659 + (embed)1.63451\n",
            "Epoch 20 (train)2.6s + (eval)0.7s: train loss = 2.98152 = (mf)1.34001 + (embed)1.64152, recall = 0.00756, ndcg = 0.11420\n",
            "Epoch 21 (train)2.4s: train loss = 2.96481 = (mf)1.31881 + (embed)1.64600\n",
            "Epoch 22 (train)2.3s: train loss = 3.02077 = (mf)1.35105 + (embed)1.66972\n",
            "Epoch 23 (train)2.3s: train loss = 2.93094 = (mf)1.25230 + (embed)1.67864\n",
            "Epoch 24 (train)2.3s: train loss = 2.99095 = (mf)1.29979 + (embed)1.69116\n",
            "Epoch 25 (train)2.8s + (eval)0.2s: train loss = 2.97937 = (mf)1.27544 + (embed)1.70393, recall = 0.00792, ndcg = 0.13808\n",
            "Training finished in 63.70 seconds.\n",
            "Evaluation results for this combination: NDCG@10: 0.13808, Recall@10: 0.00792\n",
            "--- Trying combination: Epochs=25, TopK=10, LearningRate=0.5, Layers=5 ---\n",
            "Already normalize adjacency matrix (extended).\n",
            "Using xavier initialization for user, item, and genre embeddings.\n",
            "Epoch 1 (train)3.0s: train loss = 0.47436 = (mf)0.34687 + (embed)0.12749\n",
            "Epoch 2 (train)2.4s: train loss = 0.92055 = (mf)0.54471 + (embed)0.37584\n",
            "Epoch 3 (train)2.6s: train loss = 1.28162 = (mf)0.71646 + (embed)0.56517\n",
            "Epoch 4 (train)2.6s: train loss = 1.54710 = (mf)0.83502 + (embed)0.71208\n",
            "Epoch 5 (train)2.4s + (eval)0.4s: train loss = 1.66614 = (mf)0.84118 + (embed)0.82496, recall = 0.00743, ndcg = 0.14477\n",
            "Epoch 6 (train)2.4s: train loss = 1.81040 = (mf)0.90978 + (embed)0.90062\n",
            "Epoch 7 (train)2.4s: train loss = 1.85225 = (mf)0.88889 + (embed)0.96336\n",
            "Epoch 8 (train)2.9s: train loss = 1.93631 = (mf)0.92215 + (embed)1.01416\n",
            "Epoch 9 (train)2.4s: train loss = 2.01809 = (mf)0.95940 + (embed)1.05869\n",
            "Epoch 10 (train)2.4s + (eval)0.5s: train loss = 2.03985 = (mf)0.94142 + (embed)1.09843, recall = 0.00692, ndcg = 0.14394\n",
            "Epoch 11 (train)2.4s: train loss = 2.01742 = (mf)0.89045 + (embed)1.12698\n",
            "Epoch 12 (train)2.6s: train loss = 1.99918 = (mf)0.84386 + (embed)1.15532\n",
            "Epoch 13 (train)2.8s: train loss = 2.05589 = (mf)0.88120 + (embed)1.17470\n",
            "Epoch 14 (train)2.4s: train loss = 2.06822 = (mf)0.87322 + (embed)1.19500\n",
            "Epoch 15 (train)2.4s + (eval)0.2s: train loss = 2.04105 = (mf)0.83417 + (embed)1.20688, recall = 0.00735, ndcg = 0.09972\n",
            "Epoch 16 (train)2.4s: train loss = 2.06369 = (mf)0.84180 + (embed)1.22190\n",
            "Epoch 17 (train)2.8s: train loss = 2.08692 = (mf)0.85334 + (embed)1.23358\n",
            "Epoch 18 (train)2.5s: train loss = 2.03164 = (mf)0.78926 + (embed)1.24238\n",
            "Epoch 19 (train)2.4s: train loss = 2.10060 = (mf)0.84935 + (embed)1.25124\n",
            "Epoch 20 (train)2.4s + (eval)0.2s: train loss = 2.04770 = (mf)0.79378 + (embed)1.25392, recall = 0.00827, ndcg = 0.13301\n",
            "Epoch 21 (train)2.4s: train loss = 2.03450 = (mf)0.77838 + (embed)1.25612\n",
            "Epoch 22 (train)2.9s: train loss = 2.05887 = (mf)0.79904 + (embed)1.25983\n",
            "Epoch 23 (train)2.4s: train loss = 2.02815 = (mf)0.76321 + (embed)1.26494\n",
            "Epoch 24 (train)2.4s: train loss = 2.02482 = (mf)0.76149 + (embed)1.26333\n",
            "Epoch 25 (train)2.4s + (eval)0.5s: train loss = 2.00263 = (mf)0.74705 + (embed)1.25559, recall = 0.00764, ndcg = 0.13142\n",
            "Training finished in 64.98 seconds.\n",
            "Evaluation results for this combination: NDCG@10: 0.13142, Recall@10: 0.00764\n",
            "--- Trying combination: Epochs=25, TopK=20, LearningRate=0.005, Layers=3 ---\n",
            "Already normalize adjacency matrix (extended).\n",
            "Using xavier initialization for user, item, and genre embeddings.\n",
            "Epoch 1 (train)3.1s: train loss = 0.29282 = (mf)0.29226 + (embed)0.00055\n",
            "Epoch 2 (train)2.3s: train loss = 0.19267 = (mf)0.19172 + (embed)0.00096\n",
            "Epoch 3 (train)2.3s: train loss = 0.15615 = (mf)0.15478 + (embed)0.00136\n",
            "Epoch 4 (train)2.3s: train loss = 0.13454 = (mf)0.13275 + (embed)0.00179\n",
            "Epoch 5 (train)2.8s + (eval)0.4s: train loss = 0.12149 = (mf)0.11935 + (embed)0.00214, recall = 0.01692, ndcg = 0.17706\n",
            "Epoch 6 (train)2.3s: train loss = 0.10690 = (mf)0.10436 + (embed)0.00254\n",
            "Epoch 7 (train)2.3s: train loss = 0.09710 = (mf)0.09415 + (embed)0.00295\n",
            "Epoch 8 (train)2.3s: train loss = 0.08591 = (mf)0.08252 + (embed)0.00339\n",
            "Epoch 9 (train)2.3s: train loss = 0.07926 = (mf)0.07545 + (embed)0.00381\n",
            "Epoch 10 (train)2.8s + (eval)0.5s: train loss = 0.07232 = (mf)0.06811 + (embed)0.00421, recall = 0.02271, ndcg = 0.22987\n",
            "Epoch 11 (train)2.3s: train loss = 0.06733 = (mf)0.06272 + (embed)0.00461\n",
            "Epoch 12 (train)2.3s: train loss = 0.06301 = (mf)0.05805 + (embed)0.00496\n",
            "Epoch 13 (train)2.3s: train loss = 0.05909 = (mf)0.05378 + (embed)0.00531\n",
            "Epoch 14 (train)2.3s: train loss = 0.05476 = (mf)0.04911 + (embed)0.00566\n",
            "Epoch 15 (train)2.7s + (eval)0.2s: train loss = 0.05230 = (mf)0.04636 + (embed)0.00594, recall = 0.02538, ndcg = 0.24029\n",
            "Epoch 16 (train)2.3s: train loss = 0.04946 = (mf)0.04325 + (embed)0.00621\n",
            "Epoch 17 (train)2.3s: train loss = 0.04705 = (mf)0.04058 + (embed)0.00648\n",
            "Epoch 18 (train)2.3s: train loss = 0.04601 = (mf)0.03930 + (embed)0.00671\n",
            "Epoch 19 (train)2.4s: train loss = 0.04382 = (mf)0.03689 + (embed)0.00693\n",
            "Epoch 20 (train)2.7s + (eval)0.5s: train loss = 0.04305 = (mf)0.03590 + (embed)0.00715, recall = 0.02624, ndcg = 0.25772\n",
            "Epoch 21 (train)2.3s: train loss = 0.04101 = (mf)0.03368 + (embed)0.00733\n",
            "Epoch 22 (train)2.3s: train loss = 0.04085 = (mf)0.03334 + (embed)0.00752\n",
            "Epoch 23 (train)2.3s: train loss = 0.03837 = (mf)0.03070 + (embed)0.00768\n",
            "Epoch 24 (train)2.7s: train loss = 0.03735 = (mf)0.02952 + (embed)0.00783\n",
            "Epoch 25 (train)2.5s + (eval)0.3s: train loss = 0.03639 = (mf)0.02841 + (embed)0.00798, recall = 0.02740, ndcg = 0.25783\n",
            "Training finished in 62.58 seconds.\n",
            "Evaluation results for this combination: NDCG@20: 0.25783, Recall@20: 0.02740\n",
            "--- Trying combination: Epochs=25, TopK=20, LearningRate=0.005, Layers=4 ---\n",
            "Already normalize adjacency matrix (extended).\n",
            "Using xavier initialization for user, item, and genre embeddings.\n",
            "Epoch 1 (train)3.0s: train loss = 0.29584 = (mf)0.29526 + (embed)0.00058\n",
            "Epoch 2 (train)2.4s: train loss = 0.20340 = (mf)0.20240 + (embed)0.00100\n",
            "Epoch 3 (train)2.9s: train loss = 0.18320 = (mf)0.18182 + (embed)0.00138\n",
            "Epoch 4 (train)2.4s: train loss = 0.15389 = (mf)0.15197 + (embed)0.00192\n",
            "Epoch 5 (train)2.4s + (eval)0.7s: train loss = 0.13216 = (mf)0.12970 + (embed)0.00246, recall = 0.01605, ndcg = 0.17096\n",
            "Epoch 6 (train)2.4s: train loss = 0.12233 = (mf)0.11942 + (embed)0.00291\n",
            "Epoch 7 (train)2.8s: train loss = 0.11245 = (mf)0.10914 + (embed)0.00332\n",
            "Epoch 8 (train)2.5s: train loss = 0.10514 = (mf)0.10141 + (embed)0.00373\n",
            "Epoch 9 (train)2.3s: train loss = 0.09745 = (mf)0.09330 + (embed)0.00415\n",
            "Epoch 10 (train)2.3s + (eval)0.3s: train loss = 0.09079 = (mf)0.08618 + (embed)0.00461, recall = 0.01975, ndcg = 0.21313\n",
            "Epoch 11 (train)2.3s: train loss = 0.08470 = (mf)0.07963 + (embed)0.00507\n",
            "Epoch 12 (train)2.9s: train loss = 0.07957 = (mf)0.07403 + (embed)0.00554\n",
            "Epoch 13 (train)2.4s: train loss = 0.07381 = (mf)0.06781 + (embed)0.00600\n",
            "Epoch 14 (train)2.3s: train loss = 0.07085 = (mf)0.06444 + (embed)0.00640\n",
            "Epoch 15 (train)2.3s + (eval)0.5s: train loss = 0.06776 = (mf)0.06097 + (embed)0.00679, recall = 0.02452, ndcg = 0.24498\n",
            "Epoch 16 (train)2.6s: train loss = 0.06355 = (mf)0.05641 + (embed)0.00714\n",
            "Epoch 17 (train)3.5s: train loss = 0.06106 = (mf)0.05358 + (embed)0.00748\n",
            "Epoch 18 (train)2.3s: train loss = 0.05953 = (mf)0.05177 + (embed)0.00777\n",
            "Epoch 19 (train)2.3s: train loss = 0.05739 = (mf)0.04935 + (embed)0.00804\n",
            "Epoch 20 (train)2.3s + (eval)0.3s: train loss = 0.05485 = (mf)0.04656 + (embed)0.00830, recall = 0.02630, ndcg = 0.24902\n",
            "Epoch 21 (train)2.7s: train loss = 0.05309 = (mf)0.04452 + (embed)0.00857\n",
            "Epoch 22 (train)2.6s: train loss = 0.05136 = (mf)0.04256 + (embed)0.00880\n",
            "Epoch 23 (train)2.3s: train loss = 0.04924 = (mf)0.04021 + (embed)0.00903\n",
            "Epoch 24 (train)2.3s: train loss = 0.04842 = (mf)0.03918 + (embed)0.00924\n",
            "Epoch 25 (train)2.3s + (eval)0.5s: train loss = 0.04718 = (mf)0.03775 + (embed)0.00943, recall = 0.02681, ndcg = 0.26116\n",
            "Training finished in 64.93 seconds.\n",
            "Evaluation results for this combination: NDCG@20: 0.26116, Recall@20: 0.02681\n",
            "--- Trying combination: Epochs=25, TopK=20, LearningRate=0.005, Layers=5 ---\n",
            "Already normalize adjacency matrix (extended).\n",
            "Using xavier initialization for user, item, and genre embeddings.\n",
            "Epoch 1 (train)3.1s: train loss = 0.29842 = (mf)0.29783 + (embed)0.00059\n",
            "Epoch 2 (train)2.4s: train loss = 0.21246 = (mf)0.21142 + (embed)0.00104\n",
            "Epoch 3 (train)2.4s: train loss = 0.19496 = (mf)0.19349 + (embed)0.00147\n",
            "Epoch 4 (train)2.7s: train loss = 0.16980 = (mf)0.16773 + (embed)0.00207\n",
            "Epoch 5 (train)2.6s + (eval)0.4s: train loss = 0.15236 = (mf)0.14966 + (embed)0.00270, recall = 0.01614, ndcg = 0.16818\n",
            "Epoch 6 (train)2.4s: train loss = 0.13927 = (mf)0.13609 + (embed)0.00319\n",
            "Epoch 7 (train)2.4s: train loss = 0.13212 = (mf)0.12850 + (embed)0.00362\n",
            "Epoch 8 (train)2.4s: train loss = 0.12380 = (mf)0.11977 + (embed)0.00404\n",
            "Epoch 9 (train)2.9s: train loss = 0.11701 = (mf)0.11248 + (embed)0.00453\n",
            "Epoch 10 (train)2.4s + (eval)0.5s: train loss = 0.10851 = (mf)0.10345 + (embed)0.00506, recall = 0.01956, ndcg = 0.20404\n",
            "Epoch 11 (train)2.4s: train loss = 0.10210 = (mf)0.09653 + (embed)0.00557\n",
            "Epoch 12 (train)2.4s: train loss = 0.09660 = (mf)0.09050 + (embed)0.00610\n",
            "Epoch 13 (train)2.6s: train loss = 0.09098 = (mf)0.08438 + (embed)0.00660\n",
            "Epoch 14 (train)2.7s: train loss = 0.08610 = (mf)0.07899 + (embed)0.00711\n",
            "Epoch 15 (train)2.4s + (eval)0.2s: train loss = 0.08305 = (mf)0.07548 + (embed)0.00756, recall = 0.02255, ndcg = 0.23818\n",
            "Epoch 16 (train)2.4s: train loss = 0.07766 = (mf)0.06962 + (embed)0.00804\n",
            "Epoch 17 (train)2.4s: train loss = 0.07436 = (mf)0.06592 + (embed)0.00844\n",
            "Epoch 18 (train)2.8s: train loss = 0.07280 = (mf)0.06401 + (embed)0.00880\n",
            "Epoch 19 (train)2.4s: train loss = 0.06925 = (mf)0.06010 + (embed)0.00914\n",
            "Epoch 20 (train)2.4s + (eval)0.5s: train loss = 0.06640 = (mf)0.05692 + (embed)0.00948, recall = 0.02514, ndcg = 0.24291\n",
            "Epoch 21 (train)2.4s: train loss = 0.06545 = (mf)0.05567 + (embed)0.00978\n",
            "Epoch 22 (train)2.4s: train loss = 0.06387 = (mf)0.05381 + (embed)0.01006\n",
            "Epoch 23 (train)2.9s: train loss = 0.06316 = (mf)0.05285 + (embed)0.01030\n",
            "Epoch 24 (train)2.4s: train loss = 0.05911 = (mf)0.04855 + (embed)0.01055\n",
            "Epoch 25 (train)2.4s + (eval)0.2s: train loss = 0.05820 = (mf)0.04744 + (embed)0.01076, recall = 0.02562, ndcg = 0.25813\n",
            "Training finished in 64.82 seconds.\n",
            "Evaluation results for this combination: NDCG@20: 0.25813, Recall@20: 0.02562\n",
            "--- Trying combination: Epochs=25, TopK=20, LearningRate=0.05, Layers=3 ---\n",
            "Already normalize adjacency matrix (extended).\n",
            "Using xavier initialization for user, item, and genre embeddings.\n",
            "Epoch 1 (train)3.3s: train loss = 0.15502 = (mf)0.15176 + (embed)0.00326\n",
            "Epoch 2 (train)2.4s: train loss = 0.07031 = (mf)0.06243 + (embed)0.00787\n",
            "Epoch 3 (train)2.3s: train loss = 0.05557 = (mf)0.04448 + (embed)0.01109\n",
            "Epoch 4 (train)2.3s: train loss = 0.04997 = (mf)0.03662 + (embed)0.01335\n",
            "Epoch 5 (train)2.3s + (eval)0.4s: train loss = 0.04852 = (mf)0.03348 + (embed)0.01504, recall = 0.02103, ndcg = 0.17843\n",
            "Epoch 6 (train)2.8s: train loss = 0.04617 = (mf)0.02969 + (embed)0.01648\n",
            "Epoch 7 (train)2.3s: train loss = 0.04526 = (mf)0.02763 + (embed)0.01762\n",
            "Epoch 8 (train)2.3s: train loss = 0.04549 = (mf)0.02684 + (embed)0.01865\n",
            "Epoch 9 (train)2.3s: train loss = 0.04537 = (mf)0.02586 + (embed)0.01951\n",
            "Epoch 10 (train)2.3s + (eval)0.7s: train loss = 0.04569 = (mf)0.02538 + (embed)0.02031, recall = 0.02011, ndcg = 0.16677\n",
            "Epoch 11 (train)2.7s: train loss = 0.04553 = (mf)0.02449 + (embed)0.02104\n",
            "Epoch 12 (train)2.3s: train loss = 0.04781 = (mf)0.02607 + (embed)0.02174\n",
            "Epoch 13 (train)2.3s: train loss = 0.04800 = (mf)0.02558 + (embed)0.02242\n",
            "Epoch 14 (train)2.3s: train loss = 0.04738 = (mf)0.02437 + (embed)0.02301\n",
            "Epoch 15 (train)2.5s + (eval)0.4s: train loss = 0.04764 = (mf)0.02422 + (embed)0.02342, recall = 0.02032, ndcg = 0.18007\n",
            "Epoch 16 (train)2.6s: train loss = 0.04750 = (mf)0.02377 + (embed)0.02374\n",
            "Epoch 17 (train)2.3s: train loss = 0.04693 = (mf)0.02294 + (embed)0.02399\n",
            "Epoch 18 (train)2.3s: train loss = 0.04680 = (mf)0.02249 + (embed)0.02431\n",
            "Epoch 19 (train)2.3s: train loss = 0.04839 = (mf)0.02379 + (embed)0.02460\n",
            "Epoch 20 (train)2.6s + (eval)0.7s: train loss = 0.04918 = (mf)0.02407 + (embed)0.02511, recall = 0.01845, ndcg = 0.15590\n",
            "Epoch 21 (train)2.4s: train loss = 0.04920 = (mf)0.02362 + (embed)0.02558\n",
            "Epoch 22 (train)2.3s: train loss = 0.04743 = (mf)0.02169 + (embed)0.02574\n",
            "Epoch 23 (train)2.3s: train loss = 0.04869 = (mf)0.02271 + (embed)0.02598\n",
            "Epoch 24 (train)2.3s: train loss = 0.04893 = (mf)0.02268 + (embed)0.02625\n",
            "Epoch 25 (train)2.8s + (eval)0.2s: train loss = 0.04821 = (mf)0.02190 + (embed)0.02631, recall = 0.01954, ndcg = 0.17009\n",
            "Training finished in 63.17 seconds.\n",
            "Evaluation results for this combination: NDCG@20: 0.17009, Recall@20: 0.01954\n",
            "--- Trying combination: Epochs=25, TopK=20, LearningRate=0.05, Layers=4 ---\n",
            "Already normalize adjacency matrix (extended).\n",
            "Using xavier initialization for user, item, and genre embeddings.\n",
            "Epoch 1 (train)3.0s: train loss = 0.16469 = (mf)0.16133 + (embed)0.00336\n",
            "Epoch 2 (train)2.3s: train loss = 0.08062 = (mf)0.07237 + (embed)0.00825\n",
            "Epoch 3 (train)2.6s: train loss = 0.06007 = (mf)0.04817 + (embed)0.01190\n",
            "Epoch 4 (train)2.6s: train loss = 0.05246 = (mf)0.03804 + (embed)0.01442\n",
            "Epoch 5 (train)2.3s + (eval)0.7s: train loss = 0.04905 = (mf)0.03285 + (embed)0.01621, recall = 0.02312, ndcg = 0.22823\n",
            "Epoch 6 (train)2.4s: train loss = 0.04582 = (mf)0.02821 + (embed)0.01761\n",
            "Epoch 7 (train)2.3s: train loss = 0.04545 = (mf)0.02672 + (embed)0.01873\n",
            "Epoch 8 (train)2.8s: train loss = 0.04351 = (mf)0.02392 + (embed)0.01959\n",
            "Epoch 9 (train)2.3s: train loss = 0.04229 = (mf)0.02206 + (embed)0.02023\n",
            "Epoch 10 (train)2.3s + (eval)0.3s: train loss = 0.04242 = (mf)0.02164 + (embed)0.02078, recall = 0.02371, ndcg = 0.21751\n",
            "Epoch 11 (train)2.3s: train loss = 0.04294 = (mf)0.02170 + (embed)0.02124\n",
            "Epoch 12 (train)2.3s: train loss = 0.04144 = (mf)0.01974 + (embed)0.02169\n",
            "Epoch 13 (train)2.9s: train loss = 0.04220 = (mf)0.02015 + (embed)0.02205\n",
            "Epoch 14 (train)2.3s: train loss = 0.04068 = (mf)0.01826 + (embed)0.02242\n",
            "Epoch 15 (train)2.3s + (eval)0.5s: train loss = 0.04150 = (mf)0.01877 + (embed)0.02273, recall = 0.02151, ndcg = 0.21927\n",
            "Epoch 16 (train)2.3s: train loss = 0.04211 = (mf)0.01916 + (embed)0.02294\n",
            "Epoch 17 (train)2.5s: train loss = 0.04055 = (mf)0.01739 + (embed)0.02316\n",
            "Epoch 18 (train)2.7s: train loss = 0.04056 = (mf)0.01727 + (embed)0.02329\n",
            "Epoch 19 (train)2.3s: train loss = 0.04061 = (mf)0.01713 + (embed)0.02348\n",
            "Epoch 20 (train)2.3s + (eval)0.2s: train loss = 0.04072 = (mf)0.01709 + (embed)0.02363, recall = 0.02233, ndcg = 0.21561\n",
            "Epoch 21 (train)2.3s: train loss = 0.04062 = (mf)0.01688 + (embed)0.02374\n",
            "Epoch 22 (train)2.7s: train loss = 0.04022 = (mf)0.01638 + (embed)0.02384\n",
            "Epoch 23 (train)2.5s: train loss = 0.04117 = (mf)0.01718 + (embed)0.02399\n",
            "Epoch 24 (train)2.3s: train loss = 0.04084 = (mf)0.01661 + (embed)0.02423\n",
            "Epoch 25 (train)2.3s + (eval)0.2s: train loss = 0.04092 = (mf)0.01659 + (embed)0.02434, recall = 0.02163, ndcg = 0.19025\n",
            "Training finished in 63.38 seconds.\n",
            "Evaluation results for this combination: NDCG@20: 0.19025, Recall@20: 0.02163\n",
            "--- Trying combination: Epochs=25, TopK=20, LearningRate=0.05, Layers=5 ---\n",
            "Already normalize adjacency matrix (extended).\n",
            "Using xavier initialization for user, item, and genre embeddings.\n",
            "Epoch 1 (train)3.7s: train loss = 0.17603 = (mf)0.17224 + (embed)0.00379\n",
            "Epoch 2 (train)2.4s: train loss = 0.09345 = (mf)0.08436 + (embed)0.00909\n",
            "Epoch 3 (train)2.4s: train loss = 0.07329 = (mf)0.06033 + (embed)0.01295\n",
            "Epoch 4 (train)2.4s: train loss = 0.06159 = (mf)0.04592 + (embed)0.01567\n",
            "Epoch 5 (train)2.7s + (eval)0.8s: train loss = 0.05680 = (mf)0.03917 + (embed)0.01763, recall = 0.02287, ndcg = 0.20748\n",
            "Epoch 6 (train)2.5s: train loss = 0.05192 = (mf)0.03290 + (embed)0.01902\n",
            "Epoch 7 (train)2.4s: train loss = 0.05005 = (mf)0.03007 + (embed)0.01997\n",
            "Epoch 8 (train)2.4s: train loss = 0.04783 = (mf)0.02701 + (embed)0.02082\n",
            "Epoch 9 (train)2.4s: train loss = 0.04642 = (mf)0.02500 + (embed)0.02142\n",
            "Epoch 10 (train)2.9s + (eval)0.2s: train loss = 0.04453 = (mf)0.02269 + (embed)0.02184, recall = 0.02356, ndcg = 0.22128\n",
            "Epoch 11 (train)2.4s: train loss = 0.04451 = (mf)0.02225 + (embed)0.02226\n",
            "Epoch 12 (train)2.6s: train loss = 0.04406 = (mf)0.02147 + (embed)0.02260\n",
            "Epoch 13 (train)2.6s: train loss = 0.04370 = (mf)0.02065 + (embed)0.02305\n",
            "Epoch 14 (train)2.8s: train loss = 0.04325 = (mf)0.02003 + (embed)0.02322\n",
            "Epoch 15 (train)2.5s + (eval)0.5s: train loss = 0.04275 = (mf)0.01911 + (embed)0.02363, recall = 0.02450, ndcg = 0.22114\n",
            "Epoch 16 (train)2.4s: train loss = 0.04336 = (mf)0.01956 + (embed)0.02380\n",
            "Epoch 17 (train)2.4s: train loss = 0.04231 = (mf)0.01826 + (embed)0.02405\n",
            "Epoch 18 (train)2.4s: train loss = 0.04172 = (mf)0.01755 + (embed)0.02416\n",
            "Epoch 19 (train)2.9s: train loss = 0.04251 = (mf)0.01818 + (embed)0.02433\n",
            "Epoch 20 (train)2.4s + (eval)0.2s: train loss = 0.04161 = (mf)0.01706 + (embed)0.02455, recall = 0.02302, ndcg = 0.22699\n",
            "Epoch 21 (train)2.4s: train loss = 0.04207 = (mf)0.01741 + (embed)0.02466\n",
            "Epoch 22 (train)2.4s: train loss = 0.04193 = (mf)0.01711 + (embed)0.02482\n",
            "Epoch 23 (train)2.7s: train loss = 0.04128 = (mf)0.01645 + (embed)0.02484\n",
            "Epoch 24 (train)2.6s: train loss = 0.04091 = (mf)0.01595 + (embed)0.02496\n",
            "Epoch 25 (train)2.4s + (eval)0.5s: train loss = 0.04111 = (mf)0.01608 + (embed)0.02504, recall = 0.02494, ndcg = 0.23419\n",
            "Training finished in 66.50 seconds.\n",
            "Evaluation results for this combination: NDCG@20: 0.23419, Recall@20: 0.02494\n",
            "--- Trying combination: Epochs=25, TopK=20, LearningRate=0.5, Layers=3 ---\n",
            "Already normalize adjacency matrix (extended).\n",
            "Using xavier initialization for user, item, and genre embeddings.\n",
            "Epoch 1 (train)3.0s: train loss = 0.95072 = (mf)0.77674 + (embed)0.17398\n",
            "Epoch 2 (train)2.7s: train loss = 2.03859 = (mf)1.52605 + (embed)0.51254\n",
            "Epoch 3 (train)2.3s: train loss = 2.77266 = (mf)1.98513 + (embed)0.78752\n",
            "Epoch 4 (train)2.3s: train loss = 3.07402 = (mf)2.08521 + (embed)0.98881\n",
            "Epoch 5 (train)2.3s + (eval)0.7s: train loss = 3.44637 = (mf)2.28886 + (embed)1.15751, recall = 0.01329, ndcg = 0.11820\n",
            "Epoch 6 (train)2.8s: train loss = 3.68172 = (mf)2.37557 + (embed)1.30615\n",
            "Epoch 7 (train)2.4s: train loss = 3.88186 = (mf)2.44419 + (embed)1.43767\n",
            "Epoch 8 (train)2.3s: train loss = 4.00313 = (mf)2.45643 + (embed)1.54670\n",
            "Epoch 9 (train)2.3s: train loss = 4.07454 = (mf)2.44008 + (embed)1.63446\n",
            "Epoch 10 (train)2.3s + (eval)0.3s: train loss = 4.22247 = (mf)2.49948 + (embed)1.72300, recall = 0.01688, ndcg = 0.14714\n",
            "Epoch 11 (train)2.8s: train loss = 4.40464 = (mf)2.60360 + (embed)1.80104\n",
            "Epoch 12 (train)2.4s: train loss = 4.32705 = (mf)2.46002 + (embed)1.86703\n",
            "Epoch 13 (train)2.3s: train loss = 4.40346 = (mf)2.47710 + (embed)1.92635\n",
            "Epoch 14 (train)2.3s: train loss = 4.44613 = (mf)2.45749 + (embed)1.98864\n",
            "Epoch 15 (train)2.3s + (eval)0.6s: train loss = 4.45291 = (mf)2.41117 + (embed)2.04174, recall = 0.01429, ndcg = 0.13140\n",
            "Epoch 16 (train)2.8s: train loss = 4.55235 = (mf)2.46860 + (embed)2.08375\n",
            "Epoch 17 (train)2.4s: train loss = 4.57847 = (mf)2.45788 + (embed)2.12059\n",
            "Epoch 18 (train)2.3s: train loss = 4.45988 = (mf)2.30203 + (embed)2.15786\n",
            "Epoch 19 (train)2.3s: train loss = 4.75218 = (mf)2.54970 + (embed)2.20249\n",
            "Epoch 20 (train)2.5s + (eval)0.4s: train loss = 4.65255 = (mf)2.40758 + (embed)2.24498, recall = 0.01535, ndcg = 0.12608\n",
            "Epoch 21 (train)2.6s: train loss = 4.73197 = (mf)2.45557 + (embed)2.27641\n",
            "Epoch 22 (train)2.3s: train loss = 4.62056 = (mf)2.33293 + (embed)2.28764\n",
            "Epoch 23 (train)2.3s: train loss = 4.67606 = (mf)2.36263 + (embed)2.31343\n",
            "Epoch 24 (train)2.3s: train loss = 4.77790 = (mf)2.43862 + (embed)2.33928\n",
            "Epoch 25 (train)2.7s + (eval)0.6s: train loss = 4.78534 = (mf)2.40796 + (embed)2.37738, recall = 0.01575, ndcg = 0.11914\n",
            "Training finished in 64.14 seconds.\n",
            "Evaluation results for this combination: NDCG@20: 0.11914, Recall@20: 0.01575\n",
            "--- Trying combination: Epochs=25, TopK=20, LearningRate=0.5, Layers=4 ---\n",
            "Already normalize adjacency matrix (extended).\n",
            "Using xavier initialization for user, item, and genre embeddings.\n",
            "Epoch 1 (train)3.1s: train loss = 0.66575 = (mf)0.51925 + (embed)0.14650\n",
            "Epoch 2 (train)2.3s: train loss = 1.31279 = (mf)0.87814 + (embed)0.43465\n",
            "Epoch 3 (train)2.6s: train loss = 1.81824 = (mf)1.16125 + (embed)0.65699\n",
            "Epoch 4 (train)2.5s: train loss = 2.10226 = (mf)1.26892 + (embed)0.83334\n",
            "Epoch 5 (train)2.3s + (eval)0.4s: train loss = 2.27813 = (mf)1.30933 + (embed)0.96880, recall = 0.01072, ndcg = 0.12141\n",
            "Epoch 6 (train)2.4s: train loss = 2.38677 = (mf)1.31937 + (embed)1.06740\n",
            "Epoch 7 (train)2.3s: train loss = 2.49848 = (mf)1.34726 + (embed)1.15122\n",
            "Epoch 8 (train)2.8s: train loss = 2.66135 = (mf)1.42451 + (embed)1.23684\n",
            "Epoch 9 (train)2.4s: train loss = 2.70209 = (mf)1.40593 + (embed)1.29616\n",
            "Epoch 10 (train)2.3s + (eval)0.5s: train loss = 2.79228 = (mf)1.44641 + (embed)1.34588, recall = 0.01269, ndcg = 0.11440\n",
            "Epoch 11 (train)2.4s: train loss = 2.71999 = (mf)1.32668 + (embed)1.39330\n",
            "Epoch 12 (train)2.4s: train loss = 2.82277 = (mf)1.38826 + (embed)1.43451\n",
            "Epoch 13 (train)2.8s: train loss = 2.81026 = (mf)1.33974 + (embed)1.47052\n",
            "Epoch 14 (train)2.3s: train loss = 2.88248 = (mf)1.38356 + (embed)1.49891\n",
            "Epoch 15 (train)2.3s + (eval)0.2s: train loss = 2.89781 = (mf)1.37369 + (embed)1.52411, recall = 0.01350, ndcg = 0.13009\n",
            "Epoch 16 (train)2.4s: train loss = 2.87171 = (mf)1.31745 + (embed)1.55426\n",
            "Epoch 17 (train)2.6s: train loss = 2.89691 = (mf)1.32850 + (embed)1.56841\n",
            "Epoch 18 (train)2.6s: train loss = 2.87652 = (mf)1.28665 + (embed)1.58987\n",
            "Epoch 19 (train)2.3s: train loss = 2.89653 = (mf)1.28912 + (embed)1.60740\n",
            "Epoch 20 (train)2.3s + (eval)0.5s: train loss = 2.90174 = (mf)1.27469 + (embed)1.62705, recall = 0.01415, ndcg = 0.12345\n",
            "Epoch 21 (train)2.4s: train loss = 2.97330 = (mf)1.33004 + (embed)1.64326\n",
            "Epoch 22 (train)2.8s: train loss = 2.94667 = (mf)1.28867 + (embed)1.65800\n",
            "Epoch 23 (train)2.4s: train loss = 2.93973 = (mf)1.27378 + (embed)1.66595\n",
            "Epoch 24 (train)2.3s: train loss = 3.04622 = (mf)1.37107 + (embed)1.67516\n",
            "Epoch 25 (train)2.3s + (eval)0.2s: train loss = 3.05638 = (mf)1.35792 + (embed)1.69846, recall = 0.01375, ndcg = 0.11350\n",
            "Training finished in 63.69 seconds.\n",
            "Evaluation results for this combination: NDCG@20: 0.11350, Recall@20: 0.01375\n",
            "--- Trying combination: Epochs=25, TopK=20, LearningRate=0.5, Layers=5 ---\n",
            "Already normalize adjacency matrix (extended).\n",
            "Using xavier initialization for user, item, and genre embeddings.\n",
            "Epoch 1 (train)3.5s: train loss = 0.47332 = (mf)0.35059 + (embed)0.12273\n",
            "Epoch 2 (train)2.4s: train loss = 0.94859 = (mf)0.57576 + (embed)0.37283\n",
            "Epoch 3 (train)2.4s: train loss = 1.30091 = (mf)0.73487 + (embed)0.56604\n",
            "Epoch 4 (train)2.4s: train loss = 1.53397 = (mf)0.82696 + (embed)0.70701\n",
            "Epoch 5 (train)2.9s + (eval)0.5s: train loss = 1.64731 = (mf)0.84690 + (embed)0.80040, recall = 0.01163, ndcg = 0.10291\n",
            "Epoch 6 (train)2.5s: train loss = 1.79862 = (mf)0.91656 + (embed)0.88206\n",
            "Epoch 7 (train)2.4s: train loss = 1.85819 = (mf)0.90237 + (embed)0.95582\n",
            "Epoch 8 (train)2.4s: train loss = 1.92504 = (mf)0.91684 + (embed)1.00821\n",
            "Epoch 9 (train)2.6s: train loss = 1.96291 = (mf)0.91244 + (embed)1.05047\n",
            "Epoch 10 (train)2.8s + (eval)0.5s: train loss = 1.97764 = (mf)0.89420 + (embed)1.08343, recall = 0.01125, ndcg = 0.11405\n",
            "Epoch 11 (train)2.4s: train loss = 2.01228 = (mf)0.89666 + (embed)1.11562\n",
            "Epoch 12 (train)2.4s: train loss = 2.08241 = (mf)0.93260 + (embed)1.14980\n",
            "Epoch 13 (train)2.4s: train loss = 2.05773 = (mf)0.88587 + (embed)1.17187\n",
            "Epoch 14 (train)2.9s: train loss = 2.09426 = (mf)0.90892 + (embed)1.18534\n",
            "Epoch 15 (train)2.4s + (eval)0.3s: train loss = 2.08307 = (mf)0.87400 + (embed)1.20907, recall = 0.01222, ndcg = 0.10856\n",
            "Epoch 16 (train)2.4s: train loss = 2.08741 = (mf)0.85742 + (embed)1.22999\n",
            "Epoch 17 (train)2.4s: train loss = 2.08700 = (mf)0.84550 + (embed)1.24150\n",
            "Epoch 18 (train)2.5s: train loss = 2.09669 = (mf)0.84710 + (embed)1.24959\n",
            "Epoch 19 (train)2.8s: train loss = 2.11442 = (mf)0.84954 + (embed)1.26488\n",
            "Epoch 20 (train)2.4s + (eval)0.5s: train loss = 2.13656 = (mf)0.86597 + (embed)1.27059, recall = 0.01221, ndcg = 0.11264\n",
            "Epoch 21 (train)2.4s: train loss = 2.10742 = (mf)0.84039 + (embed)1.26703\n",
            "Epoch 22 (train)2.4s: train loss = 2.10328 = (mf)0.82885 + (embed)1.27442\n",
            "Epoch 23 (train)2.8s: train loss = 2.09285 = (mf)0.81711 + (embed)1.27574\n",
            "Epoch 24 (train)2.5s: train loss = 2.06048 = (mf)0.79084 + (embed)1.26964\n",
            "Epoch 25 (train)2.4s + (eval)0.3s: train loss = 2.04822 = (mf)0.77637 + (embed)1.27184, recall = 0.01323, ndcg = 0.11134\n",
            "Training finished in 65.73 seconds.\n",
            "Evaluation results for this combination: NDCG@20: 0.11134, Recall@20: 0.01323\n",
            "--- Trying combination: Epochs=25, TopK=50, LearningRate=0.005, Layers=3 ---\n",
            "Already normalize adjacency matrix (extended).\n",
            "Using xavier initialization for user, item, and genre embeddings.\n",
            "Epoch 1 (train)3.2s: train loss = 0.29049 = (mf)0.28992 + (embed)0.00057\n",
            "Epoch 2 (train)2.5s: train loss = 0.17796 = (mf)0.17694 + (embed)0.00102\n",
            "Epoch 3 (train)2.3s: train loss = 0.14740 = (mf)0.14598 + (embed)0.00142\n",
            "Epoch 4 (train)2.3s: train loss = 0.13288 = (mf)0.13108 + (embed)0.00180\n",
            "Epoch 5 (train)2.3s + (eval)0.5s: train loss = 0.11643 = (mf)0.11426 + (embed)0.00218, recall = 0.03091, ndcg = 0.13909\n",
            "Epoch 6 (train)2.9s: train loss = 0.10609 = (mf)0.10351 + (embed)0.00258\n",
            "Epoch 7 (train)2.4s: train loss = 0.09668 = (mf)0.09372 + (embed)0.00296\n",
            "Epoch 8 (train)2.8s: train loss = 0.08798 = (mf)0.08463 + (embed)0.00334\n",
            "Epoch 9 (train)2.4s: train loss = 0.07844 = (mf)0.07466 + (embed)0.00378\n",
            "Epoch 10 (train)2.4s + (eval)0.7s: train loss = 0.07198 = (mf)0.06780 + (embed)0.00418, recall = 0.03548, ndcg = 0.16828\n",
            "Epoch 11 (train)2.6s: train loss = 0.06693 = (mf)0.06235 + (embed)0.00458\n",
            "Epoch 12 (train)2.3s: train loss = 0.06399 = (mf)0.05904 + (embed)0.00495\n",
            "Epoch 13 (train)2.3s: train loss = 0.05903 = (mf)0.05373 + (embed)0.00530\n",
            "Epoch 14 (train)2.3s: train loss = 0.05485 = (mf)0.04922 + (embed)0.00562\n",
            "Epoch 15 (train)2.7s + (eval)0.4s: train loss = 0.05243 = (mf)0.04649 + (embed)0.00594, recall = 0.03932, ndcg = 0.18596\n",
            "Epoch 16 (train)2.4s: train loss = 0.04952 = (mf)0.04330 + (embed)0.00622\n",
            "Epoch 17 (train)2.3s: train loss = 0.04784 = (mf)0.04135 + (embed)0.00650\n",
            "Epoch 18 (train)2.3s: train loss = 0.04461 = (mf)0.03787 + (embed)0.00674\n",
            "Epoch 19 (train)2.3s: train loss = 0.04351 = (mf)0.03653 + (embed)0.00698\n",
            "Epoch 20 (train)2.8s + (eval)0.6s: train loss = 0.04149 = (mf)0.03428 + (embed)0.00721, recall = 0.04273, ndcg = 0.19381\n",
            "Epoch 21 (train)2.4s: train loss = 0.04055 = (mf)0.03315 + (embed)0.00740\n",
            "Epoch 22 (train)2.3s: train loss = 0.03847 = (mf)0.03089 + (embed)0.00757\n",
            "Epoch 23 (train)2.3s: train loss = 0.03811 = (mf)0.03035 + (embed)0.00775\n",
            "Epoch 24 (train)2.4s: train loss = 0.03688 = (mf)0.02896 + (embed)0.00792\n",
            "Epoch 25 (train)2.8s + (eval)0.3s: train loss = 0.03516 = (mf)0.02708 + (embed)0.00808, recall = 0.04369, ndcg = 0.19784\n",
            "Training finished in 64.71 seconds.\n",
            "Evaluation results for this combination: NDCG@50: 0.19784, Recall@50: 0.04369\n",
            "--- Trying combination: Epochs=25, TopK=50, LearningRate=0.005, Layers=4 ---\n",
            "Already normalize adjacency matrix (extended).\n",
            "Using xavier initialization for user, item, and genre embeddings.\n",
            "Epoch 1 (train)3.1s: train loss = 0.29504 = (mf)0.29446 + (embed)0.00058\n",
            "Epoch 2 (train)2.3s: train loss = 0.20573 = (mf)0.20473 + (embed)0.00100\n",
            "Epoch 3 (train)2.9s: train loss = 0.18748 = (mf)0.18612 + (embed)0.00136\n",
            "Epoch 4 (train)2.3s: train loss = 0.16094 = (mf)0.15910 + (embed)0.00184\n",
            "Epoch 5 (train)2.3s + (eval)0.5s: train loss = 0.13737 = (mf)0.13496 + (embed)0.00241, recall = 0.02791, ndcg = 0.13126\n",
            "Epoch 6 (train)2.4s: train loss = 0.12533 = (mf)0.12248 + (embed)0.00285\n",
            "Epoch 7 (train)2.7s: train loss = 0.11618 = (mf)0.11291 + (embed)0.00328\n",
            "Epoch 8 (train)2.6s: train loss = 0.10713 = (mf)0.10340 + (embed)0.00372\n",
            "Epoch 9 (train)2.3s: train loss = 0.09774 = (mf)0.09353 + (embed)0.00421\n",
            "Epoch 10 (train)2.3s + (eval)0.6s: train loss = 0.08997 = (mf)0.08526 + (embed)0.00470, recall = 0.03526, ndcg = 0.16785\n",
            "Epoch 11 (train)2.4s: train loss = 0.08399 = (mf)0.07881 + (embed)0.00518\n",
            "Epoch 12 (train)2.9s: train loss = 0.07880 = (mf)0.07318 + (embed)0.00562\n",
            "Epoch 13 (train)2.4s: train loss = 0.07377 = (mf)0.06773 + (embed)0.00603\n",
            "Epoch 14 (train)2.3s: train loss = 0.07115 = (mf)0.06472 + (embed)0.00642\n",
            "Epoch 15 (train)2.3s + (eval)0.3s: train loss = 0.06757 = (mf)0.06081 + (embed)0.00677, recall = 0.03790, ndcg = 0.17991\n",
            "Epoch 16 (train)2.4s: train loss = 0.06426 = (mf)0.05716 + (embed)0.00710\n",
            "Epoch 17 (train)2.9s: train loss = 0.06255 = (mf)0.05514 + (embed)0.00741\n",
            "Epoch 18 (train)2.4s: train loss = 0.05993 = (mf)0.05226 + (embed)0.00767\n",
            "Epoch 19 (train)2.3s: train loss = 0.05812 = (mf)0.05018 + (embed)0.00794\n",
            "Epoch 20 (train)2.3s + (eval)0.5s: train loss = 0.05557 = (mf)0.04738 + (embed)0.00819, recall = 0.04071, ndcg = 0.19001\n",
            "Epoch 21 (train)2.7s: train loss = 0.05383 = (mf)0.04540 + (embed)0.00843\n",
            "Epoch 22 (train)2.5s: train loss = 0.05168 = (mf)0.04302 + (embed)0.00866\n",
            "Epoch 23 (train)2.4s: train loss = 0.05022 = (mf)0.04133 + (embed)0.00888\n",
            "Epoch 24 (train)2.4s: train loss = 0.05003 = (mf)0.04095 + (embed)0.00908\n",
            "Epoch 25 (train)2.3s + (eval)0.3s: train loss = 0.04878 = (mf)0.03951 + (embed)0.00927, recall = 0.04297, ndcg = 0.19692\n",
            "Training finished in 64.28 seconds.\n",
            "Evaluation results for this combination: NDCG@50: 0.19692, Recall@50: 0.04297\n",
            "--- Trying combination: Epochs=25, TopK=50, LearningRate=0.005, Layers=5 ---\n",
            "Already normalize adjacency matrix (extended).\n",
            "Using xavier initialization for user, item, and genre embeddings.\n",
            "Epoch 1 (train)3.2s: train loss = 0.30085 = (mf)0.30026 + (embed)0.00059\n",
            "Epoch 2 (train)2.4s: train loss = 0.21290 = (mf)0.21186 + (embed)0.00104\n",
            "Epoch 3 (train)2.4s: train loss = 0.20237 = (mf)0.20095 + (embed)0.00143\n",
            "Epoch 4 (train)2.9s: train loss = 0.18246 = (mf)0.18053 + (embed)0.00193\n",
            "Epoch 5 (train)2.4s + (eval)0.8s: train loss = 0.16038 = (mf)0.15784 + (embed)0.00254, recall = 0.02787, ndcg = 0.13118\n",
            "Epoch 6 (train)2.4s: train loss = 0.14300 = (mf)0.13983 + (embed)0.00316\n",
            "Epoch 7 (train)2.4s: train loss = 0.13441 = (mf)0.13076 + (embed)0.00365\n",
            "Epoch 8 (train)2.7s: train loss = 0.12608 = (mf)0.12195 + (embed)0.00413\n",
            "Epoch 9 (train)2.6s: train loss = 0.11599 = (mf)0.11134 + (embed)0.00465\n",
            "Epoch 10 (train)2.4s + (eval)0.3s: train loss = 0.10875 = (mf)0.10360 + (embed)0.00515, recall = 0.03299, ndcg = 0.15524\n",
            "Epoch 11 (train)2.4s: train loss = 0.10055 = (mf)0.09490 + (embed)0.00565\n",
            "Epoch 12 (train)2.4s: train loss = 0.09504 = (mf)0.08888 + (embed)0.00616\n",
            "Epoch 13 (train)2.9s: train loss = 0.09070 = (mf)0.08405 + (embed)0.00665\n",
            "Epoch 14 (train)2.4s: train loss = 0.08591 = (mf)0.07878 + (embed)0.00713\n",
            "Epoch 15 (train)2.4s + (eval)0.3s: train loss = 0.08175 = (mf)0.07415 + (embed)0.00759, recall = 0.03537, ndcg = 0.17349\n",
            "Epoch 16 (train)2.4s: train loss = 0.07781 = (mf)0.06979 + (embed)0.00802\n",
            "Epoch 17 (train)2.6s: train loss = 0.07492 = (mf)0.06648 + (embed)0.00844\n",
            "Epoch 18 (train)2.8s: train loss = 0.07206 = (mf)0.06327 + (embed)0.00878\n",
            "Epoch 19 (train)2.5s: train loss = 0.06963 = (mf)0.06053 + (embed)0.00910\n",
            "Epoch 20 (train)2.4s + (eval)0.6s: train loss = 0.06745 = (mf)0.05804 + (embed)0.00941, recall = 0.03908, ndcg = 0.18745\n",
            "Epoch 21 (train)2.4s: train loss = 0.06572 = (mf)0.05601 + (embed)0.00971\n",
            "Epoch 22 (train)2.9s: train loss = 0.06284 = (mf)0.05287 + (embed)0.00997\n",
            "Epoch 23 (train)2.4s: train loss = 0.06309 = (mf)0.05288 + (embed)0.01021\n",
            "Epoch 24 (train)2.4s: train loss = 0.06134 = (mf)0.05093 + (embed)0.01041\n",
            "Epoch 25 (train)2.4s + (eval)0.3s: train loss = 0.05977 = (mf)0.04916 + (embed)0.01061, recall = 0.04122, ndcg = 0.19430\n",
            "Training finished in 66.10 seconds.\n",
            "Evaluation results for this combination: NDCG@50: 0.19430, Recall@50: 0.04122\n",
            "--- Trying combination: Epochs=25, TopK=50, LearningRate=0.05, Layers=3 ---\n",
            "Already normalize adjacency matrix (extended).\n",
            "Using xavier initialization for user, item, and genre embeddings.\n",
            "Epoch 1 (train)3.1s: train loss = 0.15044 = (mf)0.14712 + (embed)0.00332\n",
            "Epoch 2 (train)2.3s: train loss = 0.07124 = (mf)0.06352 + (embed)0.00772\n",
            "Epoch 3 (train)2.3s: train loss = 0.05611 = (mf)0.04510 + (embed)0.01101\n",
            "Epoch 4 (train)2.4s: train loss = 0.05172 = (mf)0.03837 + (embed)0.01335\n",
            "Epoch 5 (train)2.8s + (eval)0.8s: train loss = 0.04852 = (mf)0.03339 + (embed)0.01514, recall = 0.03542, ndcg = 0.14930\n",
            "Epoch 6 (train)2.4s: train loss = 0.04644 = (mf)0.02989 + (embed)0.01655\n",
            "Epoch 7 (train)2.3s: train loss = 0.04553 = (mf)0.02781 + (embed)0.01772\n",
            "Epoch 8 (train)2.3s: train loss = 0.04695 = (mf)0.02812 + (embed)0.01883\n",
            "Epoch 9 (train)2.7s: train loss = 0.04611 = (mf)0.02641 + (embed)0.01971\n",
            "Epoch 10 (train)2.4s + (eval)0.3s: train loss = 0.04709 = (mf)0.02664 + (embed)0.02046, recall = 0.03582, ndcg = 0.14409\n",
            "Epoch 11 (train)2.4s: train loss = 0.04653 = (mf)0.02539 + (embed)0.02114\n",
            "Epoch 12 (train)2.3s: train loss = 0.04477 = (mf)0.02303 + (embed)0.02174\n",
            "Epoch 13 (train)2.3s: train loss = 0.04728 = (mf)0.02497 + (embed)0.02231\n",
            "Epoch 14 (train)2.8s: train loss = 0.04621 = (mf)0.02346 + (embed)0.02276\n",
            "Epoch 15 (train)2.3s + (eval)0.3s: train loss = 0.04705 = (mf)0.02382 + (embed)0.02323, recall = 0.03556, ndcg = 0.14202\n",
            "Epoch 16 (train)2.3s: train loss = 0.04656 = (mf)0.02283 + (embed)0.02373\n",
            "Epoch 17 (train)2.3s: train loss = 0.04738 = (mf)0.02325 + (embed)0.02413\n",
            "Epoch 18 (train)2.3s: train loss = 0.04707 = (mf)0.02260 + (embed)0.02446\n",
            "Epoch 19 (train)2.8s: train loss = 0.04759 = (mf)0.02281 + (embed)0.02478\n",
            "Epoch 20 (train)2.3s + (eval)0.5s: train loss = 0.04767 = (mf)0.02267 + (embed)0.02500, recall = 0.03412, ndcg = 0.14270\n",
            "Epoch 21 (train)2.3s: train loss = 0.04785 = (mf)0.02263 + (embed)0.02522\n",
            "Epoch 22 (train)2.3s: train loss = 0.04714 = (mf)0.02163 + (embed)0.02551\n",
            "Epoch 23 (train)2.6s: train loss = 0.04853 = (mf)0.02277 + (embed)0.02576\n",
            "Epoch 24 (train)2.6s: train loss = 0.04759 = (mf)0.02160 + (embed)0.02599\n",
            "Epoch 25 (train)2.3s + (eval)0.3s: train loss = 0.04998 = (mf)0.02375 + (embed)0.02623, recall = 0.03391, ndcg = 0.14033\n",
            "Training finished in 63.76 seconds.\n",
            "Evaluation results for this combination: NDCG@50: 0.14033, Recall@50: 0.03391\n",
            "--- Trying combination: Epochs=25, TopK=50, LearningRate=0.05, Layers=4 ---\n",
            "Already normalize adjacency matrix (extended).\n",
            "Using xavier initialization for user, item, and genre embeddings.\n",
            "Epoch 1 (train)3.3s: train loss = 0.16824 = (mf)0.16481 + (embed)0.00343\n",
            "Epoch 2 (train)2.7s: train loss = 0.08239 = (mf)0.07424 + (embed)0.00815\n",
            "Epoch 3 (train)2.9s: train loss = 0.06198 = (mf)0.05027 + (embed)0.01171\n",
            "Epoch 4 (train)2.4s: train loss = 0.05265 = (mf)0.03837 + (embed)0.01428\n",
            "Epoch 5 (train)2.3s + (eval)0.9s: train loss = 0.04874 = (mf)0.03268 + (embed)0.01606, recall = 0.03795, ndcg = 0.16246\n",
            "Epoch 6 (train)3.0s: train loss = 0.04655 = (mf)0.02919 + (embed)0.01736\n",
            "Epoch 7 (train)2.4s: train loss = 0.04562 = (mf)0.02726 + (embed)0.01837\n",
            "Epoch 8 (train)2.4s: train loss = 0.04475 = (mf)0.02551 + (embed)0.01923\n",
            "Epoch 9 (train)2.3s: train loss = 0.04480 = (mf)0.02486 + (embed)0.01994\n",
            "Epoch 10 (train)2.6s + (eval)0.4s: train loss = 0.04270 = (mf)0.02196 + (embed)0.02074, recall = 0.03862, ndcg = 0.16346\n",
            "Epoch 11 (train)2.6s: train loss = 0.04273 = (mf)0.02148 + (embed)0.02125\n",
            "Epoch 12 (train)2.3s: train loss = 0.04246 = (mf)0.02071 + (embed)0.02174\n",
            "Epoch 13 (train)2.4s: train loss = 0.04202 = (mf)0.01995 + (embed)0.02207\n",
            "Epoch 14 (train)2.4s: train loss = 0.04179 = (mf)0.01939 + (embed)0.02241\n",
            "Epoch 15 (train)2.8s + (eval)0.6s: train loss = 0.04109 = (mf)0.01839 + (embed)0.02270, recall = 0.03645, ndcg = 0.16419\n",
            "Epoch 16 (train)2.4s: train loss = 0.04049 = (mf)0.01772 + (embed)0.02277\n",
            "Epoch 17 (train)2.4s: train loss = 0.04110 = (mf)0.01805 + (embed)0.02305\n",
            "Epoch 18 (train)2.3s: train loss = 0.04123 = (mf)0.01793 + (embed)0.02330\n",
            "Epoch 19 (train)2.4s: train loss = 0.04148 = (mf)0.01790 + (embed)0.02358\n",
            "Epoch 20 (train)2.9s + (eval)0.3s: train loss = 0.04147 = (mf)0.01775 + (embed)0.02372, recall = 0.03694, ndcg = 0.15798\n",
            "Epoch 21 (train)2.4s: train loss = 0.04156 = (mf)0.01768 + (embed)0.02388\n",
            "Epoch 22 (train)2.3s: train loss = 0.04092 = (mf)0.01686 + (embed)0.02406\n",
            "Epoch 23 (train)2.3s: train loss = 0.04103 = (mf)0.01685 + (embed)0.02419\n",
            "Epoch 24 (train)2.6s: train loss = 0.04082 = (mf)0.01653 + (embed)0.02429\n",
            "Epoch 25 (train)2.7s + (eval)0.3s: train loss = 0.04073 = (mf)0.01642 + (embed)0.02431, recall = 0.03717, ndcg = 0.15149\n",
            "Training finished in 65.88 seconds.\n",
            "Evaluation results for this combination: NDCG@50: 0.15149, Recall@50: 0.03717\n",
            "--- Trying combination: Epochs=25, TopK=50, LearningRate=0.05, Layers=5 ---\n",
            "Already normalize adjacency matrix (extended).\n",
            "Using xavier initialization for user, item, and genre embeddings.\n",
            "Epoch 1 (train)3.3s: train loss = 0.17557 = (mf)0.17188 + (embed)0.00370\n",
            "Epoch 2 (train)2.8s: train loss = 0.09428 = (mf)0.08532 + (embed)0.00896\n",
            "Epoch 3 (train)2.5s: train loss = 0.07058 = (mf)0.05759 + (embed)0.01299\n",
            "Epoch 4 (train)2.4s: train loss = 0.05988 = (mf)0.04411 + (embed)0.01577\n",
            "Epoch 5 (train)2.4s + (eval)0.8s: train loss = 0.05574 = (mf)0.03808 + (embed)0.01765, recall = 0.03839, ndcg = 0.18164\n",
            "Epoch 6 (train)2.5s: train loss = 0.05164 = (mf)0.03270 + (embed)0.01894\n",
            "Epoch 7 (train)2.8s: train loss = 0.04957 = (mf)0.02963 + (embed)0.01993\n",
            "Epoch 8 (train)2.4s: train loss = 0.04705 = (mf)0.02633 + (embed)0.02073\n",
            "Epoch 9 (train)2.4s: train loss = 0.04625 = (mf)0.02484 + (embed)0.02140\n",
            "Epoch 10 (train)2.4s + (eval)0.3s: train loss = 0.04471 = (mf)0.02271 + (embed)0.02200, recall = 0.04006, ndcg = 0.17919\n",
            "Epoch 11 (train)2.9s: train loss = 0.04437 = (mf)0.02198 + (embed)0.02238\n",
            "Epoch 12 (train)2.5s: train loss = 0.04297 = (mf)0.02009 + (embed)0.02288\n",
            "Epoch 13 (train)2.4s: train loss = 0.04313 = (mf)0.01999 + (embed)0.02314\n",
            "Epoch 14 (train)2.4s: train loss = 0.04284 = (mf)0.01945 + (embed)0.02339\n",
            "Epoch 15 (train)2.4s + (eval)0.3s: train loss = 0.04222 = (mf)0.01867 + (embed)0.02355, recall = 0.03956, ndcg = 0.18046\n",
            "Epoch 16 (train)2.9s: train loss = 0.04240 = (mf)0.01852 + (embed)0.02388\n",
            "Epoch 17 (train)2.4s: train loss = 0.04221 = (mf)0.01811 + (embed)0.02410\n",
            "Epoch 18 (train)2.4s: train loss = 0.04173 = (mf)0.01746 + (embed)0.02426\n",
            "Epoch 19 (train)2.4s: train loss = 0.04136 = (mf)0.01698 + (embed)0.02438\n",
            "Epoch 20 (train)2.6s + (eval)0.8s: train loss = 0.04133 = (mf)0.01679 + (embed)0.02454, recall = 0.03929, ndcg = 0.16863\n",
            "Epoch 21 (train)2.6s: train loss = 0.04142 = (mf)0.01677 + (embed)0.02465\n",
            "Epoch 22 (train)2.4s: train loss = 0.04094 = (mf)0.01622 + (embed)0.02472\n",
            "Epoch 23 (train)2.4s: train loss = 0.04116 = (mf)0.01638 + (embed)0.02478\n",
            "Epoch 24 (train)2.4s: train loss = 0.04140 = (mf)0.01647 + (embed)0.02492\n",
            "Epoch 25 (train)2.9s + (eval)0.3s: train loss = 0.04146 = (mf)0.01633 + (embed)0.02513, recall = 0.03816, ndcg = 0.17156\n",
            "Training finished in 66.52 seconds.\n",
            "Evaluation results for this combination: NDCG@50: 0.17156, Recall@50: 0.03816\n",
            "--- Trying combination: Epochs=25, TopK=50, LearningRate=0.5, Layers=3 ---\n",
            "Already normalize adjacency matrix (extended).\n",
            "Using xavier initialization for user, item, and genre embeddings.\n",
            "Epoch 1 (train)3.0s: train loss = 0.96068 = (mf)0.78757 + (embed)0.17311\n",
            "Epoch 2 (train)2.3s: train loss = 1.99912 = (mf)1.49268 + (embed)0.50643\n",
            "Epoch 3 (train)2.8s: train loss = 2.70835 = (mf)1.93721 + (embed)0.77114\n",
            "Epoch 4 (train)2.3s: train loss = 3.08796 = (mf)2.10933 + (embed)0.97864\n",
            "Epoch 5 (train)2.3s + (eval)0.9s: train loss = 3.48858 = (mf)2.33434 + (embed)1.15424, recall = 0.02282, ndcg = 0.09991\n",
            "Epoch 6 (train)2.4s: train loss = 3.68156 = (mf)2.37566 + (embed)1.30591\n",
            "Epoch 7 (train)2.6s: train loss = 3.91456 = (mf)2.48820 + (embed)1.42636\n",
            "Epoch 8 (train)2.5s: train loss = 4.00556 = (mf)2.46764 + (embed)1.53792\n",
            "Epoch 9 (train)2.4s: train loss = 4.22141 = (mf)2.58978 + (embed)1.63163\n",
            "Epoch 10 (train)2.3s + (eval)0.3s: train loss = 4.32486 = (mf)2.60258 + (embed)1.72228, recall = 0.02507, ndcg = 0.10325\n",
            "Epoch 11 (train)2.4s: train loss = 4.44914 = (mf)2.64290 + (embed)1.80623\n",
            "Epoch 12 (train)2.8s: train loss = 4.47228 = (mf)2.60078 + (embed)1.87149\n",
            "Epoch 13 (train)2.4s: train loss = 4.56192 = (mf)2.63190 + (embed)1.93001\n",
            "Epoch 14 (train)2.4s: train loss = 4.60349 = (mf)2.61281 + (embed)1.99068\n",
            "Epoch 15 (train)2.3s + (eval)0.6s: train loss = 4.66521 = (mf)2.62027 + (embed)2.04493, recall = 0.02555, ndcg = 0.11670\n",
            "Epoch 16 (train)2.4s: train loss = 4.61187 = (mf)2.52461 + (embed)2.08726\n",
            "Epoch 17 (train)2.8s: train loss = 4.71942 = (mf)2.58496 + (embed)2.13446\n",
            "Epoch 18 (train)2.4s: train loss = 4.69294 = (mf)2.51060 + (embed)2.18234\n",
            "Epoch 19 (train)2.3s: train loss = 4.80237 = (mf)2.58363 + (embed)2.21874\n",
            "Epoch 20 (train)2.3s + (eval)0.3s: train loss = 4.68862 = (mf)2.44495 + (embed)2.24367, recall = 0.02450, ndcg = 0.10381\n",
            "Epoch 21 (train)2.6s: train loss = 4.67824 = (mf)2.40127 + (embed)2.27697\n",
            "Epoch 22 (train)2.6s: train loss = 4.78309 = (mf)2.47088 + (embed)2.31221\n",
            "Epoch 23 (train)2.4s: train loss = 4.72762 = (mf)2.38788 + (embed)2.33974\n",
            "Epoch 24 (train)2.3s: train loss = 4.87660 = (mf)2.51878 + (embed)2.35782\n",
            "Epoch 25 (train)2.3s + (eval)0.3s: train loss = 4.74040 = (mf)2.35441 + (embed)2.38600, recall = 0.02615, ndcg = 0.10913\n",
            "Training finished in 64.21 seconds.\n",
            "Evaluation results for this combination: NDCG@50: 0.10913, Recall@50: 0.02615\n",
            "--- Trying combination: Epochs=25, TopK=50, LearningRate=0.5, Layers=4 ---\n",
            "Already normalize adjacency matrix (extended).\n",
            "Using xavier initialization for user, item, and genre embeddings.\n",
            "Epoch 1 (train)3.2s: train loss = 0.63323 = (mf)0.48754 + (embed)0.14570\n",
            "Epoch 2 (train)2.4s: train loss = 1.27743 = (mf)0.85172 + (embed)0.42570\n",
            "Epoch 3 (train)2.4s: train loss = 1.79232 = (mf)1.13007 + (embed)0.66225\n",
            "Epoch 4 (train)2.9s: train loss = 2.07157 = (mf)1.23867 + (embed)0.83290\n",
            "Epoch 5 (train)2.4s + (eval)0.6s: train loss = 2.26721 = (mf)1.30385 + (embed)0.96336, recall = 0.02317, ndcg = 0.10119\n",
            "Epoch 6 (train)2.3s: train loss = 2.44117 = (mf)1.36895 + (embed)1.07222\n",
            "Epoch 7 (train)2.3s: train loss = 2.53819 = (mf)1.37414 + (embed)1.16405\n",
            "Epoch 8 (train)2.6s: train loss = 2.67732 = (mf)1.43907 + (embed)1.23825\n",
            "Epoch 9 (train)2.7s: train loss = 2.69295 = (mf)1.39085 + (embed)1.30210\n",
            "Epoch 10 (train)2.3s + (eval)0.6s: train loss = 2.67856 = (mf)1.32526 + (embed)1.35330, recall = 0.02313, ndcg = 0.09525\n",
            "Epoch 11 (train)2.4s: train loss = 2.81133 = (mf)1.41202 + (embed)1.39931\n",
            "Epoch 12 (train)2.3s: train loss = 2.84498 = (mf)1.39791 + (embed)1.44707\n",
            "Epoch 13 (train)2.8s: train loss = 2.92161 = (mf)1.44211 + (embed)1.47951\n",
            "Epoch 14 (train)2.4s: train loss = 2.94789 = (mf)1.43612 + (embed)1.51177\n",
            "Epoch 15 (train)2.3s + (eval)0.3s: train loss = 2.87812 = (mf)1.33514 + (embed)1.54298, recall = 0.02504, ndcg = 0.09786\n",
            "Epoch 16 (train)2.3s: train loss = 2.97806 = (mf)1.40919 + (embed)1.56888\n",
            "Epoch 17 (train)2.3s: train loss = 2.96620 = (mf)1.36839 + (embed)1.59780\n",
            "Epoch 18 (train)2.9s: train loss = 2.95158 = (mf)1.33362 + (embed)1.61796\n",
            "Epoch 19 (train)2.4s: train loss = 3.04128 = (mf)1.40865 + (embed)1.63262\n",
            "Epoch 20 (train)2.3s + (eval)0.6s: train loss = 2.92791 = (mf)1.28860 + (embed)1.63932, recall = 0.02622, ndcg = 0.10462\n",
            "Epoch 21 (train)2.4s: train loss = 2.95664 = (mf)1.30260 + (embed)1.65404\n",
            "Epoch 22 (train)2.9s: train loss = 2.87412 = (mf)1.21647 + (embed)1.65765\n",
            "Epoch 23 (train)3.1s: train loss = 2.97082 = (mf)1.30435 + (embed)1.66647\n",
            "Epoch 24 (train)2.4s: train loss = 2.96464 = (mf)1.28770 + (embed)1.67694\n",
            "Epoch 25 (train)2.3s + (eval)0.3s: train loss = 2.90557 = (mf)1.21806 + (embed)1.68751, recall = 0.02706, ndcg = 0.10652\n",
            "Training finished in 65.27 seconds.\n",
            "Evaluation results for this combination: NDCG@50: 0.10652, Recall@50: 0.02706\n",
            "--- Trying combination: Epochs=25, TopK=50, LearningRate=0.5, Layers=5 ---\n",
            "Already normalize adjacency matrix (extended).\n",
            "Using xavier initialization for user, item, and genre embeddings.\n",
            "Epoch 1 (train)3.7s: train loss = 0.47482 = (mf)0.35111 + (embed)0.12371\n",
            "Epoch 2 (train)2.4s: train loss = 0.92673 = (mf)0.56139 + (embed)0.36534\n",
            "Epoch 3 (train)2.4s: train loss = 1.26153 = (mf)0.70223 + (embed)0.55930\n",
            "Epoch 4 (train)2.4s: train loss = 1.54627 = (mf)0.84294 + (embed)0.70332\n",
            "Epoch 5 (train)2.9s + (eval)0.6s: train loss = 1.67959 = (mf)0.86760 + (embed)0.81199, recall = 0.02309, ndcg = 0.09814\n",
            "Epoch 6 (train)2.4s: train loss = 1.80427 = (mf)0.90766 + (embed)0.89662\n",
            "Epoch 7 (train)2.4s: train loss = 1.84550 = (mf)0.88149 + (embed)0.96401\n",
            "Epoch 8 (train)2.4s: train loss = 1.93233 = (mf)0.92014 + (embed)1.01219\n",
            "Epoch 9 (train)2.7s: train loss = 1.95634 = (mf)0.90512 + (embed)1.05122\n",
            "Epoch 10 (train)2.7s + (eval)0.6s: train loss = 2.02495 = (mf)0.93234 + (embed)1.09261, recall = 0.02789, ndcg = 0.11076\n",
            "Epoch 11 (train)2.4s: train loss = 2.05735 = (mf)0.92774 + (embed)1.12961\n",
            "Epoch 12 (train)2.4s: train loss = 2.01829 = (mf)0.86577 + (embed)1.15253\n",
            "Epoch 13 (train)2.4s: train loss = 2.05700 = (mf)0.88006 + (embed)1.17694\n",
            "Epoch 14 (train)2.9s: train loss = 2.06324 = (mf)0.87349 + (embed)1.18976\n",
            "Epoch 15 (train)2.4s + (eval)0.3s: train loss = 2.05317 = (mf)0.84628 + (embed)1.20690, recall = 0.02223, ndcg = 0.08416\n",
            "Epoch 16 (train)2.4s: train loss = 2.07151 = (mf)0.84705 + (embed)1.22446\n",
            "Epoch 17 (train)2.4s: train loss = 2.13718 = (mf)0.89226 + (embed)1.24491\n",
            "Epoch 18 (train)2.6s: train loss = 2.09436 = (mf)0.83615 + (embed)1.25821\n",
            "Epoch 19 (train)2.7s: train loss = 2.08630 = (mf)0.82831 + (embed)1.25799\n",
            "Epoch 20 (train)2.4s + (eval)0.6s: train loss = 2.04654 = (mf)0.78481 + (embed)1.26173, recall = 0.02258, ndcg = 0.08337\n",
            "Epoch 21 (train)2.4s: train loss = 2.08704 = (mf)0.82207 + (embed)1.26497\n",
            "Epoch 22 (train)2.4s: train loss = 2.05916 = (mf)0.78765 + (embed)1.27152\n",
            "Epoch 23 (train)3.0s: train loss = 2.07034 = (mf)0.80150 + (embed)1.26884\n",
            "Epoch 24 (train)2.4s: train loss = 2.06868 = (mf)0.79688 + (embed)1.27180\n",
            "Epoch 25 (train)2.4s + (eval)0.3s: train loss = 2.13620 = (mf)0.85972 + (embed)1.27647, recall = 0.02351, ndcg = 0.09074\n",
            "Training finished in 66.57 seconds.\n",
            "Evaluation results for this combination: NDCG@50: 0.09074, Recall@50: 0.02351\n",
            "--- Trying combination: Epochs=50, TopK=10, LearningRate=0.005, Layers=3 ---\n",
            "Already normalize adjacency matrix (extended).\n",
            "Using xavier initialization for user, item, and genre embeddings.\n",
            "Epoch 1 (train)3.7s: train loss = 0.28660 = (mf)0.28602 + (embed)0.00058\n",
            "Epoch 2 (train)2.4s: train loss = 0.17164 = (mf)0.17058 + (embed)0.00107\n",
            "Epoch 3 (train)2.3s: train loss = 0.14175 = (mf)0.14026 + (embed)0.00149\n",
            "Epoch 4 (train)2.3s: train loss = 0.12916 = (mf)0.12733 + (embed)0.00183\n",
            "Epoch 5 (train)2.5s + (eval)0.7s: train loss = 0.11628 = (mf)0.11411 + (embed)0.00216, recall = 0.01011, ndcg = 0.21815\n",
            "Epoch 6 (train)2.5s: train loss = 0.10679 = (mf)0.10428 + (embed)0.00251\n",
            "Epoch 7 (train)2.4s: train loss = 0.09500 = (mf)0.09210 + (embed)0.00290\n",
            "Epoch 8 (train)2.3s: train loss = 0.08695 = (mf)0.08366 + (embed)0.00329\n",
            "Epoch 9 (train)2.3s: train loss = 0.07901 = (mf)0.07531 + (embed)0.00370\n",
            "Epoch 10 (train)2.8s + (eval)0.5s: train loss = 0.07235 = (mf)0.06825 + (embed)0.00410, recall = 0.01342, ndcg = 0.26569\n",
            "Epoch 11 (train)2.4s: train loss = 0.06731 = (mf)0.06280 + (embed)0.00451\n",
            "Epoch 12 (train)2.4s: train loss = 0.06355 = (mf)0.05867 + (embed)0.00488\n",
            "Epoch 13 (train)2.4s: train loss = 0.05943 = (mf)0.05421 + (embed)0.00522\n",
            "Epoch 14 (train)2.5s: train loss = 0.05575 = (mf)0.05019 + (embed)0.00556\n",
            "Epoch 15 (train)2.8s + (eval)0.2s: train loss = 0.05244 = (mf)0.04657 + (embed)0.00588, recall = 0.01575, ndcg = 0.29369\n",
            "Epoch 16 (train)2.3s: train loss = 0.04998 = (mf)0.04382 + (embed)0.00616\n",
            "Epoch 17 (train)2.3s: train loss = 0.04704 = (mf)0.04060 + (embed)0.00643\n",
            "Epoch 18 (train)2.3s: train loss = 0.04574 = (mf)0.03908 + (embed)0.00666\n",
            "Epoch 19 (train)2.6s: train loss = 0.04378 = (mf)0.03688 + (embed)0.00691\n",
            "Epoch 20 (train)2.6s + (eval)0.2s: train loss = 0.04233 = (mf)0.03520 + (embed)0.00713, recall = 0.01723, ndcg = 0.30877\n",
            "Epoch 21 (train)2.4s: train loss = 0.04116 = (mf)0.03384 + (embed)0.00732\n",
            "Epoch 22 (train)2.3s: train loss = 0.04042 = (mf)0.03290 + (embed)0.00752\n",
            "Epoch 23 (train)2.4s: train loss = 0.03766 = (mf)0.02996 + (embed)0.00770\n",
            "Epoch 24 (train)2.8s: train loss = 0.03761 = (mf)0.02974 + (embed)0.00787\n",
            "Epoch 25 (train)2.4s + (eval)0.5s: train loss = 0.03568 = (mf)0.02766 + (embed)0.00803, recall = 0.01698, ndcg = 0.31188\n",
            "Epoch 26 (train)2.3s: train loss = 0.03477 = (mf)0.02660 + (embed)0.00817\n",
            "Epoch 27 (train)2.3s: train loss = 0.03345 = (mf)0.02516 + (embed)0.00829\n",
            "Epoch 28 (train)2.3s: train loss = 0.03383 = (mf)0.02541 + (embed)0.00842\n",
            "Epoch 29 (train)2.8s: train loss = 0.03207 = (mf)0.02354 + (embed)0.00853\n",
            "Epoch 30 (train)2.3s + (eval)0.2s: train loss = 0.03176 = (mf)0.02312 + (embed)0.00864, recall = 0.01789, ndcg = 0.32868\n",
            "Epoch 31 (train)2.4s: train loss = 0.03115 = (mf)0.02241 + (embed)0.00874\n",
            "Epoch 32 (train)2.3s: train loss = 0.03047 = (mf)0.02164 + (embed)0.00883\n",
            "Epoch 33 (train)2.4s: train loss = 0.02992 = (mf)0.02099 + (embed)0.00893\n",
            "Epoch 34 (train)2.8s: train loss = 0.02943 = (mf)0.02041 + (embed)0.00901\n",
            "Epoch 35 (train)2.4s + (eval)0.5s: train loss = 0.02882 = (mf)0.01972 + (embed)0.00909, recall = 0.01745, ndcg = 0.33626\n",
            "Epoch 36 (train)2.3s: train loss = 0.02852 = (mf)0.01936 + (embed)0.00916\n",
            "Epoch 37 (train)2.3s: train loss = 0.02846 = (mf)0.01925 + (embed)0.00921\n",
            "Epoch 38 (train)2.7s: train loss = 0.02694 = (mf)0.01766 + (embed)0.00928\n",
            "Epoch 39 (train)2.5s: train loss = 0.02741 = (mf)0.01808 + (embed)0.00933\n",
            "Epoch 40 (train)2.3s + (eval)0.2s: train loss = 0.02685 = (mf)0.01745 + (embed)0.00940, recall = 0.01698, ndcg = 0.31988\n",
            "Epoch 41 (train)2.3s: train loss = 0.02602 = (mf)0.01656 + (embed)0.00945\n",
            "Epoch 42 (train)2.3s: train loss = 0.02639 = (mf)0.01689 + (embed)0.00950\n",
            "Epoch 43 (train)2.8s: train loss = 0.02574 = (mf)0.01621 + (embed)0.00953\n",
            "Epoch 44 (train)2.4s: train loss = 0.02537 = (mf)0.01580 + (embed)0.00957\n",
            "Epoch 45 (train)2.3s + (eval)0.2s: train loss = 0.02483 = (mf)0.01520 + (embed)0.00963, recall = 0.01823, ndcg = 0.32805\n",
            "Epoch 46 (train)2.3s: train loss = 0.02497 = (mf)0.01534 + (embed)0.00963\n",
            "Epoch 47 (train)2.3s: train loss = 0.02510 = (mf)0.01544 + (embed)0.00966\n",
            "Epoch 48 (train)2.9s: train loss = 0.02448 = (mf)0.01481 + (embed)0.00967\n",
            "Epoch 49 (train)2.4s: train loss = 0.02413 = (mf)0.01442 + (embed)0.00971\n",
            "Epoch 50 (train)2.3s + (eval)0.5s: train loss = 0.02391 = (mf)0.01417 + (embed)0.00974, recall = 0.01845, ndcg = 0.32248\n",
            "Training finished in 127.53 seconds.\n",
            "Evaluation results for this combination: NDCG@10: 0.32248, Recall@10: 0.01845\n",
            "--- Trying combination: Epochs=50, TopK=10, LearningRate=0.005, Layers=4 ---\n",
            "Already normalize adjacency matrix (extended).\n",
            "Using xavier initialization for user, item, and genre embeddings.\n",
            "Epoch 1 (train)3.8s: train loss = 0.29489 = (mf)0.29431 + (embed)0.00058\n",
            "Epoch 2 (train)2.3s: train loss = 0.19764 = (mf)0.19659 + (embed)0.00105\n",
            "Epoch 3 (train)2.3s: train loss = 0.16719 = (mf)0.16566 + (embed)0.00153\n",
            "Epoch 4 (train)2.3s: train loss = 0.14724 = (mf)0.14521 + (embed)0.00202\n",
            "Epoch 5 (train)2.6s + (eval)1.1s: train loss = 0.13314 = (mf)0.13070 + (embed)0.00244, recall = 0.01033, ndcg = 0.21152\n",
            "Epoch 6 (train)2.5s: train loss = 0.12296 = (mf)0.12013 + (embed)0.00284\n",
            "Epoch 7 (train)2.4s: train loss = 0.11330 = (mf)0.11003 + (embed)0.00328\n",
            "Epoch 8 (train)2.4s: train loss = 0.10509 = (mf)0.10135 + (embed)0.00374\n",
            "Epoch 9 (train)2.4s: train loss = 0.09538 = (mf)0.09116 + (embed)0.00422\n",
            "Epoch 10 (train)2.9s + (eval)0.2s: train loss = 0.08878 = (mf)0.08405 + (embed)0.00473, recall = 0.01279, ndcg = 0.27374\n",
            "Epoch 11 (train)2.4s: train loss = 0.08114 = (mf)0.07592 + (embed)0.00522\n",
            "Epoch 12 (train)2.3s: train loss = 0.07642 = (mf)0.07074 + (embed)0.00569\n",
            "Epoch 13 (train)2.3s: train loss = 0.07349 = (mf)0.06739 + (embed)0.00610\n",
            "Epoch 14 (train)2.5s: train loss = 0.06897 = (mf)0.06248 + (embed)0.00649\n",
            "Epoch 15 (train)2.8s + (eval)0.5s: train loss = 0.06654 = (mf)0.05968 + (embed)0.00685, recall = 0.01434, ndcg = 0.30293\n",
            "Epoch 16 (train)2.4s: train loss = 0.06408 = (mf)0.05689 + (embed)0.00719\n",
            "Epoch 17 (train)2.9s: train loss = 0.06048 = (mf)0.05299 + (embed)0.00749\n",
            "Epoch 18 (train)2.4s: train loss = 0.05850 = (mf)0.05074 + (embed)0.00776\n",
            "Epoch 19 (train)2.9s: train loss = 0.05681 = (mf)0.04878 + (embed)0.00803\n",
            "Epoch 20 (train)2.4s + (eval)0.2s: train loss = 0.05369 = (mf)0.04541 + (embed)0.00828, recall = 0.01659, ndcg = 0.30541\n",
            "Epoch 21 (train)2.4s: train loss = 0.05291 = (mf)0.04437 + (embed)0.00853\n",
            "Epoch 22 (train)2.3s: train loss = 0.05165 = (mf)0.04290 + (embed)0.00875\n",
            "Epoch 23 (train)2.4s: train loss = 0.04999 = (mf)0.04102 + (embed)0.00897\n",
            "Epoch 24 (train)2.8s: train loss = 0.04830 = (mf)0.03912 + (embed)0.00918\n",
            "Epoch 25 (train)2.4s + (eval)0.5s: train loss = 0.04696 = (mf)0.03761 + (embed)0.00935, recall = 0.01806, ndcg = 0.32230\n",
            "Epoch 26 (train)2.4s: train loss = 0.04533 = (mf)0.03579 + (embed)0.00954\n",
            "Epoch 27 (train)2.3s: train loss = 0.04504 = (mf)0.03532 + (embed)0.00972\n",
            "Epoch 28 (train)2.8s: train loss = 0.04307 = (mf)0.03318 + (embed)0.00989\n",
            "Epoch 29 (train)2.5s: train loss = 0.04301 = (mf)0.03298 + (embed)0.01002\n",
            "Epoch 30 (train)2.3s + (eval)0.3s: train loss = 0.04136 = (mf)0.03120 + (embed)0.01017, recall = 0.01754, ndcg = 0.32023\n",
            "Epoch 31 (train)2.3s: train loss = 0.04149 = (mf)0.03118 + (embed)0.01030\n",
            "Epoch 32 (train)2.4s: train loss = 0.04098 = (mf)0.03056 + (embed)0.01041\n",
            "Epoch 33 (train)2.9s: train loss = 0.03899 = (mf)0.02846 + (embed)0.01053\n",
            "Epoch 34 (train)2.4s: train loss = 0.03879 = (mf)0.02815 + (embed)0.01064\n",
            "Epoch 35 (train)2.3s + (eval)0.3s: train loss = 0.03785 = (mf)0.02710 + (embed)0.01075, recall = 0.01792, ndcg = 0.33096\n",
            "Epoch 36 (train)2.4s: train loss = 0.03731 = (mf)0.02645 + (embed)0.01086\n",
            "Epoch 37 (train)2.4s: train loss = 0.03663 = (mf)0.02569 + (embed)0.01094\n",
            "Epoch 38 (train)2.9s: train loss = 0.03671 = (mf)0.02569 + (embed)0.01103\n",
            "Epoch 39 (train)2.4s: train loss = 0.03518 = (mf)0.02407 + (embed)0.01112\n",
            "Epoch 40 (train)2.4s + (eval)0.5s: train loss = 0.03499 = (mf)0.02378 + (embed)0.01121, recall = 0.01864, ndcg = 0.33775\n",
            "Epoch 41 (train)2.4s: train loss = 0.03476 = (mf)0.02348 + (embed)0.01129\n",
            "Epoch 42 (train)2.8s: train loss = 0.03359 = (mf)0.02225 + (embed)0.01134\n",
            "Epoch 43 (train)2.5s: train loss = 0.03398 = (mf)0.02259 + (embed)0.01140\n",
            "Epoch 44 (train)2.4s: train loss = 0.03387 = (mf)0.02241 + (embed)0.01146\n",
            "Epoch 45 (train)2.3s + (eval)0.2s: train loss = 0.03373 = (mf)0.02221 + (embed)0.01152, recall = 0.01802, ndcg = 0.33770\n",
            "Epoch 46 (train)2.4s: train loss = 0.03270 = (mf)0.02113 + (embed)0.01157\n",
            "Epoch 47 (train)2.9s: train loss = 0.03316 = (mf)0.02154 + (embed)0.01162\n",
            "Epoch 48 (train)2.4s: train loss = 0.03190 = (mf)0.02023 + (embed)0.01166\n",
            "Epoch 49 (train)2.3s: train loss = 0.03171 = (mf)0.01999 + (embed)0.01173\n",
            "Epoch 50 (train)2.3s + (eval)0.5s: train loss = 0.03154 = (mf)0.01978 + (embed)0.01177, recall = 0.01888, ndcg = 0.34805\n",
            "Training finished in 129.69 seconds.\n",
            "Evaluation results for this combination: NDCG@10: 0.34805, Recall@10: 0.01888\n",
            "--- Trying combination: Epochs=50, TopK=10, LearningRate=0.005, Layers=5 ---\n",
            "Already normalize adjacency matrix (extended).\n",
            "Using xavier initialization for user, item, and genre embeddings.\n",
            "Epoch 1 (train)3.4s: train loss = 0.29893 = (mf)0.29834 + (embed)0.00059\n",
            "Epoch 2 (train)2.4s: train loss = 0.21356 = (mf)0.21253 + (embed)0.00103\n",
            "Epoch 3 (train)2.4s: train loss = 0.19862 = (mf)0.19718 + (embed)0.00145\n",
            "Epoch 4 (train)2.8s: train loss = 0.17911 = (mf)0.17714 + (embed)0.00197\n",
            "Epoch 5 (train)2.6s + (eval)0.9s: train loss = 0.15578 = (mf)0.15321 + (embed)0.00258, recall = 0.00979, ndcg = 0.20673\n",
            "Epoch 6 (train)2.4s: train loss = 0.14240 = (mf)0.13924 + (embed)0.00316\n",
            "Epoch 7 (train)2.4s: train loss = 0.13298 = (mf)0.12938 + (embed)0.00360\n",
            "Epoch 8 (train)2.5s: train loss = 0.12401 = (mf)0.11995 + (embed)0.00406\n",
            "Epoch 9 (train)2.9s: train loss = 0.11662 = (mf)0.11206 + (embed)0.00456\n",
            "Epoch 10 (train)2.4s + (eval)0.2s: train loss = 0.10905 = (mf)0.10395 + (embed)0.00509, recall = 0.01111, ndcg = 0.25593\n",
            "Epoch 11 (train)2.4s: train loss = 0.10183 = (mf)0.09620 + (embed)0.00563\n",
            "Epoch 12 (train)2.4s: train loss = 0.09576 = (mf)0.08963 + (embed)0.00613\n",
            "Epoch 13 (train)2.8s: train loss = 0.08974 = (mf)0.08307 + (embed)0.00666\n",
            "Epoch 14 (train)2.5s: train loss = 0.08617 = (mf)0.07905 + (embed)0.00712\n",
            "Epoch 15 (train)2.4s + (eval)0.5s: train loss = 0.08085 = (mf)0.07327 + (embed)0.00759, recall = 0.01281, ndcg = 0.28226\n",
            "Epoch 16 (train)2.4s: train loss = 0.07825 = (mf)0.07024 + (embed)0.00801\n",
            "Epoch 17 (train)2.4s: train loss = 0.07539 = (mf)0.06698 + (embed)0.00841\n",
            "Epoch 18 (train)2.9s: train loss = 0.07190 = (mf)0.06311 + (embed)0.00880\n",
            "Epoch 19 (train)2.4s: train loss = 0.07044 = (mf)0.06130 + (embed)0.00914\n",
            "Epoch 20 (train)2.4s + (eval)0.2s: train loss = 0.06769 = (mf)0.05825 + (embed)0.00944, recall = 0.01534, ndcg = 0.30768\n",
            "Epoch 21 (train)2.4s: train loss = 0.06561 = (mf)0.05590 + (embed)0.00971\n",
            "Epoch 22 (train)2.7s: train loss = 0.06366 = (mf)0.05368 + (embed)0.00998\n",
            "Epoch 23 (train)2.6s: train loss = 0.06274 = (mf)0.05252 + (embed)0.01022\n",
            "Epoch 24 (train)2.4s: train loss = 0.06072 = (mf)0.05027 + (embed)0.01045\n",
            "Epoch 25 (train)2.4s + (eval)0.2s: train loss = 0.05932 = (mf)0.04866 + (embed)0.01066, recall = 0.01485, ndcg = 0.29300\n",
            "Epoch 26 (train)2.4s: train loss = 0.05746 = (mf)0.04658 + (embed)0.01088\n",
            "Epoch 27 (train)2.9s: train loss = 0.05550 = (mf)0.04442 + (embed)0.01108\n",
            "Epoch 28 (train)2.4s: train loss = 0.05478 = (mf)0.04352 + (embed)0.01126\n",
            "Epoch 29 (train)2.4s: train loss = 0.05370 = (mf)0.04229 + (embed)0.01141\n",
            "Epoch 30 (train)2.4s + (eval)0.5s: train loss = 0.05231 = (mf)0.04070 + (embed)0.01160, recall = 0.01655, ndcg = 0.31258\n",
            "Epoch 31 (train)2.6s: train loss = 0.05247 = (mf)0.04076 + (embed)0.01171\n",
            "Epoch 32 (train)2.7s: train loss = 0.05111 = (mf)0.03922 + (embed)0.01189\n",
            "Epoch 33 (train)2.4s: train loss = 0.05091 = (mf)0.03890 + (embed)0.01202\n",
            "Epoch 34 (train)2.4s: train loss = 0.04941 = (mf)0.03725 + (embed)0.01216\n",
            "Epoch 35 (train)2.4s + (eval)0.2s: train loss = 0.04864 = (mf)0.03635 + (embed)0.01229, recall = 0.01713, ndcg = 0.31715\n",
            "Epoch 36 (train)2.9s: train loss = 0.04771 = (mf)0.03529 + (embed)0.01242\n",
            "Epoch 37 (train)2.4s: train loss = 0.04586 = (mf)0.03331 + (embed)0.01255\n",
            "Epoch 38 (train)2.4s: train loss = 0.04538 = (mf)0.03271 + (embed)0.01266\n",
            "Epoch 39 (train)2.4s: train loss = 0.04528 = (mf)0.03254 + (embed)0.01274\n",
            "Epoch 40 (train)2.4s + (eval)0.7s: train loss = 0.04435 = (mf)0.03151 + (embed)0.01285, recall = 0.01736, ndcg = 0.33302\n",
            "Epoch 41 (train)2.8s: train loss = 0.04305 = (mf)0.03010 + (embed)0.01295\n",
            "Epoch 42 (train)2.4s: train loss = 0.04367 = (mf)0.03065 + (embed)0.01302\n",
            "Epoch 43 (train)2.4s: train loss = 0.04264 = (mf)0.02956 + (embed)0.01308\n",
            "Epoch 44 (train)2.4s: train loss = 0.04297 = (mf)0.02980 + (embed)0.01317\n",
            "Epoch 45 (train)2.8s + (eval)0.4s: train loss = 0.04197 = (mf)0.02873 + (embed)0.01324, recall = 0.01757, ndcg = 0.32441\n",
            "Epoch 46 (train)2.5s: train loss = 0.04180 = (mf)0.02848 + (embed)0.01332\n",
            "Epoch 47 (train)2.4s: train loss = 0.04070 = (mf)0.02728 + (embed)0.01342\n",
            "Epoch 48 (train)2.4s: train loss = 0.03987 = (mf)0.02640 + (embed)0.01347\n",
            "Epoch 49 (train)2.4s: train loss = 0.04084 = (mf)0.02730 + (embed)0.01354\n",
            "Epoch 50 (train)2.9s + (eval)0.2s: train loss = 0.04007 = (mf)0.02644 + (embed)0.01362, recall = 0.01697, ndcg = 0.33220\n",
            "Training finished in 131.42 seconds.\n",
            "Evaluation results for this combination: NDCG@10: 0.33220, Recall@10: 0.01697\n",
            "--- Trying combination: Epochs=50, TopK=10, LearningRate=0.05, Layers=3 ---\n",
            "Already normalize adjacency matrix (extended).\n",
            "Using xavier initialization for user, item, and genre embeddings.\n",
            "Epoch 1 (train)3.2s: train loss = 0.15621 = (mf)0.15302 + (embed)0.00319\n",
            "Epoch 2 (train)2.6s: train loss = 0.07034 = (mf)0.06259 + (embed)0.00775\n",
            "Epoch 3 (train)2.7s: train loss = 0.05610 = (mf)0.04513 + (embed)0.01097\n",
            "Epoch 4 (train)2.4s: train loss = 0.04899 = (mf)0.03568 + (embed)0.01331\n",
            "Epoch 5 (train)2.4s + (eval)0.6s: train loss = 0.04764 = (mf)0.03243 + (embed)0.01521, recall = 0.01569, ndcg = 0.23969\n",
            "Epoch 6 (train)2.4s: train loss = 0.04593 = (mf)0.02932 + (embed)0.01661\n",
            "Epoch 7 (train)2.9s: train loss = 0.04626 = (mf)0.02854 + (embed)0.01772\n",
            "Epoch 8 (train)2.4s: train loss = 0.04527 = (mf)0.02653 + (embed)0.01874\n",
            "Epoch 9 (train)2.3s: train loss = 0.04494 = (mf)0.02536 + (embed)0.01958\n",
            "Epoch 10 (train)2.3s + (eval)0.5s: train loss = 0.04511 = (mf)0.02473 + (embed)0.02037, recall = 0.01227, ndcg = 0.22962\n",
            "Epoch 11 (train)2.4s: train loss = 0.04555 = (mf)0.02458 + (embed)0.02098\n",
            "Epoch 12 (train)3.4s: train loss = 0.04555 = (mf)0.02390 + (embed)0.02165\n",
            "Epoch 13 (train)2.4s: train loss = 0.04627 = (mf)0.02404 + (embed)0.02223\n",
            "Epoch 14 (train)2.3s: train loss = 0.04757 = (mf)0.02482 + (embed)0.02275\n",
            "Epoch 15 (train)2.3s + (eval)0.2s: train loss = 0.04700 = (mf)0.02379 + (embed)0.02321, recall = 0.01126, ndcg = 0.21678\n",
            "Epoch 16 (train)2.7s: train loss = 0.04691 = (mf)0.02331 + (embed)0.02360\n",
            "Epoch 17 (train)2.5s: train loss = 0.04756 = (mf)0.02348 + (embed)0.02407\n",
            "Epoch 18 (train)2.3s: train loss = 0.04665 = (mf)0.02224 + (embed)0.02441\n",
            "Epoch 19 (train)2.3s: train loss = 0.04708 = (mf)0.02236 + (embed)0.02473\n",
            "Epoch 20 (train)2.3s + (eval)0.6s: train loss = 0.04820 = (mf)0.02313 + (embed)0.02506, recall = 0.01209, ndcg = 0.19378\n",
            "Epoch 21 (train)3.0s: train loss = 0.04807 = (mf)0.02271 + (embed)0.02536\n",
            "Epoch 22 (train)2.4s: train loss = 0.04789 = (mf)0.02233 + (embed)0.02555\n",
            "Epoch 23 (train)2.3s: train loss = 0.04832 = (mf)0.02260 + (embed)0.02572\n",
            "Epoch 24 (train)2.3s: train loss = 0.04823 = (mf)0.02222 + (embed)0.02601\n",
            "Epoch 25 (train)2.3s + (eval)0.3s: train loss = 0.04862 = (mf)0.02232 + (embed)0.02630, recall = 0.01146, ndcg = 0.20599\n",
            "Epoch 26 (train)2.8s: train loss = 0.04934 = (mf)0.02292 + (embed)0.02642\n",
            "Epoch 27 (train)2.4s: train loss = 0.04794 = (mf)0.02131 + (embed)0.02663\n",
            "Epoch 28 (train)2.3s: train loss = 0.04732 = (mf)0.02070 + (embed)0.02662\n",
            "Epoch 29 (train)2.3s: train loss = 0.04800 = (mf)0.02135 + (embed)0.02664\n",
            "Epoch 30 (train)2.5s + (eval)0.4s: train loss = 0.04742 = (mf)0.02070 + (embed)0.02672, recall = 0.01244, ndcg = 0.22326\n",
            "Epoch 31 (train)2.7s: train loss = 0.04882 = (mf)0.02192 + (embed)0.02690\n",
            "Epoch 32 (train)2.4s: train loss = 0.04777 = (mf)0.02083 + (embed)0.02693\n",
            "Epoch 33 (train)2.3s: train loss = 0.04783 = (mf)0.02064 + (embed)0.02720\n",
            "Epoch 34 (train)2.4s: train loss = 0.04789 = (mf)0.02060 + (embed)0.02729\n",
            "Epoch 35 (train)2.8s + (eval)0.6s: train loss = 0.04803 = (mf)0.02070 + (embed)0.02732, recall = 0.01277, ndcg = 0.21222\n",
            "Epoch 36 (train)2.4s: train loss = 0.04897 = (mf)0.02162 + (embed)0.02735\n",
            "Epoch 37 (train)2.3s: train loss = 0.04827 = (mf)0.02081 + (embed)0.02746\n",
            "Epoch 38 (train)2.3s: train loss = 0.04885 = (mf)0.02120 + (embed)0.02765\n",
            "Epoch 39 (train)2.3s: train loss = 0.04684 = (mf)0.01913 + (embed)0.02771\n",
            "Epoch 40 (train)2.8s + (eval)0.2s: train loss = 0.04895 = (mf)0.02121 + (embed)0.02773, recall = 0.01217, ndcg = 0.21751\n",
            "Epoch 41 (train)2.4s: train loss = 0.04759 = (mf)0.01978 + (embed)0.02781\n",
            "Epoch 42 (train)2.3s: train loss = 0.04699 = (mf)0.01925 + (embed)0.02773\n",
            "Epoch 43 (train)2.3s: train loss = 0.04814 = (mf)0.02033 + (embed)0.02781\n",
            "Epoch 44 (train)2.4s: train loss = 0.04833 = (mf)0.02038 + (embed)0.02795\n",
            "Epoch 45 (train)2.8s + (eval)0.5s: train loss = 0.04935 = (mf)0.02134 + (embed)0.02801, recall = 0.01212, ndcg = 0.16942\n",
            "Epoch 46 (train)2.4s: train loss = 0.04832 = (mf)0.02028 + (embed)0.02804\n",
            "Epoch 47 (train)2.3s: train loss = 0.04842 = (mf)0.02034 + (embed)0.02808\n",
            "Epoch 48 (train)2.3s: train loss = 0.04900 = (mf)0.02094 + (embed)0.02806\n",
            "Epoch 49 (train)2.7s: train loss = 0.04869 = (mf)0.02059 + (embed)0.02810\n",
            "Epoch 50 (train)2.5s + (eval)0.2s: train loss = 0.04692 = (mf)0.01887 + (embed)0.02804, recall = 0.01117, ndcg = 0.16477\n",
            "Training finished in 128.54 seconds.\n",
            "Evaluation results for this combination: NDCG@10: 0.16477, Recall@10: 0.01117\n",
            "--- Trying combination: Epochs=50, TopK=10, LearningRate=0.05, Layers=4 ---\n",
            "Already normalize adjacency matrix (extended).\n",
            "Using xavier initialization for user, item, and genre embeddings.\n",
            "Epoch 1 (train)3.3s: train loss = 0.16657 = (mf)0.16319 + (embed)0.00337\n",
            "Epoch 2 (train)2.9s: train loss = 0.08229 = (mf)0.07406 + (embed)0.00823\n",
            "Epoch 3 (train)2.4s: train loss = 0.06260 = (mf)0.05076 + (embed)0.01184\n",
            "Epoch 4 (train)2.4s: train loss = 0.05401 = (mf)0.03958 + (embed)0.01442\n",
            "Epoch 5 (train)2.4s + (eval)0.6s: train loss = 0.04919 = (mf)0.03294 + (embed)0.01625, recall = 0.01534, ndcg = 0.24175\n",
            "Epoch 6 (train)2.8s: train loss = 0.04833 = (mf)0.03076 + (embed)0.01757\n",
            "Epoch 7 (train)2.5s: train loss = 0.04532 = (mf)0.02669 + (embed)0.01863\n",
            "Epoch 8 (train)2.4s: train loss = 0.04447 = (mf)0.02499 + (embed)0.01948\n",
            "Epoch 9 (train)2.3s: train loss = 0.04374 = (mf)0.02357 + (embed)0.02017\n",
            "Epoch 10 (train)2.3s + (eval)0.6s: train loss = 0.04401 = (mf)0.02323 + (embed)0.02078, recall = 0.01373, ndcg = 0.22369\n",
            "Epoch 11 (train)2.9s: train loss = 0.04180 = (mf)0.02055 + (embed)0.02125\n",
            "Epoch 12 (train)2.4s: train loss = 0.04255 = (mf)0.02088 + (embed)0.02168\n",
            "Epoch 13 (train)2.3s: train loss = 0.04195 = (mf)0.01984 + (embed)0.02211\n",
            "Epoch 14 (train)2.4s: train loss = 0.04200 = (mf)0.01952 + (embed)0.02248\n",
            "Epoch 15 (train)2.4s + (eval)0.4s: train loss = 0.04109 = (mf)0.01834 + (embed)0.02275, recall = 0.01348, ndcg = 0.26902\n",
            "Epoch 16 (train)2.7s: train loss = 0.04113 = (mf)0.01830 + (embed)0.02283\n",
            "Epoch 17 (train)2.3s: train loss = 0.04079 = (mf)0.01778 + (embed)0.02302\n",
            "Epoch 18 (train)2.3s: train loss = 0.04155 = (mf)0.01842 + (embed)0.02313\n",
            "Epoch 19 (train)2.3s: train loss = 0.04143 = (mf)0.01800 + (embed)0.02343\n",
            "Epoch 20 (train)2.6s + (eval)0.4s: train loss = 0.04072 = (mf)0.01721 + (embed)0.02351, recall = 0.01457, ndcg = 0.26564\n",
            "Epoch 21 (train)2.6s: train loss = 0.04144 = (mf)0.01779 + (embed)0.02365\n",
            "Epoch 22 (train)2.4s: train loss = 0.04069 = (mf)0.01682 + (embed)0.02387\n",
            "Epoch 23 (train)2.3s: train loss = 0.04199 = (mf)0.01798 + (embed)0.02401\n",
            "Epoch 24 (train)2.4s: train loss = 0.04097 = (mf)0.01676 + (embed)0.02421\n",
            "Epoch 25 (train)2.8s + (eval)0.5s: train loss = 0.04028 = (mf)0.01607 + (embed)0.02421, recall = 0.01290, ndcg = 0.23733\n",
            "Epoch 26 (train)2.5s: train loss = 0.04133 = (mf)0.01705 + (embed)0.02428\n",
            "Epoch 27 (train)2.4s: train loss = 0.04169 = (mf)0.01708 + (embed)0.02460\n",
            "Epoch 28 (train)2.3s: train loss = 0.04103 = (mf)0.01624 + (embed)0.02479\n",
            "Epoch 29 (train)2.4s: train loss = 0.04105 = (mf)0.01631 + (embed)0.02474\n",
            "Epoch 30 (train)2.8s + (eval)0.2s: train loss = 0.04072 = (mf)0.01588 + (embed)0.02484, recall = 0.01441, ndcg = 0.26155\n",
            "Epoch 31 (train)2.4s: train loss = 0.04103 = (mf)0.01610 + (embed)0.02493\n",
            "Epoch 32 (train)2.4s: train loss = 0.04094 = (mf)0.01603 + (embed)0.02491\n",
            "Epoch 33 (train)2.4s: train loss = 0.04028 = (mf)0.01539 + (embed)0.02489\n",
            "Epoch 34 (train)2.7s: train loss = 0.04077 = (mf)0.01585 + (embed)0.02492\n",
            "Epoch 35 (train)2.6s + (eval)0.5s: train loss = 0.04120 = (mf)0.01619 + (embed)0.02501, recall = 0.01405, ndcg = 0.24238\n",
            "Epoch 36 (train)2.4s: train loss = 0.04147 = (mf)0.01640 + (embed)0.02507\n",
            "Epoch 37 (train)2.3s: train loss = 0.04143 = (mf)0.01631 + (embed)0.02512\n",
            "Epoch 38 (train)2.4s: train loss = 0.04073 = (mf)0.01563 + (embed)0.02510\n",
            "Epoch 39 (train)2.9s: train loss = 0.04068 = (mf)0.01560 + (embed)0.02508\n",
            "Epoch 40 (train)2.4s + (eval)0.2s: train loss = 0.04041 = (mf)0.01529 + (embed)0.02512, recall = 0.01517, ndcg = 0.22514\n",
            "Epoch 41 (train)2.3s: train loss = 0.04162 = (mf)0.01640 + (embed)0.02522\n",
            "Epoch 42 (train)2.3s: train loss = 0.04134 = (mf)0.01611 + (embed)0.02523\n",
            "Epoch 43 (train)2.5s: train loss = 0.04085 = (mf)0.01562 + (embed)0.02523\n",
            "Epoch 44 (train)2.8s: train loss = 0.04062 = (mf)0.01540 + (embed)0.02522\n",
            "Epoch 45 (train)2.4s + (eval)0.2s: train loss = 0.04019 = (mf)0.01501 + (embed)0.02518, recall = 0.01447, ndcg = 0.24554\n",
            "Epoch 46 (train)2.4s: train loss = 0.04004 = (mf)0.01487 + (embed)0.02517\n",
            "Epoch 47 (train)2.4s: train loss = 0.04052 = (mf)0.01555 + (embed)0.02497\n",
            "Epoch 48 (train)2.7s: train loss = 0.04039 = (mf)0.01531 + (embed)0.02508\n",
            "Epoch 49 (train)2.6s: train loss = 0.04031 = (mf)0.01524 + (embed)0.02507\n",
            "Epoch 50 (train)2.3s + (eval)0.5s: train loss = 0.04021 = (mf)0.01523 + (embed)0.02498, recall = 0.01687, ndcg = 0.26262\n",
            "Training finished in 129.04 seconds.\n",
            "Evaluation results for this combination: NDCG@10: 0.26262, Recall@10: 0.01687\n",
            "--- Trying combination: Epochs=50, TopK=10, LearningRate=0.05, Layers=5 ---\n",
            "Already normalize adjacency matrix (extended).\n",
            "Using xavier initialization for user, item, and genre embeddings.\n",
            "Epoch 1 (train)4.0s: train loss = 0.17479 = (mf)0.17112 + (embed)0.00367\n",
            "Epoch 2 (train)2.4s: train loss = 0.09198 = (mf)0.08307 + (embed)0.00891\n",
            "Epoch 3 (train)2.4s: train loss = 0.06947 = (mf)0.05657 + (embed)0.01289\n",
            "Epoch 4 (train)2.4s: train loss = 0.05890 = (mf)0.04318 + (embed)0.01572\n",
            "Epoch 5 (train)2.7s + (eval)1.2s: train loss = 0.05441 = (mf)0.03673 + (embed)0.01768, recall = 0.01569, ndcg = 0.28843\n",
            "Epoch 6 (train)2.5s: train loss = 0.05099 = (mf)0.03190 + (embed)0.01910\n",
            "Epoch 7 (train)2.5s: train loss = 0.04899 = (mf)0.02876 + (embed)0.02023\n",
            "Epoch 8 (train)2.8s: train loss = 0.04654 = (mf)0.02547 + (embed)0.02107\n",
            "Epoch 9 (train)2.8s: train loss = 0.04504 = (mf)0.02346 + (embed)0.02158\n",
            "Epoch 10 (train)2.8s + (eval)0.2s: train loss = 0.04495 = (mf)0.02287 + (embed)0.02207, recall = 0.01596, ndcg = 0.26931\n",
            "Epoch 11 (train)2.4s: train loss = 0.04298 = (mf)0.02048 + (embed)0.02250\n",
            "Epoch 12 (train)2.4s: train loss = 0.04279 = (mf)0.01997 + (embed)0.02281\n",
            "Epoch 13 (train)2.4s: train loss = 0.04293 = (mf)0.01973 + (embed)0.02320\n",
            "Epoch 14 (train)2.9s: train loss = 0.04292 = (mf)0.01941 + (embed)0.02351\n",
            "Epoch 15 (train)2.4s + (eval)0.5s: train loss = 0.04262 = (mf)0.01889 + (embed)0.02373, recall = 0.01464, ndcg = 0.28316\n",
            "Epoch 16 (train)2.4s: train loss = 0.04186 = (mf)0.01788 + (embed)0.02397\n",
            "Epoch 17 (train)2.4s: train loss = 0.04142 = (mf)0.01729 + (embed)0.02413\n",
            "Epoch 18 (train)2.5s: train loss = 0.04148 = (mf)0.01714 + (embed)0.02433\n",
            "Epoch 19 (train)2.8s: train loss = 0.04131 = (mf)0.01682 + (embed)0.02449\n",
            "Epoch 20 (train)2.4s + (eval)0.2s: train loss = 0.04177 = (mf)0.01717 + (embed)0.02460, recall = 0.01428, ndcg = 0.26570\n",
            "Epoch 21 (train)2.5s: train loss = 0.04085 = (mf)0.01608 + (embed)0.02477\n",
            "Epoch 22 (train)2.4s: train loss = 0.04167 = (mf)0.01684 + (embed)0.02483\n",
            "Epoch 23 (train)2.9s: train loss = 0.04124 = (mf)0.01628 + (embed)0.02497\n",
            "Epoch 24 (train)2.5s: train loss = 0.04114 = (mf)0.01606 + (embed)0.02508\n",
            "Epoch 25 (train)2.4s + (eval)0.3s: train loss = 0.04167 = (mf)0.01656 + (embed)0.02512, recall = 0.01396, ndcg = 0.23031\n",
            "Epoch 26 (train)2.4s: train loss = 0.04092 = (mf)0.01570 + (embed)0.02522\n",
            "Epoch 27 (train)2.4s: train loss = 0.04136 = (mf)0.01609 + (embed)0.02526\n",
            "Epoch 28 (train)3.0s: train loss = 0.04167 = (mf)0.01623 + (embed)0.02544\n",
            "Epoch 29 (train)2.4s: train loss = 0.04125 = (mf)0.01578 + (embed)0.02547\n",
            "Epoch 30 (train)2.4s + (eval)0.5s: train loss = 0.04059 = (mf)0.01521 + (embed)0.02537, recall = 0.01553, ndcg = 0.27168\n",
            "Epoch 31 (train)2.4s: train loss = 0.04070 = (mf)0.01520 + (embed)0.02550\n",
            "Epoch 32 (train)2.8s: train loss = 0.04073 = (mf)0.01520 + (embed)0.02553\n",
            "Epoch 33 (train)2.6s: train loss = 0.04082 = (mf)0.01533 + (embed)0.02549\n",
            "Epoch 34 (train)2.5s: train loss = 0.04108 = (mf)0.01552 + (embed)0.02556\n",
            "Epoch 35 (train)2.4s + (eval)0.2s: train loss = 0.04108 = (mf)0.01542 + (embed)0.02566, recall = 0.01580, ndcg = 0.25587\n",
            "Epoch 36 (train)2.5s: train loss = 0.04116 = (mf)0.01548 + (embed)0.02567\n",
            "Epoch 37 (train)2.9s: train loss = 0.04066 = (mf)0.01505 + (embed)0.02561\n",
            "Epoch 38 (train)2.5s: train loss = 0.04077 = (mf)0.01512 + (embed)0.02565\n",
            "Epoch 39 (train)2.5s: train loss = 0.04037 = (mf)0.01463 + (embed)0.02574\n",
            "Epoch 40 (train)2.5s + (eval)0.5s: train loss = 0.04124 = (mf)0.01549 + (embed)0.02576, recall = 0.01528, ndcg = 0.26053\n",
            "Epoch 41 (train)2.8s: train loss = 0.04047 = (mf)0.01467 + (embed)0.02580\n",
            "Epoch 42 (train)2.5s: train loss = 0.04072 = (mf)0.01497 + (embed)0.02574\n",
            "Epoch 43 (train)2.5s: train loss = 0.04010 = (mf)0.01441 + (embed)0.02569\n",
            "Epoch 44 (train)2.4s: train loss = 0.04049 = (mf)0.01479 + (embed)0.02570\n",
            "Epoch 45 (train)2.4s + (eval)0.2s: train loss = 0.04057 = (mf)0.01485 + (embed)0.02572, recall = 0.01538, ndcg = 0.26015\n",
            "Epoch 46 (train)2.9s: train loss = 0.04100 = (mf)0.01532 + (embed)0.02569\n",
            "Epoch 47 (train)2.5s: train loss = 0.04074 = (mf)0.01497 + (embed)0.02577\n",
            "Epoch 48 (train)2.4s: train loss = 0.04056 = (mf)0.01481 + (embed)0.02574\n",
            "Epoch 49 (train)2.5s: train loss = 0.04072 = (mf)0.01487 + (embed)0.02585\n",
            "Epoch 50 (train)2.7s + (eval)0.4s: train loss = 0.04129 = (mf)0.01542 + (embed)0.02587, recall = 0.01529, ndcg = 0.27662\n",
            "Training finished in 133.52 seconds.\n",
            "Evaluation results for this combination: NDCG@10: 0.27662, Recall@10: 0.01529\n",
            "--- Trying combination: Epochs=50, TopK=10, LearningRate=0.5, Layers=3 ---\n",
            "Already normalize adjacency matrix (extended).\n",
            "Using xavier initialization for user, item, and genre embeddings.\n",
            "Epoch 1 (train)3.4s: train loss = 0.96028 = (mf)0.78705 + (embed)0.17323\n",
            "Epoch 2 (train)2.7s: train loss = 1.94597 = (mf)1.44319 + (embed)0.50278\n",
            "Epoch 3 (train)2.8s: train loss = 2.65240 = (mf)1.89637 + (embed)0.75603\n",
            "Epoch 4 (train)2.4s: train loss = 2.98326 = (mf)2.02451 + (embed)0.95875\n",
            "Epoch 5 (train)2.4s + (eval)0.6s: train loss = 3.31862 = (mf)2.19570 + (embed)1.12293, recall = 0.00780, ndcg = 0.14620\n",
            "Epoch 6 (train)2.4s: train loss = 3.60133 = (mf)2.34277 + (embed)1.25856\n",
            "Epoch 7 (train)2.9s: train loss = 3.73666 = (mf)2.34656 + (embed)1.39010\n",
            "Epoch 8 (train)2.4s: train loss = 3.97542 = (mf)2.47292 + (embed)1.50249\n",
            "Epoch 9 (train)2.4s: train loss = 4.16959 = (mf)2.56711 + (embed)1.60248\n",
            "Epoch 10 (train)2.4s + (eval)0.6s: train loss = 4.15822 = (mf)2.47086 + (embed)1.68736, recall = 0.00896, ndcg = 0.17295\n",
            "Epoch 11 (train)2.5s: train loss = 4.22787 = (mf)2.46363 + (embed)1.76424\n",
            "Epoch 12 (train)2.8s: train loss = 4.31581 = (mf)2.48670 + (embed)1.82911\n",
            "Epoch 13 (train)2.5s: train loss = 4.44793 = (mf)2.55075 + (embed)1.89718\n",
            "Epoch 14 (train)2.5s: train loss = 4.65791 = (mf)2.69180 + (embed)1.96611\n",
            "Epoch 15 (train)2.5s + (eval)0.2s: train loss = 4.50332 = (mf)2.47887 + (embed)2.02444, recall = 0.00677, ndcg = 0.11814\n",
            "Epoch 16 (train)3.0s: train loss = 4.59459 = (mf)2.52205 + (embed)2.07254\n",
            "Epoch 17 (train)2.5s: train loss = 4.63661 = (mf)2.51307 + (embed)2.12354\n",
            "Epoch 18 (train)2.4s: train loss = 4.69712 = (mf)2.53025 + (embed)2.16687\n",
            "Epoch 19 (train)2.4s: train loss = 4.62081 = (mf)2.41421 + (embed)2.20660\n",
            "Epoch 20 (train)2.5s + (eval)0.3s: train loss = 4.71926 = (mf)2.48298 + (embed)2.23628, recall = 0.00879, ndcg = 0.12196\n",
            "Epoch 21 (train)3.0s: train loss = 4.82526 = (mf)2.55307 + (embed)2.27220\n",
            "Epoch 22 (train)2.5s: train loss = 4.81403 = (mf)2.51033 + (embed)2.30369\n",
            "Epoch 23 (train)2.4s: train loss = 4.87007 = (mf)2.54301 + (embed)2.32706\n",
            "Epoch 24 (train)2.4s: train loss = 4.82210 = (mf)2.47055 + (embed)2.35154\n",
            "Epoch 25 (train)2.7s + (eval)0.8s: train loss = 4.93543 = (mf)2.55617 + (embed)2.37925, recall = 0.01059, ndcg = 0.12740\n",
            "Epoch 26 (train)2.4s: train loss = 4.91603 = (mf)2.51270 + (embed)2.40333\n",
            "Epoch 27 (train)2.4s: train loss = 4.75065 = (mf)2.33102 + (embed)2.41962\n",
            "Epoch 28 (train)2.4s: train loss = 4.81635 = (mf)2.38292 + (embed)2.43343\n",
            "Epoch 29 (train)2.4s: train loss = 4.67747 = (mf)2.21824 + (embed)2.45923\n",
            "Epoch 30 (train)2.9s + (eval)0.2s: train loss = 4.79438 = (mf)2.31825 + (embed)2.47613, recall = 0.00753, ndcg = 0.10811\n",
            "Epoch 31 (train)2.4s: train loss = 4.88481 = (mf)2.39693 + (embed)2.48788\n",
            "Epoch 32 (train)2.4s: train loss = 4.86059 = (mf)2.35284 + (embed)2.50775\n",
            "Epoch 33 (train)2.4s: train loss = 4.67852 = (mf)2.16914 + (embed)2.50938\n",
            "Epoch 34 (train)2.5s: train loss = 4.75263 = (mf)2.22827 + (embed)2.52436\n",
            "Epoch 35 (train)2.8s + (eval)0.6s: train loss = 4.77240 = (mf)2.23305 + (embed)2.53935, recall = 0.00665, ndcg = 0.11550\n",
            "Epoch 36 (train)2.5s: train loss = 4.85810 = (mf)2.29517 + (embed)2.56293\n",
            "Epoch 37 (train)2.4s: train loss = 4.77031 = (mf)2.19992 + (embed)2.57040\n",
            "Epoch 38 (train)2.4s: train loss = 4.82740 = (mf)2.24251 + (embed)2.58489\n",
            "Epoch 39 (train)3.0s: train loss = 4.87231 = (mf)2.27223 + (embed)2.60009\n",
            "Epoch 40 (train)2.5s + (eval)0.3s: train loss = 4.83153 = (mf)2.22244 + (embed)2.60909, recall = 0.00750, ndcg = 0.13562\n",
            "Epoch 41 (train)2.4s: train loss = 4.87584 = (mf)2.25065 + (embed)2.62519\n",
            "Epoch 42 (train)2.4s: train loss = 4.96405 = (mf)2.32405 + (embed)2.64000\n",
            "Epoch 43 (train)2.5s: train loss = 4.89689 = (mf)2.24721 + (embed)2.64968\n",
            "Epoch 44 (train)2.8s: train loss = 4.97823 = (mf)2.32017 + (embed)2.65806\n",
            "Epoch 45 (train)2.4s + (eval)0.2s: train loss = 4.93851 = (mf)2.28593 + (embed)2.65258, recall = 0.00766, ndcg = 0.13205\n",
            "Epoch 46 (train)2.3s: train loss = 4.84927 = (mf)2.18685 + (embed)2.66243\n",
            "Epoch 47 (train)2.3s: train loss = 4.93160 = (mf)2.26485 + (embed)2.66675\n",
            "Epoch 48 (train)2.7s: train loss = 4.80409 = (mf)2.14180 + (embed)2.66229\n",
            "Epoch 49 (train)2.6s: train loss = 4.86871 = (mf)2.19669 + (embed)2.67203\n",
            "Epoch 50 (train)2.4s + (eval)0.5s: train loss = 4.84606 = (mf)2.16599 + (embed)2.68007, recall = 0.00642, ndcg = 0.10829\n",
            "Training finished in 131.52 seconds.\n",
            "Evaluation results for this combination: NDCG@10: 0.10829, Recall@10: 0.00642\n",
            "--- Trying combination: Epochs=50, TopK=10, LearningRate=0.5, Layers=4 ---\n",
            "Already normalize adjacency matrix (extended).\n",
            "Using xavier initialization for user, item, and genre embeddings.\n",
            "Epoch 1 (train)4.2s: train loss = 0.65441 = (mf)0.50878 + (embed)0.14562\n",
            "Epoch 2 (train)2.7s: train loss = 1.30078 = (mf)0.87888 + (embed)0.42191\n",
            "Epoch 3 (train)2.3s: train loss = 1.73262 = (mf)1.08625 + (embed)0.64637\n",
            "Epoch 4 (train)2.4s: train loss = 2.08918 = (mf)1.26741 + (embed)0.82177\n",
            "Epoch 5 (train)2.8s + (eval)1.0s: train loss = 2.29797 = (mf)1.34048 + (embed)0.95749, recall = 0.00794, ndcg = 0.13356\n",
            "Epoch 6 (train)2.5s: train loss = 2.40292 = (mf)1.33936 + (embed)1.06355\n",
            "Epoch 7 (train)2.4s: train loss = 2.55369 = (mf)1.40083 + (embed)1.15286\n",
            "Epoch 8 (train)2.4s: train loss = 2.67058 = (mf)1.43872 + (embed)1.23186\n",
            "Epoch 9 (train)2.5s: train loss = 2.71231 = (mf)1.41910 + (embed)1.29321\n",
            "Epoch 10 (train)2.7s + (eval)0.2s: train loss = 2.72601 = (mf)1.38538 + (embed)1.34062, recall = 0.00821, ndcg = 0.14406\n",
            "Epoch 11 (train)2.3s: train loss = 2.77670 = (mf)1.38421 + (embed)1.39250\n",
            "Epoch 12 (train)2.3s: train loss = 2.86754 = (mf)1.43295 + (embed)1.43460\n",
            "Epoch 13 (train)2.4s: train loss = 2.78985 = (mf)1.31611 + (embed)1.47374\n",
            "Epoch 14 (train)2.7s: train loss = 2.84927 = (mf)1.35482 + (embed)1.49444\n",
            "Epoch 15 (train)2.5s + (eval)0.5s: train loss = 2.84094 = (mf)1.32248 + (embed)1.51846, recall = 0.00724, ndcg = 0.13007\n",
            "Epoch 16 (train)2.4s: train loss = 2.86655 = (mf)1.32337 + (embed)1.54318\n",
            "Epoch 17 (train)2.3s: train loss = 2.94708 = (mf)1.37010 + (embed)1.57699\n",
            "Epoch 18 (train)2.3s: train loss = 2.95891 = (mf)1.35820 + (embed)1.60072\n",
            "Epoch 19 (train)2.9s: train loss = 2.85999 = (mf)1.24827 + (embed)1.61172\n",
            "Epoch 20 (train)2.4s + (eval)0.2s: train loss = 2.90398 = (mf)1.28241 + (embed)1.62157, recall = 0.00821, ndcg = 0.12122\n",
            "Epoch 21 (train)2.4s: train loss = 3.02500 = (mf)1.39352 + (embed)1.63148\n",
            "Epoch 22 (train)2.3s: train loss = 2.95798 = (mf)1.30142 + (embed)1.65656\n",
            "Epoch 23 (train)2.4s: train loss = 2.90692 = (mf)1.24677 + (embed)1.66015\n",
            "Epoch 24 (train)2.8s: train loss = 2.99809 = (mf)1.31853 + (embed)1.67956\n",
            "Epoch 25 (train)2.4s + (eval)0.6s: train loss = 2.88456 = (mf)1.19238 + (embed)1.69218, recall = 0.00794, ndcg = 0.15261\n",
            "Epoch 26 (train)2.4s: train loss = 2.88856 = (mf)1.19709 + (embed)1.69148\n",
            "Epoch 27 (train)2.4s: train loss = 2.90387 = (mf)1.20926 + (embed)1.69461\n",
            "Epoch 28 (train)2.8s: train loss = 2.94251 = (mf)1.24171 + (embed)1.70080\n",
            "Epoch 29 (train)2.4s: train loss = 2.96843 = (mf)1.26813 + (embed)1.70030\n",
            "Epoch 30 (train)2.4s + (eval)0.2s: train loss = 2.97640 = (mf)1.26516 + (embed)1.71124, recall = 0.00766, ndcg = 0.12588\n",
            "Epoch 31 (train)2.4s: train loss = 2.94117 = (mf)1.21698 + (embed)1.72419\n",
            "Epoch 32 (train)2.4s: train loss = 2.92423 = (mf)1.19615 + (embed)1.72808\n",
            "Epoch 33 (train)2.8s: train loss = 2.92597 = (mf)1.19106 + (embed)1.73491\n",
            "Epoch 34 (train)2.4s: train loss = 2.89263 = (mf)1.15450 + (embed)1.73812\n",
            "Epoch 35 (train)2.4s + (eval)0.2s: train loss = 2.94814 = (mf)1.20492 + (embed)1.74322, recall = 0.00666, ndcg = 0.11799\n",
            "Epoch 36 (train)2.4s: train loss = 3.02383 = (mf)1.27800 + (embed)1.74583\n",
            "Epoch 37 (train)2.5s: train loss = 3.01924 = (mf)1.26478 + (embed)1.75446\n",
            "Epoch 38 (train)2.8s: train loss = 2.94480 = (mf)1.18774 + (embed)1.75707\n",
            "Epoch 39 (train)2.4s: train loss = 2.99003 = (mf)1.23194 + (embed)1.75810\n",
            "Epoch 40 (train)2.4s + (eval)0.6s: train loss = 3.00745 = (mf)1.25073 + (embed)1.75672, recall = 0.00706, ndcg = 0.12171\n",
            "Epoch 41 (train)2.5s: train loss = 2.97080 = (mf)1.21223 + (embed)1.75857\n",
            "Epoch 42 (train)2.9s: train loss = 3.01006 = (mf)1.24335 + (embed)1.76671\n",
            "Epoch 43 (train)2.4s: train loss = 3.06984 = (mf)1.29571 + (embed)1.77414\n",
            "Epoch 44 (train)2.4s: train loss = 3.00056 = (mf)1.22419 + (embed)1.77637\n",
            "Epoch 45 (train)2.4s + (eval)0.2s: train loss = 2.93471 = (mf)1.15427 + (embed)1.78044, recall = 0.00778, ndcg = 0.13528\n",
            "Epoch 46 (train)2.4s: train loss = 2.91417 = (mf)1.14434 + (embed)1.76983\n",
            "Epoch 47 (train)2.9s: train loss = 2.91580 = (mf)1.15009 + (embed)1.76571\n",
            "Epoch 48 (train)2.3s: train loss = 2.93929 = (mf)1.17477 + (embed)1.76452\n",
            "Epoch 49 (train)2.3s: train loss = 2.93102 = (mf)1.15554 + (embed)1.77548\n",
            "Epoch 50 (train)2.3s + (eval)0.2s: train loss = 2.89692 = (mf)1.12533 + (embed)1.77159, recall = 0.00652, ndcg = 0.10869\n",
            "Training finished in 129.90 seconds.\n",
            "Evaluation results for this combination: NDCG@10: 0.10869, Recall@10: 0.00652\n",
            "--- Trying combination: Epochs=50, TopK=10, LearningRate=0.5, Layers=5 ---\n",
            "Already normalize adjacency matrix (extended).\n",
            "Using xavier initialization for user, item, and genre embeddings.\n",
            "Epoch 1 (train)3.5s: train loss = 0.48122 = (mf)0.35626 + (embed)0.12496\n",
            "Epoch 2 (train)2.4s: train loss = 0.90615 = (mf)0.54607 + (embed)0.36008\n",
            "Epoch 3 (train)2.5s: train loss = 1.25114 = (mf)0.69778 + (embed)0.55336\n",
            "Epoch 4 (train)2.9s: train loss = 1.51194 = (mf)0.81168 + (embed)0.70026\n",
            "Epoch 5 (train)2.4s + (eval)0.6s: train loss = 1.72342 = (mf)0.90920 + (embed)0.81422, recall = 0.00783, ndcg = 0.12085\n",
            "Epoch 6 (train)2.4s: train loss = 1.83688 = (mf)0.93652 + (embed)0.90036\n",
            "Epoch 7 (train)2.4s: train loss = 1.89690 = (mf)0.92697 + (embed)0.96993\n",
            "Epoch 8 (train)2.9s: train loss = 1.91529 = (mf)0.89527 + (embed)1.02003\n",
            "Epoch 9 (train)2.5s: train loss = 1.96413 = (mf)0.90163 + (embed)1.06250\n",
            "Epoch 10 (train)2.4s + (eval)0.6s: train loss = 1.99219 = (mf)0.90200 + (embed)1.09020, recall = 0.00636, ndcg = 0.12453\n",
            "Epoch 11 (train)2.4s: train loss = 2.05676 = (mf)0.93443 + (embed)1.12233\n",
            "Epoch 12 (train)2.6s: train loss = 2.05999 = (mf)0.90825 + (embed)1.15174\n",
            "Epoch 13 (train)2.9s: train loss = 2.06380 = (mf)0.88851 + (embed)1.17529\n",
            "Epoch 14 (train)2.5s: train loss = 2.01878 = (mf)0.82765 + (embed)1.19114\n",
            "Epoch 15 (train)2.5s + (eval)0.2s: train loss = 2.06518 = (mf)0.85434 + (embed)1.21084, recall = 0.00582, ndcg = 0.11393\n",
            "Epoch 16 (train)2.4s: train loss = 2.06063 = (mf)0.84400 + (embed)1.21663\n",
            "Epoch 17 (train)2.9s: train loss = 2.06552 = (mf)0.83628 + (embed)1.22924\n",
            "Epoch 18 (train)2.5s: train loss = 2.05707 = (mf)0.81839 + (embed)1.23868\n",
            "Epoch 19 (train)2.4s: train loss = 2.02837 = (mf)0.78868 + (embed)1.23969\n",
            "Epoch 20 (train)2.4s + (eval)0.6s: train loss = 2.03534 = (mf)0.79424 + (embed)1.24110, recall = 0.00804, ndcg = 0.11495\n",
            "Epoch 21 (train)2.5s: train loss = 2.04245 = (mf)0.79554 + (embed)1.24691\n",
            "Epoch 22 (train)2.9s: train loss = 2.03172 = (mf)0.78188 + (embed)1.24984\n",
            "Epoch 23 (train)2.4s: train loss = 2.03880 = (mf)0.77801 + (embed)1.26079\n",
            "Epoch 24 (train)2.4s: train loss = 2.06605 = (mf)0.79710 + (embed)1.26895\n",
            "Epoch 25 (train)2.4s + (eval)0.3s: train loss = 2.06566 = (mf)0.79121 + (embed)1.27445, recall = 0.00797, ndcg = 0.13270\n",
            "Epoch 26 (train)2.8s: train loss = 2.02870 = (mf)0.75400 + (embed)1.27469\n",
            "Epoch 27 (train)2.6s: train loss = 2.07426 = (mf)0.79686 + (embed)1.27740\n",
            "Epoch 28 (train)2.4s: train loss = 2.04907 = (mf)0.76911 + (embed)1.27996\n",
            "Epoch 29 (train)2.4s: train loss = 2.00952 = (mf)0.73770 + (embed)1.27181\n",
            "Epoch 30 (train)2.4s + (eval)0.2s: train loss = 2.01445 = (mf)0.74766 + (embed)1.26680, recall = 0.00637, ndcg = 0.10911\n",
            "Epoch 31 (train)2.9s: train loss = 2.02192 = (mf)0.75769 + (embed)1.26423\n",
            "Epoch 32 (train)2.4s: train loss = 2.00062 = (mf)0.74127 + (embed)1.25935\n",
            "Epoch 33 (train)2.4s: train loss = 2.02072 = (mf)0.76314 + (embed)1.25758\n",
            "Epoch 34 (train)2.4s: train loss = 2.05005 = (mf)0.78162 + (embed)1.26843\n",
            "Epoch 35 (train)2.5s + (eval)0.7s: train loss = 2.04246 = (mf)0.76131 + (embed)1.28115, recall = 0.00761, ndcg = 0.13022\n",
            "Epoch 36 (train)2.6s: train loss = 2.02800 = (mf)0.74990 + (embed)1.27809\n",
            "Epoch 37 (train)2.4s: train loss = 2.05121 = (mf)0.77273 + (embed)1.27849\n",
            "Epoch 38 (train)2.4s: train loss = 2.05896 = (mf)0.77854 + (embed)1.28042\n",
            "Epoch 39 (train)2.4s: train loss = 2.04066 = (mf)0.76454 + (embed)1.27612\n",
            "Epoch 40 (train)2.9s + (eval)0.2s: train loss = 2.06419 = (mf)0.78214 + (embed)1.28205, recall = 0.00573, ndcg = 0.12458\n",
            "Epoch 41 (train)2.5s: train loss = 1.99399 = (mf)0.71607 + (embed)1.27792\n",
            "Epoch 42 (train)2.4s: train loss = 2.05544 = (mf)0.78217 + (embed)1.27326\n",
            "Epoch 43 (train)2.4s: train loss = 2.03607 = (mf)0.75278 + (embed)1.28328\n",
            "Epoch 44 (train)2.4s: train loss = 2.07992 = (mf)0.78647 + (embed)1.29345\n",
            "Epoch 45 (train)2.9s + (eval)0.5s: train loss = 2.08863 = (mf)0.78571 + (embed)1.30292, recall = 0.00720, ndcg = 0.12056\n",
            "Epoch 46 (train)2.4s: train loss = 2.04755 = (mf)0.74597 + (embed)1.30159\n",
            "Epoch 47 (train)2.7s: train loss = 2.06714 = (mf)0.76671 + (embed)1.30043\n",
            "Epoch 48 (train)2.7s: train loss = 2.06329 = (mf)0.75998 + (embed)1.30331\n",
            "Epoch 49 (train)2.9s: train loss = 2.04549 = (mf)0.75031 + (embed)1.29517\n",
            "Epoch 50 (train)2.4s + (eval)0.2s: train loss = 2.02816 = (mf)0.73942 + (embed)1.28874, recall = 0.00539, ndcg = 0.12479\n",
            "Training finished in 132.54 seconds.\n",
            "Evaluation results for this combination: NDCG@10: 0.12479, Recall@10: 0.00539\n",
            "--- Trying combination: Epochs=50, TopK=20, LearningRate=0.005, Layers=3 ---\n",
            "Already normalize adjacency matrix (extended).\n",
            "Using xavier initialization for user, item, and genre embeddings.\n",
            "Epoch 1 (train)3.6s: train loss = 0.29271 = (mf)0.29216 + (embed)0.00056\n",
            "Epoch 2 (train)2.5s: train loss = 0.18817 = (mf)0.18720 + (embed)0.00098\n",
            "Epoch 3 (train)2.3s: train loss = 0.15204 = (mf)0.15066 + (embed)0.00138\n",
            "Epoch 4 (train)2.3s: train loss = 0.13302 = (mf)0.13122 + (embed)0.00180\n",
            "Epoch 5 (train)2.3s + (eval)0.6s: train loss = 0.11828 = (mf)0.11607 + (embed)0.00220, recall = 0.01835, ndcg = 0.18651\n",
            "Epoch 6 (train)2.9s: train loss = 0.10707 = (mf)0.10450 + (embed)0.00257\n",
            "Epoch 7 (train)2.4s: train loss = 0.09765 = (mf)0.09469 + (embed)0.00296\n",
            "Epoch 8 (train)2.4s: train loss = 0.08634 = (mf)0.08295 + (embed)0.00339\n",
            "Epoch 9 (train)2.3s: train loss = 0.07815 = (mf)0.07432 + (embed)0.00383\n",
            "Epoch 10 (train)2.4s + (eval)0.4s: train loss = 0.07306 = (mf)0.06883 + (embed)0.00423, recall = 0.02207, ndcg = 0.22079\n",
            "Epoch 11 (train)2.7s: train loss = 0.06769 = (mf)0.06307 + (embed)0.00462\n",
            "Epoch 12 (train)2.4s: train loss = 0.06171 = (mf)0.05675 + (embed)0.00497\n",
            "Epoch 13 (train)2.4s: train loss = 0.05893 = (mf)0.05361 + (embed)0.00532\n",
            "Epoch 14 (train)2.3s: train loss = 0.05580 = (mf)0.05018 + (embed)0.00563\n",
            "Epoch 15 (train)2.6s + (eval)0.8s: train loss = 0.05365 = (mf)0.04773 + (embed)0.00591, recall = 0.02561, ndcg = 0.24891\n",
            "Epoch 16 (train)2.5s: train loss = 0.05145 = (mf)0.04526 + (embed)0.00619\n",
            "Epoch 17 (train)2.4s: train loss = 0.04824 = (mf)0.04181 + (embed)0.00644\n",
            "Epoch 18 (train)2.3s: train loss = 0.04617 = (mf)0.03948 + (embed)0.00669\n",
            "Epoch 19 (train)2.4s: train loss = 0.04437 = (mf)0.03744 + (embed)0.00693\n",
            "Epoch 20 (train)2.9s + (eval)0.3s: train loss = 0.04291 = (mf)0.03577 + (embed)0.00714, recall = 0.02633, ndcg = 0.24961\n",
            "Epoch 21 (train)2.4s: train loss = 0.04145 = (mf)0.03409 + (embed)0.00736\n",
            "Epoch 22 (train)2.3s: train loss = 0.03973 = (mf)0.03218 + (embed)0.00755\n",
            "Epoch 23 (train)2.3s: train loss = 0.03890 = (mf)0.03119 + (embed)0.00771\n",
            "Epoch 24 (train)2.3s: train loss = 0.03746 = (mf)0.02959 + (embed)0.00788\n",
            "Epoch 25 (train)2.8s + (eval)0.6s: train loss = 0.03645 = (mf)0.02844 + (embed)0.00801, recall = 0.02791, ndcg = 0.25917\n",
            "Epoch 26 (train)2.3s: train loss = 0.03454 = (mf)0.02639 + (embed)0.00815\n",
            "Epoch 27 (train)2.4s: train loss = 0.03440 = (mf)0.02613 + (embed)0.00828\n",
            "Epoch 28 (train)2.3s: train loss = 0.03377 = (mf)0.02537 + (embed)0.00840\n",
            "Epoch 29 (train)2.6s: train loss = 0.03318 = (mf)0.02467 + (embed)0.00851\n",
            "Epoch 30 (train)2.6s + (eval)0.2s: train loss = 0.03257 = (mf)0.02395 + (embed)0.00862, recall = 0.02881, ndcg = 0.26077\n",
            "Epoch 31 (train)2.4s: train loss = 0.03164 = (mf)0.02291 + (embed)0.00873\n",
            "Epoch 32 (train)2.3s: train loss = 0.03084 = (mf)0.02203 + (embed)0.00882\n",
            "Epoch 33 (train)2.3s: train loss = 0.03014 = (mf)0.02126 + (embed)0.00888\n",
            "Epoch 34 (train)2.8s: train loss = 0.03038 = (mf)0.02141 + (embed)0.00897\n",
            "Epoch 35 (train)2.4s + (eval)0.2s: train loss = 0.02931 = (mf)0.02028 + (embed)0.00903, recall = 0.02819, ndcg = 0.26885\n",
            "Epoch 36 (train)2.4s: train loss = 0.02924 = (mf)0.02013 + (embed)0.00911\n",
            "Epoch 37 (train)2.3s: train loss = 0.02829 = (mf)0.01911 + (embed)0.00918\n",
            "Epoch 38 (train)2.3s: train loss = 0.02764 = (mf)0.01839 + (embed)0.00925\n",
            "Epoch 39 (train)2.8s: train loss = 0.02791 = (mf)0.01862 + (embed)0.00929\n",
            "Epoch 40 (train)2.4s + (eval)0.5s: train loss = 0.02743 = (mf)0.01808 + (embed)0.00935, recall = 0.02754, ndcg = 0.26923\n",
            "Epoch 41 (train)2.3s: train loss = 0.02694 = (mf)0.01755 + (embed)0.00940\n",
            "Epoch 42 (train)2.4s: train loss = 0.02650 = (mf)0.01705 + (embed)0.00945\n",
            "Epoch 43 (train)2.5s: train loss = 0.02621 = (mf)0.01674 + (embed)0.00948\n",
            "Epoch 44 (train)2.7s: train loss = 0.02554 = (mf)0.01601 + (embed)0.00953\n",
            "Epoch 45 (train)2.3s + (eval)0.2s: train loss = 0.02558 = (mf)0.01601 + (embed)0.00957, recall = 0.02721, ndcg = 0.27026\n",
            "Epoch 46 (train)2.3s: train loss = 0.02591 = (mf)0.01632 + (embed)0.00959\n",
            "Epoch 47 (train)2.3s: train loss = 0.02482 = (mf)0.01518 + (embed)0.00964\n",
            "Epoch 48 (train)2.7s: train loss = 0.02472 = (mf)0.01505 + (embed)0.00967\n",
            "Epoch 49 (train)2.5s: train loss = 0.02488 = (mf)0.01517 + (embed)0.00971\n",
            "Epoch 50 (train)2.3s + (eval)0.2s: train loss = 0.02396 = (mf)0.01424 + (embed)0.00972, recall = 0.02830, ndcg = 0.26899\n",
            "Training finished in 127.58 seconds.\n",
            "Evaluation results for this combination: NDCG@20: 0.26899, Recall@20: 0.02830\n",
            "--- Trying combination: Epochs=50, TopK=20, LearningRate=0.005, Layers=4 ---\n",
            "Already normalize adjacency matrix (extended).\n",
            "Using xavier initialization for user, item, and genre embeddings.\n",
            "Epoch 1 (train)4.1s: train loss = 0.29580 = (mf)0.29522 + (embed)0.00058\n",
            "Epoch 2 (train)2.4s: train loss = 0.20457 = (mf)0.20358 + (embed)0.00099\n",
            "Epoch 3 (train)2.3s: train loss = 0.18450 = (mf)0.18314 + (embed)0.00136\n",
            "Epoch 4 (train)2.3s: train loss = 0.15633 = (mf)0.15446 + (embed)0.00187\n",
            "Epoch 5 (train)2.7s + (eval)1.1s: train loss = 0.13766 = (mf)0.13524 + (embed)0.00242, recall = 0.01576, ndcg = 0.17236\n",
            "Epoch 6 (train)2.4s: train loss = 0.12541 = (mf)0.12256 + (embed)0.00285\n",
            "Epoch 7 (train)2.3s: train loss = 0.11670 = (mf)0.11344 + (embed)0.00326\n",
            "Epoch 8 (train)2.3s: train loss = 0.10773 = (mf)0.10402 + (embed)0.00371\n",
            "Epoch 9 (train)2.4s: train loss = 0.09757 = (mf)0.09337 + (embed)0.00419\n",
            "Epoch 10 (train)2.9s + (eval)0.3s: train loss = 0.08887 = (mf)0.08421 + (embed)0.00467, recall = 0.01995, ndcg = 0.21539\n",
            "Epoch 11 (train)2.4s: train loss = 0.08457 = (mf)0.07947 + (embed)0.00510\n",
            "Epoch 12 (train)2.3s: train loss = 0.07841 = (mf)0.07287 + (embed)0.00554\n",
            "Epoch 13 (train)2.3s: train loss = 0.07427 = (mf)0.06832 + (embed)0.00595\n",
            "Epoch 14 (train)2.6s: train loss = 0.07025 = (mf)0.06391 + (embed)0.00635\n",
            "Epoch 15 (train)2.6s + (eval)0.2s: train loss = 0.06663 = (mf)0.05992 + (embed)0.00671, recall = 0.02420, ndcg = 0.24862\n",
            "Epoch 16 (train)2.3s: train loss = 0.06562 = (mf)0.05858 + (embed)0.00703\n",
            "Epoch 17 (train)2.3s: train loss = 0.06209 = (mf)0.05475 + (embed)0.00734\n",
            "Epoch 18 (train)2.3s: train loss = 0.06061 = (mf)0.05300 + (embed)0.00761\n",
            "Epoch 19 (train)2.8s: train loss = 0.05786 = (mf)0.04998 + (embed)0.00788\n",
            "Epoch 20 (train)2.4s + (eval)0.6s: train loss = 0.05520 = (mf)0.04706 + (embed)0.00814, recall = 0.02649, ndcg = 0.26626\n",
            "Epoch 21 (train)2.3s: train loss = 0.05370 = (mf)0.04530 + (embed)0.00840\n",
            "Epoch 22 (train)2.4s: train loss = 0.05346 = (mf)0.04484 + (embed)0.00862\n",
            "Epoch 23 (train)2.3s: train loss = 0.05092 = (mf)0.04207 + (embed)0.00885\n",
            "Epoch 24 (train)2.9s: train loss = 0.04876 = (mf)0.03973 + (embed)0.00903\n",
            "Epoch 25 (train)2.4s + (eval)0.2s: train loss = 0.04763 = (mf)0.03841 + (embed)0.00922, recall = 0.02678, ndcg = 0.26611\n",
            "Epoch 26 (train)2.4s: train loss = 0.04678 = (mf)0.03736 + (embed)0.00941\n",
            "Epoch 27 (train)2.4s: train loss = 0.04526 = (mf)0.03567 + (embed)0.00958\n",
            "Epoch 28 (train)2.5s: train loss = 0.04366 = (mf)0.03392 + (embed)0.00974\n",
            "Epoch 29 (train)2.8s: train loss = 0.04353 = (mf)0.03364 + (embed)0.00990\n",
            "Epoch 30 (train)2.3s + (eval)0.3s: train loss = 0.04257 = (mf)0.03254 + (embed)0.01003, recall = 0.02661, ndcg = 0.26924\n",
            "Epoch 31 (train)2.3s: train loss = 0.04101 = (mf)0.03086 + (embed)0.01015\n",
            "Epoch 32 (train)2.3s: train loss = 0.04135 = (mf)0.03107 + (embed)0.01028\n",
            "Epoch 33 (train)2.6s: train loss = 0.03955 = (mf)0.02917 + (embed)0.01038\n",
            "Epoch 34 (train)2.6s: train loss = 0.04033 = (mf)0.02983 + (embed)0.01050\n",
            "Epoch 35 (train)2.3s + (eval)0.6s: train loss = 0.03871 = (mf)0.02809 + (embed)0.01062, recall = 0.02681, ndcg = 0.26605\n",
            "Epoch 36 (train)2.4s: train loss = 0.03733 = (mf)0.02663 + (embed)0.01071\n",
            "Epoch 37 (train)2.3s: train loss = 0.03662 = (mf)0.02581 + (embed)0.01081\n",
            "Epoch 38 (train)2.9s: train loss = 0.03638 = (mf)0.02548 + (embed)0.01090\n",
            "Epoch 39 (train)2.4s: train loss = 0.03611 = (mf)0.02512 + (embed)0.01099\n",
            "Epoch 40 (train)2.3s + (eval)0.2s: train loss = 0.03550 = (mf)0.02443 + (embed)0.01107, recall = 0.02801, ndcg = 0.27453\n",
            "Epoch 41 (train)2.3s: train loss = 0.03499 = (mf)0.02385 + (embed)0.01114\n",
            "Epoch 42 (train)2.4s: train loss = 0.03492 = (mf)0.02372 + (embed)0.01120\n",
            "Epoch 43 (train)3.5s: train loss = 0.03416 = (mf)0.02290 + (embed)0.01126\n",
            "Epoch 44 (train)2.4s: train loss = 0.03419 = (mf)0.02287 + (embed)0.01132\n",
            "Epoch 45 (train)2.4s + (eval)0.6s: train loss = 0.03393 = (mf)0.02256 + (embed)0.01137, recall = 0.02871, ndcg = 0.27539\n",
            "Epoch 46 (train)2.5s: train loss = 0.03304 = (mf)0.02161 + (embed)0.01143\n",
            "Epoch 47 (train)3.0s: train loss = 0.03287 = (mf)0.02137 + (embed)0.01150\n",
            "Epoch 48 (train)2.6s: train loss = 0.03277 = (mf)0.02124 + (embed)0.01153\n",
            "Epoch 49 (train)2.6s: train loss = 0.03253 = (mf)0.02094 + (embed)0.01159\n",
            "Epoch 50 (train)2.6s + (eval)0.3s: train loss = 0.03213 = (mf)0.02049 + (embed)0.01164, recall = 0.02939, ndcg = 0.28421\n",
            "Training finished in 130.48 seconds.\n",
            "Evaluation results for this combination: NDCG@20: 0.28421, Recall@20: 0.02939\n",
            "--- Trying combination: Epochs=50, TopK=20, LearningRate=0.005, Layers=5 ---\n",
            "Already normalize adjacency matrix (extended).\n",
            "Using xavier initialization for user, item, and genre embeddings.\n",
            "Epoch 1 (train)3.8s: train loss = 0.29860 = (mf)0.29801 + (embed)0.00059\n",
            "Epoch 2 (train)2.6s: train loss = 0.21174 = (mf)0.21071 + (embed)0.00104\n",
            "Epoch 3 (train)2.9s: train loss = 0.20061 = (mf)0.19918 + (embed)0.00143\n",
            "Epoch 4 (train)3.1s: train loss = 0.18200 = (mf)0.18006 + (embed)0.00194\n",
            "Epoch 5 (train)2.4s + (eval)0.7s: train loss = 0.15403 = (mf)0.15138 + (embed)0.00265, recall = 0.01478, ndcg = 0.16638\n",
            "Epoch 6 (train)2.5s: train loss = 0.14227 = (mf)0.13902 + (embed)0.00324\n",
            "Epoch 7 (train)2.6s: train loss = 0.13307 = (mf)0.12936 + (embed)0.00371\n",
            "Epoch 8 (train)2.8s: train loss = 0.12545 = (mf)0.12129 + (embed)0.00415\n",
            "Epoch 9 (train)2.4s: train loss = 0.11483 = (mf)0.11017 + (embed)0.00465\n",
            "Epoch 10 (train)2.4s + (eval)0.2s: train loss = 0.10810 = (mf)0.10296 + (embed)0.00514, recall = 0.01928, ndcg = 0.20472\n",
            "Epoch 11 (train)2.4s: train loss = 0.10141 = (mf)0.09579 + (embed)0.00562\n",
            "Epoch 12 (train)2.8s: train loss = 0.09611 = (mf)0.09000 + (embed)0.00611\n",
            "Epoch 13 (train)2.5s: train loss = 0.08978 = (mf)0.08318 + (embed)0.00660\n",
            "Epoch 14 (train)2.4s: train loss = 0.08648 = (mf)0.07940 + (embed)0.00707\n",
            "Epoch 15 (train)2.4s + (eval)0.6s: train loss = 0.08169 = (mf)0.07418 + (embed)0.00751, recall = 0.02174, ndcg = 0.22940\n",
            "Epoch 16 (train)2.5s: train loss = 0.07879 = (mf)0.07087 + (embed)0.00793\n",
            "Epoch 17 (train)2.9s: train loss = 0.07532 = (mf)0.06700 + (embed)0.00832\n",
            "Epoch 18 (train)2.4s: train loss = 0.07298 = (mf)0.06430 + (embed)0.00868\n",
            "Epoch 19 (train)2.4s: train loss = 0.07115 = (mf)0.06215 + (embed)0.00901\n",
            "Epoch 20 (train)2.4s + (eval)0.2s: train loss = 0.06906 = (mf)0.05974 + (embed)0.00932, recall = 0.02395, ndcg = 0.25061\n",
            "Epoch 21 (train)2.7s: train loss = 0.06675 = (mf)0.05714 + (embed)0.00961\n",
            "Epoch 22 (train)2.6s: train loss = 0.06490 = (mf)0.05505 + (embed)0.00985\n",
            "Epoch 23 (train)2.4s: train loss = 0.06288 = (mf)0.05275 + (embed)0.01012\n",
            "Epoch 24 (train)2.4s: train loss = 0.06090 = (mf)0.05052 + (embed)0.01037\n",
            "Epoch 25 (train)2.4s + (eval)0.2s: train loss = 0.05906 = (mf)0.04845 + (embed)0.01061, recall = 0.02566, ndcg = 0.24954\n",
            "Epoch 26 (train)2.9s: train loss = 0.05864 = (mf)0.04781 + (embed)0.01084\n",
            "Epoch 27 (train)2.4s: train loss = 0.05537 = (mf)0.04434 + (embed)0.01103\n",
            "Epoch 28 (train)2.4s: train loss = 0.05498 = (mf)0.04378 + (embed)0.01120\n",
            "Epoch 29 (train)2.4s: train loss = 0.05355 = (mf)0.04216 + (embed)0.01138\n",
            "Epoch 30 (train)2.5s + (eval)0.7s: train loss = 0.05418 = (mf)0.04263 + (embed)0.01155, recall = 0.02592, ndcg = 0.25370\n",
            "Epoch 31 (train)2.6s: train loss = 0.05214 = (mf)0.04044 + (embed)0.01170\n",
            "Epoch 32 (train)2.4s: train loss = 0.05113 = (mf)0.03924 + (embed)0.01189\n",
            "Epoch 33 (train)2.4s: train loss = 0.04991 = (mf)0.03787 + (embed)0.01203\n",
            "Epoch 34 (train)2.4s: train loss = 0.05000 = (mf)0.03783 + (embed)0.01217\n",
            "Epoch 35 (train)2.9s + (eval)0.2s: train loss = 0.04808 = (mf)0.03577 + (embed)0.01231, recall = 0.02721, ndcg = 0.26203\n",
            "Epoch 36 (train)2.5s: train loss = 0.04839 = (mf)0.03597 + (embed)0.01242\n",
            "Epoch 37 (train)2.4s: train loss = 0.04642 = (mf)0.03388 + (embed)0.01254\n",
            "Epoch 38 (train)2.4s: train loss = 0.04601 = (mf)0.03334 + (embed)0.01267\n",
            "Epoch 39 (train)2.4s: train loss = 0.04516 = (mf)0.03239 + (embed)0.01277\n",
            "Epoch 40 (train)2.9s + (eval)0.6s: train loss = 0.04528 = (mf)0.03242 + (embed)0.01286, recall = 0.02784, ndcg = 0.26282\n",
            "Epoch 41 (train)2.4s: train loss = 0.04411 = (mf)0.03118 + (embed)0.01293\n",
            "Epoch 42 (train)2.4s: train loss = 0.04400 = (mf)0.03098 + (embed)0.01301\n",
            "Epoch 43 (train)2.4s: train loss = 0.04336 = (mf)0.03026 + (embed)0.01309\n",
            "Epoch 44 (train)2.8s: train loss = 0.04256 = (mf)0.02936 + (embed)0.01319\n",
            "Epoch 45 (train)2.5s + (eval)0.3s: train loss = 0.04211 = (mf)0.02883 + (embed)0.01328, recall = 0.02748, ndcg = 0.25859\n",
            "Epoch 46 (train)2.4s: train loss = 0.04220 = (mf)0.02888 + (embed)0.01332\n",
            "Epoch 47 (train)2.4s: train loss = 0.04198 = (mf)0.02860 + (embed)0.01338\n",
            "Epoch 48 (train)2.4s: train loss = 0.04045 = (mf)0.02698 + (embed)0.01347\n",
            "Epoch 49 (train)2.9s: train loss = 0.04105 = (mf)0.02755 + (embed)0.01350\n",
            "Epoch 50 (train)2.5s + (eval)0.3s: train loss = 0.03947 = (mf)0.02589 + (embed)0.01358, recall = 0.02708, ndcg = 0.27080\n",
            "Training finished in 132.65 seconds.\n",
            "Evaluation results for this combination: NDCG@20: 0.27080, Recall@20: 0.02708\n",
            "--- Trying combination: Epochs=50, TopK=20, LearningRate=0.05, Layers=3 ---\n",
            "Already normalize adjacency matrix (extended).\n",
            "Using xavier initialization for user, item, and genre embeddings.\n",
            "Epoch 1 (train)3.9s: train loss = 0.15817 = (mf)0.15497 + (embed)0.00320\n",
            "Epoch 2 (train)2.4s: train loss = 0.07019 = (mf)0.06235 + (embed)0.00783\n",
            "Epoch 3 (train)2.3s: train loss = 0.05517 = (mf)0.04401 + (embed)0.01116\n",
            "Epoch 4 (train)2.3s: train loss = 0.04973 = (mf)0.03632 + (embed)0.01341\n",
            "Epoch 5 (train)2.3s + (eval)1.0s: train loss = 0.04781 = (mf)0.03267 + (embed)0.01513, recall = 0.01951, ndcg = 0.19633\n",
            "Epoch 6 (train)2.6s: train loss = 0.04524 = (mf)0.02875 + (embed)0.01650\n",
            "Epoch 7 (train)2.4s: train loss = 0.04679 = (mf)0.02908 + (embed)0.01770\n",
            "Epoch 8 (train)2.3s: train loss = 0.04513 = (mf)0.02645 + (embed)0.01868\n",
            "Epoch 9 (train)2.3s: train loss = 0.04622 = (mf)0.02663 + (embed)0.01960\n",
            "Epoch 10 (train)2.6s + (eval)0.7s: train loss = 0.04645 = (mf)0.02596 + (embed)0.02050, recall = 0.01863, ndcg = 0.17355\n",
            "Epoch 11 (train)2.4s: train loss = 0.04615 = (mf)0.02496 + (embed)0.02119\n",
            "Epoch 12 (train)2.3s: train loss = 0.04552 = (mf)0.02366 + (embed)0.02186\n",
            "Epoch 13 (train)2.3s: train loss = 0.04712 = (mf)0.02468 + (embed)0.02244\n",
            "Epoch 14 (train)2.3s: train loss = 0.04859 = (mf)0.02554 + (embed)0.02305\n",
            "Epoch 15 (train)2.8s + (eval)0.2s: train loss = 0.04772 = (mf)0.02428 + (embed)0.02344, recall = 0.01903, ndcg = 0.16937\n",
            "Epoch 16 (train)2.4s: train loss = 0.04639 = (mf)0.02252 + (embed)0.02387\n",
            "Epoch 17 (train)2.3s: train loss = 0.04754 = (mf)0.02340 + (embed)0.02414\n",
            "Epoch 18 (train)2.3s: train loss = 0.04687 = (mf)0.02229 + (embed)0.02458\n",
            "Epoch 19 (train)2.3s: train loss = 0.04872 = (mf)0.02384 + (embed)0.02488\n",
            "Epoch 20 (train)2.9s + (eval)0.2s: train loss = 0.04881 = (mf)0.02352 + (embed)0.02528, recall = 0.02073, ndcg = 0.17938\n",
            "Epoch 21 (train)2.4s: train loss = 0.04748 = (mf)0.02197 + (embed)0.02551\n",
            "Epoch 22 (train)2.3s: train loss = 0.04908 = (mf)0.02330 + (embed)0.02578\n",
            "Epoch 23 (train)2.3s: train loss = 0.04766 = (mf)0.02169 + (embed)0.02597\n",
            "Epoch 24 (train)2.5s: train loss = 0.04997 = (mf)0.02370 + (embed)0.02627\n",
            "Epoch 25 (train)2.7s + (eval)0.6s: train loss = 0.04882 = (mf)0.02222 + (embed)0.02660, recall = 0.01988, ndcg = 0.16576\n",
            "Epoch 26 (train)2.3s: train loss = 0.04873 = (mf)0.02204 + (embed)0.02669\n",
            "Epoch 27 (train)2.3s: train loss = 0.04834 = (mf)0.02156 + (embed)0.02678\n",
            "Epoch 28 (train)2.3s: train loss = 0.04874 = (mf)0.02181 + (embed)0.02693\n",
            "Epoch 29 (train)2.8s: train loss = 0.04867 = (mf)0.02158 + (embed)0.02709\n",
            "Epoch 30 (train)2.4s + (eval)0.3s: train loss = 0.04859 = (mf)0.02138 + (embed)0.02721, recall = 0.02040, ndcg = 0.16725\n",
            "Epoch 31 (train)2.3s: train loss = 0.04874 = (mf)0.02147 + (embed)0.02726\n",
            "Epoch 32 (train)2.3s: train loss = 0.04755 = (mf)0.02016 + (embed)0.02739\n",
            "Epoch 33 (train)2.3s: train loss = 0.04821 = (mf)0.02079 + (embed)0.02742\n",
            "Epoch 34 (train)2.9s: train loss = 0.04919 = (mf)0.02167 + (embed)0.02752\n",
            "Epoch 35 (train)2.5s + (eval)0.4s: train loss = 0.04846 = (mf)0.02088 + (embed)0.02758, recall = 0.02051, ndcg = 0.17517\n",
            "Epoch 36 (train)2.7s: train loss = 0.04785 = (mf)0.02020 + (embed)0.02765\n",
            "Epoch 37 (train)2.4s: train loss = 0.04912 = (mf)0.02140 + (embed)0.02772\n",
            "Epoch 38 (train)2.5s: train loss = 0.04780 = (mf)0.02011 + (embed)0.02769\n",
            "Epoch 39 (train)2.6s: train loss = 0.04831 = (mf)0.02058 + (embed)0.02773\n",
            "Epoch 40 (train)2.4s + (eval)0.6s: train loss = 0.04926 = (mf)0.02145 + (embed)0.02781, recall = 0.01891, ndcg = 0.16866\n",
            "Epoch 41 (train)2.4s: train loss = 0.04870 = (mf)0.02079 + (embed)0.02791\n",
            "Epoch 42 (train)2.4s: train loss = 0.04768 = (mf)0.01974 + (embed)0.02793\n",
            "Epoch 43 (train)2.9s: train loss = 0.04933 = (mf)0.02140 + (embed)0.02794\n",
            "Epoch 44 (train)2.4s: train loss = 0.04807 = (mf)0.02007 + (embed)0.02800\n",
            "Epoch 45 (train)2.4s + (eval)0.2s: train loss = 0.04849 = (mf)0.02039 + (embed)0.02810, recall = 0.01798, ndcg = 0.17483\n",
            "Epoch 46 (train)2.4s: train loss = 0.04880 = (mf)0.02063 + (embed)0.02817\n",
            "Epoch 47 (train)2.4s: train loss = 0.04919 = (mf)0.02098 + (embed)0.02820\n",
            "Epoch 48 (train)2.9s: train loss = 0.04851 = (mf)0.02033 + (embed)0.02818\n",
            "Epoch 49 (train)2.3s: train loss = 0.04935 = (mf)0.02115 + (embed)0.02820\n",
            "Epoch 50 (train)2.3s + (eval)0.6s: train loss = 0.04777 = (mf)0.01954 + (embed)0.02824, recall = 0.02056, ndcg = 0.16285\n",
            "Training finished in 128.63 seconds.\n",
            "Evaluation results for this combination: NDCG@20: 0.16285, Recall@20: 0.02056\n",
            "--- Trying combination: Epochs=50, TopK=20, LearningRate=0.05, Layers=4 ---\n",
            "Already normalize adjacency matrix (extended).\n",
            "Using xavier initialization for user, item, and genre embeddings.\n",
            "Epoch 1 (train)3.5s: train loss = 0.16178 = (mf)0.15835 + (embed)0.00343\n",
            "Epoch 2 (train)2.3s: train loss = 0.08090 = (mf)0.07257 + (embed)0.00833\n",
            "Epoch 3 (train)2.3s: train loss = 0.06044 = (mf)0.04842 + (embed)0.01202\n",
            "Epoch 4 (train)2.4s: train loss = 0.05277 = (mf)0.03824 + (embed)0.01454\n",
            "Epoch 5 (train)2.9s + (eval)1.0s: train loss = 0.04851 = (mf)0.03217 + (embed)0.01634, recall = 0.02386, ndcg = 0.20705\n",
            "Epoch 6 (train)2.4s: train loss = 0.04665 = (mf)0.02904 + (embed)0.01761\n",
            "Epoch 7 (train)2.4s: train loss = 0.04513 = (mf)0.02648 + (embed)0.01865\n",
            "Epoch 8 (train)2.4s: train loss = 0.04423 = (mf)0.02473 + (embed)0.01950\n",
            "Epoch 9 (train)2.8s: train loss = 0.04384 = (mf)0.02365 + (embed)0.02019\n",
            "Epoch 10 (train)2.4s + (eval)0.3s: train loss = 0.04270 = (mf)0.02196 + (embed)0.02073, recall = 0.02209, ndcg = 0.20682\n",
            "Epoch 11 (train)2.4s: train loss = 0.04213 = (mf)0.02093 + (embed)0.02120\n",
            "Epoch 12 (train)2.4s: train loss = 0.04199 = (mf)0.02030 + (embed)0.02169\n",
            "Epoch 13 (train)2.3s: train loss = 0.04090 = (mf)0.01891 + (embed)0.02199\n",
            "Epoch 14 (train)2.9s: train loss = 0.04186 = (mf)0.01961 + (embed)0.02225\n",
            "Epoch 15 (train)2.4s + (eval)0.2s: train loss = 0.04221 = (mf)0.01950 + (embed)0.02271, recall = 0.02485, ndcg = 0.22794\n",
            "Epoch 16 (train)2.4s: train loss = 0.04102 = (mf)0.01796 + (embed)0.02306\n",
            "Epoch 17 (train)2.4s: train loss = 0.04037 = (mf)0.01720 + (embed)0.02317\n",
            "Epoch 18 (train)2.5s: train loss = 0.04082 = (mf)0.01757 + (embed)0.02325\n",
            "Epoch 19 (train)2.8s: train loss = 0.04043 = (mf)0.01692 + (embed)0.02351\n",
            "Epoch 20 (train)2.4s + (eval)0.6s: train loss = 0.04103 = (mf)0.01742 + (embed)0.02360, recall = 0.02202, ndcg = 0.20549\n",
            "Epoch 21 (train)2.3s: train loss = 0.04081 = (mf)0.01705 + (embed)0.02376\n",
            "Epoch 22 (train)2.3s: train loss = 0.04146 = (mf)0.01753 + (embed)0.02393\n",
            "Epoch 23 (train)2.8s: train loss = 0.04066 = (mf)0.01652 + (embed)0.02414\n",
            "Epoch 24 (train)2.4s: train loss = 0.04088 = (mf)0.01669 + (embed)0.02420\n",
            "Epoch 25 (train)2.4s + (eval)0.3s: train loss = 0.04144 = (mf)0.01709 + (embed)0.02435, recall = 0.02241, ndcg = 0.20117\n",
            "Epoch 26 (train)2.3s: train loss = 0.04060 = (mf)0.01611 + (embed)0.02448\n",
            "Epoch 27 (train)2.3s: train loss = 0.04111 = (mf)0.01656 + (embed)0.02455\n",
            "Epoch 28 (train)2.9s: train loss = 0.04063 = (mf)0.01594 + (embed)0.02469\n",
            "Epoch 29 (train)2.4s: train loss = 0.04126 = (mf)0.01654 + (embed)0.02472\n",
            "Epoch 30 (train)2.3s + (eval)0.2s: train loss = 0.04192 = (mf)0.01704 + (embed)0.02488, recall = 0.02192, ndcg = 0.20061\n",
            "Epoch 31 (train)2.4s: train loss = 0.04122 = (mf)0.01625 + (embed)0.02497\n",
            "Epoch 32 (train)2.5s: train loss = 0.04152 = (mf)0.01647 + (embed)0.02505\n",
            "Epoch 33 (train)2.8s: train loss = 0.04056 = (mf)0.01547 + (embed)0.02509\n",
            "Epoch 34 (train)2.3s: train loss = 0.04074 = (mf)0.01572 + (embed)0.02501\n",
            "Epoch 35 (train)2.4s + (eval)0.6s: train loss = 0.04083 = (mf)0.01578 + (embed)0.02506, recall = 0.02082, ndcg = 0.19717\n",
            "Epoch 36 (train)2.4s: train loss = 0.04067 = (mf)0.01554 + (embed)0.02513\n",
            "Epoch 37 (train)2.8s: train loss = 0.04003 = (mf)0.01502 + (embed)0.02501\n",
            "Epoch 38 (train)2.5s: train loss = 0.03966 = (mf)0.01468 + (embed)0.02499\n",
            "Epoch 39 (train)2.3s: train loss = 0.04014 = (mf)0.01523 + (embed)0.02491\n",
            "Epoch 40 (train)2.3s + (eval)0.2s: train loss = 0.04036 = (mf)0.01540 + (embed)0.02496, recall = 0.02219, ndcg = 0.18503\n",
            "Epoch 41 (train)2.4s: train loss = 0.04066 = (mf)0.01563 + (embed)0.02503\n",
            "Epoch 42 (train)2.9s: train loss = 0.04119 = (mf)0.01616 + (embed)0.02503\n",
            "Epoch 43 (train)2.4s: train loss = 0.04083 = (mf)0.01572 + (embed)0.02511\n",
            "Epoch 44 (train)2.3s: train loss = 0.04097 = (mf)0.01580 + (embed)0.02517\n",
            "Epoch 45 (train)2.3s + (eval)0.3s: train loss = 0.04115 = (mf)0.01590 + (embed)0.02524, recall = 0.02070, ndcg = 0.19857\n",
            "Epoch 46 (train)2.4s: train loss = 0.04044 = (mf)0.01523 + (embed)0.02521\n",
            "Epoch 47 (train)2.8s: train loss = 0.04052 = (mf)0.01533 + (embed)0.02520\n",
            "Epoch 48 (train)2.3s: train loss = 0.04002 = (mf)0.01486 + (embed)0.02516\n",
            "Epoch 49 (train)2.4s: train loss = 0.04048 = (mf)0.01532 + (embed)0.02516\n",
            "Epoch 50 (train)2.3s + (eval)0.6s: train loss = 0.04033 = (mf)0.01517 + (embed)0.02516, recall = 0.02196, ndcg = 0.18292\n",
            "Training finished in 128.53 seconds.\n",
            "Evaluation results for this combination: NDCG@20: 0.18292, Recall@20: 0.02196\n",
            "--- Trying combination: Epochs=50, TopK=20, LearningRate=0.05, Layers=5 ---\n",
            "Already normalize adjacency matrix (extended).\n",
            "Using xavier initialization for user, item, and genre embeddings.\n",
            "Epoch 1 (train)3.6s: train loss = 0.17107 = (mf)0.16740 + (embed)0.00366\n",
            "Epoch 2 (train)2.4s: train loss = 0.09356 = (mf)0.08477 + (embed)0.00880\n",
            "Epoch 3 (train)2.7s: train loss = 0.07098 = (mf)0.05807 + (embed)0.01290\n",
            "Epoch 4 (train)2.7s: train loss = 0.06098 = (mf)0.04519 + (embed)0.01580\n",
            "Epoch 5 (train)2.4s + (eval)1.0s: train loss = 0.05485 = (mf)0.03707 + (embed)0.01777, recall = 0.02545, ndcg = 0.23699\n",
            "Epoch 6 (train)2.4s: train loss = 0.05185 = (mf)0.03272 + (embed)0.01914\n",
            "Epoch 7 (train)2.4s: train loss = 0.04953 = (mf)0.02940 + (embed)0.02013\n",
            "Epoch 8 (train)2.9s: train loss = 0.04723 = (mf)0.02630 + (embed)0.02093\n",
            "Epoch 9 (train)2.4s: train loss = 0.04564 = (mf)0.02407 + (embed)0.02157\n",
            "Epoch 10 (train)2.4s + (eval)0.3s: train loss = 0.04599 = (mf)0.02378 + (embed)0.02221, recall = 0.02436, ndcg = 0.24060\n",
            "Epoch 11 (train)2.4s: train loss = 0.04456 = (mf)0.02191 + (embed)0.02265\n",
            "Epoch 12 (train)2.7s: train loss = 0.04482 = (mf)0.02176 + (embed)0.02306\n",
            "Epoch 13 (train)2.6s: train loss = 0.04416 = (mf)0.02078 + (embed)0.02338\n",
            "Epoch 14 (train)2.4s: train loss = 0.04417 = (mf)0.02050 + (embed)0.02368\n",
            "Epoch 15 (train)2.4s + (eval)0.2s: train loss = 0.04334 = (mf)0.01938 + (embed)0.02396, recall = 0.02518, ndcg = 0.21474\n",
            "Epoch 16 (train)2.4s: train loss = 0.04257 = (mf)0.01846 + (embed)0.02411\n",
            "Epoch 17 (train)2.9s: train loss = 0.04320 = (mf)0.01888 + (embed)0.02432\n",
            "Epoch 18 (train)2.4s: train loss = 0.04241 = (mf)0.01787 + (embed)0.02454\n",
            "Epoch 19 (train)2.4s: train loss = 0.04256 = (mf)0.01782 + (embed)0.02474\n",
            "Epoch 20 (train)2.4s + (eval)0.6s: train loss = 0.04229 = (mf)0.01741 + (embed)0.02488, recall = 0.02477, ndcg = 0.22345\n",
            "Epoch 21 (train)2.6s: train loss = 0.04187 = (mf)0.01693 + (embed)0.02494\n",
            "Epoch 22 (train)2.8s: train loss = 0.04187 = (mf)0.01682 + (embed)0.02505\n",
            "Epoch 23 (train)2.4s: train loss = 0.04146 = (mf)0.01634 + (embed)0.02512\n",
            "Epoch 24 (train)2.4s: train loss = 0.04200 = (mf)0.01677 + (embed)0.02523\n",
            "Epoch 25 (train)2.4s + (eval)0.3s: train loss = 0.04176 = (mf)0.01649 + (embed)0.02527, recall = 0.02377, ndcg = 0.21497\n",
            "Epoch 26 (train)2.9s: train loss = 0.04148 = (mf)0.01611 + (embed)0.02537\n",
            "Epoch 27 (train)2.4s: train loss = 0.04108 = (mf)0.01569 + (embed)0.02539\n",
            "Epoch 28 (train)2.4s: train loss = 0.04061 = (mf)0.01526 + (embed)0.02535\n",
            "Epoch 29 (train)2.9s: train loss = 0.04150 = (mf)0.01606 + (embed)0.02544\n",
            "Epoch 30 (train)2.5s + (eval)0.8s: train loss = 0.04150 = (mf)0.01601 + (embed)0.02549, recall = 0.02584, ndcg = 0.23081\n",
            "Epoch 31 (train)2.6s: train loss = 0.04084 = (mf)0.01528 + (embed)0.02556\n",
            "Epoch 32 (train)2.4s: train loss = 0.04081 = (mf)0.01533 + (embed)0.02548\n",
            "Epoch 33 (train)2.4s: train loss = 0.04062 = (mf)0.01518 + (embed)0.02544\n",
            "Epoch 34 (train)2.4s: train loss = 0.04136 = (mf)0.01583 + (embed)0.02554\n",
            "Epoch 35 (train)2.8s + (eval)0.3s: train loss = 0.04123 = (mf)0.01567 + (embed)0.02556, recall = 0.02394, ndcg = 0.21235\n",
            "Epoch 36 (train)2.5s: train loss = 0.04092 = (mf)0.01535 + (embed)0.02557\n",
            "Epoch 37 (train)2.4s: train loss = 0.04045 = (mf)0.01491 + (embed)0.02554\n",
            "Epoch 38 (train)2.4s: train loss = 0.04081 = (mf)0.01516 + (embed)0.02565\n",
            "Epoch 39 (train)2.4s: train loss = 0.04070 = (mf)0.01498 + (embed)0.02572\n",
            "Epoch 40 (train)2.9s + (eval)0.3s: train loss = 0.04103 = (mf)0.01527 + (embed)0.02576, recall = 0.02387, ndcg = 0.21868\n",
            "Epoch 41 (train)2.4s: train loss = 0.04077 = (mf)0.01514 + (embed)0.02563\n",
            "Epoch 42 (train)2.4s: train loss = 0.04142 = (mf)0.01560 + (embed)0.02581\n",
            "Epoch 43 (train)2.4s: train loss = 0.04115 = (mf)0.01530 + (embed)0.02585\n",
            "Epoch 44 (train)2.6s: train loss = 0.04058 = (mf)0.01472 + (embed)0.02586\n",
            "Epoch 45 (train)2.7s + (eval)0.6s: train loss = 0.04159 = (mf)0.01574 + (embed)0.02586, recall = 0.02492, ndcg = 0.23270\n",
            "Epoch 46 (train)2.4s: train loss = 0.04110 = (mf)0.01508 + (embed)0.02602\n",
            "Epoch 47 (train)2.4s: train loss = 0.04077 = (mf)0.01475 + (embed)0.02602\n",
            "Epoch 48 (train)2.4s: train loss = 0.04131 = (mf)0.01540 + (embed)0.02591\n",
            "Epoch 49 (train)2.9s: train loss = 0.04010 = (mf)0.01416 + (embed)0.02594\n",
            "Epoch 50 (train)2.4s + (eval)0.2s: train loss = 0.04054 = (mf)0.01477 + (embed)0.02577, recall = 0.02453, ndcg = 0.19911\n",
            "Training finished in 131.81 seconds.\n",
            "Evaluation results for this combination: NDCG@20: 0.19911, Recall@20: 0.02453\n",
            "--- Trying combination: Epochs=50, TopK=20, LearningRate=0.5, Layers=3 ---\n",
            "Already normalize adjacency matrix (extended).\n",
            "Using xavier initialization for user, item, and genre embeddings.\n",
            "Epoch 1 (train)4.0s: train loss = 0.92160 = (mf)0.75388 + (embed)0.16772\n",
            "Epoch 2 (train)2.4s: train loss = 1.95517 = (mf)1.45940 + (embed)0.49577\n",
            "Epoch 3 (train)2.3s: train loss = 2.65924 = (mf)1.88844 + (embed)0.77080\n",
            "Epoch 4 (train)2.3s: train loss = 3.10199 = (mf)2.12007 + (embed)0.98191\n",
            "Epoch 5 (train)2.3s + (eval)1.0s: train loss = 3.47548 = (mf)2.32101 + (embed)1.15448, recall = 0.01196, ndcg = 0.11894\n",
            "Epoch 6 (train)2.6s: train loss = 3.62620 = (mf)2.32522 + (embed)1.30098\n",
            "Epoch 7 (train)2.3s: train loss = 3.84099 = (mf)2.41732 + (embed)1.42368\n",
            "Epoch 8 (train)2.3s: train loss = 4.05291 = (mf)2.52257 + (embed)1.53034\n",
            "Epoch 9 (train)2.3s: train loss = 4.15935 = (mf)2.52541 + (embed)1.63394\n",
            "Epoch 10 (train)2.6s + (eval)0.4s: train loss = 4.31769 = (mf)2.58262 + (embed)1.73507, recall = 0.01304, ndcg = 0.12455\n",
            "Epoch 11 (train)2.5s: train loss = 4.35389 = (mf)2.54198 + (embed)1.81191\n",
            "Epoch 12 (train)2.3s: train loss = 4.57206 = (mf)2.69792 + (embed)1.87414\n",
            "Epoch 13 (train)2.3s: train loss = 4.47153 = (mf)2.53692 + (embed)1.93461\n",
            "Epoch 14 (train)2.3s: train loss = 4.52107 = (mf)2.53010 + (embed)1.99097\n",
            "Epoch 15 (train)2.8s + (eval)0.6s: train loss = 4.55750 = (mf)2.51492 + (embed)2.04258, recall = 0.01451, ndcg = 0.13140\n",
            "Epoch 16 (train)2.4s: train loss = 4.55901 = (mf)2.47598 + (embed)2.08303\n",
            "Epoch 17 (train)2.3s: train loss = 4.70730 = (mf)2.57678 + (embed)2.13051\n",
            "Epoch 18 (train)2.3s: train loss = 4.66712 = (mf)2.49924 + (embed)2.16788\n",
            "Epoch 19 (train)2.3s: train loss = 4.79208 = (mf)2.58471 + (embed)2.20737\n",
            "Epoch 20 (train)2.8s + (eval)0.3s: train loss = 4.68733 = (mf)2.45104 + (embed)2.23629, recall = 0.01189, ndcg = 0.10482\n",
            "Epoch 21 (train)2.3s: train loss = 4.83628 = (mf)2.56831 + (embed)2.26797\n",
            "Epoch 22 (train)2.3s: train loss = 4.79184 = (mf)2.48751 + (embed)2.30433\n",
            "Epoch 23 (train)2.3s: train loss = 4.82667 = (mf)2.49416 + (embed)2.33252\n",
            "Epoch 24 (train)2.5s: train loss = 4.72699 = (mf)2.37295 + (embed)2.35405\n",
            "Epoch 25 (train)2.7s + (eval)0.3s: train loss = 4.79826 = (mf)2.41559 + (embed)2.38268, recall = 0.01479, ndcg = 0.13267\n",
            "Epoch 26 (train)2.4s: train loss = 4.75792 = (mf)2.35422 + (embed)2.40370\n",
            "Epoch 27 (train)2.3s: train loss = 4.81129 = (mf)2.39200 + (embed)2.41929\n",
            "Epoch 28 (train)2.3s: train loss = 4.85113 = (mf)2.39519 + (embed)2.45594\n",
            "Epoch 29 (train)2.6s: train loss = 4.87006 = (mf)2.39873 + (embed)2.47132\n",
            "Epoch 30 (train)2.6s + (eval)0.6s: train loss = 4.87480 = (mf)2.39597 + (embed)2.47883, recall = 0.01344, ndcg = 0.13071\n",
            "Epoch 31 (train)2.3s: train loss = 4.81700 = (mf)2.31820 + (embed)2.49880\n",
            "Epoch 32 (train)2.3s: train loss = 4.91217 = (mf)2.39357 + (embed)2.51860\n",
            "Epoch 33 (train)2.3s: train loss = 4.97986 = (mf)2.44342 + (embed)2.53644\n",
            "Epoch 34 (train)2.8s: train loss = 4.76710 = (mf)2.22049 + (embed)2.54662\n",
            "Epoch 35 (train)2.3s + (eval)0.2s: train loss = 4.87768 = (mf)2.31931 + (embed)2.55837, recall = 0.01385, ndcg = 0.12445\n",
            "Epoch 36 (train)2.3s: train loss = 4.76877 = (mf)2.20172 + (embed)2.56705\n",
            "Epoch 37 (train)2.3s: train loss = 4.79505 = (mf)2.22249 + (embed)2.57256\n",
            "Epoch 38 (train)2.3s: train loss = 4.84642 = (mf)2.27030 + (embed)2.57612\n",
            "Epoch 39 (train)2.8s: train loss = 4.78765 = (mf)2.20361 + (embed)2.58404\n",
            "Epoch 40 (train)2.4s + (eval)0.6s: train loss = 4.80056 = (mf)2.19864 + (embed)2.60193, recall = 0.01495, ndcg = 0.10858\n",
            "Epoch 41 (train)2.3s: train loss = 4.79971 = (mf)2.19122 + (embed)2.60848\n",
            "Epoch 42 (train)2.3s: train loss = 4.85870 = (mf)2.24846 + (embed)2.61024\n",
            "Epoch 43 (train)2.5s: train loss = 4.94416 = (mf)2.32183 + (embed)2.62233\n",
            "Epoch 44 (train)2.7s: train loss = 4.95873 = (mf)2.33041 + (embed)2.62832\n",
            "Epoch 45 (train)2.3s + (eval)0.2s: train loss = 4.84943 = (mf)2.20574 + (embed)2.64369, recall = 0.01506, ndcg = 0.12352\n",
            "Epoch 46 (train)2.3s: train loss = 4.87854 = (mf)2.23003 + (embed)2.64852\n",
            "Epoch 47 (train)2.3s: train loss = 4.81324 = (mf)2.16141 + (embed)2.65183\n",
            "Epoch 48 (train)2.7s: train loss = 4.85262 = (mf)2.20258 + (embed)2.65004\n",
            "Epoch 49 (train)2.5s: train loss = 4.96449 = (mf)2.30918 + (embed)2.65531\n",
            "Epoch 50 (train)2.3s + (eval)0.3s: train loss = 4.95312 = (mf)2.28553 + (embed)2.66759, recall = 0.01539, ndcg = 0.12021\n",
            "Training finished in 127.34 seconds.\n",
            "Evaluation results for this combination: NDCG@20: 0.12021, Recall@20: 0.01539\n",
            "--- Trying combination: Epochs=50, TopK=20, LearningRate=0.5, Layers=4 ---\n",
            "Already normalize adjacency matrix (extended).\n",
            "Using xavier initialization for user, item, and genre embeddings.\n",
            "Epoch 1 (train)3.9s: train loss = 0.66026 = (mf)0.51156 + (embed)0.14869\n",
            "Epoch 2 (train)2.4s: train loss = 1.29980 = (mf)0.86720 + (embed)0.43260\n",
            "Epoch 3 (train)2.3s: train loss = 1.78947 = (mf)1.13854 + (embed)0.65093\n",
            "Epoch 4 (train)2.3s: train loss = 2.10627 = (mf)1.28066 + (embed)0.82560\n",
            "Epoch 5 (train)2.8s + (eval)0.8s: train loss = 2.28211 = (mf)1.31605 + (embed)0.96606, recall = 0.01346, ndcg = 0.12880\n",
            "Epoch 6 (train)2.4s: train loss = 2.50072 = (mf)1.43073 + (embed)1.06999\n",
            "Epoch 7 (train)2.3s: train loss = 2.52853 = (mf)1.37608 + (embed)1.15245\n",
            "Epoch 8 (train)2.3s: train loss = 2.58287 = (mf)1.36129 + (embed)1.22158\n",
            "Epoch 9 (train)2.4s: train loss = 2.72198 = (mf)1.43600 + (embed)1.28598\n",
            "Epoch 10 (train)2.8s + (eval)0.3s: train loss = 2.73524 = (mf)1.38207 + (embed)1.35317, recall = 0.01223, ndcg = 0.14409\n",
            "Epoch 11 (train)2.4s: train loss = 2.84391 = (mf)1.44490 + (embed)1.39901\n",
            "Epoch 12 (train)2.3s: train loss = 2.87956 = (mf)1.43172 + (embed)1.44784\n",
            "Epoch 13 (train)2.3s: train loss = 2.89665 = (mf)1.41259 + (embed)1.48406\n",
            "Epoch 14 (train)2.6s: train loss = 2.94776 = (mf)1.43100 + (embed)1.51677\n",
            "Epoch 15 (train)2.6s + (eval)0.6s: train loss = 2.91399 = (mf)1.36788 + (embed)1.54611, recall = 0.01323, ndcg = 0.11168\n",
            "Epoch 16 (train)2.3s: train loss = 2.92980 = (mf)1.36585 + (embed)1.56395\n",
            "Epoch 17 (train)2.3s: train loss = 2.88880 = (mf)1.30215 + (embed)1.58665\n",
            "Epoch 18 (train)2.3s: train loss = 2.95001 = (mf)1.35342 + (embed)1.59659\n",
            "Epoch 19 (train)2.8s: train loss = 2.92531 = (mf)1.30257 + (embed)1.62274\n",
            "Epoch 20 (train)2.4s + (eval)0.2s: train loss = 2.95142 = (mf)1.31400 + (embed)1.63741, recall = 0.01262, ndcg = 0.10031\n",
            "Epoch 21 (train)2.3s: train loss = 2.94914 = (mf)1.30377 + (embed)1.64536\n",
            "Epoch 22 (train)2.5s: train loss = 2.83705 = (mf)1.18627 + (embed)1.65078\n",
            "Epoch 23 (train)2.9s: train loss = 2.91389 = (mf)1.25631 + (embed)1.65757\n",
            "Epoch 24 (train)2.7s: train loss = 3.01144 = (mf)1.33918 + (embed)1.67225\n",
            "Epoch 25 (train)2.4s + (eval)0.6s: train loss = 3.00587 = (mf)1.31895 + (embed)1.68692, recall = 0.01232, ndcg = 0.11932\n",
            "Epoch 26 (train)2.4s: train loss = 2.95356 = (mf)1.25773 + (embed)1.69584\n",
            "Epoch 27 (train)2.3s: train loss = 3.02858 = (mf)1.31858 + (embed)1.71000\n",
            "Epoch 28 (train)2.8s: train loss = 2.98570 = (mf)1.26505 + (embed)1.72065\n",
            "Epoch 29 (train)2.4s: train loss = 3.01554 = (mf)1.28993 + (embed)1.72562\n",
            "Epoch 30 (train)2.3s + (eval)0.3s: train loss = 2.94331 = (mf)1.21940 + (embed)1.72391, recall = 0.01381, ndcg = 0.12840\n",
            "Epoch 31 (train)2.3s: train loss = 3.01913 = (mf)1.29119 + (embed)1.72793\n",
            "Epoch 32 (train)2.3s: train loss = 3.03669 = (mf)1.30130 + (embed)1.73539\n",
            "Epoch 33 (train)2.8s: train loss = 3.07692 = (mf)1.33359 + (embed)1.74333\n",
            "Epoch 34 (train)2.3s: train loss = 2.96281 = (mf)1.21017 + (embed)1.75263\n",
            "Epoch 35 (train)2.3s + (eval)0.2s: train loss = 3.02065 = (mf)1.26237 + (embed)1.75828, recall = 0.01478, ndcg = 0.12926\n",
            "Epoch 36 (train)2.4s: train loss = 3.02137 = (mf)1.25787 + (embed)1.76349\n",
            "Epoch 37 (train)2.4s: train loss = 3.08084 = (mf)1.31456 + (embed)1.76629\n",
            "Epoch 38 (train)2.8s: train loss = 2.91742 = (mf)1.15252 + (embed)1.76490\n",
            "Epoch 39 (train)2.3s: train loss = 2.98476 = (mf)1.21588 + (embed)1.76888\n",
            "Epoch 40 (train)2.3s + (eval)0.6s: train loss = 2.92476 = (mf)1.15565 + (embed)1.76911, recall = 0.01364, ndcg = 0.12997\n",
            "Epoch 41 (train)2.4s: train loss = 2.91158 = (mf)1.14792 + (embed)1.76365\n",
            "Epoch 42 (train)2.7s: train loss = 2.92952 = (mf)1.16469 + (embed)1.76483\n",
            "Epoch 43 (train)2.5s: train loss = 2.94165 = (mf)1.17760 + (embed)1.76405\n",
            "Epoch 44 (train)2.3s: train loss = 2.94727 = (mf)1.18150 + (embed)1.76577\n",
            "Epoch 45 (train)2.4s + (eval)0.2s: train loss = 2.95022 = (mf)1.18361 + (embed)1.76662, recall = 0.01449, ndcg = 0.12397\n",
            "Epoch 46 (train)2.3s: train loss = 2.93919 = (mf)1.17977 + (embed)1.75942\n",
            "Epoch 47 (train)2.9s: train loss = 3.01285 = (mf)1.24441 + (embed)1.76845\n",
            "Epoch 48 (train)2.3s: train loss = 2.98758 = (mf)1.21556 + (embed)1.77202\n",
            "Epoch 49 (train)2.3s: train loss = 3.00606 = (mf)1.22590 + (embed)1.78015\n",
            "Epoch 50 (train)2.3s + (eval)0.2s: train loss = 2.96498 = (mf)1.18171 + (embed)1.78327, recall = 0.01331, ndcg = 0.11273\n",
            "Training finished in 128.44 seconds.\n",
            "Evaluation results for this combination: NDCG@20: 0.11273, Recall@20: 0.01331\n",
            "--- Trying combination: Epochs=50, TopK=20, LearningRate=0.5, Layers=5 ---\n",
            "Already normalize adjacency matrix (extended).\n",
            "Using xavier initialization for user, item, and genre embeddings.\n",
            "Epoch 1 (train)3.7s: train loss = 0.49854 = (mf)0.37460 + (embed)0.12394\n",
            "Epoch 2 (train)2.4s: train loss = 0.91325 = (mf)0.54624 + (embed)0.36701\n",
            "Epoch 3 (train)2.5s: train loss = 1.24228 = (mf)0.69364 + (embed)0.54865\n",
            "Epoch 4 (train)2.8s: train loss = 1.47674 = (mf)0.78852 + (embed)0.68822\n",
            "Epoch 5 (train)2.4s + (eval)0.8s: train loss = 1.66796 = (mf)0.86611 + (embed)0.80185, recall = 0.01343, ndcg = 0.12035\n",
            "Epoch 6 (train)2.4s: train loss = 1.80672 = (mf)0.91274 + (embed)0.89398\n",
            "Epoch 7 (train)2.4s: train loss = 1.87252 = (mf)0.90449 + (embed)0.96803\n",
            "Epoch 8 (train)2.9s: train loss = 1.98812 = (mf)0.95803 + (embed)1.03009\n",
            "Epoch 9 (train)2.4s: train loss = 1.99874 = (mf)0.92498 + (embed)1.07376\n",
            "Epoch 10 (train)2.4s + (eval)0.2s: train loss = 2.03877 = (mf)0.92623 + (embed)1.11254, recall = 0.01152, ndcg = 0.10173\n",
            "Epoch 11 (train)2.4s: train loss = 2.05452 = (mf)0.91165 + (embed)1.14288\n",
            "Epoch 12 (train)2.5s: train loss = 2.03088 = (mf)0.86576 + (embed)1.16512\n",
            "Epoch 13 (train)2.8s: train loss = 2.06197 = (mf)0.88496 + (embed)1.17701\n",
            "Epoch 14 (train)2.4s: train loss = 2.05844 = (mf)0.86766 + (embed)1.19079\n",
            "Epoch 15 (train)2.4s + (eval)0.6s: train loss = 2.04378 = (mf)0.84923 + (embed)1.19454, recall = 0.01350, ndcg = 0.11971\n",
            "Epoch 16 (train)2.4s: train loss = 2.04531 = (mf)0.83787 + (embed)1.20744\n",
            "Epoch 17 (train)2.9s: train loss = 2.05179 = (mf)0.83598 + (embed)1.21581\n",
            "Epoch 18 (train)2.4s: train loss = 2.03393 = (mf)0.80596 + (embed)1.22797\n",
            "Epoch 19 (train)2.4s: train loss = 2.01788 = (mf)0.78258 + (embed)1.23530\n",
            "Epoch 20 (train)2.4s + (eval)0.3s: train loss = 2.04804 = (mf)0.80172 + (embed)1.24632, recall = 0.01204, ndcg = 0.10807\n",
            "Epoch 21 (train)2.4s: train loss = 2.05177 = (mf)0.79740 + (embed)1.25437\n",
            "Epoch 22 (train)2.9s: train loss = 2.10892 = (mf)0.83865 + (embed)1.27027\n",
            "Epoch 23 (train)2.4s: train loss = 2.11104 = (mf)0.83626 + (embed)1.27478\n",
            "Epoch 24 (train)2.4s: train loss = 2.07301 = (mf)0.79791 + (embed)1.27510\n",
            "Epoch 25 (train)2.4s + (eval)0.2s: train loss = 2.06380 = (mf)0.79465 + (embed)1.26915, recall = 0.01324, ndcg = 0.13167\n",
            "Epoch 26 (train)2.7s: train loss = 2.02917 = (mf)0.76130 + (embed)1.26787\n",
            "Epoch 27 (train)2.6s: train loss = 2.08557 = (mf)0.81101 + (embed)1.27456\n",
            "Epoch 28 (train)2.4s: train loss = 2.06983 = (mf)0.79266 + (embed)1.27717\n",
            "Epoch 29 (train)2.4s: train loss = 2.04654 = (mf)0.76857 + (embed)1.27797\n",
            "Epoch 30 (train)2.4s + (eval)0.6s: train loss = 2.02844 = (mf)0.75122 + (embed)1.27722, recall = 0.01204, ndcg = 0.09662\n",
            "Epoch 31 (train)3.0s: train loss = 2.03794 = (mf)0.76049 + (embed)1.27745\n",
            "Epoch 32 (train)2.4s: train loss = 1.99330 = (mf)0.72716 + (embed)1.26614\n",
            "Epoch 33 (train)2.4s: train loss = 2.03259 = (mf)0.76423 + (embed)1.26836\n",
            "Epoch 34 (train)2.4s: train loss = 2.02512 = (mf)0.75229 + (embed)1.27283\n",
            "Epoch 35 (train)2.5s + (eval)0.4s: train loss = 1.99456 = (mf)0.72036 + (embed)1.27421, recall = 0.01340, ndcg = 0.12269\n",
            "Epoch 36 (train)2.7s: train loss = 2.00658 = (mf)0.73382 + (embed)1.27275\n",
            "Epoch 37 (train)2.4s: train loss = 2.00331 = (mf)0.73385 + (embed)1.26947\n",
            "Epoch 38 (train)2.4s: train loss = 2.01709 = (mf)0.74109 + (embed)1.27600\n",
            "Epoch 39 (train)2.4s: train loss = 2.02935 = (mf)0.74918 + (embed)1.28017\n",
            "Epoch 40 (train)2.9s + (eval)0.6s: train loss = 2.06399 = (mf)0.78282 + (embed)1.28117, recall = 0.01191, ndcg = 0.09090\n",
            "Epoch 41 (train)2.5s: train loss = 2.04334 = (mf)0.75338 + (embed)1.28996\n",
            "Epoch 42 (train)2.4s: train loss = 2.04650 = (mf)0.76424 + (embed)1.28226\n",
            "Epoch 43 (train)2.4s: train loss = 2.04328 = (mf)0.75626 + (embed)1.28702\n",
            "Epoch 44 (train)2.5s: train loss = 2.07467 = (mf)0.78475 + (embed)1.28993\n",
            "Epoch 45 (train)2.8s + (eval)0.3s: train loss = 2.09089 = (mf)0.79358 + (embed)1.29731, recall = 0.01126, ndcg = 0.10199\n",
            "Epoch 46 (train)2.4s: train loss = 2.00980 = (mf)0.71859 + (embed)1.29121\n",
            "Epoch 47 (train)2.4s: train loss = 2.01550 = (mf)0.72408 + (embed)1.29142\n",
            "Epoch 48 (train)2.4s: train loss = 2.01441 = (mf)0.72435 + (embed)1.29006\n",
            "Epoch 49 (train)2.7s: train loss = 2.02553 = (mf)0.73927 + (embed)1.28626\n",
            "Epoch 50 (train)2.6s + (eval)0.2s: train loss = 2.06562 = (mf)0.77575 + (embed)1.28987, recall = 0.01249, ndcg = 0.10913\n",
            "Training finished in 131.48 seconds.\n",
            "Evaluation results for this combination: NDCG@20: 0.10913, Recall@20: 0.01249\n",
            "--- Trying combination: Epochs=50, TopK=50, LearningRate=0.005, Layers=3 ---\n",
            "Already normalize adjacency matrix (extended).\n",
            "Using xavier initialization for user, item, and genre embeddings.\n",
            "Epoch 1 (train)3.9s: train loss = 0.28941 = (mf)0.28884 + (embed)0.00057\n",
            "Epoch 2 (train)2.4s: train loss = 0.17743 = (mf)0.17642 + (embed)0.00101\n",
            "Epoch 3 (train)2.3s: train loss = 0.14805 = (mf)0.14666 + (embed)0.00139\n",
            "Epoch 4 (train)2.3s: train loss = 0.13174 = (mf)0.12998 + (embed)0.00176\n",
            "Epoch 5 (train)2.4s + (eval)0.9s: train loss = 0.11820 = (mf)0.11606 + (embed)0.00214, recall = 0.03152, ndcg = 0.14061\n",
            "Epoch 6 (train)2.8s: train loss = 0.10466 = (mf)0.10210 + (embed)0.00256\n",
            "Epoch 7 (train)2.3s: train loss = 0.09473 = (mf)0.09176 + (embed)0.00297\n",
            "Epoch 8 (train)2.3s: train loss = 0.08438 = (mf)0.08101 + (embed)0.00337\n",
            "Epoch 9 (train)2.3s: train loss = 0.07767 = (mf)0.07387 + (embed)0.00381\n",
            "Epoch 10 (train)2.5s + (eval)0.4s: train loss = 0.07135 = (mf)0.06714 + (embed)0.00421, recall = 0.03870, ndcg = 0.17874\n",
            "Epoch 11 (train)2.6s: train loss = 0.06681 = (mf)0.06220 + (embed)0.00461\n",
            "Epoch 12 (train)2.4s: train loss = 0.06221 = (mf)0.05725 + (embed)0.00496\n",
            "Epoch 13 (train)2.4s: train loss = 0.05816 = (mf)0.05285 + (embed)0.00531\n",
            "Epoch 14 (train)2.5s: train loss = 0.05525 = (mf)0.04963 + (embed)0.00562\n",
            "Epoch 15 (train)3.3s + (eval)0.6s: train loss = 0.05171 = (mf)0.04577 + (embed)0.00594, recall = 0.04020, ndcg = 0.18642\n",
            "Epoch 16 (train)2.4s: train loss = 0.04927 = (mf)0.04306 + (embed)0.00621\n",
            "Epoch 17 (train)2.4s: train loss = 0.04725 = (mf)0.04076 + (embed)0.00649\n",
            "Epoch 18 (train)2.3s: train loss = 0.04559 = (mf)0.03888 + (embed)0.00672\n",
            "Epoch 19 (train)2.4s: train loss = 0.04367 = (mf)0.03674 + (embed)0.00694\n",
            "Epoch 20 (train)2.8s + (eval)0.3s: train loss = 0.04231 = (mf)0.03515 + (embed)0.00716, recall = 0.04296, ndcg = 0.19430\n",
            "Epoch 21 (train)2.4s: train loss = 0.04083 = (mf)0.03347 + (embed)0.00736\n",
            "Epoch 22 (train)2.4s: train loss = 0.03934 = (mf)0.03177 + (embed)0.00757\n",
            "Epoch 23 (train)2.3s: train loss = 0.03890 = (mf)0.03118 + (embed)0.00772\n",
            "Epoch 24 (train)2.6s: train loss = 0.03670 = (mf)0.02882 + (embed)0.00787\n",
            "Epoch 25 (train)2.6s + (eval)0.6s: train loss = 0.03585 = (mf)0.02781 + (embed)0.00804, recall = 0.04330, ndcg = 0.19554\n",
            "Epoch 26 (train)2.4s: train loss = 0.03505 = (mf)0.02687 + (embed)0.00817\n",
            "Epoch 27 (train)2.3s: train loss = 0.03409 = (mf)0.02579 + (embed)0.00830\n",
            "Epoch 28 (train)2.3s: train loss = 0.03341 = (mf)0.02499 + (embed)0.00842\n",
            "Epoch 29 (train)2.9s: train loss = 0.03237 = (mf)0.02383 + (embed)0.00853\n",
            "Epoch 30 (train)2.4s + (eval)0.3s: train loss = 0.03234 = (mf)0.02371 + (embed)0.00863, recall = 0.04372, ndcg = 0.19775\n",
            "Epoch 31 (train)2.4s: train loss = 0.03107 = (mf)0.02234 + (embed)0.00873\n",
            "Epoch 32 (train)2.3s: train loss = 0.03036 = (mf)0.02155 + (embed)0.00881\n",
            "Epoch 33 (train)2.3s: train loss = 0.03096 = (mf)0.02207 + (embed)0.00889\n",
            "Epoch 34 (train)2.9s: train loss = 0.02987 = (mf)0.02089 + (embed)0.00898\n",
            "Epoch 35 (train)2.4s + (eval)0.3s: train loss = 0.02935 = (mf)0.02030 + (embed)0.00905, recall = 0.04288, ndcg = 0.19798\n",
            "Epoch 36 (train)2.4s: train loss = 0.02861 = (mf)0.01949 + (embed)0.00912\n",
            "Epoch 37 (train)2.3s: train loss = 0.02767 = (mf)0.01848 + (embed)0.00918\n",
            "Epoch 38 (train)2.5s: train loss = 0.02757 = (mf)0.01832 + (embed)0.00925\n",
            "Epoch 39 (train)2.6s: train loss = 0.02706 = (mf)0.01775 + (embed)0.00931\n",
            "Epoch 40 (train)2.3s + (eval)0.6s: train loss = 0.02674 = (mf)0.01738 + (embed)0.00936, recall = 0.04508, ndcg = 0.20702\n",
            "Epoch 41 (train)2.3s: train loss = 0.02692 = (mf)0.01751 + (embed)0.00941\n",
            "Epoch 42 (train)2.3s: train loss = 0.02607 = (mf)0.01661 + (embed)0.00946\n",
            "Epoch 43 (train)2.8s: train loss = 0.02607 = (mf)0.01656 + (embed)0.00950\n",
            "Epoch 44 (train)2.4s: train loss = 0.02606 = (mf)0.01651 + (embed)0.00955\n",
            "Epoch 45 (train)2.3s + (eval)0.3s: train loss = 0.02537 = (mf)0.01579 + (embed)0.00958, recall = 0.04517, ndcg = 0.20261\n",
            "Epoch 46 (train)2.4s: train loss = 0.02514 = (mf)0.01551 + (embed)0.00963\n",
            "Epoch 47 (train)2.3s: train loss = 0.02445 = (mf)0.01477 + (embed)0.00967\n",
            "Epoch 48 (train)2.9s: train loss = 0.02482 = (mf)0.01511 + (embed)0.00971\n",
            "Epoch 49 (train)2.4s: train loss = 0.02412 = (mf)0.01440 + (embed)0.00972\n",
            "Epoch 50 (train)2.3s + (eval)0.3s: train loss = 0.02449 = (mf)0.01474 + (embed)0.00975, recall = 0.04489, ndcg = 0.19755\n",
            "Training finished in 129.13 seconds.\n",
            "Evaluation results for this combination: NDCG@50: 0.19755, Recall@50: 0.04489\n",
            "--- Trying combination: Epochs=50, TopK=50, LearningRate=0.005, Layers=4 ---\n",
            "Already normalize adjacency matrix (extended).\n",
            "Using xavier initialization for user, item, and genre embeddings.\n",
            "Epoch 1 (train)3.5s: train loss = 0.29404 = (mf)0.29346 + (embed)0.00058\n",
            "Epoch 2 (train)2.3s: train loss = 0.19985 = (mf)0.19883 + (embed)0.00102\n",
            "Epoch 3 (train)2.3s: train loss = 0.17101 = (mf)0.16956 + (embed)0.00144\n",
            "Epoch 4 (train)2.5s: train loss = 0.14954 = (mf)0.14763 + (embed)0.00191\n",
            "Epoch 5 (train)2.7s + (eval)0.8s: train loss = 0.13626 = (mf)0.13391 + (embed)0.00235, recall = 0.02858, ndcg = 0.13290\n",
            "Epoch 6 (train)2.4s: train loss = 0.12537 = (mf)0.12260 + (embed)0.00277\n",
            "Epoch 7 (train)2.4s: train loss = 0.11697 = (mf)0.11378 + (embed)0.00319\n",
            "Epoch 8 (train)2.3s: train loss = 0.10623 = (mf)0.10258 + (embed)0.00365\n",
            "Epoch 9 (train)2.9s: train loss = 0.09698 = (mf)0.09284 + (embed)0.00413\n",
            "Epoch 10 (train)2.3s + (eval)0.3s: train loss = 0.09034 = (mf)0.08571 + (embed)0.00463, recall = 0.03379, ndcg = 0.16060\n",
            "Epoch 11 (train)2.3s: train loss = 0.08343 = (mf)0.07831 + (embed)0.00512\n",
            "Epoch 12 (train)2.3s: train loss = 0.07815 = (mf)0.07257 + (embed)0.00558\n",
            "Epoch 13 (train)2.3s: train loss = 0.07259 = (mf)0.06653 + (embed)0.00606\n",
            "Epoch 14 (train)2.9s: train loss = 0.06993 = (mf)0.06349 + (embed)0.00644\n",
            "Epoch 15 (train)2.3s + (eval)0.6s: train loss = 0.06495 = (mf)0.05812 + (embed)0.00682, recall = 0.03910, ndcg = 0.18167\n",
            "Epoch 16 (train)2.3s: train loss = 0.06378 = (mf)0.05660 + (embed)0.00718\n",
            "Epoch 17 (train)2.4s: train loss = 0.06013 = (mf)0.05263 + (embed)0.00751\n",
            "Epoch 18 (train)2.7s: train loss = 0.05813 = (mf)0.05032 + (embed)0.00781\n",
            "Epoch 19 (train)2.5s: train loss = 0.05686 = (mf)0.04876 + (embed)0.00810\n",
            "Epoch 20 (train)2.3s + (eval)0.3s: train loss = 0.05456 = (mf)0.04624 + (embed)0.00832, recall = 0.04115, ndcg = 0.18960\n",
            "Epoch 21 (train)2.3s: train loss = 0.05257 = (mf)0.04401 + (embed)0.00856\n",
            "Epoch 22 (train)2.3s: train loss = 0.05147 = (mf)0.04268 + (embed)0.00879\n",
            "Epoch 23 (train)2.8s: train loss = 0.04954 = (mf)0.04052 + (embed)0.00902\n",
            "Epoch 24 (train)2.4s: train loss = 0.04803 = (mf)0.03882 + (embed)0.00921\n",
            "Epoch 25 (train)2.3s + (eval)0.3s: train loss = 0.04736 = (mf)0.03797 + (embed)0.00939, recall = 0.04220, ndcg = 0.19313\n",
            "Epoch 26 (train)2.4s: train loss = 0.04557 = (mf)0.03600 + (embed)0.00957\n",
            "Epoch 27 (train)2.3s: train loss = 0.04449 = (mf)0.03478 + (embed)0.00971\n",
            "Epoch 28 (train)2.9s: train loss = 0.04419 = (mf)0.03431 + (embed)0.00988\n",
            "Epoch 29 (train)2.4s: train loss = 0.04323 = (mf)0.03321 + (embed)0.01002\n",
            "Epoch 30 (train)2.3s + (eval)0.6s: train loss = 0.04136 = (mf)0.03120 + (embed)0.01016, recall = 0.04499, ndcg = 0.20550\n",
            "Epoch 31 (train)2.3s: train loss = 0.04166 = (mf)0.03140 + (embed)0.01026\n",
            "Epoch 32 (train)2.5s: train loss = 0.03925 = (mf)0.02887 + (embed)0.01037\n",
            "Epoch 33 (train)2.6s: train loss = 0.03918 = (mf)0.02868 + (embed)0.01050\n",
            "Epoch 34 (train)2.4s: train loss = 0.03809 = (mf)0.02746 + (embed)0.01063\n",
            "Epoch 35 (train)2.3s + (eval)0.3s: train loss = 0.03788 = (mf)0.02716 + (embed)0.01072, recall = 0.04458, ndcg = 0.20224\n",
            "Epoch 36 (train)2.3s: train loss = 0.03685 = (mf)0.02603 + (embed)0.01082\n",
            "Epoch 37 (train)2.8s: train loss = 0.03679 = (mf)0.02590 + (embed)0.01090\n",
            "Epoch 38 (train)2.4s: train loss = 0.03597 = (mf)0.02498 + (embed)0.01100\n",
            "Epoch 39 (train)2.3s: train loss = 0.03539 = (mf)0.02431 + (embed)0.01108\n",
            "Epoch 40 (train)2.3s + (eval)0.6s: train loss = 0.03574 = (mf)0.02460 + (embed)0.01114, recall = 0.04490, ndcg = 0.20797\n",
            "Epoch 41 (train)2.4s: train loss = 0.03480 = (mf)0.02359 + (embed)0.01121\n",
            "Epoch 42 (train)2.8s: train loss = 0.03460 = (mf)0.02332 + (embed)0.01128\n",
            "Epoch 43 (train)2.3s: train loss = 0.03346 = (mf)0.02211 + (embed)0.01135\n",
            "Epoch 44 (train)2.3s: train loss = 0.03358 = (mf)0.02216 + (embed)0.01142\n",
            "Epoch 45 (train)2.3s + (eval)0.3s: train loss = 0.03326 = (mf)0.02177 + (embed)0.01149, recall = 0.04438, ndcg = 0.20612\n",
            "Epoch 46 (train)2.6s: train loss = 0.03286 = (mf)0.02133 + (embed)0.01153\n",
            "Epoch 47 (train)2.7s: train loss = 0.03236 = (mf)0.02077 + (embed)0.01159\n",
            "Epoch 48 (train)2.3s: train loss = 0.03215 = (mf)0.02051 + (embed)0.01164\n",
            "Epoch 49 (train)2.3s: train loss = 0.03186 = (mf)0.02016 + (embed)0.01169\n",
            "Epoch 50 (train)2.3s + (eval)0.3s: train loss = 0.03176 = (mf)0.02004 + (embed)0.01172, recall = 0.04447, ndcg = 0.20497\n",
            "Training finished in 127.90 seconds.\n",
            "Evaluation results for this combination: NDCG@50: 0.20497, Recall@50: 0.04447\n",
            "--- Trying combination: Epochs=50, TopK=50, LearningRate=0.005, Layers=5 ---\n",
            "Already normalize adjacency matrix (extended).\n",
            "Using xavier initialization for user, item, and genre embeddings.\n",
            "Epoch 1 (train)3.8s: train loss = 0.30203 = (mf)0.30144 + (embed)0.00059\n",
            "Epoch 2 (train)2.4s: train loss = 0.21248 = (mf)0.21144 + (embed)0.00104\n",
            "Epoch 3 (train)2.9s: train loss = 0.19547 = (mf)0.19400 + (embed)0.00147\n",
            "Epoch 4 (train)2.4s: train loss = 0.17390 = (mf)0.17185 + (embed)0.00204\n",
            "Epoch 5 (train)2.4s + (eval)0.8s: train loss = 0.15244 = (mf)0.14978 + (embed)0.00267, recall = 0.02880, ndcg = 0.13251\n",
            "Epoch 6 (train)2.4s: train loss = 0.14082 = (mf)0.13763 + (embed)0.00319\n",
            "Epoch 7 (train)3.6s: train loss = 0.13173 = (mf)0.12810 + (embed)0.00363\n",
            "Epoch 8 (train)2.5s: train loss = 0.12430 = (mf)0.12024 + (embed)0.00406\n",
            "Epoch 9 (train)2.4s: train loss = 0.11507 = (mf)0.11053 + (embed)0.00454\n",
            "Epoch 10 (train)2.4s + (eval)0.3s: train loss = 0.10878 = (mf)0.10374 + (embed)0.00505, recall = 0.03237, ndcg = 0.15375\n",
            "Epoch 11 (train)2.4s: train loss = 0.10027 = (mf)0.09466 + (embed)0.00561\n",
            "Epoch 12 (train)2.9s: train loss = 0.09605 = (mf)0.08991 + (embed)0.00615\n",
            "Epoch 13 (train)2.4s: train loss = 0.08931 = (mf)0.08266 + (embed)0.00665\n",
            "Epoch 14 (train)2.4s: train loss = 0.08459 = (mf)0.07743 + (embed)0.00716\n",
            "Epoch 15 (train)2.4s + (eval)0.6s: train loss = 0.08128 = (mf)0.07366 + (embed)0.00762, recall = 0.03670, ndcg = 0.17444\n",
            "Epoch 16 (train)2.9s: train loss = 0.07852 = (mf)0.07045 + (embed)0.00807\n",
            "Epoch 17 (train)2.5s: train loss = 0.07401 = (mf)0.06554 + (embed)0.00846\n",
            "Epoch 18 (train)2.4s: train loss = 0.07237 = (mf)0.06358 + (embed)0.00880\n",
            "Epoch 19 (train)2.4s: train loss = 0.07056 = (mf)0.06143 + (embed)0.00913\n",
            "Epoch 20 (train)2.4s + (eval)0.3s: train loss = 0.06758 = (mf)0.05815 + (embed)0.00943, recall = 0.03952, ndcg = 0.18846\n",
            "Epoch 21 (train)2.9s: train loss = 0.06593 = (mf)0.05623 + (embed)0.00970\n",
            "Epoch 22 (train)2.4s: train loss = 0.06384 = (mf)0.05388 + (embed)0.00996\n",
            "Epoch 23 (train)2.4s: train loss = 0.06244 = (mf)0.05223 + (embed)0.01021\n",
            "Epoch 24 (train)2.4s: train loss = 0.06133 = (mf)0.05088 + (embed)0.01045\n",
            "Epoch 25 (train)2.6s + (eval)0.4s: train loss = 0.05944 = (mf)0.04879 + (embed)0.01065, recall = 0.04044, ndcg = 0.19321\n",
            "Epoch 26 (train)2.6s: train loss = 0.05750 = (mf)0.04662 + (embed)0.01088\n",
            "Epoch 27 (train)2.4s: train loss = 0.05592 = (mf)0.04485 + (embed)0.01107\n",
            "Epoch 28 (train)2.4s: train loss = 0.05450 = (mf)0.04325 + (embed)0.01125\n",
            "Epoch 29 (train)2.4s: train loss = 0.05442 = (mf)0.04297 + (embed)0.01145\n",
            "Epoch 30 (train)2.9s + (eval)0.6s: train loss = 0.05316 = (mf)0.04159 + (embed)0.01157, recall = 0.04206, ndcg = 0.19993\n",
            "Epoch 31 (train)2.5s: train loss = 0.05120 = (mf)0.03944 + (embed)0.01175\n",
            "Epoch 32 (train)2.4s: train loss = 0.05101 = (mf)0.03911 + (embed)0.01189\n",
            "Epoch 33 (train)2.4s: train loss = 0.05033 = (mf)0.03827 + (embed)0.01206\n",
            "Epoch 34 (train)2.5s: train loss = 0.04893 = (mf)0.03673 + (embed)0.01220\n",
            "Epoch 35 (train)2.8s + (eval)0.3s: train loss = 0.04819 = (mf)0.03585 + (embed)0.01233, recall = 0.04277, ndcg = 0.20364\n",
            "Epoch 36 (train)2.4s: train loss = 0.04757 = (mf)0.03511 + (embed)0.01246\n",
            "Epoch 37 (train)2.4s: train loss = 0.04653 = (mf)0.03395 + (embed)0.01257\n",
            "Epoch 38 (train)2.4s: train loss = 0.04582 = (mf)0.03313 + (embed)0.01269\n",
            "Epoch 39 (train)2.9s: train loss = 0.04524 = (mf)0.03248 + (embed)0.01276\n",
            "Epoch 40 (train)2.5s + (eval)0.3s: train loss = 0.04445 = (mf)0.03158 + (embed)0.01287, recall = 0.04307, ndcg = 0.20607\n",
            "Epoch 41 (train)2.4s: train loss = 0.04418 = (mf)0.03125 + (embed)0.01293\n",
            "Epoch 42 (train)2.4s: train loss = 0.04276 = (mf)0.02969 + (embed)0.01307\n",
            "Epoch 43 (train)2.4s: train loss = 0.04271 = (mf)0.02956 + (embed)0.01315\n",
            "Epoch 44 (train)2.9s: train loss = 0.04208 = (mf)0.02886 + (embed)0.01322\n",
            "Epoch 45 (train)2.4s + (eval)0.6s: train loss = 0.04198 = (mf)0.02867 + (embed)0.01331, recall = 0.04387, ndcg = 0.20451\n",
            "Epoch 46 (train)2.4s: train loss = 0.04136 = (mf)0.02797 + (embed)0.01339\n",
            "Epoch 47 (train)2.4s: train loss = 0.04107 = (mf)0.02764 + (embed)0.01344\n",
            "Epoch 48 (train)2.8s: train loss = 0.04006 = (mf)0.02653 + (embed)0.01353\n",
            "Epoch 49 (train)2.5s: train loss = 0.04039 = (mf)0.02682 + (embed)0.01357\n",
            "Epoch 50 (train)2.4s + (eval)0.3s: train loss = 0.03933 = (mf)0.02568 + (embed)0.01365, recall = 0.04478, ndcg = 0.20526\n",
            "Training finished in 132.98 seconds.\n",
            "Evaluation results for this combination: NDCG@50: 0.20526, Recall@50: 0.04478\n",
            "--- Trying combination: Epochs=50, TopK=50, LearningRate=0.05, Layers=3 ---\n",
            "Already normalize adjacency matrix (extended).\n",
            "Using xavier initialization for user, item, and genre embeddings.\n",
            "Epoch 1 (train)3.7s: train loss = 0.15460 = (mf)0.15136 + (embed)0.00323\n",
            "Epoch 2 (train)2.3s: train loss = 0.07181 = (mf)0.06403 + (embed)0.00778\n",
            "Epoch 3 (train)2.3s: train loss = 0.05462 = (mf)0.04359 + (embed)0.01103\n",
            "Epoch 4 (train)2.4s: train loss = 0.05039 = (mf)0.03709 + (embed)0.01329\n",
            "Epoch 5 (train)2.9s + (eval)1.2s: train loss = 0.04653 = (mf)0.03147 + (embed)0.01507, recall = 0.03512, ndcg = 0.14903\n",
            "Epoch 6 (train)2.4s: train loss = 0.04703 = (mf)0.03049 + (embed)0.01653\n",
            "Epoch 7 (train)2.3s: train loss = 0.04534 = (mf)0.02758 + (embed)0.01776\n",
            "Epoch 8 (train)2.3s: train loss = 0.04445 = (mf)0.02575 + (embed)0.01869\n",
            "Epoch 9 (train)2.7s: train loss = 0.04582 = (mf)0.02625 + (embed)0.01957\n",
            "Epoch 10 (train)2.5s + (eval)0.3s: train loss = 0.04595 = (mf)0.02551 + (embed)0.02043, recall = 0.03217, ndcg = 0.13964\n",
            "Epoch 11 (train)2.3s: train loss = 0.04712 = (mf)0.02595 + (embed)0.02117\n",
            "Epoch 12 (train)2.3s: train loss = 0.04620 = (mf)0.02441 + (embed)0.02179\n",
            "Epoch 13 (train)2.3s: train loss = 0.04740 = (mf)0.02502 + (embed)0.02239\n",
            "Epoch 14 (train)2.8s: train loss = 0.04644 = (mf)0.02344 + (embed)0.02299\n",
            "Epoch 15 (train)2.3s + (eval)0.6s: train loss = 0.04782 = (mf)0.02440 + (embed)0.02341, recall = 0.03349, ndcg = 0.13447\n",
            "Epoch 16 (train)2.3s: train loss = 0.04653 = (mf)0.02262 + (embed)0.02391\n",
            "Epoch 17 (train)2.4s: train loss = 0.04809 = (mf)0.02384 + (embed)0.02425\n",
            "Epoch 18 (train)2.4s: train loss = 0.04779 = (mf)0.02319 + (embed)0.02459\n",
            "Epoch 19 (train)2.8s: train loss = 0.04875 = (mf)0.02378 + (embed)0.02497\n",
            "Epoch 20 (train)2.3s + (eval)0.3s: train loss = 0.04767 = (mf)0.02244 + (embed)0.02523, recall = 0.03304, ndcg = 0.13310\n",
            "Epoch 21 (train)2.3s: train loss = 0.04744 = (mf)0.02203 + (embed)0.02540\n",
            "Epoch 22 (train)2.4s: train loss = 0.04812 = (mf)0.02244 + (embed)0.02568\n",
            "Epoch 23 (train)2.6s: train loss = 0.04837 = (mf)0.02243 + (embed)0.02595\n",
            "Epoch 24 (train)2.6s: train loss = 0.04853 = (mf)0.02235 + (embed)0.02618\n",
            "Epoch 25 (train)2.3s + (eval)0.3s: train loss = 0.04799 = (mf)0.02155 + (embed)0.02644, recall = 0.03390, ndcg = 0.13620\n",
            "Epoch 26 (train)2.3s: train loss = 0.04792 = (mf)0.02138 + (embed)0.02654\n",
            "Epoch 27 (train)2.3s: train loss = 0.04862 = (mf)0.02190 + (embed)0.02673\n",
            "Epoch 28 (train)2.8s: train loss = 0.04943 = (mf)0.02255 + (embed)0.02688\n",
            "Epoch 29 (train)2.4s: train loss = 0.04756 = (mf)0.02051 + (embed)0.02705\n",
            "Epoch 30 (train)2.4s + (eval)0.6s: train loss = 0.04822 = (mf)0.02108 + (embed)0.02714, recall = 0.03148, ndcg = 0.13244\n",
            "Epoch 31 (train)2.3s: train loss = 0.04952 = (mf)0.02222 + (embed)0.02731\n",
            "Epoch 32 (train)2.3s: train loss = 0.04773 = (mf)0.02037 + (embed)0.02736\n",
            "Epoch 33 (train)2.9s: train loss = 0.04940 = (mf)0.02193 + (embed)0.02747\n",
            "Epoch 34 (train)2.4s: train loss = 0.04871 = (mf)0.02117 + (embed)0.02754\n",
            "Epoch 35 (train)2.3s + (eval)0.3s: train loss = 0.05013 = (mf)0.02251 + (embed)0.02762, recall = 0.03193, ndcg = 0.12433\n",
            "Epoch 36 (train)2.3s: train loss = 0.04916 = (mf)0.02143 + (embed)0.02774\n",
            "Epoch 37 (train)2.5s: train loss = 0.04948 = (mf)0.02171 + (embed)0.02776\n",
            "Epoch 38 (train)2.7s: train loss = 0.04921 = (mf)0.02133 + (embed)0.02787\n",
            "Epoch 39 (train)2.4s: train loss = 0.04937 = (mf)0.02140 + (embed)0.02797\n",
            "Epoch 40 (train)2.4s + (eval)0.3s: train loss = 0.04942 = (mf)0.02153 + (embed)0.02789, recall = 0.03273, ndcg = 0.13570\n",
            "Epoch 41 (train)2.4s: train loss = 0.04831 = (mf)0.02038 + (embed)0.02793\n",
            "Epoch 42 (train)2.7s: train loss = 0.04856 = (mf)0.02066 + (embed)0.02790\n",
            "Epoch 43 (train)2.5s: train loss = 0.04691 = (mf)0.01908 + (embed)0.02783\n",
            "Epoch 44 (train)2.3s: train loss = 0.04799 = (mf)0.02020 + (embed)0.02779\n",
            "Epoch 45 (train)2.4s + (eval)0.6s: train loss = 0.04758 = (mf)0.01967 + (embed)0.02791, recall = 0.03249, ndcg = 0.13581\n",
            "Epoch 46 (train)2.4s: train loss = 0.04722 = (mf)0.01931 + (embed)0.02791\n",
            "Epoch 47 (train)2.9s: train loss = 0.04834 = (mf)0.02046 + (embed)0.02788\n",
            "Epoch 48 (train)2.4s: train loss = 0.04878 = (mf)0.02091 + (embed)0.02787\n",
            "Epoch 49 (train)2.3s: train loss = 0.04763 = (mf)0.01978 + (embed)0.02785\n",
            "Epoch 50 (train)2.3s + (eval)0.3s: train loss = 0.04884 = (mf)0.02096 + (embed)0.02788, recall = 0.03212, ndcg = 0.12232\n",
            "Training finished in 128.40 seconds.\n",
            "Evaluation results for this combination: NDCG@50: 0.12232, Recall@50: 0.03212\n",
            "--- Trying combination: Epochs=50, TopK=50, LearningRate=0.05, Layers=4 ---\n",
            "Already normalize adjacency matrix (extended).\n",
            "Using xavier initialization for user, item, and genre embeddings.\n",
            "Epoch 1 (train)3.6s: train loss = 0.16248 = (mf)0.15911 + (embed)0.00337\n",
            "Epoch 2 (train)2.4s: train loss = 0.08194 = (mf)0.07372 + (embed)0.00822\n",
            "Epoch 3 (train)2.7s: train loss = 0.06194 = (mf)0.05001 + (embed)0.01193\n",
            "Epoch 4 (train)2.5s: train loss = 0.05355 = (mf)0.03907 + (embed)0.01448\n",
            "Epoch 5 (train)2.4s + (eval)1.2s: train loss = 0.04950 = (mf)0.03318 + (embed)0.01631, recall = 0.03866, ndcg = 0.16610\n",
            "Epoch 6 (train)2.5s: train loss = 0.04622 = (mf)0.02857 + (embed)0.01765\n",
            "Epoch 7 (train)2.5s: train loss = 0.04477 = (mf)0.02616 + (embed)0.01861\n",
            "Epoch 8 (train)2.7s: train loss = 0.04487 = (mf)0.02541 + (embed)0.01946\n",
            "Epoch 9 (train)2.4s: train loss = 0.04346 = (mf)0.02321 + (embed)0.02024\n",
            "Epoch 10 (train)2.4s + (eval)0.3s: train loss = 0.04329 = (mf)0.02247 + (embed)0.02081, recall = 0.03694, ndcg = 0.15362\n",
            "Epoch 11 (train)2.3s: train loss = 0.04262 = (mf)0.02127 + (embed)0.02135\n",
            "Epoch 12 (train)2.7s: train loss = 0.04278 = (mf)0.02098 + (embed)0.02181\n",
            "Epoch 13 (train)2.5s: train loss = 0.04256 = (mf)0.02040 + (embed)0.02217\n",
            "Epoch 14 (train)2.3s: train loss = 0.04175 = (mf)0.01930 + (embed)0.02245\n",
            "Epoch 15 (train)2.3s + (eval)0.3s: train loss = 0.04225 = (mf)0.01945 + (embed)0.02280, recall = 0.03661, ndcg = 0.15977\n",
            "Epoch 16 (train)2.4s: train loss = 0.04194 = (mf)0.01883 + (embed)0.02311\n",
            "Epoch 17 (train)2.9s: train loss = 0.04110 = (mf)0.01779 + (embed)0.02331\n",
            "Epoch 18 (train)2.4s: train loss = 0.04168 = (mf)0.01820 + (embed)0.02348\n",
            "Epoch 19 (train)2.3s: train loss = 0.04114 = (mf)0.01747 + (embed)0.02367\n",
            "Epoch 20 (train)2.3s + (eval)0.3s: train loss = 0.04173 = (mf)0.01788 + (embed)0.02385, recall = 0.03516, ndcg = 0.15325\n",
            "Epoch 21 (train)2.4s: train loss = 0.04149 = (mf)0.01758 + (embed)0.02391\n",
            "Epoch 22 (train)2.9s: train loss = 0.04125 = (mf)0.01709 + (embed)0.02416\n",
            "Epoch 23 (train)2.4s: train loss = 0.04079 = (mf)0.01654 + (embed)0.02425\n",
            "Epoch 24 (train)2.3s: train loss = 0.04068 = (mf)0.01639 + (embed)0.02429\n",
            "Epoch 25 (train)2.3s + (eval)0.6s: train loss = 0.04117 = (mf)0.01677 + (embed)0.02441, recall = 0.03765, ndcg = 0.15289\n",
            "Epoch 26 (train)2.9s: train loss = 0.04126 = (mf)0.01667 + (embed)0.02459\n",
            "Epoch 27 (train)2.5s: train loss = 0.04112 = (mf)0.01650 + (embed)0.02462\n",
            "Epoch 28 (train)2.3s: train loss = 0.04087 = (mf)0.01628 + (embed)0.02459\n",
            "Epoch 29 (train)2.3s: train loss = 0.04151 = (mf)0.01681 + (embed)0.02470\n",
            "Epoch 30 (train)2.3s + (eval)0.3s: train loss = 0.04085 = (mf)0.01597 + (embed)0.02488, recall = 0.03756, ndcg = 0.14860\n",
            "Epoch 31 (train)2.9s: train loss = 0.04033 = (mf)0.01537 + (embed)0.02496\n",
            "Epoch 32 (train)2.4s: train loss = 0.04078 = (mf)0.01585 + (embed)0.02494\n",
            "Epoch 33 (train)2.4s: train loss = 0.04081 = (mf)0.01574 + (embed)0.02507\n",
            "Epoch 34 (train)2.3s: train loss = 0.04158 = (mf)0.01647 + (embed)0.02511\n",
            "Epoch 35 (train)2.3s + (eval)0.8s: train loss = 0.04094 = (mf)0.01576 + (embed)0.02517, recall = 0.03694, ndcg = 0.15395\n",
            "Epoch 36 (train)2.8s: train loss = 0.04145 = (mf)0.01625 + (embed)0.02520\n",
            "Epoch 37 (train)2.3s: train loss = 0.04098 = (mf)0.01579 + (embed)0.02518\n",
            "Epoch 38 (train)2.3s: train loss = 0.04132 = (mf)0.01598 + (embed)0.02534\n",
            "Epoch 39 (train)2.3s: train loss = 0.04075 = (mf)0.01545 + (embed)0.02529\n",
            "Epoch 40 (train)2.6s + (eval)0.4s: train loss = 0.04081 = (mf)0.01553 + (embed)0.02527, recall = 0.03444, ndcg = 0.14411\n",
            "Epoch 41 (train)2.5s: train loss = 0.04092 = (mf)0.01568 + (embed)0.02525\n",
            "Epoch 42 (train)2.4s: train loss = 0.04071 = (mf)0.01553 + (embed)0.02518\n",
            "Epoch 43 (train)2.4s: train loss = 0.04093 = (mf)0.01575 + (embed)0.02519\n",
            "Epoch 44 (train)2.3s: train loss = 0.04020 = (mf)0.01498 + (embed)0.02523\n",
            "Epoch 45 (train)2.9s + (eval)0.3s: train loss = 0.04032 = (mf)0.01518 + (embed)0.02513, recall = 0.03684, ndcg = 0.15683\n",
            "Epoch 46 (train)2.4s: train loss = 0.04014 = (mf)0.01505 + (embed)0.02509\n",
            "Epoch 47 (train)2.4s: train loss = 0.04046 = (mf)0.01535 + (embed)0.02511\n",
            "Epoch 48 (train)2.3s: train loss = 0.04071 = (mf)0.01559 + (embed)0.02512\n",
            "Epoch 49 (train)2.3s: train loss = 0.04100 = (mf)0.01579 + (embed)0.02521\n",
            "Epoch 50 (train)2.9s + (eval)0.6s: train loss = 0.04011 = (mf)0.01485 + (embed)0.02526, recall = 0.03741, ndcg = 0.15918\n",
            "Training finished in 129.85 seconds.\n",
            "Evaluation results for this combination: NDCG@50: 0.15918, Recall@50: 0.03741\n",
            "--- Trying combination: Epochs=50, TopK=50, LearningRate=0.05, Layers=5 ---\n",
            "Already normalize adjacency matrix (extended).\n",
            "Using xavier initialization for user, item, and genre embeddings.\n",
            "Epoch 1 (train)4.4s: train loss = 0.17722 = (mf)0.17359 + (embed)0.00364\n",
            "Epoch 2 (train)2.5s: train loss = 0.09140 = (mf)0.08233 + (embed)0.00907\n",
            "Epoch 3 (train)2.4s: train loss = 0.07027 = (mf)0.05712 + (embed)0.01315\n",
            "Epoch 4 (train)2.4s: train loss = 0.06029 = (mf)0.04440 + (embed)0.01588\n",
            "Epoch 5 (train)2.5s + (eval)1.2s: train loss = 0.05445 = (mf)0.03669 + (embed)0.01776, recall = 0.03890, ndcg = 0.17492\n",
            "Epoch 6 (train)2.7s: train loss = 0.05137 = (mf)0.03233 + (embed)0.01905\n",
            "Epoch 7 (train)2.4s: train loss = 0.04920 = (mf)0.02902 + (embed)0.02017\n",
            "Epoch 8 (train)2.4s: train loss = 0.04877 = (mf)0.02783 + (embed)0.02095\n",
            "Epoch 9 (train)2.4s: train loss = 0.04645 = (mf)0.02479 + (embed)0.02166\n",
            "Epoch 10 (train)2.9s + (eval)0.4s: train loss = 0.04550 = (mf)0.02343 + (embed)0.02208, recall = 0.03795, ndcg = 0.17780\n",
            "Epoch 11 (train)2.5s: train loss = 0.04484 = (mf)0.02227 + (embed)0.02257\n",
            "Epoch 12 (train)2.4s: train loss = 0.04492 = (mf)0.02201 + (embed)0.02291\n",
            "Epoch 13 (train)2.4s: train loss = 0.04428 = (mf)0.02100 + (embed)0.02327\n",
            "Epoch 14 (train)2.4s: train loss = 0.04317 = (mf)0.01953 + (embed)0.02363\n",
            "Epoch 15 (train)3.0s + (eval)0.6s: train loss = 0.04289 = (mf)0.01906 + (embed)0.02383, recall = 0.03923, ndcg = 0.17661\n",
            "Epoch 16 (train)2.4s: train loss = 0.04266 = (mf)0.01856 + (embed)0.02410\n",
            "Epoch 17 (train)2.4s: train loss = 0.04272 = (mf)0.01842 + (embed)0.02430\n",
            "Epoch 18 (train)2.4s: train loss = 0.04287 = (mf)0.01836 + (embed)0.02451\n",
            "Epoch 19 (train)2.8s: train loss = 0.04238 = (mf)0.01769 + (embed)0.02469\n",
            "Epoch 20 (train)2.5s + (eval)0.3s: train loss = 0.04239 = (mf)0.01752 + (embed)0.02487, recall = 0.03843, ndcg = 0.17396\n",
            "Epoch 21 (train)2.4s: train loss = 0.04282 = (mf)0.01781 + (embed)0.02501\n",
            "Epoch 22 (train)2.4s: train loss = 0.04258 = (mf)0.01742 + (embed)0.02517\n",
            "Epoch 23 (train)2.4s: train loss = 0.04320 = (mf)0.01790 + (embed)0.02530\n",
            "Epoch 24 (train)2.9s: train loss = 0.04259 = (mf)0.01719 + (embed)0.02540\n",
            "Epoch 25 (train)2.4s + (eval)0.3s: train loss = 0.04211 = (mf)0.01664 + (embed)0.02547, recall = 0.03778, ndcg = 0.16706\n",
            "Epoch 26 (train)2.5s: train loss = 0.04159 = (mf)0.01607 + (embed)0.02553\n",
            "Epoch 27 (train)2.4s: train loss = 0.04152 = (mf)0.01610 + (embed)0.02542\n",
            "Epoch 28 (train)2.6s: train loss = 0.04167 = (mf)0.01623 + (embed)0.02544\n",
            "Epoch 29 (train)2.7s: train loss = 0.04197 = (mf)0.01642 + (embed)0.02555\n",
            "Epoch 30 (train)2.4s + (eval)0.6s: train loss = 0.04167 = (mf)0.01614 + (embed)0.02553, recall = 0.03862, ndcg = 0.16787\n",
            "Epoch 31 (train)2.4s: train loss = 0.04072 = (mf)0.01524 + (embed)0.02548\n",
            "Epoch 32 (train)2.4s: train loss = 0.04054 = (mf)0.01509 + (embed)0.02545\n",
            "Epoch 33 (train)2.9s: train loss = 0.04068 = (mf)0.01522 + (embed)0.02547\n",
            "Epoch 34 (train)2.4s: train loss = 0.04118 = (mf)0.01565 + (embed)0.02554\n",
            "Epoch 35 (train)2.4s + (eval)0.3s: train loss = 0.04169 = (mf)0.01604 + (embed)0.02565, recall = 0.03822, ndcg = 0.16447\n",
            "Epoch 36 (train)2.4s: train loss = 0.04098 = (mf)0.01522 + (embed)0.02576\n",
            "Epoch 37 (train)2.6s: train loss = 0.04134 = (mf)0.01554 + (embed)0.02580\n",
            "Epoch 38 (train)2.8s: train loss = 0.04114 = (mf)0.01530 + (embed)0.02584\n",
            "Epoch 39 (train)2.4s: train loss = 0.03998 = (mf)0.01428 + (embed)0.02571\n",
            "Epoch 40 (train)2.4s + (eval)0.6s: train loss = 0.04145 = (mf)0.01583 + (embed)0.02562, recall = 0.03973, ndcg = 0.16537\n",
            "Epoch 41 (train)2.4s: train loss = 0.04091 = (mf)0.01523 + (embed)0.02567\n",
            "Epoch 42 (train)3.2s: train loss = 0.04120 = (mf)0.01550 + (embed)0.02570\n",
            "Epoch 43 (train)2.8s: train loss = 0.04041 = (mf)0.01469 + (embed)0.02572\n",
            "Epoch 44 (train)2.4s: train loss = 0.04030 = (mf)0.01470 + (embed)0.02560\n",
            "Epoch 45 (train)2.4s + (eval)0.3s: train loss = 0.04138 = (mf)0.01573 + (embed)0.02564, recall = 0.03977, ndcg = 0.16773\n",
            "Epoch 46 (train)2.6s: train loss = 0.04035 = (mf)0.01467 + (embed)0.02569\n",
            "Epoch 47 (train)2.8s: train loss = 0.04044 = (mf)0.01485 + (embed)0.02559\n",
            "Epoch 48 (train)2.4s: train loss = 0.04083 = (mf)0.01517 + (embed)0.02566\n",
            "Epoch 49 (train)2.4s: train loss = 0.04031 = (mf)0.01461 + (embed)0.02570\n",
            "Epoch 50 (train)2.4s + (eval)0.3s: train loss = 0.04077 = (mf)0.01511 + (embed)0.02566, recall = 0.03934, ndcg = 0.17138\n",
            "Training finished in 133.29 seconds.\n",
            "Evaluation results for this combination: NDCG@50: 0.17138, Recall@50: 0.03934\n",
            "--- Trying combination: Epochs=50, TopK=50, LearningRate=0.5, Layers=3 ---\n",
            "Already normalize adjacency matrix (extended).\n",
            "Using xavier initialization for user, item, and genre embeddings.\n",
            "Epoch 1 (train)3.7s: train loss = 0.94185 = (mf)0.77283 + (embed)0.16902\n",
            "Epoch 2 (train)2.4s: train loss = 2.07893 = (mf)1.56773 + (embed)0.51120\n",
            "Epoch 3 (train)2.8s: train loss = 2.82516 = (mf)2.04619 + (embed)0.77898\n",
            "Epoch 4 (train)2.3s: train loss = 3.16035 = (mf)2.17233 + (embed)0.98802\n",
            "Epoch 5 (train)2.3s + (eval)0.9s: train loss = 3.46251 = (mf)2.30401 + (embed)1.15849, recall = 0.02230, ndcg = 0.09752\n",
            "Epoch 6 (train)2.4s: train loss = 3.68704 = (mf)2.38388 + (embed)1.30317\n",
            "Epoch 7 (train)2.9s: train loss = 3.80099 = (mf)2.37692 + (embed)1.42407\n",
            "Epoch 8 (train)2.4s: train loss = 4.12137 = (mf)2.59244 + (embed)1.52894\n",
            "Epoch 9 (train)2.4s: train loss = 4.16030 = (mf)2.53816 + (embed)1.62214\n",
            "Epoch 10 (train)2.3s + (eval)0.3s: train loss = 4.20415 = (mf)2.48838 + (embed)1.71577, recall = 0.02510, ndcg = 0.10527\n",
            "Epoch 11 (train)2.3s: train loss = 4.48442 = (mf)2.68836 + (embed)1.79606\n",
            "Epoch 12 (train)2.9s: train loss = 4.47610 = (mf)2.59455 + (embed)1.88155\n",
            "Epoch 13 (train)2.4s: train loss = 4.64229 = (mf)2.69588 + (embed)1.94640\n",
            "Epoch 14 (train)2.4s: train loss = 4.53319 = (mf)2.53146 + (embed)2.00173\n",
            "Epoch 15 (train)2.3s + (eval)0.6s: train loss = 4.56169 = (mf)2.51019 + (embed)2.05150, recall = 0.02453, ndcg = 0.10747\n",
            "Epoch 16 (train)2.6s: train loss = 4.62258 = (mf)2.52192 + (embed)2.10066\n",
            "Epoch 17 (train)2.6s: train loss = 4.79559 = (mf)2.64221 + (embed)2.15337\n",
            "Epoch 18 (train)2.3s: train loss = 4.67956 = (mf)2.48241 + (embed)2.19714\n",
            "Epoch 19 (train)2.4s: train loss = 4.56009 = (mf)2.33570 + (embed)2.22439\n",
            "Epoch 20 (train)2.4s + (eval)0.3s: train loss = 4.70177 = (mf)2.45461 + (embed)2.24715, recall = 0.02628, ndcg = 0.09672\n",
            "Epoch 21 (train)2.8s: train loss = 4.88422 = (mf)2.59720 + (embed)2.28702\n",
            "Epoch 22 (train)2.4s: train loss = 4.76748 = (mf)2.44523 + (embed)2.32225\n",
            "Epoch 23 (train)2.3s: train loss = 4.77289 = (mf)2.43753 + (embed)2.33536\n",
            "Epoch 24 (train)2.3s: train loss = 4.74424 = (mf)2.38592 + (embed)2.35832\n",
            "Epoch 25 (train)2.3s + (eval)0.3s: train loss = 4.72157 = (mf)2.33618 + (embed)2.38539, recall = 0.02429, ndcg = 0.10633\n",
            "Epoch 26 (train)2.8s: train loss = 4.74901 = (mf)2.33554 + (embed)2.41347\n",
            "Epoch 27 (train)2.4s: train loss = 4.73266 = (mf)2.30132 + (embed)2.43134\n",
            "Epoch 28 (train)2.3s: train loss = 4.84735 = (mf)2.39476 + (embed)2.45259\n",
            "Epoch 29 (train)2.3s: train loss = 4.83621 = (mf)2.36464 + (embed)2.47157\n",
            "Epoch 30 (train)2.3s + (eval)0.8s: train loss = 4.74921 = (mf)2.26319 + (embed)2.48602, recall = 0.02501, ndcg = 0.11167\n",
            "Epoch 31 (train)2.8s: train loss = 4.85761 = (mf)2.35760 + (embed)2.50001\n",
            "Epoch 32 (train)2.4s: train loss = 4.81782 = (mf)2.29881 + (embed)2.51901\n",
            "Epoch 33 (train)2.3s: train loss = 4.80261 = (mf)2.26111 + (embed)2.54150\n",
            "Epoch 34 (train)2.3s: train loss = 4.76688 = (mf)2.21979 + (embed)2.54708\n",
            "Epoch 35 (train)2.5s + (eval)0.4s: train loss = 4.76655 = (mf)2.21349 + (embed)2.55306, recall = 0.02666, ndcg = 0.10016\n",
            "Epoch 36 (train)2.6s: train loss = 4.82449 = (mf)2.24875 + (embed)2.57574\n",
            "Epoch 37 (train)2.3s: train loss = 4.98411 = (mf)2.39915 + (embed)2.58496\n",
            "Epoch 38 (train)2.3s: train loss = 4.96733 = (mf)2.37280 + (embed)2.59452\n",
            "Epoch 39 (train)2.3s: train loss = 4.88074 = (mf)2.26627 + (embed)2.61447\n",
            "Epoch 40 (train)2.7s + (eval)0.4s: train loss = 4.90714 = (mf)2.28407 + (embed)2.62307, recall = 0.02710, ndcg = 0.10133\n",
            "Epoch 41 (train)2.4s: train loss = 4.89115 = (mf)2.26000 + (embed)2.63116\n",
            "Epoch 42 (train)2.3s: train loss = 4.84856 = (mf)2.20898 + (embed)2.63958\n",
            "Epoch 43 (train)2.3s: train loss = 4.72059 = (mf)2.07681 + (embed)2.64378\n",
            "Epoch 44 (train)2.3s: train loss = 4.90180 = (mf)2.25682 + (embed)2.64498\n",
            "Epoch 45 (train)2.8s + (eval)0.6s: train loss = 4.80203 = (mf)2.14609 + (embed)2.65595, recall = 0.02773, ndcg = 0.10317\n",
            "Epoch 46 (train)2.3s: train loss = 4.87648 = (mf)2.22227 + (embed)2.65421\n",
            "Epoch 47 (train)2.3s: train loss = 4.87995 = (mf)2.22010 + (embed)2.65985\n",
            "Epoch 48 (train)2.3s: train loss = 4.84993 = (mf)2.18404 + (embed)2.66589\n",
            "Epoch 49 (train)2.4s: train loss = 4.94386 = (mf)2.27102 + (embed)2.67284\n",
            "Epoch 50 (train)2.8s + (eval)0.3s: train loss = 4.84975 = (mf)2.17177 + (embed)2.67798, recall = 0.02587, ndcg = 0.10409\n",
            "Training finished in 128.55 seconds.\n",
            "Evaluation results for this combination: NDCG@50: 0.10409, Recall@50: 0.02587\n",
            "--- Trying combination: Epochs=50, TopK=50, LearningRate=0.5, Layers=4 ---\n",
            "Already normalize adjacency matrix (extended).\n",
            "Using xavier initialization for user, item, and genre embeddings.\n",
            "Epoch 1 (train)4.3s: train loss = 0.63651 = (mf)0.49256 + (embed)0.14395\n",
            "Epoch 2 (train)2.4s: train loss = 1.35148 = (mf)0.91729 + (embed)0.43419\n",
            "Epoch 3 (train)2.3s: train loss = 1.76700 = (mf)1.10592 + (embed)0.66108\n",
            "Epoch 4 (train)2.3s: train loss = 2.03202 = (mf)1.20568 + (embed)0.82635\n",
            "Epoch 5 (train)2.3s + (eval)1.1s: train loss = 2.29843 = (mf)1.34698 + (embed)0.95145, recall = 0.02032, ndcg = 0.09166\n",
            "Epoch 6 (train)2.9s: train loss = 2.48861 = (mf)1.43409 + (embed)1.05452\n",
            "Epoch 7 (train)2.3s: train loss = 2.52394 = (mf)1.37225 + (embed)1.15169\n",
            "Epoch 8 (train)2.3s: train loss = 2.66868 = (mf)1.44478 + (embed)1.22390\n",
            "Epoch 9 (train)2.3s: train loss = 2.73141 = (mf)1.44159 + (embed)1.28982\n",
            "Epoch 10 (train)2.6s + (eval)0.9s: train loss = 2.74508 = (mf)1.40088 + (embed)1.34420, recall = 0.02439, ndcg = 0.09708\n",
            "Epoch 11 (train)2.5s: train loss = 2.80074 = (mf)1.41299 + (embed)1.38774\n",
            "Epoch 12 (train)2.3s: train loss = 2.77274 = (mf)1.35718 + (embed)1.41556\n",
            "Epoch 13 (train)2.4s: train loss = 2.81130 = (mf)1.36125 + (embed)1.45005\n",
            "Epoch 14 (train)2.4s: train loss = 2.82774 = (mf)1.34861 + (embed)1.47912\n",
            "Epoch 15 (train)2.9s + (eval)0.3s: train loss = 2.83384 = (mf)1.32152 + (embed)1.51231, recall = 0.02727, ndcg = 0.11012\n",
            "Epoch 16 (train)2.4s: train loss = 2.84373 = (mf)1.30098 + (embed)1.54275\n",
            "Epoch 17 (train)2.3s: train loss = 2.82849 = (mf)1.26723 + (embed)1.56125\n",
            "Epoch 18 (train)2.3s: train loss = 2.91810 = (mf)1.32680 + (embed)1.59130\n",
            "Epoch 19 (train)2.4s: train loss = 2.92797 = (mf)1.31709 + (embed)1.61088\n",
            "Epoch 20 (train)2.8s + (eval)0.6s: train loss = 2.97217 = (mf)1.35033 + (embed)1.62184, recall = 0.02527, ndcg = 0.09527\n",
            "Epoch 21 (train)2.4s: train loss = 2.90317 = (mf)1.26276 + (embed)1.64041\n",
            "Epoch 22 (train)2.3s: train loss = 2.93010 = (mf)1.27485 + (embed)1.65525\n",
            "Epoch 23 (train)2.3s: train loss = 2.96890 = (mf)1.30378 + (embed)1.66512\n",
            "Epoch 24 (train)2.8s: train loss = 2.93166 = (mf)1.25438 + (embed)1.67728\n",
            "Epoch 25 (train)2.5s + (eval)0.3s: train loss = 2.96801 = (mf)1.27969 + (embed)1.68831, recall = 0.02498, ndcg = 0.10938\n",
            "Epoch 26 (train)2.4s: train loss = 3.00379 = (mf)1.30633 + (embed)1.69746\n",
            "Epoch 27 (train)2.4s: train loss = 2.97503 = (mf)1.25560 + (embed)1.71943\n",
            "Epoch 28 (train)2.3s: train loss = 3.05127 = (mf)1.32397 + (embed)1.72730\n",
            "Epoch 29 (train)2.9s: train loss = 2.96965 = (mf)1.23264 + (embed)1.73702\n",
            "Epoch 30 (train)2.4s + (eval)0.3s: train loss = 2.98550 = (mf)1.23971 + (embed)1.74579, recall = 0.02621, ndcg = 0.10417\n",
            "Epoch 31 (train)2.3s: train loss = 2.97924 = (mf)1.23500 + (embed)1.74423\n",
            "Epoch 32 (train)2.3s: train loss = 3.00095 = (mf)1.26234 + (embed)1.73862\n",
            "Epoch 33 (train)2.5s: train loss = 2.92602 = (mf)1.18619 + (embed)1.73983\n",
            "Epoch 34 (train)3.5s: train loss = 3.02415 = (mf)1.27601 + (embed)1.74814\n",
            "Epoch 35 (train)2.4s + (eval)0.3s: train loss = 2.94881 = (mf)1.19719 + (embed)1.75162, recall = 0.02707, ndcg = 0.10476\n",
            "Epoch 36 (train)2.4s: train loss = 3.03581 = (mf)1.27898 + (embed)1.75682\n",
            "Epoch 37 (train)2.4s: train loss = 3.05282 = (mf)1.29088 + (embed)1.76194\n",
            "Epoch 38 (train)2.7s: train loss = 2.96998 = (mf)1.20896 + (embed)1.76102\n",
            "Epoch 39 (train)2.5s: train loss = 3.04244 = (mf)1.26371 + (embed)1.77873\n",
            "Epoch 40 (train)2.3s + (eval)0.6s: train loss = 2.98249 = (mf)1.20590 + (embed)1.77659, recall = 0.02459, ndcg = 0.10099\n",
            "Epoch 41 (train)2.4s: train loss = 2.96583 = (mf)1.19351 + (embed)1.77232\n",
            "Epoch 42 (train)2.3s: train loss = 2.94518 = (mf)1.17264 + (embed)1.77255\n",
            "Epoch 43 (train)2.9s: train loss = 2.94939 = (mf)1.16733 + (embed)1.78206\n",
            "Epoch 44 (train)2.3s: train loss = 3.02395 = (mf)1.23573 + (embed)1.78822\n",
            "Epoch 45 (train)2.3s + (eval)0.3s: train loss = 2.99764 = (mf)1.21417 + (embed)1.78347, recall = 0.02627, ndcg = 0.10045\n",
            "Epoch 46 (train)2.4s: train loss = 2.99262 = (mf)1.20211 + (embed)1.79051\n",
            "Epoch 47 (train)2.5s: train loss = 2.95629 = (mf)1.17677 + (embed)1.77952\n",
            "Epoch 48 (train)2.8s: train loss = 2.96329 = (mf)1.18402 + (embed)1.77926\n",
            "Epoch 49 (train)2.4s: train loss = 2.94238 = (mf)1.17177 + (embed)1.77061\n",
            "Epoch 50 (train)2.3s + (eval)0.6s: train loss = 2.95545 = (mf)1.18535 + (embed)1.77010, recall = 0.02563, ndcg = 0.10676\n",
            "Training finished in 130.92 seconds.\n",
            "Evaluation results for this combination: NDCG@50: 0.10676, Recall@50: 0.02563\n",
            "--- Trying combination: Epochs=50, TopK=50, LearningRate=0.5, Layers=5 ---\n",
            "Already normalize adjacency matrix (extended).\n",
            "Using xavier initialization for user, item, and genre embeddings.\n",
            "Epoch 1 (train)4.0s: train loss = 0.47577 = (mf)0.35564 + (embed)0.12014\n",
            "Epoch 2 (train)2.4s: train loss = 0.90746 = (mf)0.54603 + (embed)0.36143\n",
            "Epoch 3 (train)2.6s: train loss = 1.27490 = (mf)0.71695 + (embed)0.55795\n",
            "Epoch 4 (train)2.7s: train loss = 1.50005 = (mf)0.79424 + (embed)0.70581\n",
            "Epoch 5 (train)2.4s + (eval)0.9s: train loss = 1.71413 = (mf)0.89917 + (embed)0.81496, recall = 0.02339, ndcg = 0.09998\n",
            "Epoch 6 (train)2.4s: train loss = 1.81404 = (mf)0.90761 + (embed)0.90643\n",
            "Epoch 7 (train)2.4s: train loss = 1.87703 = (mf)0.90489 + (embed)0.97214\n",
            "Epoch 8 (train)3.0s: train loss = 1.96647 = (mf)0.94810 + (embed)1.01838\n",
            "Epoch 9 (train)2.4s: train loss = 1.96634 = (mf)0.90797 + (embed)1.05837\n",
            "Epoch 10 (train)2.4s + (eval)0.3s: train loss = 1.97727 = (mf)0.88480 + (embed)1.09246, recall = 0.02502, ndcg = 0.09467\n",
            "Epoch 11 (train)2.4s: train loss = 2.02596 = (mf)0.90274 + (embed)1.12323\n",
            "Epoch 12 (train)2.7s: train loss = 2.07945 = (mf)0.92587 + (embed)1.15358\n",
            "Epoch 13 (train)2.6s: train loss = 2.02792 = (mf)0.86024 + (embed)1.16768\n",
            "Epoch 14 (train)2.4s: train loss = 2.03513 = (mf)0.85054 + (embed)1.18460\n",
            "Epoch 15 (train)2.4s + (eval)0.6s: train loss = 2.03073 = (mf)0.83060 + (embed)1.20013, recall = 0.02288, ndcg = 0.09028\n",
            "Epoch 16 (train)2.4s: train loss = 2.07227 = (mf)0.85149 + (embed)1.22078\n",
            "Epoch 17 (train)2.9s: train loss = 2.04553 = (mf)0.82143 + (embed)1.22410\n",
            "Epoch 18 (train)2.5s: train loss = 2.05469 = (mf)0.82558 + (embed)1.22911\n",
            "Epoch 19 (train)2.4s: train loss = 2.08622 = (mf)0.84652 + (embed)1.23970\n",
            "Epoch 20 (train)2.4s + (eval)0.3s: train loss = 2.10552 = (mf)0.85459 + (embed)1.25093, recall = 0.02552, ndcg = 0.10062\n",
            "Epoch 21 (train)2.6s: train loss = 2.08293 = (mf)0.82831 + (embed)1.25462\n",
            "Epoch 22 (train)2.7s: train loss = 2.13777 = (mf)0.87160 + (embed)1.26616\n",
            "Epoch 23 (train)2.4s: train loss = 2.05507 = (mf)0.77686 + (embed)1.27821\n",
            "Epoch 24 (train)2.4s: train loss = 2.13616 = (mf)0.85564 + (embed)1.28052\n",
            "Epoch 25 (train)2.4s + (eval)0.6s: train loss = 2.05895 = (mf)0.78321 + (embed)1.27574, recall = 0.02059, ndcg = 0.09525\n",
            "Epoch 26 (train)3.0s: train loss = 2.05463 = (mf)0.78473 + (embed)1.26990\n",
            "Epoch 27 (train)2.4s: train loss = 2.02879 = (mf)0.76358 + (embed)1.26520\n",
            "Epoch 28 (train)2.4s: train loss = 2.04213 = (mf)0.77223 + (embed)1.26990\n",
            "Epoch 29 (train)2.4s: train loss = 2.04105 = (mf)0.76692 + (embed)1.27413\n",
            "Epoch 30 (train)2.5s + (eval)0.4s: train loss = 2.01368 = (mf)0.74262 + (embed)1.27105, recall = 0.02459, ndcg = 0.09399\n",
            "Epoch 31 (train)2.8s: train loss = 2.05584 = (mf)0.78371 + (embed)1.27213\n",
            "Epoch 32 (train)2.4s: train loss = 2.04063 = (mf)0.76354 + (embed)1.27709\n",
            "Epoch 33 (train)2.4s: train loss = 2.03765 = (mf)0.75850 + (embed)1.27915\n",
            "Epoch 34 (train)2.4s: train loss = 2.05807 = (mf)0.78575 + (embed)1.27232\n",
            "Epoch 35 (train)2.8s + (eval)0.4s: train loss = 2.01485 = (mf)0.74487 + (embed)1.26998, recall = 0.02504, ndcg = 0.09010\n",
            "Epoch 36 (train)2.4s: train loss = 2.06260 = (mf)0.78284 + (embed)1.27975\n",
            "Epoch 37 (train)2.4s: train loss = 2.04143 = (mf)0.75766 + (embed)1.28378\n",
            "Epoch 38 (train)2.4s: train loss = 1.99456 = (mf)0.70910 + (embed)1.28547\n",
            "Epoch 39 (train)2.4s: train loss = 2.02255 = (mf)0.74261 + (embed)1.27994\n",
            "Epoch 40 (train)2.9s + (eval)0.3s: train loss = 2.07947 = (mf)0.79954 + (embed)1.27993, recall = 0.02387, ndcg = 0.09308\n",
            "Epoch 41 (train)2.4s: train loss = 2.03422 = (mf)0.75177 + (embed)1.28245\n",
            "Epoch 42 (train)2.4s: train loss = 2.00302 = (mf)0.72300 + (embed)1.28002\n",
            "Epoch 43 (train)2.4s: train loss = 2.03836 = (mf)0.75949 + (embed)1.27887\n",
            "Epoch 44 (train)2.6s: train loss = 2.01024 = (mf)0.73185 + (embed)1.27839\n",
            "Epoch 45 (train)2.8s + (eval)0.6s: train loss = 2.02233 = (mf)0.74041 + (embed)1.28192, recall = 0.02482, ndcg = 0.09748\n",
            "Epoch 46 (train)2.4s: train loss = 1.98921 = (mf)0.71400 + (embed)1.27521\n",
            "Epoch 47 (train)2.4s: train loss = 2.01278 = (mf)0.74099 + (embed)1.27178\n",
            "Epoch 48 (train)2.4s: train loss = 2.01794 = (mf)0.74500 + (embed)1.27294\n",
            "Epoch 49 (train)2.9s: train loss = 2.01863 = (mf)0.73810 + (embed)1.28053\n",
            "Epoch 50 (train)2.4s + (eval)0.3s: train loss = 2.00582 = (mf)0.72296 + (embed)1.28286, recall = 0.02344, ndcg = 0.09145\n",
            "Training finished in 132.50 seconds.\n",
            "Evaluation results for this combination: NDCG@50: 0.09145, Recall@50: 0.02344\n",
            "--- Trying combination: Epochs=100, TopK=10, LearningRate=0.005, Layers=3 ---\n",
            "Already normalize adjacency matrix (extended).\n",
            "Using xavier initialization for user, item, and genre embeddings.\n",
            "Epoch 1 (train)4.0s: train loss = 0.28964 = (mf)0.28908 + (embed)0.00057\n",
            "Epoch 2 (train)2.3s: train loss = 0.17742 = (mf)0.17638 + (embed)0.00104\n",
            "Epoch 3 (train)2.3s: train loss = 0.14843 = (mf)0.14699 + (embed)0.00144\n",
            "Epoch 4 (train)2.3s: train loss = 0.13154 = (mf)0.12974 + (embed)0.00180\n",
            "Epoch 5 (train)2.8s + (eval)0.9s: train loss = 0.11877 = (mf)0.11660 + (embed)0.00217, recall = 0.01066, ndcg = 0.22435\n",
            "Epoch 6 (train)2.4s: train loss = 0.10736 = (mf)0.10480 + (embed)0.00256\n",
            "Epoch 7 (train)2.3s: train loss = 0.09728 = (mf)0.09432 + (embed)0.00295\n",
            "Epoch 8 (train)2.3s: train loss = 0.08750 = (mf)0.08412 + (embed)0.00338\n",
            "Epoch 9 (train)2.4s: train loss = 0.07846 = (mf)0.07466 + (embed)0.00380\n",
            "Epoch 10 (train)2.7s + (eval)0.2s: train loss = 0.07330 = (mf)0.06909 + (embed)0.00422, recall = 0.01388, ndcg = 0.27990\n",
            "Epoch 11 (train)2.4s: train loss = 0.06648 = (mf)0.06185 + (embed)0.00462\n",
            "Epoch 12 (train)2.3s: train loss = 0.06212 = (mf)0.05713 + (embed)0.00499\n",
            "Epoch 13 (train)2.3s: train loss = 0.05957 = (mf)0.05424 + (embed)0.00532\n",
            "Epoch 14 (train)2.6s: train loss = 0.05485 = (mf)0.04920 + (embed)0.00564\n",
            "Epoch 15 (train)2.6s + (eval)0.6s: train loss = 0.05282 = (mf)0.04688 + (embed)0.00594, recall = 0.01561, ndcg = 0.27560\n",
            "Epoch 16 (train)2.4s: train loss = 0.05025 = (mf)0.04403 + (embed)0.00622\n",
            "Epoch 17 (train)2.3s: train loss = 0.04722 = (mf)0.04076 + (embed)0.00647\n",
            "Epoch 18 (train)2.3s: train loss = 0.04495 = (mf)0.03823 + (embed)0.00673\n",
            "Epoch 19 (train)2.8s: train loss = 0.04372 = (mf)0.03678 + (embed)0.00694\n",
            "Epoch 20 (train)2.3s + (eval)0.2s: train loss = 0.04225 = (mf)0.03511 + (embed)0.00714, recall = 0.01698, ndcg = 0.31592\n",
            "Epoch 21 (train)2.3s: train loss = 0.04079 = (mf)0.03347 + (embed)0.00733\n",
            "Epoch 22 (train)2.3s: train loss = 0.03855 = (mf)0.03102 + (embed)0.00753\n",
            "Epoch 23 (train)2.3s: train loss = 0.03834 = (mf)0.03067 + (embed)0.00767\n",
            "Epoch 24 (train)3.6s: train loss = 0.03759 = (mf)0.02976 + (embed)0.00783\n",
            "Epoch 25 (train)2.4s + (eval)0.2s: train loss = 0.03600 = (mf)0.02800 + (embed)0.00799, recall = 0.01735, ndcg = 0.31959\n",
            "Epoch 26 (train)2.3s: train loss = 0.03498 = (mf)0.02685 + (embed)0.00813\n",
            "Epoch 27 (train)2.3s: train loss = 0.03447 = (mf)0.02621 + (embed)0.00826\n",
            "Epoch 28 (train)2.4s: train loss = 0.03349 = (mf)0.02510 + (embed)0.00839\n",
            "Epoch 29 (train)2.8s: train loss = 0.03258 = (mf)0.02409 + (embed)0.00849\n",
            "Epoch 30 (train)2.3s + (eval)0.6s: train loss = 0.03207 = (mf)0.02346 + (embed)0.00861, recall = 0.01763, ndcg = 0.33183\n",
            "Epoch 31 (train)2.3s: train loss = 0.03130 = (mf)0.02260 + (embed)0.00871\n",
            "Epoch 32 (train)2.3s: train loss = 0.03037 = (mf)0.02159 + (embed)0.00878\n",
            "Epoch 33 (train)2.7s: train loss = 0.03052 = (mf)0.02165 + (embed)0.00886\n",
            "Epoch 34 (train)2.6s: train loss = 0.02971 = (mf)0.02076 + (embed)0.00895\n",
            "Epoch 35 (train)2.3s + (eval)0.2s: train loss = 0.02932 = (mf)0.02028 + (embed)0.00903, recall = 0.01795, ndcg = 0.33166\n",
            "Epoch 36 (train)2.3s: train loss = 0.02871 = (mf)0.01963 + (embed)0.00908\n",
            "Epoch 37 (train)2.3s: train loss = 0.02847 = (mf)0.01931 + (embed)0.00916\n",
            "Epoch 38 (train)2.8s: train loss = 0.02815 = (mf)0.01894 + (embed)0.00921\n",
            "Epoch 39 (train)2.4s: train loss = 0.02772 = (mf)0.01846 + (embed)0.00926\n",
            "Epoch 40 (train)2.3s + (eval)0.2s: train loss = 0.02693 = (mf)0.01762 + (embed)0.00931, recall = 0.01867, ndcg = 0.33631\n",
            "Epoch 41 (train)2.3s: train loss = 0.02602 = (mf)0.01665 + (embed)0.00937\n",
            "Epoch 42 (train)2.4s: train loss = 0.02610 = (mf)0.01667 + (embed)0.00943\n",
            "Epoch 43 (train)2.9s: train loss = 0.02622 = (mf)0.01678 + (embed)0.00945\n",
            "Epoch 44 (train)2.3s: train loss = 0.02624 = (mf)0.01675 + (embed)0.00949\n",
            "Epoch 45 (train)2.3s + (eval)0.2s: train loss = 0.02531 = (mf)0.01578 + (embed)0.00953, recall = 0.01804, ndcg = 0.33944\n",
            "Epoch 46 (train)2.3s: train loss = 0.02570 = (mf)0.01615 + (embed)0.00955\n",
            "Epoch 47 (train)2.4s: train loss = 0.02537 = (mf)0.01577 + (embed)0.00959\n",
            "Epoch 48 (train)2.8s: train loss = 0.02484 = (mf)0.01520 + (embed)0.00964\n",
            "Epoch 49 (train)2.3s: train loss = 0.02457 = (mf)0.01490 + (embed)0.00967\n",
            "Epoch 50 (train)2.3s + (eval)0.6s: train loss = 0.02430 = (mf)0.01460 + (embed)0.00971, recall = 0.01953, ndcg = 0.33913\n",
            "Epoch 51 (train)2.4s: train loss = 0.02389 = (mf)0.01416 + (embed)0.00973\n",
            "Epoch 52 (train)2.7s: train loss = 0.02368 = (mf)0.01392 + (embed)0.00976\n",
            "Epoch 53 (train)2.5s: train loss = 0.02370 = (mf)0.01392 + (embed)0.00978\n",
            "Epoch 54 (train)2.3s: train loss = 0.02368 = (mf)0.01387 + (embed)0.00982\n",
            "Epoch 55 (train)2.3s + (eval)0.2s: train loss = 0.02317 = (mf)0.01331 + (embed)0.00985, recall = 0.01900, ndcg = 0.33907\n",
            "Epoch 56 (train)2.3s: train loss = 0.02302 = (mf)0.01314 + (embed)0.00988\n",
            "Epoch 57 (train)2.8s: train loss = 0.02298 = (mf)0.01307 + (embed)0.00991\n",
            "Epoch 58 (train)2.4s: train loss = 0.02271 = (mf)0.01279 + (embed)0.00992\n",
            "Epoch 59 (train)2.4s: train loss = 0.02208 = (mf)0.01213 + (embed)0.00994\n",
            "Epoch 60 (train)2.3s + (eval)0.2s: train loss = 0.02210 = (mf)0.01215 + (embed)0.00995, recall = 0.01849, ndcg = 0.33552\n",
            "Epoch 61 (train)2.3s: train loss = 0.02203 = (mf)0.01205 + (embed)0.00998\n",
            "Epoch 62 (train)2.8s: train loss = 0.02184 = (mf)0.01184 + (embed)0.01000\n",
            "Epoch 63 (train)2.4s: train loss = 0.02192 = (mf)0.01193 + (embed)0.00999\n",
            "Epoch 64 (train)2.3s: train loss = 0.02150 = (mf)0.01150 + (embed)0.01000\n",
            "Epoch 65 (train)2.3s + (eval)0.6s: train loss = 0.02159 = (mf)0.01157 + (embed)0.01002, recall = 0.01852, ndcg = 0.32537\n",
            "Epoch 66 (train)2.5s: train loss = 0.02139 = (mf)0.01135 + (embed)0.01004\n",
            "Epoch 67 (train)2.7s: train loss = 0.02123 = (mf)0.01118 + (embed)0.01005\n",
            "Epoch 68 (train)2.3s: train loss = 0.02135 = (mf)0.01129 + (embed)0.01006\n",
            "Epoch 69 (train)2.3s: train loss = 0.02132 = (mf)0.01126 + (embed)0.01006\n",
            "Epoch 70 (train)2.3s + (eval)0.2s: train loss = 0.02130 = (mf)0.01122 + (embed)0.01008, recall = 0.01956, ndcg = 0.33454\n",
            "Epoch 71 (train)2.8s: train loss = 0.02089 = (mf)0.01080 + (embed)0.01009\n",
            "Epoch 72 (train)2.5s: train loss = 0.02070 = (mf)0.01060 + (embed)0.01010\n",
            "Epoch 73 (train)2.3s: train loss = 0.02093 = (mf)0.01082 + (embed)0.01012\n",
            "Epoch 74 (train)2.3s: train loss = 0.02026 = (mf)0.01012 + (embed)0.01013\n",
            "Epoch 75 (train)2.3s + (eval)0.2s: train loss = 0.02074 = (mf)0.01060 + (embed)0.01014, recall = 0.01877, ndcg = 0.34001\n",
            "Epoch 76 (train)2.8s: train loss = 0.02005 = (mf)0.00991 + (embed)0.01014\n",
            "Epoch 77 (train)2.3s: train loss = 0.02039 = (mf)0.01026 + (embed)0.01014\n",
            "Epoch 78 (train)2.3s: train loss = 0.02016 = (mf)0.01000 + (embed)0.01016\n",
            "Epoch 79 (train)2.3s: train loss = 0.02024 = (mf)0.01007 + (embed)0.01016\n",
            "Epoch 80 (train)2.3s + (eval)0.6s: train loss = 0.02045 = (mf)0.01029 + (embed)0.01016, recall = 0.01969, ndcg = 0.32162\n",
            "Epoch 81 (train)2.9s: train loss = 0.01994 = (mf)0.00976 + (embed)0.01018\n",
            "Epoch 82 (train)2.3s: train loss = 0.01968 = (mf)0.00950 + (embed)0.01018\n",
            "Epoch 83 (train)2.3s: train loss = 0.01956 = (mf)0.00937 + (embed)0.01019\n",
            "Epoch 84 (train)2.3s: train loss = 0.01967 = (mf)0.00948 + (embed)0.01019\n",
            "Epoch 85 (train)2.4s + (eval)0.4s: train loss = 0.01991 = (mf)0.00971 + (embed)0.01020, recall = 0.01872, ndcg = 0.31786\n",
            "Epoch 86 (train)2.7s: train loss = 0.01941 = (mf)0.00920 + (embed)0.01021\n",
            "Epoch 87 (train)2.4s: train loss = 0.01956 = (mf)0.00934 + (embed)0.01022\n",
            "Epoch 88 (train)2.3s: train loss = 0.01942 = (mf)0.00919 + (embed)0.01022\n",
            "Epoch 89 (train)2.3s: train loss = 0.01936 = (mf)0.00913 + (embed)0.01022\n",
            "Epoch 90 (train)2.6s + (eval)0.4s: train loss = 0.01947 = (mf)0.00923 + (embed)0.01024, recall = 0.01960, ndcg = 0.32046\n",
            "Epoch 91 (train)2.5s: train loss = 0.01937 = (mf)0.00912 + (embed)0.01025\n",
            "Epoch 92 (train)2.3s: train loss = 0.01932 = (mf)0.00906 + (embed)0.01026\n",
            "Epoch 93 (train)2.3s: train loss = 0.01945 = (mf)0.00919 + (embed)0.01026\n",
            "Epoch 94 (train)2.3s: train loss = 0.01900 = (mf)0.00872 + (embed)0.01028\n",
            "Epoch 95 (train)2.9s + (eval)0.6s: train loss = 0.01919 = (mf)0.00891 + (embed)0.01029, recall = 0.01941, ndcg = 0.31941\n",
            "Epoch 96 (train)2.4s: train loss = 0.01942 = (mf)0.00911 + (embed)0.01031\n",
            "Epoch 97 (train)2.3s: train loss = 0.01873 = (mf)0.00842 + (embed)0.01031\n",
            "Epoch 98 (train)2.3s: train loss = 0.01891 = (mf)0.00859 + (embed)0.01031\n",
            "Epoch 99 (train)2.3s: train loss = 0.01901 = (mf)0.00869 + (embed)0.01032\n",
            "Epoch 100 (train)2.8s + (eval)0.2s: train loss = 0.01865 = (mf)0.00832 + (embed)0.01034, recall = 0.01891, ndcg = 0.33238\n",
            "Training finished in 254.33 seconds.\n",
            "Evaluation results for this combination: NDCG@10: 0.33238, Recall@10: 0.01891\n",
            "--- Trying combination: Epochs=100, TopK=10, LearningRate=0.005, Layers=4 ---\n",
            "Already normalize adjacency matrix (extended).\n",
            "Using xavier initialization for user, item, and genre embeddings.\n",
            "Epoch 1 (train)4.3s: train loss = 0.29737 = (mf)0.29680 + (embed)0.00057\n",
            "Epoch 2 (train)2.4s: train loss = 0.20326 = (mf)0.20227 + (embed)0.00100\n",
            "Epoch 3 (train)2.4s: train loss = 0.18492 = (mf)0.18354 + (embed)0.00137\n",
            "Epoch 4 (train)2.4s: train loss = 0.15902 = (mf)0.15718 + (embed)0.00184\n",
            "Epoch 5 (train)2.3s + (eval)1.6s: train loss = 0.13928 = (mf)0.13693 + (embed)0.00235, recall = 0.01044, ndcg = 0.20918\n",
            "Epoch 6 (train)2.7s: train loss = 0.12793 = (mf)0.12515 + (embed)0.00279\n",
            "Epoch 7 (train)2.4s: train loss = 0.11687 = (mf)0.11365 + (embed)0.00322\n",
            "Epoch 8 (train)2.3s: train loss = 0.10694 = (mf)0.10322 + (embed)0.00372\n",
            "Epoch 9 (train)2.3s: train loss = 0.09885 = (mf)0.09463 + (embed)0.00422\n",
            "Epoch 10 (train)2.8s + (eval)0.3s: train loss = 0.09059 = (mf)0.08586 + (embed)0.00473, recall = 0.01228, ndcg = 0.26245\n",
            "Epoch 11 (train)2.4s: train loss = 0.08263 = (mf)0.07741 + (embed)0.00522\n",
            "Epoch 12 (train)2.4s: train loss = 0.07784 = (mf)0.07216 + (embed)0.00569\n",
            "Epoch 13 (train)2.3s: train loss = 0.07295 = (mf)0.06683 + (embed)0.00612\n",
            "Epoch 14 (train)2.3s: train loss = 0.06950 = (mf)0.06297 + (embed)0.00653\n",
            "Epoch 15 (train)2.9s + (eval)0.2s: train loss = 0.06679 = (mf)0.05990 + (embed)0.00690, recall = 0.01398, ndcg = 0.29051\n",
            "Epoch 16 (train)2.4s: train loss = 0.06363 = (mf)0.05639 + (embed)0.00723\n",
            "Epoch 17 (train)2.3s: train loss = 0.06110 = (mf)0.05357 + (embed)0.00753\n",
            "Epoch 18 (train)2.3s: train loss = 0.05886 = (mf)0.05105 + (embed)0.00782\n",
            "Epoch 19 (train)2.8s: train loss = 0.05717 = (mf)0.04907 + (embed)0.00810\n",
            "Epoch 20 (train)3.1s + (eval)0.6s: train loss = 0.05464 = (mf)0.04630 + (embed)0.00834, recall = 0.01561, ndcg = 0.30007\n",
            "Epoch 21 (train)2.4s: train loss = 0.05375 = (mf)0.04518 + (embed)0.00857\n",
            "Epoch 22 (train)2.3s: train loss = 0.05150 = (mf)0.04270 + (embed)0.00880\n",
            "Epoch 23 (train)2.3s: train loss = 0.04962 = (mf)0.04061 + (embed)0.00901\n",
            "Epoch 24 (train)2.7s: train loss = 0.04846 = (mf)0.03927 + (embed)0.00919\n",
            "Epoch 25 (train)2.5s + (eval)0.2s: train loss = 0.04678 = (mf)0.03742 + (embed)0.00936, recall = 0.01775, ndcg = 0.32934\n",
            "Epoch 26 (train)2.4s: train loss = 0.04520 = (mf)0.03564 + (embed)0.00956\n",
            "Epoch 27 (train)2.3s: train loss = 0.04553 = (mf)0.03582 + (embed)0.00970\n",
            "Epoch 28 (train)2.3s: train loss = 0.04376 = (mf)0.03392 + (embed)0.00984\n",
            "Epoch 29 (train)2.9s: train loss = 0.04315 = (mf)0.03318 + (embed)0.00997\n",
            "Epoch 30 (train)2.4s + (eval)0.2s: train loss = 0.04209 = (mf)0.03197 + (embed)0.01012, recall = 0.01654, ndcg = 0.33181\n",
            "Epoch 31 (train)2.4s: train loss = 0.04190 = (mf)0.03166 + (embed)0.01024\n",
            "Epoch 32 (train)2.4s: train loss = 0.04089 = (mf)0.03053 + (embed)0.01036\n",
            "Epoch 33 (train)2.4s: train loss = 0.03966 = (mf)0.02918 + (embed)0.01048\n",
            "Epoch 34 (train)2.9s: train loss = 0.03809 = (mf)0.02749 + (embed)0.01060\n",
            "Epoch 35 (train)2.3s + (eval)0.6s: train loss = 0.03777 = (mf)0.02708 + (embed)0.01069, recall = 0.01635, ndcg = 0.32012\n",
            "Epoch 36 (train)2.3s: train loss = 0.03809 = (mf)0.02728 + (embed)0.01081\n",
            "Epoch 37 (train)2.3s: train loss = 0.03623 = (mf)0.02534 + (embed)0.01089\n",
            "Epoch 38 (train)2.7s: train loss = 0.03591 = (mf)0.02493 + (embed)0.01097\n",
            "Epoch 39 (train)2.6s: train loss = 0.03572 = (mf)0.02466 + (embed)0.01106\n",
            "Epoch 40 (train)2.3s + (eval)0.2s: train loss = 0.03569 = (mf)0.02456 + (embed)0.01113, recall = 0.01640, ndcg = 0.32911\n",
            "Epoch 41 (train)2.3s: train loss = 0.03451 = (mf)0.02330 + (embed)0.01121\n",
            "Epoch 42 (train)2.3s: train loss = 0.03477 = (mf)0.02350 + (embed)0.01127\n",
            "Epoch 43 (train)2.8s: train loss = 0.03410 = (mf)0.02276 + (embed)0.01134\n",
            "Epoch 44 (train)2.4s: train loss = 0.03399 = (mf)0.02257 + (embed)0.01141\n",
            "Epoch 45 (train)2.3s + (eval)0.2s: train loss = 0.03374 = (mf)0.02225 + (embed)0.01148, recall = 0.01755, ndcg = 0.34379\n",
            "Epoch 46 (train)2.3s: train loss = 0.03303 = (mf)0.02147 + (embed)0.01156\n",
            "Epoch 47 (train)2.3s: train loss = 0.03266 = (mf)0.02107 + (embed)0.01159\n",
            "Epoch 48 (train)2.9s: train loss = 0.03238 = (mf)0.02074 + (embed)0.01164\n",
            "Epoch 49 (train)2.4s: train loss = 0.03214 = (mf)0.02045 + (embed)0.01168\n",
            "Epoch 50 (train)2.3s + (eval)0.6s: train loss = 0.03164 = (mf)0.01991 + (embed)0.01173, recall = 0.01832, ndcg = 0.34681\n",
            "Epoch 51 (train)2.4s: train loss = 0.03151 = (mf)0.01973 + (embed)0.01177\n",
            "Epoch 52 (train)2.6s: train loss = 0.03071 = (mf)0.01888 + (embed)0.01183\n",
            "Epoch 53 (train)2.6s: train loss = 0.03094 = (mf)0.01906 + (embed)0.01188\n",
            "Epoch 54 (train)2.3s: train loss = 0.03027 = (mf)0.01838 + (embed)0.01189\n",
            "Epoch 55 (train)2.3s + (eval)0.2s: train loss = 0.03029 = (mf)0.01834 + (embed)0.01195, recall = 0.01826, ndcg = 0.34909\n",
            "Epoch 56 (train)2.4s: train loss = 0.03027 = (mf)0.01829 + (embed)0.01198\n",
            "Epoch 57 (train)2.8s: train loss = 0.02924 = (mf)0.01723 + (embed)0.01202\n",
            "Epoch 58 (train)2.4s: train loss = 0.02923 = (mf)0.01718 + (embed)0.01205\n",
            "Epoch 59 (train)2.3s: train loss = 0.02941 = (mf)0.01730 + (embed)0.01211\n",
            "Epoch 60 (train)2.3s + (eval)0.3s: train loss = 0.02894 = (mf)0.01681 + (embed)0.01212, recall = 0.01857, ndcg = 0.36830\n",
            "Epoch 61 (train)2.4s: train loss = 0.02911 = (mf)0.01695 + (embed)0.01216\n",
            "Epoch 62 (train)2.9s: train loss = 0.02848 = (mf)0.01632 + (embed)0.01216\n",
            "Epoch 63 (train)2.4s: train loss = 0.02854 = (mf)0.01636 + (embed)0.01218\n",
            "Epoch 64 (train)2.3s: train loss = 0.02848 = (mf)0.01626 + (embed)0.01223\n",
            "Epoch 65 (train)2.3s + (eval)0.6s: train loss = 0.02803 = (mf)0.01578 + (embed)0.01225, recall = 0.01710, ndcg = 0.36335\n",
            "Epoch 66 (train)2.6s: train loss = 0.02839 = (mf)0.01612 + (embed)0.01227\n",
            "Epoch 67 (train)2.7s: train loss = 0.02777 = (mf)0.01548 + (embed)0.01229\n",
            "Epoch 68 (train)2.3s: train loss = 0.02763 = (mf)0.01531 + (embed)0.01232\n",
            "Epoch 69 (train)2.3s: train loss = 0.02772 = (mf)0.01538 + (embed)0.01234\n",
            "Epoch 70 (train)2.3s + (eval)0.2s: train loss = 0.02740 = (mf)0.01504 + (embed)0.01236, recall = 0.01781, ndcg = 0.35543\n",
            "Epoch 71 (train)2.8s: train loss = 0.02701 = (mf)0.01462 + (embed)0.01239\n",
            "Epoch 72 (train)2.5s: train loss = 0.02692 = (mf)0.01453 + (embed)0.01239\n",
            "Epoch 73 (train)2.4s: train loss = 0.02685 = (mf)0.01444 + (embed)0.01241\n",
            "Epoch 74 (train)2.4s: train loss = 0.02670 = (mf)0.01426 + (embed)0.01243\n",
            "Epoch 75 (train)2.3s + (eval)0.2s: train loss = 0.02632 = (mf)0.01385 + (embed)0.01247, recall = 0.01800, ndcg = 0.36694\n",
            "Epoch 76 (train)2.9s: train loss = 0.02635 = (mf)0.01386 + (embed)0.01249\n",
            "Epoch 77 (train)2.4s: train loss = 0.02645 = (mf)0.01393 + (embed)0.01252\n",
            "Epoch 78 (train)2.3s: train loss = 0.02642 = (mf)0.01388 + (embed)0.01254\n",
            "Epoch 79 (train)2.3s: train loss = 0.02618 = (mf)0.01362 + (embed)0.01256\n",
            "Epoch 80 (train)2.3s + (eval)0.3s: train loss = 0.02657 = (mf)0.01399 + (embed)0.01258, recall = 0.01904, ndcg = 0.36629\n",
            "Epoch 81 (train)3.0s: train loss = 0.02591 = (mf)0.01329 + (embed)0.01261\n",
            "Epoch 82 (train)2.3s: train loss = 0.02583 = (mf)0.01321 + (embed)0.01262\n",
            "Epoch 83 (train)2.3s: train loss = 0.02513 = (mf)0.01250 + (embed)0.01263\n",
            "Epoch 84 (train)2.4s: train loss = 0.02545 = (mf)0.01280 + (embed)0.01265\n",
            "Epoch 85 (train)2.5s + (eval)0.8s: train loss = 0.02517 = (mf)0.01251 + (embed)0.01266, recall = 0.01837, ndcg = 0.35461\n",
            "Epoch 86 (train)2.6s: train loss = 0.02522 = (mf)0.01254 + (embed)0.01268\n",
            "Epoch 87 (train)2.3s: train loss = 0.02554 = (mf)0.01284 + (embed)0.01271\n",
            "Epoch 88 (train)2.3s: train loss = 0.02525 = (mf)0.01253 + (embed)0.01273\n",
            "Epoch 89 (train)2.4s: train loss = 0.02529 = (mf)0.01256 + (embed)0.01273\n",
            "Epoch 90 (train)2.9s + (eval)0.2s: train loss = 0.02497 = (mf)0.01222 + (embed)0.01274, recall = 0.01885, ndcg = 0.36246\n",
            "Epoch 91 (train)2.4s: train loss = 0.02458 = (mf)0.01183 + (embed)0.01276\n",
            "Epoch 92 (train)2.3s: train loss = 0.02469 = (mf)0.01193 + (embed)0.01276\n",
            "Epoch 93 (train)2.3s: train loss = 0.02495 = (mf)0.01219 + (embed)0.01277\n",
            "Epoch 94 (train)2.3s: train loss = 0.02457 = (mf)0.01179 + (embed)0.01278\n",
            "Epoch 95 (train)2.9s + (eval)0.6s: train loss = 0.02480 = (mf)0.01200 + (embed)0.01280, recall = 0.01813, ndcg = 0.34805\n",
            "Epoch 96 (train)2.4s: train loss = 0.02507 = (mf)0.01225 + (embed)0.01282\n",
            "Epoch 97 (train)2.4s: train loss = 0.02446 = (mf)0.01163 + (embed)0.01283\n",
            "Epoch 98 (train)2.4s: train loss = 0.02485 = (mf)0.01199 + (embed)0.01286\n",
            "Epoch 99 (train)2.6s: train loss = 0.02427 = (mf)0.01141 + (embed)0.01286\n",
            "Epoch 100 (train)2.6s + (eval)0.2s: train loss = 0.02424 = (mf)0.01137 + (embed)0.01287, recall = 0.01816, ndcg = 0.35791\n",
            "Training finished in 257.44 seconds.\n",
            "Evaluation results for this combination: NDCG@10: 0.35791, Recall@10: 0.01816\n",
            "--- Trying combination: Epochs=100, TopK=10, LearningRate=0.005, Layers=5 ---\n",
            "Already normalize adjacency matrix (extended).\n",
            "Using xavier initialization for user, item, and genre embeddings.\n",
            "Epoch 1 (train)4.7s: train loss = 0.30106 = (mf)0.30047 + (embed)0.00059\n",
            "Epoch 2 (train)2.4s: train loss = 0.21068 = (mf)0.20961 + (embed)0.00107\n",
            "Epoch 3 (train)2.4s: train loss = 0.18246 = (mf)0.18088 + (embed)0.00158\n",
            "Epoch 4 (train)2.4s: train loss = 0.16099 = (mf)0.15882 + (embed)0.00216\n",
            "Epoch 5 (train)2.8s + (eval)1.1s: train loss = 0.14737 = (mf)0.14468 + (embed)0.00269, recall = 0.00991, ndcg = 0.21069\n",
            "Epoch 6 (train)2.5s: train loss = 0.13788 = (mf)0.13474 + (embed)0.00314\n",
            "Epoch 7 (train)2.4s: train loss = 0.12915 = (mf)0.12557 + (embed)0.00358\n",
            "Epoch 8 (train)2.4s: train loss = 0.12189 = (mf)0.11785 + (embed)0.00404\n",
            "Epoch 9 (train)2.7s: train loss = 0.11343 = (mf)0.10889 + (embed)0.00454\n",
            "Epoch 10 (train)2.7s + (eval)0.6s: train loss = 0.10808 = (mf)0.10302 + (embed)0.00506, recall = 0.01176, ndcg = 0.25428\n",
            "Epoch 11 (train)2.4s: train loss = 0.09816 = (mf)0.09253 + (embed)0.00563\n",
            "Epoch 12 (train)2.4s: train loss = 0.09408 = (mf)0.08792 + (embed)0.00616\n",
            "Epoch 13 (train)2.9s: train loss = 0.08792 = (mf)0.08122 + (embed)0.00670\n",
            "Epoch 14 (train)2.9s: train loss = 0.08358 = (mf)0.07637 + (embed)0.00721\n",
            "Epoch 15 (train)2.5s + (eval)0.2s: train loss = 0.08049 = (mf)0.07282 + (embed)0.00767, recall = 0.01442, ndcg = 0.29821\n",
            "Epoch 16 (train)2.4s: train loss = 0.07627 = (mf)0.06815 + (embed)0.00812\n",
            "Epoch 17 (train)2.5s: train loss = 0.07300 = (mf)0.06445 + (embed)0.00855\n",
            "Epoch 18 (train)2.7s: train loss = 0.07191 = (mf)0.06302 + (embed)0.00889\n",
            "Epoch 19 (train)2.6s: train loss = 0.06945 = (mf)0.06024 + (embed)0.00922\n",
            "Epoch 20 (train)2.4s + (eval)0.2s: train loss = 0.06649 = (mf)0.05693 + (embed)0.00956, recall = 0.01546, ndcg = 0.30517\n",
            "Epoch 21 (train)2.4s: train loss = 0.06456 = (mf)0.05471 + (embed)0.00984\n",
            "Epoch 22 (train)2.4s: train loss = 0.06336 = (mf)0.05324 + (embed)0.01012\n",
            "Epoch 23 (train)3.0s: train loss = 0.06124 = (mf)0.05084 + (embed)0.01041\n",
            "Epoch 24 (train)2.4s: train loss = 0.05982 = (mf)0.04915 + (embed)0.01067\n",
            "Epoch 25 (train)2.4s + (eval)0.6s: train loss = 0.05722 = (mf)0.04632 + (embed)0.01091, recall = 0.01610, ndcg = 0.31274\n",
            "Epoch 26 (train)2.4s: train loss = 0.05639 = (mf)0.04525 + (embed)0.01114\n",
            "Epoch 27 (train)2.7s: train loss = 0.05345 = (mf)0.04209 + (embed)0.01136\n",
            "Epoch 28 (train)2.7s: train loss = 0.05404 = (mf)0.04248 + (embed)0.01156\n",
            "Epoch 29 (train)2.4s: train loss = 0.05225 = (mf)0.04049 + (embed)0.01176\n",
            "Epoch 30 (train)2.4s + (eval)0.2s: train loss = 0.05113 = (mf)0.03920 + (embed)0.01193, recall = 0.01658, ndcg = 0.31871\n",
            "Epoch 31 (train)2.4s: train loss = 0.04959 = (mf)0.03747 + (embed)0.01212\n",
            "Epoch 32 (train)2.9s: train loss = 0.04915 = (mf)0.03689 + (embed)0.01226\n",
            "Epoch 33 (train)2.4s: train loss = 0.04689 = (mf)0.03449 + (embed)0.01240\n",
            "Epoch 34 (train)2.4s: train loss = 0.04705 = (mf)0.03451 + (embed)0.01254\n",
            "Epoch 35 (train)2.4s + (eval)0.2s: train loss = 0.04682 = (mf)0.03417 + (embed)0.01265, recall = 0.01651, ndcg = 0.32196\n",
            "Epoch 36 (train)2.5s: train loss = 0.04595 = (mf)0.03316 + (embed)0.01279\n",
            "Epoch 37 (train)2.8s: train loss = 0.04502 = (mf)0.03213 + (embed)0.01290\n",
            "Epoch 38 (train)2.4s: train loss = 0.04502 = (mf)0.03198 + (embed)0.01304\n",
            "Epoch 39 (train)2.5s: train loss = 0.04396 = (mf)0.03084 + (embed)0.01312\n",
            "Epoch 40 (train)2.4s + (eval)0.6s: train loss = 0.04263 = (mf)0.02941 + (embed)0.01322, recall = 0.01711, ndcg = 0.31737\n",
            "Epoch 41 (train)2.9s: train loss = 0.04252 = (mf)0.02922 + (embed)0.01331\n",
            "Epoch 42 (train)2.4s: train loss = 0.04172 = (mf)0.02833 + (embed)0.01339\n",
            "Epoch 43 (train)2.4s: train loss = 0.04142 = (mf)0.02795 + (embed)0.01347\n",
            "Epoch 44 (train)2.4s: train loss = 0.04150 = (mf)0.02798 + (embed)0.01352\n",
            "Epoch 45 (train)2.4s + (eval)0.3s: train loss = 0.04063 = (mf)0.02704 + (embed)0.01359, recall = 0.01633, ndcg = 0.32412\n",
            "Epoch 46 (train)2.9s: train loss = 0.03975 = (mf)0.02609 + (embed)0.01366\n",
            "Epoch 47 (train)2.4s: train loss = 0.04017 = (mf)0.02645 + (embed)0.01373\n",
            "Epoch 48 (train)2.4s: train loss = 0.03897 = (mf)0.02518 + (embed)0.01379\n",
            "Epoch 49 (train)2.4s: train loss = 0.03912 = (mf)0.02527 + (embed)0.01385\n",
            "Epoch 50 (train)2.7s + (eval)0.4s: train loss = 0.03819 = (mf)0.02431 + (embed)0.01388, recall = 0.01643, ndcg = 0.32623\n",
            "Epoch 51 (train)2.6s: train loss = 0.03793 = (mf)0.02398 + (embed)0.01396\n",
            "Epoch 52 (train)2.4s: train loss = 0.03821 = (mf)0.02421 + (embed)0.01401\n",
            "Epoch 53 (train)2.4s: train loss = 0.03754 = (mf)0.02348 + (embed)0.01405\n",
            "Epoch 54 (train)2.4s: train loss = 0.03731 = (mf)0.02322 + (embed)0.01408\n",
            "Epoch 55 (train)2.9s + (eval)0.6s: train loss = 0.03710 = (mf)0.02297 + (embed)0.01413, recall = 0.01709, ndcg = 0.33475\n",
            "Epoch 56 (train)2.4s: train loss = 0.03665 = (mf)0.02247 + (embed)0.01418\n",
            "Epoch 57 (train)2.4s: train loss = 0.03656 = (mf)0.02234 + (embed)0.01422\n",
            "Epoch 58 (train)2.4s: train loss = 0.03642 = (mf)0.02214 + (embed)0.01428\n",
            "Epoch 59 (train)2.6s: train loss = 0.03598 = (mf)0.02168 + (embed)0.01430\n",
            "Epoch 60 (train)2.7s + (eval)0.3s: train loss = 0.03558 = (mf)0.02123 + (embed)0.01435, recall = 0.01641, ndcg = 0.33992\n",
            "Epoch 61 (train)2.4s: train loss = 0.03516 = (mf)0.02077 + (embed)0.01439\n",
            "Epoch 62 (train)2.4s: train loss = 0.03511 = (mf)0.02070 + (embed)0.01441\n",
            "Epoch 63 (train)2.4s: train loss = 0.03483 = (mf)0.02037 + (embed)0.01446\n",
            "Epoch 64 (train)2.9s: train loss = 0.03488 = (mf)0.02038 + (embed)0.01450\n",
            "Epoch 65 (train)2.4s + (eval)0.2s: train loss = 0.03501 = (mf)0.02050 + (embed)0.01451, recall = 0.01684, ndcg = 0.34206\n",
            "Epoch 66 (train)2.4s: train loss = 0.03435 = (mf)0.01979 + (embed)0.01456\n",
            "Epoch 67 (train)2.4s: train loss = 0.03373 = (mf)0.01913 + (embed)0.01460\n",
            "Epoch 68 (train)2.5s: train loss = 0.03378 = (mf)0.01913 + (embed)0.01465\n",
            "Epoch 69 (train)2.9s: train loss = 0.03383 = (mf)0.01916 + (embed)0.01467\n",
            "Epoch 70 (train)2.4s + (eval)0.6s: train loss = 0.03370 = (mf)0.01900 + (embed)0.01471, recall = 0.01772, ndcg = 0.35012\n",
            "Epoch 71 (train)2.4s: train loss = 0.03386 = (mf)0.01913 + (embed)0.01474\n",
            "Epoch 72 (train)2.4s: train loss = 0.03338 = (mf)0.01865 + (embed)0.01473\n",
            "Epoch 73 (train)2.9s: train loss = 0.03299 = (mf)0.01820 + (embed)0.01479\n",
            "Epoch 74 (train)2.5s: train loss = 0.03294 = (mf)0.01815 + (embed)0.01479\n",
            "Epoch 75 (train)2.4s + (eval)0.2s: train loss = 0.03266 = (mf)0.01781 + (embed)0.01485, recall = 0.01828, ndcg = 0.35085\n",
            "Epoch 76 (train)2.4s: train loss = 0.03271 = (mf)0.01784 + (embed)0.01487\n",
            "Epoch 77 (train)2.4s: train loss = 0.03239 = (mf)0.01750 + (embed)0.01489\n",
            "Epoch 78 (train)2.9s: train loss = 0.03242 = (mf)0.01753 + (embed)0.01489\n",
            "Epoch 79 (train)2.4s: train loss = 0.03184 = (mf)0.01692 + (embed)0.01492\n",
            "Epoch 80 (train)2.4s + (eval)0.2s: train loss = 0.03175 = (mf)0.01677 + (embed)0.01498, recall = 0.01818, ndcg = 0.34426\n",
            "Epoch 81 (train)2.4s: train loss = 0.03218 = (mf)0.01721 + (embed)0.01497\n",
            "Epoch 82 (train)2.7s: train loss = 0.03155 = (mf)0.01655 + (embed)0.01500\n",
            "Epoch 83 (train)2.6s: train loss = 0.03228 = (mf)0.01731 + (embed)0.01497\n",
            "Epoch 84 (train)2.4s: train loss = 0.03174 = (mf)0.01673 + (embed)0.01501\n",
            "Epoch 85 (train)2.4s + (eval)0.6s: train loss = 0.03160 = (mf)0.01655 + (embed)0.01505, recall = 0.01940, ndcg = 0.35519\n",
            "Epoch 86 (train)2.5s: train loss = 0.03161 = (mf)0.01654 + (embed)0.01507\n",
            "Epoch 87 (train)2.9s: train loss = 0.03135 = (mf)0.01624 + (embed)0.01511\n",
            "Epoch 88 (train)2.4s: train loss = 0.03107 = (mf)0.01595 + (embed)0.01513\n",
            "Epoch 89 (train)2.4s: train loss = 0.03134 = (mf)0.01620 + (embed)0.01514\n",
            "Epoch 90 (train)2.4s + (eval)0.3s: train loss = 0.03092 = (mf)0.01573 + (embed)0.01518, recall = 0.01890, ndcg = 0.35470\n",
            "Epoch 91 (train)2.6s: train loss = 0.03087 = (mf)0.01567 + (embed)0.01520\n",
            "Epoch 92 (train)2.8s: train loss = 0.03074 = (mf)0.01553 + (embed)0.01521\n",
            "Epoch 93 (train)2.4s: train loss = 0.03038 = (mf)0.01515 + (embed)0.01523\n",
            "Epoch 94 (train)2.4s: train loss = 0.03061 = (mf)0.01535 + (embed)0.01527\n",
            "Epoch 95 (train)2.4s + (eval)0.2s: train loss = 0.03050 = (mf)0.01520 + (embed)0.01530, recall = 0.01860, ndcg = 0.36186\n",
            "Epoch 96 (train)2.9s: train loss = 0.03023 = (mf)0.01491 + (embed)0.01532\n",
            "Epoch 97 (train)2.4s: train loss = 0.03001 = (mf)0.01466 + (embed)0.01535\n",
            "Epoch 98 (train)2.4s: train loss = 0.03021 = (mf)0.01484 + (embed)0.01537\n",
            "Epoch 99 (train)2.4s: train loss = 0.03037 = (mf)0.01499 + (embed)0.01538\n",
            "Epoch 100 (train)2.4s + (eval)0.2s: train loss = 0.02975 = (mf)0.01437 + (embed)0.01538, recall = 0.01932, ndcg = 0.36099\n",
            "Training finished in 263.78 seconds.\n",
            "Evaluation results for this combination: NDCG@10: 0.36099, Recall@10: 0.01932\n",
            "--- Trying combination: Epochs=100, TopK=10, LearningRate=0.05, Layers=3 ---\n",
            "Already normalize adjacency matrix (extended).\n",
            "Using xavier initialization for user, item, and genre embeddings.\n",
            "Epoch 1 (train)3.9s: train loss = 0.15613 = (mf)0.15286 + (embed)0.00327\n",
            "Epoch 2 (train)2.8s: train loss = 0.07133 = (mf)0.06351 + (embed)0.00782\n",
            "Epoch 3 (train)2.5s: train loss = 0.05486 = (mf)0.04380 + (embed)0.01106\n",
            "Epoch 4 (train)2.8s: train loss = 0.04978 = (mf)0.03637 + (embed)0.01341\n",
            "Epoch 5 (train)2.4s + (eval)1.0s: train loss = 0.04825 = (mf)0.03305 + (embed)0.01521, recall = 0.01217, ndcg = 0.21764\n",
            "Epoch 6 (train)2.9s: train loss = 0.04682 = (mf)0.03019 + (embed)0.01663\n",
            "Epoch 7 (train)2.4s: train loss = 0.04647 = (mf)0.02875 + (embed)0.01772\n",
            "Epoch 8 (train)2.4s: train loss = 0.04551 = (mf)0.02684 + (embed)0.01866\n",
            "Epoch 9 (train)2.4s: train loss = 0.04630 = (mf)0.02680 + (embed)0.01950\n",
            "Epoch 10 (train)2.3s + (eval)0.2s: train loss = 0.04548 = (mf)0.02518 + (embed)0.02031, recall = 0.01257, ndcg = 0.21269\n",
            "Epoch 11 (train)2.9s: train loss = 0.04549 = (mf)0.02446 + (embed)0.02103\n",
            "Epoch 12 (train)2.4s: train loss = 0.04595 = (mf)0.02434 + (embed)0.02161\n",
            "Epoch 13 (train)2.4s: train loss = 0.04669 = (mf)0.02444 + (embed)0.02226\n",
            "Epoch 14 (train)2.3s: train loss = 0.04678 = (mf)0.02403 + (embed)0.02276\n",
            "Epoch 15 (train)2.4s + (eval)0.8s: train loss = 0.04807 = (mf)0.02480 + (embed)0.02327, recall = 0.01126, ndcg = 0.18193\n",
            "Epoch 16 (train)2.6s: train loss = 0.04896 = (mf)0.02508 + (embed)0.02388\n",
            "Epoch 17 (train)2.4s: train loss = 0.04808 = (mf)0.02371 + (embed)0.02437\n",
            "Epoch 18 (train)2.3s: train loss = 0.04805 = (mf)0.02335 + (embed)0.02470\n",
            "Epoch 19 (train)2.3s: train loss = 0.04853 = (mf)0.02358 + (embed)0.02494\n",
            "Epoch 20 (train)2.8s + (eval)0.4s: train loss = 0.04685 = (mf)0.02166 + (embed)0.02520, recall = 0.01108, ndcg = 0.17426\n",
            "Epoch 21 (train)2.4s: train loss = 0.04889 = (mf)0.02335 + (embed)0.02554\n",
            "Epoch 22 (train)2.4s: train loss = 0.04989 = (mf)0.02395 + (embed)0.02595\n",
            "Epoch 23 (train)2.3s: train loss = 0.04814 = (mf)0.02195 + (embed)0.02619\n",
            "Epoch 24 (train)2.3s: train loss = 0.04855 = (mf)0.02218 + (embed)0.02637\n",
            "Epoch 25 (train)2.9s + (eval)0.2s: train loss = 0.04896 = (mf)0.02254 + (embed)0.02642, recall = 0.01262, ndcg = 0.19636\n",
            "Epoch 26 (train)2.4s: train loss = 0.04849 = (mf)0.02198 + (embed)0.02651\n",
            "Epoch 27 (train)2.4s: train loss = 0.04796 = (mf)0.02133 + (embed)0.02663\n",
            "Epoch 28 (train)2.3s: train loss = 0.04853 = (mf)0.02179 + (embed)0.02674\n",
            "Epoch 29 (train)2.4s: train loss = 0.04937 = (mf)0.02256 + (embed)0.02681\n",
            "Epoch 30 (train)2.8s + (eval)0.6s: train loss = 0.04757 = (mf)0.02070 + (embed)0.02687, recall = 0.01180, ndcg = 0.19637\n",
            "Epoch 31 (train)2.4s: train loss = 0.04863 = (mf)0.02179 + (embed)0.02684\n",
            "Epoch 32 (train)2.4s: train loss = 0.04768 = (mf)0.02066 + (embed)0.02703\n",
            "Epoch 33 (train)2.3s: train loss = 0.04897 = (mf)0.02185 + (embed)0.02712\n",
            "Epoch 34 (train)2.7s: train loss = 0.04933 = (mf)0.02209 + (embed)0.02723\n",
            "Epoch 35 (train)2.5s + (eval)0.2s: train loss = 0.04878 = (mf)0.02134 + (embed)0.02743, recall = 0.01096, ndcg = 0.18326\n",
            "Epoch 36 (train)2.4s: train loss = 0.04909 = (mf)0.02162 + (embed)0.02748\n",
            "Epoch 37 (train)2.3s: train loss = 0.04894 = (mf)0.02124 + (embed)0.02769\n",
            "Epoch 38 (train)2.3s: train loss = 0.04894 = (mf)0.02115 + (embed)0.02779\n",
            "Epoch 39 (train)2.8s: train loss = 0.04919 = (mf)0.02130 + (embed)0.02789\n",
            "Epoch 40 (train)2.4s + (eval)0.2s: train loss = 0.04877 = (mf)0.02090 + (embed)0.02787, recall = 0.01193, ndcg = 0.20446\n",
            "Epoch 41 (train)2.4s: train loss = 0.04889 = (mf)0.02103 + (embed)0.02786\n",
            "Epoch 42 (train)2.3s: train loss = 0.04889 = (mf)0.02090 + (embed)0.02799\n",
            "Epoch 43 (train)2.3s: train loss = 0.04881 = (mf)0.02086 + (embed)0.02796\n",
            "Epoch 44 (train)2.9s: train loss = 0.04955 = (mf)0.02146 + (embed)0.02809\n",
            "Epoch 45 (train)2.4s + (eval)0.6s: train loss = 0.04907 = (mf)0.02096 + (embed)0.02811, recall = 0.01199, ndcg = 0.19716\n",
            "Epoch 46 (train)2.3s: train loss = 0.04880 = (mf)0.02075 + (embed)0.02805\n",
            "Epoch 47 (train)2.3s: train loss = 0.04818 = (mf)0.02013 + (embed)0.02805\n",
            "Epoch 48 (train)2.5s: train loss = 0.04667 = (mf)0.01864 + (embed)0.02802\n",
            "Epoch 49 (train)2.6s: train loss = 0.04770 = (mf)0.01964 + (embed)0.02805\n",
            "Epoch 50 (train)2.4s + (eval)0.3s: train loss = 0.04685 = (mf)0.01879 + (embed)0.02806, recall = 0.01190, ndcg = 0.21903\n",
            "Epoch 51 (train)2.3s: train loss = 0.04682 = (mf)0.01875 + (embed)0.02807\n",
            "Epoch 52 (train)2.3s: train loss = 0.04868 = (mf)0.02053 + (embed)0.02815\n",
            "Epoch 53 (train)2.8s: train loss = 0.04779 = (mf)0.01959 + (embed)0.02821\n",
            "Epoch 54 (train)2.4s: train loss = 0.04786 = (mf)0.01961 + (embed)0.02824\n",
            "Epoch 55 (train)2.3s + (eval)0.2s: train loss = 0.04845 = (mf)0.02024 + (embed)0.02820, recall = 0.01054, ndcg = 0.16229\n",
            "Epoch 56 (train)2.3s: train loss = 0.04801 = (mf)0.01976 + (embed)0.02825\n",
            "Epoch 57 (train)2.3s: train loss = 0.04779 = (mf)0.01948 + (embed)0.02831\n",
            "Epoch 58 (train)2.8s: train loss = 0.04808 = (mf)0.01988 + (embed)0.02820\n",
            "Epoch 59 (train)2.4s: train loss = 0.04802 = (mf)0.01992 + (embed)0.02811\n",
            "Epoch 60 (train)2.3s + (eval)0.6s: train loss = 0.04964 = (mf)0.02139 + (embed)0.02824, recall = 0.01368, ndcg = 0.20081\n",
            "Epoch 61 (train)2.3s: train loss = 0.04765 = (mf)0.01935 + (embed)0.02830\n",
            "Epoch 62 (train)2.5s: train loss = 0.04701 = (mf)0.01882 + (embed)0.02820\n",
            "Epoch 63 (train)2.8s: train loss = 0.04715 = (mf)0.01889 + (embed)0.02827\n",
            "Epoch 64 (train)2.3s: train loss = 0.04874 = (mf)0.02043 + (embed)0.02831\n",
            "Epoch 65 (train)2.4s + (eval)0.2s: train loss = 0.04899 = (mf)0.02058 + (embed)0.02841, recall = 0.01094, ndcg = 0.19248\n",
            "Epoch 66 (train)2.3s: train loss = 0.04726 = (mf)0.01884 + (embed)0.02842\n",
            "Epoch 67 (train)2.6s: train loss = 0.04856 = (mf)0.02017 + (embed)0.02839\n",
            "Epoch 68 (train)2.6s: train loss = 0.04832 = (mf)0.01993 + (embed)0.02839\n",
            "Epoch 69 (train)2.3s: train loss = 0.04892 = (mf)0.02051 + (embed)0.02840\n",
            "Epoch 70 (train)2.3s + (eval)0.2s: train loss = 0.04839 = (mf)0.01996 + (embed)0.02843, recall = 0.01200, ndcg = 0.20784\n",
            "Epoch 71 (train)2.3s: train loss = 0.04708 = (mf)0.01864 + (embed)0.02844\n",
            "Epoch 72 (train)2.8s: train loss = 0.04835 = (mf)0.01995 + (embed)0.02840\n",
            "Epoch 73 (train)2.4s: train loss = 0.04807 = (mf)0.01966 + (embed)0.02841\n",
            "Epoch 74 (train)2.3s: train loss = 0.04786 = (mf)0.01941 + (embed)0.02845\n",
            "Epoch 75 (train)2.3s + (eval)0.2s: train loss = 0.04814 = (mf)0.01978 + (embed)0.02836, recall = 0.01330, ndcg = 0.20040\n",
            "Epoch 76 (train)2.3s: train loss = 0.04754 = (mf)0.01916 + (embed)0.02837\n",
            "Epoch 77 (train)2.9s: train loss = 0.04812 = (mf)0.01970 + (embed)0.02842\n",
            "Epoch 78 (train)2.4s: train loss = 0.04791 = (mf)0.01946 + (embed)0.02846\n",
            "Epoch 79 (train)2.3s: train loss = 0.04784 = (mf)0.01937 + (embed)0.02847\n",
            "Epoch 80 (train)2.3s + (eval)0.6s: train loss = 0.04779 = (mf)0.01930 + (embed)0.02849, recall = 0.01190, ndcg = 0.19945\n",
            "Epoch 81 (train)2.5s: train loss = 0.04876 = (mf)0.02026 + (embed)0.02849\n",
            "Epoch 82 (train)2.7s: train loss = 0.04867 = (mf)0.02009 + (embed)0.02859\n",
            "Epoch 83 (train)2.4s: train loss = 0.04810 = (mf)0.01951 + (embed)0.02859\n",
            "Epoch 84 (train)2.4s: train loss = 0.04772 = (mf)0.01928 + (embed)0.02844\n",
            "Epoch 85 (train)2.4s + (eval)0.2s: train loss = 0.04805 = (mf)0.01952 + (embed)0.02853, recall = 0.01226, ndcg = 0.21008\n",
            "Epoch 86 (train)2.8s: train loss = 0.04876 = (mf)0.02027 + (embed)0.02849\n",
            "Epoch 87 (train)2.5s: train loss = 0.04798 = (mf)0.01945 + (embed)0.02852\n",
            "Epoch 88 (train)2.3s: train loss = 0.04664 = (mf)0.01818 + (embed)0.02846\n",
            "Epoch 89 (train)2.4s: train loss = 0.04730 = (mf)0.01894 + (embed)0.02836\n",
            "Epoch 90 (train)2.4s + (eval)0.2s: train loss = 0.04786 = (mf)0.01949 + (embed)0.02837, recall = 0.01176, ndcg = 0.19568\n",
            "Epoch 91 (train)2.9s: train loss = 0.04755 = (mf)0.01916 + (embed)0.02838\n",
            "Epoch 92 (train)2.4s: train loss = 0.04684 = (mf)0.01854 + (embed)0.02830\n",
            "Epoch 93 (train)2.3s: train loss = 0.04738 = (mf)0.01912 + (embed)0.02826\n",
            "Epoch 94 (train)2.3s: train loss = 0.04777 = (mf)0.01957 + (embed)0.02820\n",
            "Epoch 95 (train)2.3s + (eval)0.8s: train loss = 0.04821 = (mf)0.01999 + (embed)0.02822, recall = 0.01057, ndcg = 0.16949\n",
            "Epoch 96 (train)2.8s: train loss = 0.04765 = (mf)0.01924 + (embed)0.02841\n",
            "Epoch 97 (train)2.4s: train loss = 0.04803 = (mf)0.01957 + (embed)0.02846\n",
            "Epoch 98 (train)2.4s: train loss = 0.04849 = (mf)0.02002 + (embed)0.02847\n",
            "Epoch 99 (train)2.4s: train loss = 0.04731 = (mf)0.01887 + (embed)0.02844\n",
            "Epoch 100 (train)3.3s + (eval)0.4s: train loss = 0.04644 = (mf)0.01810 + (embed)0.02833, recall = 0.01175, ndcg = 0.19209\n",
            "Training finished in 257.19 seconds.\n",
            "Evaluation results for this combination: NDCG@10: 0.19209, Recall@10: 0.01175\n",
            "--- Trying combination: Epochs=100, TopK=10, LearningRate=0.05, Layers=4 ---\n",
            "Already normalize adjacency matrix (extended).\n",
            "Using xavier initialization for user, item, and genre embeddings.\n",
            "Epoch 1 (train)4.2s: train loss = 0.16474 = (mf)0.16130 + (embed)0.00344\n",
            "Epoch 2 (train)2.7s: train loss = 0.08289 = (mf)0.07472 + (embed)0.00817\n",
            "Epoch 3 (train)2.4s: train loss = 0.06230 = (mf)0.05050 + (embed)0.01180\n",
            "Epoch 4 (train)2.3s: train loss = 0.05363 = (mf)0.03935 + (embed)0.01428\n",
            "Epoch 5 (train)2.3s + (eval)1.5s: train loss = 0.04900 = (mf)0.03291 + (embed)0.01609, recall = 0.01669, ndcg = 0.27473\n",
            "Epoch 6 (train)3.0s: train loss = 0.04589 = (mf)0.02845 + (embed)0.01743\n",
            "Epoch 7 (train)2.4s: train loss = 0.04482 = (mf)0.02642 + (embed)0.01840\n",
            "Epoch 8 (train)2.4s: train loss = 0.04340 = (mf)0.02418 + (embed)0.01922\n",
            "Epoch 9 (train)2.3s: train loss = 0.04299 = (mf)0.02310 + (embed)0.01989\n",
            "Epoch 10 (train)2.7s + (eval)0.4s: train loss = 0.04310 = (mf)0.02258 + (embed)0.02052, recall = 0.01471, ndcg = 0.25751\n",
            "Epoch 11 (train)2.5s: train loss = 0.04230 = (mf)0.02125 + (embed)0.02105\n",
            "Epoch 12 (train)2.4s: train loss = 0.04226 = (mf)0.02075 + (embed)0.02152\n",
            "Epoch 13 (train)2.4s: train loss = 0.04180 = (mf)0.01998 + (embed)0.02182\n",
            "Epoch 14 (train)2.4s: train loss = 0.04146 = (mf)0.01935 + (embed)0.02211\n",
            "Epoch 15 (train)2.9s + (eval)0.3s: train loss = 0.04074 = (mf)0.01838 + (embed)0.02235, recall = 0.01477, ndcg = 0.25831\n",
            "Epoch 16 (train)2.4s: train loss = 0.04053 = (mf)0.01798 + (embed)0.02256\n",
            "Epoch 17 (train)2.4s: train loss = 0.04100 = (mf)0.01817 + (embed)0.02283\n",
            "Epoch 18 (train)2.4s: train loss = 0.04130 = (mf)0.01819 + (embed)0.02311\n",
            "Epoch 19 (train)2.4s: train loss = 0.04157 = (mf)0.01823 + (embed)0.02334\n",
            "Epoch 20 (train)2.9s + (eval)0.6s: train loss = 0.04128 = (mf)0.01767 + (embed)0.02361, recall = 0.01596, ndcg = 0.24791\n",
            "Epoch 21 (train)2.4s: train loss = 0.04080 = (mf)0.01709 + (embed)0.02370\n",
            "Epoch 22 (train)2.4s: train loss = 0.04080 = (mf)0.01701 + (embed)0.02379\n",
            "Epoch 23 (train)2.4s: train loss = 0.04038 = (mf)0.01651 + (embed)0.02387\n",
            "Epoch 24 (train)2.7s: train loss = 0.04064 = (mf)0.01668 + (embed)0.02396\n",
            "Epoch 25 (train)2.6s + (eval)0.2s: train loss = 0.04084 = (mf)0.01678 + (embed)0.02406, recall = 0.01473, ndcg = 0.23938\n",
            "Epoch 26 (train)2.4s: train loss = 0.04118 = (mf)0.01701 + (embed)0.02416\n",
            "Epoch 27 (train)2.4s: train loss = 0.04051 = (mf)0.01614 + (embed)0.02438\n",
            "Epoch 28 (train)2.3s: train loss = 0.04028 = (mf)0.01580 + (embed)0.02448\n",
            "Epoch 29 (train)2.9s: train loss = 0.04110 = (mf)0.01652 + (embed)0.02458\n",
            "Epoch 30 (train)2.4s + (eval)0.2s: train loss = 0.04144 = (mf)0.01683 + (embed)0.02461, recall = 0.01555, ndcg = 0.25854\n",
            "Epoch 31 (train)2.3s: train loss = 0.04021 = (mf)0.01559 + (embed)0.02463\n",
            "Epoch 32 (train)2.4s: train loss = 0.04149 = (mf)0.01682 + (embed)0.02467\n",
            "Epoch 33 (train)2.4s: train loss = 0.04079 = (mf)0.01593 + (embed)0.02487\n",
            "Epoch 34 (train)2.9s: train loss = 0.04057 = (mf)0.01570 + (embed)0.02487\n",
            "Epoch 35 (train)2.4s + (eval)0.2s: train loss = 0.04083 = (mf)0.01600 + (embed)0.02483, recall = 0.01410, ndcg = 0.23368\n",
            "Epoch 36 (train)2.4s: train loss = 0.04124 = (mf)0.01623 + (embed)0.02501\n",
            "Epoch 37 (train)2.3s: train loss = 0.03945 = (mf)0.01444 + (embed)0.02501\n",
            "Epoch 38 (train)2.6s: train loss = 0.03988 = (mf)0.01496 + (embed)0.02492\n",
            "Epoch 39 (train)2.7s: train loss = 0.04038 = (mf)0.01541 + (embed)0.02497\n",
            "Epoch 40 (train)2.4s + (eval)0.6s: train loss = 0.04054 = (mf)0.01553 + (embed)0.02501, recall = 0.01475, ndcg = 0.24244\n",
            "Epoch 41 (train)2.4s: train loss = 0.04084 = (mf)0.01588 + (embed)0.02496\n",
            "Epoch 42 (train)2.4s: train loss = 0.03969 = (mf)0.01473 + (embed)0.02495\n",
            "Epoch 43 (train)3.0s: train loss = 0.03983 = (mf)0.01498 + (embed)0.02485\n",
            "Epoch 44 (train)2.4s: train loss = 0.04045 = (mf)0.01551 + (embed)0.02494\n",
            "Epoch 45 (train)2.3s + (eval)0.2s: train loss = 0.03997 = (mf)0.01498 + (embed)0.02499, recall = 0.01224, ndcg = 0.22734\n",
            "Epoch 46 (train)2.5s: train loss = 0.04011 = (mf)0.01509 + (embed)0.02502\n",
            "Epoch 47 (train)2.5s: train loss = 0.04034 = (mf)0.01537 + (embed)0.02496\n",
            "Epoch 48 (train)2.8s: train loss = 0.03980 = (mf)0.01480 + (embed)0.02500\n",
            "Epoch 49 (train)2.4s: train loss = 0.04032 = (mf)0.01526 + (embed)0.02506\n",
            "Epoch 50 (train)2.4s + (eval)0.2s: train loss = 0.04036 = (mf)0.01526 + (embed)0.02509, recall = 0.01399, ndcg = 0.22624\n",
            "Epoch 51 (train)2.3s: train loss = 0.03976 = (mf)0.01464 + (embed)0.02512\n",
            "Epoch 52 (train)2.6s: train loss = 0.04021 = (mf)0.01507 + (embed)0.02514\n",
            "Epoch 53 (train)2.6s: train loss = 0.03992 = (mf)0.01486 + (embed)0.02507\n",
            "Epoch 54 (train)2.4s: train loss = 0.04021 = (mf)0.01517 + (embed)0.02504\n",
            "Epoch 55 (train)2.3s + (eval)0.6s: train loss = 0.04118 = (mf)0.01605 + (embed)0.02513, recall = 0.01495, ndcg = 0.24310\n",
            "Epoch 56 (train)2.4s: train loss = 0.04030 = (mf)0.01516 + (embed)0.02514\n",
            "Epoch 57 (train)2.8s: train loss = 0.04045 = (mf)0.01542 + (embed)0.02503\n",
            "Epoch 58 (train)2.4s: train loss = 0.04005 = (mf)0.01496 + (embed)0.02508\n",
            "Epoch 59 (train)2.3s: train loss = 0.04017 = (mf)0.01514 + (embed)0.02503\n",
            "Epoch 60 (train)2.3s + (eval)0.2s: train loss = 0.04036 = (mf)0.01529 + (embed)0.02508, recall = 0.01462, ndcg = 0.24670\n",
            "Epoch 61 (train)2.4s: train loss = 0.04117 = (mf)0.01605 + (embed)0.02513\n",
            "Epoch 62 (train)2.9s: train loss = 0.03998 = (mf)0.01478 + (embed)0.02520\n",
            "Epoch 63 (train)2.3s: train loss = 0.04075 = (mf)0.01555 + (embed)0.02520\n",
            "Epoch 64 (train)2.4s: train loss = 0.04034 = (mf)0.01511 + (embed)0.02524\n",
            "Epoch 65 (train)2.3s + (eval)0.2s: train loss = 0.04125 = (mf)0.01587 + (embed)0.02537, recall = 0.01200, ndcg = 0.22287\n",
            "Epoch 66 (train)2.6s: train loss = 0.04029 = (mf)0.01500 + (embed)0.02529\n",
            "Epoch 67 (train)2.7s: train loss = 0.04002 = (mf)0.01474 + (embed)0.02529\n",
            "Epoch 68 (train)2.3s: train loss = 0.04113 = (mf)0.01586 + (embed)0.02528\n",
            "Epoch 69 (train)2.3s: train loss = 0.03993 = (mf)0.01461 + (embed)0.02531\n",
            "Epoch 70 (train)2.3s + (eval)0.6s: train loss = 0.03999 = (mf)0.01478 + (embed)0.02521, recall = 0.01511, ndcg = 0.26545\n",
            "Epoch 71 (train)2.9s: train loss = 0.03972 = (mf)0.01454 + (embed)0.02518\n",
            "Epoch 72 (train)2.4s: train loss = 0.04002 = (mf)0.01485 + (embed)0.02516\n",
            "Epoch 73 (train)2.4s: train loss = 0.03933 = (mf)0.01428 + (embed)0.02505\n",
            "Epoch 74 (train)2.3s: train loss = 0.03965 = (mf)0.01469 + (embed)0.02496\n",
            "Epoch 75 (train)2.3s + (eval)0.2s: train loss = 0.03920 = (mf)0.01426 + (embed)0.02494, recall = 0.01326, ndcg = 0.22840\n",
            "Epoch 76 (train)2.9s: train loss = 0.04031 = (mf)0.01532 + (embed)0.02499\n",
            "Epoch 77 (train)2.4s: train loss = 0.03972 = (mf)0.01464 + (embed)0.02508\n",
            "Epoch 78 (train)2.3s: train loss = 0.04010 = (mf)0.01499 + (embed)0.02511\n",
            "Epoch 79 (train)2.4s: train loss = 0.03937 = (mf)0.01422 + (embed)0.02515\n",
            "Epoch 80 (train)2.4s + (eval)0.4s: train loss = 0.04030 = (mf)0.01513 + (embed)0.02517, recall = 0.01297, ndcg = 0.23428\n",
            "Epoch 81 (train)2.7s: train loss = 0.03955 = (mf)0.01425 + (embed)0.02529\n",
            "Epoch 82 (train)2.4s: train loss = 0.03964 = (mf)0.01445 + (embed)0.02519\n",
            "Epoch 83 (train)2.3s: train loss = 0.04040 = (mf)0.01517 + (embed)0.02522\n",
            "Epoch 84 (train)2.3s: train loss = 0.04096 = (mf)0.01572 + (embed)0.02524\n",
            "Epoch 85 (train)2.6s + (eval)0.4s: train loss = 0.04050 = (mf)0.01523 + (embed)0.02527, recall = 0.01286, ndcg = 0.20829\n",
            "Epoch 86 (train)2.5s: train loss = 0.04057 = (mf)0.01527 + (embed)0.02531\n",
            "Epoch 87 (train)2.4s: train loss = 0.03980 = (mf)0.01459 + (embed)0.02520\n",
            "Epoch 88 (train)2.3s: train loss = 0.03972 = (mf)0.01459 + (embed)0.02514\n",
            "Epoch 89 (train)2.3s: train loss = 0.04018 = (mf)0.01501 + (embed)0.02517\n",
            "Epoch 90 (train)2.9s + (eval)0.6s: train loss = 0.04048 = (mf)0.01524 + (embed)0.02524, recall = 0.01278, ndcg = 0.20847\n",
            "Epoch 91 (train)2.6s: train loss = 0.04015 = (mf)0.01493 + (embed)0.02522\n",
            "Epoch 92 (train)2.8s: train loss = 0.04000 = (mf)0.01478 + (embed)0.02522\n",
            "Epoch 93 (train)2.3s: train loss = 0.03928 = (mf)0.01409 + (embed)0.02519\n",
            "Epoch 94 (train)2.6s: train loss = 0.03956 = (mf)0.01441 + (embed)0.02515\n",
            "Epoch 95 (train)2.6s + (eval)0.2s: train loss = 0.04027 = (mf)0.01516 + (embed)0.02511, recall = 0.01405, ndcg = 0.25519\n",
            "Epoch 96 (train)2.4s: train loss = 0.04024 = (mf)0.01509 + (embed)0.02514\n",
            "Epoch 97 (train)2.3s: train loss = 0.03994 = (mf)0.01473 + (embed)0.02521\n",
            "Epoch 98 (train)2.4s: train loss = 0.04008 = (mf)0.01485 + (embed)0.02523\n",
            "Epoch 99 (train)2.9s: train loss = 0.03988 = (mf)0.01473 + (embed)0.02514\n",
            "Epoch 100 (train)2.4s + (eval)0.3s: train loss = 0.03944 = (mf)0.01428 + (embed)0.02516, recall = 0.01541, ndcg = 0.23508\n",
            "Training finished in 258.56 seconds.\n",
            "Evaluation results for this combination: NDCG@10: 0.23508, Recall@10: 0.01541\n",
            "--- Trying combination: Epochs=100, TopK=10, LearningRate=0.05, Layers=5 ---\n",
            "Already normalize adjacency matrix (extended).\n",
            "Using xavier initialization for user, item, and genre embeddings.\n",
            "Epoch 1 (train)4.3s: train loss = 0.18325 = (mf)0.17964 + (embed)0.00360\n",
            "Epoch 2 (train)2.4s: train loss = 0.09562 = (mf)0.08657 + (embed)0.00905\n",
            "Epoch 3 (train)2.4s: train loss = 0.07060 = (mf)0.05762 + (embed)0.01299\n",
            "Epoch 4 (train)2.5s: train loss = 0.06146 = (mf)0.04584 + (embed)0.01562\n",
            "Epoch 5 (train)2.9s + (eval)1.0s: train loss = 0.05618 = (mf)0.03873 + (embed)0.01745, recall = 0.01526, ndcg = 0.27344\n",
            "Epoch 6 (train)2.4s: train loss = 0.05237 = (mf)0.03353 + (embed)0.01884\n",
            "Epoch 7 (train)2.4s: train loss = 0.04960 = (mf)0.02978 + (embed)0.01982\n",
            "Epoch 8 (train)2.4s: train loss = 0.04767 = (mf)0.02710 + (embed)0.02056\n",
            "Epoch 9 (train)2.9s: train loss = 0.04653 = (mf)0.02530 + (embed)0.02123\n",
            "Epoch 10 (train)2.5s + (eval)0.2s: train loss = 0.04623 = (mf)0.02446 + (embed)0.02177, recall = 0.01562, ndcg = 0.26693\n",
            "Epoch 11 (train)2.4s: train loss = 0.04508 = (mf)0.02277 + (embed)0.02231\n",
            "Epoch 12 (train)2.4s: train loss = 0.04434 = (mf)0.02156 + (embed)0.02278\n",
            "Epoch 13 (train)2.5s: train loss = 0.04304 = (mf)0.02000 + (embed)0.02303\n",
            "Epoch 14 (train)2.8s: train loss = 0.04360 = (mf)0.02024 + (embed)0.02336\n",
            "Epoch 15 (train)2.4s + (eval)0.6s: train loss = 0.04299 = (mf)0.01933 + (embed)0.02366, recall = 0.01658, ndcg = 0.27857\n",
            "Epoch 16 (train)2.4s: train loss = 0.04228 = (mf)0.01841 + (embed)0.02387\n",
            "Epoch 17 (train)2.4s: train loss = 0.04233 = (mf)0.01831 + (embed)0.02402\n",
            "Epoch 18 (train)3.0s: train loss = 0.04222 = (mf)0.01802 + (embed)0.02420\n",
            "Epoch 19 (train)2.4s: train loss = 0.04171 = (mf)0.01731 + (embed)0.02440\n",
            "Epoch 20 (train)2.4s + (eval)0.2s: train loss = 0.04149 = (mf)0.01693 + (embed)0.02456, recall = 0.01555, ndcg = 0.26016\n",
            "Epoch 21 (train)2.4s: train loss = 0.04146 = (mf)0.01674 + (embed)0.02472\n",
            "Epoch 22 (train)2.6s: train loss = 0.04157 = (mf)0.01680 + (embed)0.02477\n",
            "Epoch 23 (train)3.0s: train loss = 0.04231 = (mf)0.01734 + (embed)0.02498\n",
            "Epoch 24 (train)2.5s: train loss = 0.04205 = (mf)0.01702 + (embed)0.02503\n",
            "Epoch 25 (train)2.4s + (eval)0.3s: train loss = 0.04151 = (mf)0.01631 + (embed)0.02520, recall = 0.01518, ndcg = 0.28091\n",
            "Epoch 26 (train)2.4s: train loss = 0.04190 = (mf)0.01652 + (embed)0.02538\n",
            "Epoch 27 (train)2.9s: train loss = 0.04087 = (mf)0.01544 + (embed)0.02543\n",
            "Epoch 28 (train)2.5s: train loss = 0.04100 = (mf)0.01560 + (embed)0.02540\n",
            "Epoch 29 (train)2.4s: train loss = 0.04128 = (mf)0.01594 + (embed)0.02534\n",
            "Epoch 30 (train)2.4s + (eval)0.2s: train loss = 0.04121 = (mf)0.01587 + (embed)0.02534, recall = 0.01601, ndcg = 0.27777\n",
            "Epoch 31 (train)2.4s: train loss = 0.04151 = (mf)0.01606 + (embed)0.02545\n",
            "Epoch 32 (train)2.9s: train loss = 0.04136 = (mf)0.01582 + (embed)0.02554\n",
            "Epoch 33 (train)2.4s: train loss = 0.04150 = (mf)0.01592 + (embed)0.02557\n",
            "Epoch 34 (train)2.4s: train loss = 0.04121 = (mf)0.01560 + (embed)0.02561\n",
            "Epoch 35 (train)2.4s + (eval)0.6s: train loss = 0.04113 = (mf)0.01541 + (embed)0.02571, recall = 0.01713, ndcg = 0.29398\n",
            "Epoch 36 (train)2.9s: train loss = 0.04150 = (mf)0.01582 + (embed)0.02568\n",
            "Epoch 37 (train)2.5s: train loss = 0.04158 = (mf)0.01584 + (embed)0.02574\n",
            "Epoch 38 (train)2.4s: train loss = 0.04175 = (mf)0.01595 + (embed)0.02580\n",
            "Epoch 39 (train)2.4s: train loss = 0.04170 = (mf)0.01580 + (embed)0.02589\n",
            "Epoch 40 (train)2.4s + (eval)0.2s: train loss = 0.04149 = (mf)0.01548 + (embed)0.02600, recall = 0.01636, ndcg = 0.28035\n",
            "Epoch 41 (train)3.0s: train loss = 0.04113 = (mf)0.01514 + (embed)0.02599\n",
            "Epoch 42 (train)2.4s: train loss = 0.04089 = (mf)0.01500 + (embed)0.02589\n",
            "Epoch 43 (train)2.4s: train loss = 0.04092 = (mf)0.01505 + (embed)0.02586\n",
            "Epoch 44 (train)2.4s: train loss = 0.04091 = (mf)0.01519 + (embed)0.02573\n",
            "Epoch 45 (train)2.7s + (eval)0.4s: train loss = 0.04042 = (mf)0.01464 + (embed)0.02578, recall = 0.01460, ndcg = 0.26754\n",
            "Epoch 46 (train)2.6s: train loss = 0.04129 = (mf)0.01550 + (embed)0.02579\n",
            "Epoch 47 (train)2.4s: train loss = 0.04072 = (mf)0.01492 + (embed)0.02580\n",
            "Epoch 48 (train)2.4s: train loss = 0.04163 = (mf)0.01572 + (embed)0.02591\n",
            "Epoch 49 (train)2.4s: train loss = 0.04083 = (mf)0.01490 + (embed)0.02593\n",
            "Epoch 50 (train)2.9s + (eval)0.6s: train loss = 0.04135 = (mf)0.01542 + (embed)0.02593, recall = 0.01400, ndcg = 0.24399\n",
            "Epoch 51 (train)2.4s: train loss = 0.04113 = (mf)0.01513 + (embed)0.02600\n",
            "Epoch 52 (train)2.4s: train loss = 0.04128 = (mf)0.01530 + (embed)0.02598\n",
            "Epoch 53 (train)2.4s: train loss = 0.04079 = (mf)0.01475 + (embed)0.02605\n",
            "Epoch 54 (train)2.6s: train loss = 0.04079 = (mf)0.01493 + (embed)0.02586\n",
            "Epoch 55 (train)2.8s + (eval)0.2s: train loss = 0.04067 = (mf)0.01480 + (embed)0.02587, recall = 0.01497, ndcg = 0.25545\n",
            "Epoch 56 (train)2.4s: train loss = 0.04092 = (mf)0.01506 + (embed)0.02586\n",
            "Epoch 57 (train)2.4s: train loss = 0.04140 = (mf)0.01545 + (embed)0.02595\n",
            "Epoch 58 (train)2.5s: train loss = 0.04106 = (mf)0.01503 + (embed)0.02604\n",
            "Epoch 59 (train)2.9s: train loss = 0.04098 = (mf)0.01496 + (embed)0.02601\n",
            "Epoch 60 (train)2.5s + (eval)0.2s: train loss = 0.04046 = (mf)0.01459 + (embed)0.02587, recall = 0.01567, ndcg = 0.24683\n",
            "Epoch 61 (train)2.4s: train loss = 0.04055 = (mf)0.01472 + (embed)0.02582\n",
            "Epoch 62 (train)2.4s: train loss = 0.04072 = (mf)0.01485 + (embed)0.02586\n",
            "Epoch 63 (train)2.4s: train loss = 0.04056 = (mf)0.01479 + (embed)0.02577\n",
            "Epoch 64 (train)3.0s: train loss = 0.04083 = (mf)0.01502 + (embed)0.02581\n",
            "Epoch 65 (train)2.5s + (eval)0.6s: train loss = 0.04046 = (mf)0.01459 + (embed)0.02588, recall = 0.01514, ndcg = 0.24484\n",
            "Epoch 66 (train)2.4s: train loss = 0.04026 = (mf)0.01446 + (embed)0.02580\n",
            "Epoch 67 (train)2.4s: train loss = 0.03979 = (mf)0.01399 + (embed)0.02580\n",
            "Epoch 68 (train)3.0s: train loss = 0.04045 = (mf)0.01462 + (embed)0.02583\n",
            "Epoch 69 (train)2.5s: train loss = 0.04009 = (mf)0.01426 + (embed)0.02583\n",
            "Epoch 70 (train)2.4s + (eval)0.3s: train loss = 0.04077 = (mf)0.01496 + (embed)0.02580, recall = 0.01467, ndcg = 0.23505\n",
            "Epoch 71 (train)2.4s: train loss = 0.04031 = (mf)0.01443 + (embed)0.02588\n",
            "Epoch 72 (train)2.5s: train loss = 0.04037 = (mf)0.01455 + (embed)0.02582\n",
            "Epoch 73 (train)2.9s: train loss = 0.03993 = (mf)0.01413 + (embed)0.02580\n",
            "Epoch 74 (train)2.4s: train loss = 0.04025 = (mf)0.01443 + (embed)0.02582\n",
            "Epoch 75 (train)2.4s + (eval)0.2s: train loss = 0.04101 = (mf)0.01522 + (embed)0.02579, recall = 0.01507, ndcg = 0.26196\n",
            "Epoch 76 (train)2.4s: train loss = 0.04124 = (mf)0.01535 + (embed)0.02589\n",
            "Epoch 77 (train)2.8s: train loss = 0.04139 = (mf)0.01534 + (embed)0.02606\n",
            "Epoch 78 (train)2.5s: train loss = 0.04127 = (mf)0.01514 + (embed)0.02613\n",
            "Epoch 79 (train)2.4s: train loss = 0.04093 = (mf)0.01476 + (embed)0.02617\n",
            "Epoch 80 (train)2.4s + (eval)0.6s: train loss = 0.04127 = (mf)0.01518 + (embed)0.02609, recall = 0.01642, ndcg = 0.26186\n",
            "Epoch 81 (train)2.8s: train loss = 0.04160 = (mf)0.01543 + (embed)0.02617\n",
            "Epoch 82 (train)3.3s: train loss = 0.04079 = (mf)0.01467 + (embed)0.02612\n",
            "Epoch 83 (train)2.4s: train loss = 0.04060 = (mf)0.01451 + (embed)0.02609\n",
            "Epoch 84 (train)2.4s: train loss = 0.04042 = (mf)0.01448 + (embed)0.02595\n",
            "Epoch 85 (train)2.4s + (eval)0.2s: train loss = 0.04060 = (mf)0.01469 + (embed)0.02590, recall = 0.01622, ndcg = 0.26495\n",
            "Epoch 86 (train)2.7s: train loss = 0.04057 = (mf)0.01465 + (embed)0.02592\n",
            "Epoch 87 (train)2.6s: train loss = 0.04028 = (mf)0.01436 + (embed)0.02591\n",
            "Epoch 88 (train)2.4s: train loss = 0.03963 = (mf)0.01385 + (embed)0.02579\n",
            "Epoch 89 (train)2.4s: train loss = 0.03957 = (mf)0.01395 + (embed)0.02561\n",
            "Epoch 90 (train)2.4s + (eval)0.2s: train loss = 0.04046 = (mf)0.01480 + (embed)0.02566, recall = 0.01618, ndcg = 0.24101\n",
            "Epoch 91 (train)2.9s: train loss = 0.04000 = (mf)0.01432 + (embed)0.02568\n",
            "Epoch 92 (train)2.4s: train loss = 0.03962 = (mf)0.01389 + (embed)0.02573\n",
            "Epoch 93 (train)2.4s: train loss = 0.04045 = (mf)0.01473 + (embed)0.02572\n",
            "Epoch 94 (train)2.4s: train loss = 0.04099 = (mf)0.01520 + (embed)0.02580\n",
            "Epoch 95 (train)2.5s + (eval)0.8s: train loss = 0.04087 = (mf)0.01497 + (embed)0.02591, recall = 0.01588, ndcg = 0.27164\n",
            "Epoch 96 (train)2.6s: train loss = 0.04091 = (mf)0.01501 + (embed)0.02590\n",
            "Epoch 97 (train)2.4s: train loss = 0.04077 = (mf)0.01476 + (embed)0.02600\n",
            "Epoch 98 (train)2.5s: train loss = 0.04106 = (mf)0.01504 + (embed)0.02602\n",
            "Epoch 99 (train)2.4s: train loss = 0.04026 = (mf)0.01421 + (embed)0.02606\n",
            "Epoch 100 (train)2.9s + (eval)0.2s: train loss = 0.04016 = (mf)0.01429 + (embed)0.02586, recall = 0.01547, ndcg = 0.26240\n",
            "Training finished in 265.00 seconds.\n",
            "Evaluation results for this combination: NDCG@10: 0.26240, Recall@10: 0.01547\n",
            "--- Trying combination: Epochs=100, TopK=10, LearningRate=0.5, Layers=3 ---\n",
            "Already normalize adjacency matrix (extended).\n",
            "Using xavier initialization for user, item, and genre embeddings.\n",
            "Epoch 1 (train)4.3s: train loss = 1.01408 = (mf)0.83897 + (embed)0.17511\n",
            "Epoch 2 (train)2.4s: train loss = 2.01575 = (mf)1.51967 + (embed)0.49608\n",
            "Epoch 3 (train)2.3s: train loss = 2.63032 = (mf)1.88069 + (embed)0.74963\n",
            "Epoch 4 (train)2.3s: train loss = 3.08329 = (mf)2.12526 + (embed)0.95803\n",
            "Epoch 5 (train)2.3s + (eval)1.2s: train loss = 3.42999 = (mf)2.29625 + (embed)1.13374, recall = 0.00771, ndcg = 0.13819\n",
            "Epoch 6 (train)2.7s: train loss = 3.72850 = (mf)2.44297 + (embed)1.28553\n",
            "Epoch 7 (train)2.4s: train loss = 3.93887 = (mf)2.52429 + (embed)1.41458\n",
            "Epoch 8 (train)2.4s: train loss = 4.06934 = (mf)2.54506 + (embed)1.52428\n",
            "Epoch 9 (train)2.4s: train loss = 4.20249 = (mf)2.58504 + (embed)1.61745\n",
            "Epoch 10 (train)2.8s + (eval)0.7s: train loss = 4.47756 = (mf)2.76580 + (embed)1.71175, recall = 0.00881, ndcg = 0.15035\n",
            "Epoch 11 (train)2.4s: train loss = 4.34001 = (mf)2.53961 + (embed)1.80040\n",
            "Epoch 12 (train)2.3s: train loss = 4.47086 = (mf)2.60150 + (embed)1.86936\n",
            "Epoch 13 (train)2.3s: train loss = 4.46423 = (mf)2.52748 + (embed)1.93675\n",
            "Epoch 14 (train)2.3s: train loss = 4.59123 = (mf)2.59640 + (embed)1.99484\n",
            "Epoch 15 (train)2.8s + (eval)0.2s: train loss = 4.50272 = (mf)2.46141 + (embed)2.04131, recall = 0.00852, ndcg = 0.17404\n",
            "Epoch 16 (train)2.3s: train loss = 4.67240 = (mf)2.59006 + (embed)2.08234\n",
            "Epoch 17 (train)2.3s: train loss = 4.64360 = (mf)2.50781 + (embed)2.13579\n",
            "Epoch 18 (train)2.3s: train loss = 4.69634 = (mf)2.51424 + (embed)2.18210\n",
            "Epoch 19 (train)2.4s: train loss = 4.76075 = (mf)2.53921 + (embed)2.22154\n",
            "Epoch 20 (train)2.8s + (eval)0.2s: train loss = 4.84021 = (mf)2.58620 + (embed)2.25400, recall = 0.00899, ndcg = 0.15095\n",
            "Epoch 21 (train)2.3s: train loss = 4.68193 = (mf)2.39082 + (embed)2.29111\n",
            "Epoch 22 (train)2.3s: train loss = 4.73771 = (mf)2.41610 + (embed)2.32160\n",
            "Epoch 23 (train)2.3s: train loss = 4.92788 = (mf)2.57158 + (embed)2.35630\n",
            "Epoch 24 (train)2.6s: train loss = 4.79370 = (mf)2.40597 + (embed)2.38773\n",
            "Epoch 25 (train)2.6s + (eval)0.6s: train loss = 4.91146 = (mf)2.50796 + (embed)2.40350, recall = 0.00848, ndcg = 0.17184\n",
            "Epoch 26 (train)2.4s: train loss = 4.83226 = (mf)2.40408 + (embed)2.42818\n",
            "Epoch 27 (train)2.3s: train loss = 4.92290 = (mf)2.47011 + (embed)2.45279\n",
            "Epoch 28 (train)2.3s: train loss = 4.86701 = (mf)2.38940 + (embed)2.47760\n",
            "Epoch 29 (train)2.8s: train loss = 4.94850 = (mf)2.44665 + (embed)2.50185\n",
            "Epoch 30 (train)2.4s + (eval)0.2s: train loss = 4.98350 = (mf)2.45920 + (embed)2.52430, recall = 0.00770, ndcg = 0.14425\n",
            "Epoch 31 (train)2.3s: train loss = 4.89555 = (mf)2.35823 + (embed)2.53732\n",
            "Epoch 32 (train)2.3s: train loss = 4.93135 = (mf)2.38850 + (embed)2.54285\n",
            "Epoch 33 (train)2.4s: train loss = 4.95555 = (mf)2.39643 + (embed)2.55912\n",
            "Epoch 34 (train)2.9s: train loss = 5.01295 = (mf)2.43470 + (embed)2.57824\n",
            "Epoch 35 (train)2.4s + (eval)0.2s: train loss = 4.95622 = (mf)2.36982 + (embed)2.58640, recall = 0.00769, ndcg = 0.14495\n",
            "Epoch 36 (train)2.3s: train loss = 4.85946 = (mf)2.26299 + (embed)2.59647\n",
            "Epoch 37 (train)2.3s: train loss = 4.92088 = (mf)2.31286 + (embed)2.60802\n",
            "Epoch 38 (train)2.5s: train loss = 4.74244 = (mf)2.13089 + (embed)2.61154\n",
            "Epoch 39 (train)2.7s: train loss = 4.92988 = (mf)2.31343 + (embed)2.61645\n",
            "Epoch 40 (train)2.3s + (eval)0.2s: train loss = 4.92039 = (mf)2.29205 + (embed)2.62833, recall = 0.01036, ndcg = 0.15146\n",
            "Epoch 41 (train)2.3s: train loss = 4.77635 = (mf)2.14640 + (embed)2.62995\n",
            "Epoch 42 (train)2.3s: train loss = 4.73544 = (mf)2.10839 + (embed)2.62705\n",
            "Epoch 43 (train)2.7s: train loss = 4.84956 = (mf)2.22196 + (embed)2.62759\n",
            "Epoch 44 (train)2.6s: train loss = 4.80795 = (mf)2.17295 + (embed)2.63500\n",
            "Epoch 45 (train)2.3s + (eval)0.6s: train loss = 4.84393 = (mf)2.20870 + (embed)2.63523, recall = 0.00901, ndcg = 0.14479\n",
            "Epoch 46 (train)2.4s: train loss = 4.85014 = (mf)2.20598 + (embed)2.64416\n",
            "Epoch 47 (train)2.3s: train loss = 4.87617 = (mf)2.23778 + (embed)2.63839\n",
            "Epoch 48 (train)2.8s: train loss = 4.78914 = (mf)2.13954 + (embed)2.64959\n",
            "Epoch 49 (train)2.4s: train loss = 5.01007 = (mf)2.34943 + (embed)2.66063\n",
            "Epoch 50 (train)2.3s + (eval)0.2s: train loss = 4.85426 = (mf)2.19042 + (embed)2.66384, recall = 0.00861, ndcg = 0.14173\n",
            "Epoch 51 (train)2.3s: train loss = 4.89642 = (mf)2.22766 + (embed)2.66876\n",
            "Epoch 52 (train)2.4s: train loss = 4.82918 = (mf)2.15399 + (embed)2.67519\n",
            "Epoch 53 (train)2.8s: train loss = 4.85300 = (mf)2.17311 + (embed)2.67989\n",
            "Epoch 54 (train)2.3s: train loss = 4.90961 = (mf)2.22364 + (embed)2.68597\n",
            "Epoch 55 (train)2.3s + (eval)0.2s: train loss = 4.81901 = (mf)2.13337 + (embed)2.68564, recall = 0.00791, ndcg = 0.12410\n",
            "Epoch 56 (train)2.4s: train loss = 4.85733 = (mf)2.16579 + (embed)2.69155\n",
            "Epoch 57 (train)2.6s: train loss = 4.93784 = (mf)2.23990 + (embed)2.69794\n",
            "Epoch 58 (train)2.7s: train loss = 4.87960 = (mf)2.18306 + (embed)2.69655\n",
            "Epoch 59 (train)2.3s: train loss = 4.85789 = (mf)2.16141 + (embed)2.69648\n",
            "Epoch 60 (train)2.3s + (eval)0.6s: train loss = 4.90523 = (mf)2.20824 + (embed)2.69699, recall = 0.00799, ndcg = 0.14894\n",
            "Epoch 61 (train)2.4s: train loss = 4.78665 = (mf)2.08461 + (embed)2.70204\n",
            "Epoch 62 (train)2.8s: train loss = 4.86905 = (mf)2.16840 + (embed)2.70065\n",
            "Epoch 63 (train)2.4s: train loss = 4.87538 = (mf)2.17138 + (embed)2.70400\n",
            "Epoch 64 (train)2.3s: train loss = 4.86230 = (mf)2.15553 + (embed)2.70677\n",
            "Epoch 65 (train)2.3s + (eval)0.3s: train loss = 4.97446 = (mf)2.26203 + (embed)2.71243, recall = 0.00722, ndcg = 0.12917\n",
            "Epoch 66 (train)2.4s: train loss = 4.87516 = (mf)2.14921 + (embed)2.72595\n",
            "Epoch 67 (train)2.9s: train loss = 4.84298 = (mf)2.11764 + (embed)2.72534\n",
            "Epoch 68 (train)2.4s: train loss = 4.96552 = (mf)2.24311 + (embed)2.72242\n",
            "Epoch 69 (train)2.3s: train loss = 5.03859 = (mf)2.31094 + (embed)2.72765\n",
            "Epoch 70 (train)2.3s + (eval)0.2s: train loss = 5.05234 = (mf)2.31847 + (embed)2.73388, recall = 0.00504, ndcg = 0.10297\n",
            "Epoch 71 (train)2.4s: train loss = 4.99196 = (mf)2.24831 + (embed)2.74365\n",
            "Epoch 72 (train)2.8s: train loss = 4.88370 = (mf)2.14390 + (embed)2.73981\n",
            "Epoch 73 (train)2.9s: train loss = 4.88238 = (mf)2.12669 + (embed)2.75569\n",
            "Epoch 74 (train)2.4s: train loss = 4.87027 = (mf)2.12193 + (embed)2.74833\n",
            "Epoch 75 (train)2.3s + (eval)0.6s: train loss = 4.99140 = (mf)2.24458 + (embed)2.74682, recall = 0.00738, ndcg = 0.12764\n",
            "Epoch 76 (train)2.9s: train loss = 4.91705 = (mf)2.16984 + (embed)2.74721\n",
            "Epoch 77 (train)2.4s: train loss = 4.95439 = (mf)2.20504 + (embed)2.74936\n",
            "Epoch 78 (train)2.4s: train loss = 4.96042 = (mf)2.20866 + (embed)2.75176\n",
            "Epoch 79 (train)2.3s: train loss = 4.89512 = (mf)2.11543 + (embed)2.77969\n",
            "Epoch 80 (train)2.3s + (eval)0.3s: train loss = 5.01944 = (mf)2.24147 + (embed)2.77797, recall = 0.00851, ndcg = 0.12691\n",
            "Epoch 81 (train)2.9s: train loss = 4.78771 = (mf)2.01155 + (embed)2.77616\n",
            "Epoch 82 (train)2.3s: train loss = 4.99410 = (mf)2.22144 + (embed)2.77267\n",
            "Epoch 83 (train)2.3s: train loss = 4.93622 = (mf)2.16872 + (embed)2.76749\n",
            "Epoch 84 (train)2.3s: train loss = 4.86163 = (mf)2.09161 + (embed)2.77003\n",
            "Epoch 85 (train)2.4s + (eval)0.4s: train loss = 4.84258 = (mf)2.08251 + (embed)2.76007, recall = 0.00843, ndcg = 0.13297\n",
            "Epoch 86 (train)2.7s: train loss = 4.89536 = (mf)2.13841 + (embed)2.75696\n",
            "Epoch 87 (train)2.3s: train loss = 4.88853 = (mf)2.12567 + (embed)2.76286\n",
            "Epoch 88 (train)2.3s: train loss = 4.82874 = (mf)2.06258 + (embed)2.76617\n",
            "Epoch 89 (train)2.3s: train loss = 4.88671 = (mf)2.13047 + (embed)2.75624\n",
            "Epoch 90 (train)2.6s + (eval)0.4s: train loss = 4.97304 = (mf)2.22071 + (embed)2.75233, recall = 0.00846, ndcg = 0.13634\n",
            "Epoch 91 (train)2.5s: train loss = 4.84657 = (mf)2.09080 + (embed)2.75577\n",
            "Epoch 92 (train)2.3s: train loss = 4.91400 = (mf)2.15262 + (embed)2.76138\n",
            "Epoch 93 (train)2.3s: train loss = 4.83022 = (mf)2.07632 + (embed)2.75390\n",
            "Epoch 94 (train)2.3s: train loss = 4.80158 = (mf)2.05389 + (embed)2.74769\n",
            "Epoch 95 (train)2.8s + (eval)0.6s: train loss = 4.84943 = (mf)2.10779 + (embed)2.74165, recall = 0.00793, ndcg = 0.11326\n",
            "Epoch 96 (train)2.4s: train loss = 4.67417 = (mf)1.92616 + (embed)2.74801\n",
            "Epoch 97 (train)2.3s: train loss = 4.75534 = (mf)2.00415 + (embed)2.75119\n",
            "Epoch 98 (train)2.4s: train loss = 4.83495 = (mf)2.08811 + (embed)2.74683\n",
            "Epoch 99 (train)2.3s: train loss = 4.88721 = (mf)2.12752 + (embed)2.75970\n",
            "Epoch 100 (train)2.8s + (eval)0.2s: train loss = 4.90177 = (mf)2.13134 + (embed)2.77043, recall = 0.00728, ndcg = 0.13569\n",
            "Training finished in 255.85 seconds.\n",
            "Evaluation results for this combination: NDCG@10: 0.13569, Recall@10: 0.00728\n",
            "--- Trying combination: Epochs=100, TopK=10, LearningRate=0.5, Layers=4 ---\n",
            "Already normalize adjacency matrix (extended).\n",
            "Using xavier initialization for user, item, and genre embeddings.\n",
            "Epoch 1 (train)4.7s: train loss = 0.62441 = (mf)0.48072 + (embed)0.14370\n",
            "Epoch 2 (train)2.4s: train loss = 1.28432 = (mf)0.85620 + (embed)0.42812\n",
            "Epoch 3 (train)2.3s: train loss = 1.81916 = (mf)1.15842 + (embed)0.66074\n",
            "Epoch 4 (train)2.3s: train loss = 2.10457 = (mf)1.26936 + (embed)0.83521\n",
            "Epoch 5 (train)2.5s + (eval)1.7s: train loss = 2.26689 = (mf)1.29977 + (embed)0.96711, recall = 0.00845, ndcg = 0.15097\n",
            "Epoch 6 (train)2.5s: train loss = 2.49923 = (mf)1.42871 + (embed)1.07052\n",
            "Epoch 7 (train)2.4s: train loss = 2.54226 = (mf)1.38108 + (embed)1.16117\n",
            "Epoch 8 (train)2.3s: train loss = 2.62517 = (mf)1.38959 + (embed)1.23558\n",
            "Epoch 9 (train)2.4s: train loss = 2.70071 = (mf)1.40907 + (embed)1.29164\n",
            "Epoch 10 (train)2.8s + (eval)0.3s: train loss = 2.74419 = (mf)1.40002 + (embed)1.34416, recall = 0.00724, ndcg = 0.14101\n",
            "Epoch 11 (train)2.3s: train loss = 2.72045 = (mf)1.33757 + (embed)1.38288\n",
            "Epoch 12 (train)2.3s: train loss = 2.73977 = (mf)1.31724 + (embed)1.42253\n",
            "Epoch 13 (train)2.3s: train loss = 2.87072 = (mf)1.40611 + (embed)1.46461\n",
            "Epoch 14 (train)2.6s: train loss = 2.85933 = (mf)1.36252 + (embed)1.49681\n",
            "Epoch 15 (train)2.6s + (eval)0.2s: train loss = 2.96435 = (mf)1.43111 + (embed)1.53324, recall = 0.00868, ndcg = 0.17655\n",
            "Epoch 16 (train)2.3s: train loss = 2.98395 = (mf)1.41751 + (embed)1.56644\n",
            "Epoch 17 (train)2.3s: train loss = 2.91957 = (mf)1.32913 + (embed)1.59044\n",
            "Epoch 18 (train)2.4s: train loss = 2.97597 = (mf)1.36025 + (embed)1.61572\n",
            "Epoch 19 (train)2.8s: train loss = 2.88209 = (mf)1.25105 + (embed)1.63105\n",
            "Epoch 20 (train)2.5s + (eval)0.3s: train loss = 3.07095 = (mf)1.42365 + (embed)1.64730, recall = 0.00835, ndcg = 0.16474\n",
            "Epoch 21 (train)2.3s: train loss = 2.95532 = (mf)1.30302 + (embed)1.65230\n",
            "Epoch 22 (train)2.3s: train loss = 3.03504 = (mf)1.35502 + (embed)1.68002\n",
            "Epoch 23 (train)2.3s: train loss = 2.94575 = (mf)1.25369 + (embed)1.69206\n",
            "Epoch 24 (train)2.9s: train loss = 2.99545 = (mf)1.30122 + (embed)1.69423\n",
            "Epoch 25 (train)2.4s + (eval)0.6s: train loss = 2.94396 = (mf)1.24455 + (embed)1.69941, recall = 0.00712, ndcg = 0.12810\n",
            "Epoch 26 (train)2.3s: train loss = 2.92577 = (mf)1.22502 + (embed)1.70074\n",
            "Epoch 27 (train)2.3s: train loss = 2.94137 = (mf)1.23699 + (embed)1.70438\n",
            "Epoch 28 (train)2.5s: train loss = 2.95645 = (mf)1.24442 + (embed)1.71203\n",
            "Epoch 29 (train)2.7s: train loss = 2.95889 = (mf)1.24019 + (embed)1.71870\n",
            "Epoch 30 (train)2.4s + (eval)0.2s: train loss = 2.90624 = (mf)1.18936 + (embed)1.71688, recall = 0.00641, ndcg = 0.14750\n",
            "Epoch 31 (train)2.3s: train loss = 2.88792 = (mf)1.16421 + (embed)1.72371\n",
            "Epoch 32 (train)2.4s: train loss = 2.92807 = (mf)1.20041 + (embed)1.72767\n",
            "Epoch 33 (train)2.7s: train loss = 2.93290 = (mf)1.19751 + (embed)1.73539\n",
            "Epoch 34 (train)2.6s: train loss = 2.91324 = (mf)1.17157 + (embed)1.74167\n",
            "Epoch 35 (train)2.4s + (eval)0.2s: train loss = 2.95866 = (mf)1.20749 + (embed)1.75117, recall = 0.00631, ndcg = 0.11919\n",
            "Epoch 36 (train)2.4s: train loss = 3.01138 = (mf)1.26122 + (embed)1.75015\n",
            "Epoch 37 (train)2.3s: train loss = 2.94109 = (mf)1.19177 + (embed)1.74931\n",
            "Epoch 38 (train)2.9s: train loss = 2.94796 = (mf)1.19712 + (embed)1.75084\n",
            "Epoch 39 (train)2.4s: train loss = 2.93486 = (mf)1.18073 + (embed)1.75413\n",
            "Epoch 40 (train)2.3s + (eval)0.6s: train loss = 2.96519 = (mf)1.20637 + (embed)1.75882, recall = 0.00636, ndcg = 0.13660\n",
            "Epoch 41 (train)2.4s: train loss = 2.95096 = (mf)1.18328 + (embed)1.76768\n",
            "Epoch 42 (train)2.5s: train loss = 2.92410 = (mf)1.14962 + (embed)1.77447\n",
            "Epoch 43 (train)2.7s: train loss = 2.99437 = (mf)1.22355 + (embed)1.77083\n",
            "Epoch 44 (train)2.3s: train loss = 2.99224 = (mf)1.21788 + (embed)1.77437\n",
            "Epoch 45 (train)2.3s + (eval)0.2s: train loss = 3.05146 = (mf)1.27288 + (embed)1.77858, recall = 0.00798, ndcg = 0.13296\n",
            "Epoch 46 (train)2.4s: train loss = 3.01024 = (mf)1.24122 + (embed)1.76902\n",
            "Epoch 47 (train)2.7s: train loss = 2.92143 = (mf)1.15248 + (embed)1.76895\n",
            "Epoch 48 (train)2.5s: train loss = 2.99344 = (mf)1.21510 + (embed)1.77834\n",
            "Epoch 49 (train)2.3s: train loss = 2.94480 = (mf)1.16769 + (embed)1.77711\n",
            "Epoch 50 (train)2.3s + (eval)0.2s: train loss = 2.99193 = (mf)1.20880 + (embed)1.78314, recall = 0.00724, ndcg = 0.11511\n",
            "Epoch 51 (train)2.3s: train loss = 2.88410 = (mf)1.10740 + (embed)1.77669\n",
            "Epoch 52 (train)2.9s: train loss = 3.00200 = (mf)1.23055 + (embed)1.77144\n",
            "Epoch 53 (train)2.4s: train loss = 2.97711 = (mf)1.19657 + (embed)1.78055\n",
            "Epoch 54 (train)2.3s: train loss = 2.99150 = (mf)1.20343 + (embed)1.78807\n",
            "Epoch 55 (train)2.3s + (eval)0.2s: train loss = 2.94957 = (mf)1.15598 + (embed)1.79359, recall = 0.00806, ndcg = 0.14790\n",
            "Epoch 56 (train)2.4s: train loss = 3.03651 = (mf)1.24166 + (embed)1.79485\n",
            "Epoch 57 (train)2.9s: train loss = 3.01416 = (mf)1.22079 + (embed)1.79337\n",
            "Epoch 58 (train)2.4s: train loss = 3.01080 = (mf)1.21016 + (embed)1.80064\n",
            "Epoch 59 (train)2.3s: train loss = 3.00951 = (mf)1.21534 + (embed)1.79417\n",
            "Epoch 60 (train)2.3s + (eval)0.6s: train loss = 2.97782 = (mf)1.18315 + (embed)1.79467, recall = 0.00980, ndcg = 0.13904\n",
            "Epoch 61 (train)2.7s: train loss = 2.91448 = (mf)1.11937 + (embed)1.79510\n",
            "Epoch 62 (train)2.6s: train loss = 2.98874 = (mf)1.19448 + (embed)1.79426\n",
            "Epoch 63 (train)2.7s: train loss = 3.01392 = (mf)1.20804 + (embed)1.80588\n",
            "Epoch 64 (train)2.5s: train loss = 2.98310 = (mf)1.17602 + (embed)1.80708\n",
            "Epoch 65 (train)2.4s + (eval)0.2s: train loss = 3.01154 = (mf)1.20755 + (embed)1.80400, recall = 0.00838, ndcg = 0.12346\n",
            "Epoch 66 (train)2.9s: train loss = 3.02602 = (mf)1.22104 + (embed)1.80499\n",
            "Epoch 67 (train)2.4s: train loss = 2.96304 = (mf)1.15338 + (embed)1.80965\n",
            "Epoch 68 (train)2.3s: train loss = 2.94280 = (mf)1.14168 + (embed)1.80112\n",
            "Epoch 69 (train)2.3s: train loss = 2.94277 = (mf)1.14721 + (embed)1.79556\n",
            "Epoch 70 (train)2.3s + (eval)0.4s: train loss = 2.95686 = (mf)1.15922 + (embed)1.79764, recall = 0.00815, ndcg = 0.14878\n",
            "Epoch 71 (train)2.8s: train loss = 2.98130 = (mf)1.18864 + (embed)1.79266\n",
            "Epoch 72 (train)2.4s: train loss = 2.96610 = (mf)1.16692 + (embed)1.79918\n",
            "Epoch 73 (train)2.3s: train loss = 2.98194 = (mf)1.18014 + (embed)1.80180\n",
            "Epoch 74 (train)2.3s: train loss = 3.02988 = (mf)1.22874 + (embed)1.80114\n",
            "Epoch 75 (train)2.5s + (eval)0.8s: train loss = 2.94777 = (mf)1.14789 + (embed)1.79988, recall = 0.00685, ndcg = 0.10516\n",
            "Epoch 76 (train)2.5s: train loss = 2.93253 = (mf)1.13795 + (embed)1.79458\n",
            "Epoch 77 (train)2.3s: train loss = 3.02670 = (mf)1.22140 + (embed)1.80530\n",
            "Epoch 78 (train)2.3s: train loss = 3.03330 = (mf)1.22089 + (embed)1.81241\n",
            "Epoch 79 (train)2.3s: train loss = 2.99456 = (mf)1.17532 + (embed)1.81923\n",
            "Epoch 80 (train)2.9s + (eval)0.2s: train loss = 3.01746 = (mf)1.20111 + (embed)1.81635, recall = 0.00823, ndcg = 0.12591\n",
            "Epoch 81 (train)2.4s: train loss = 2.98391 = (mf)1.16895 + (embed)1.81496\n",
            "Epoch 82 (train)2.3s: train loss = 3.00412 = (mf)1.20325 + (embed)1.80087\n",
            "Epoch 83 (train)2.3s: train loss = 2.98658 = (mf)1.18991 + (embed)1.79667\n",
            "Epoch 84 (train)2.4s: train loss = 2.92466 = (mf)1.13008 + (embed)1.79458\n",
            "Epoch 85 (train)2.9s + (eval)0.2s: train loss = 2.95200 = (mf)1.16033 + (embed)1.79167, recall = 0.00534, ndcg = 0.10838\n",
            "Epoch 86 (train)2.4s: train loss = 2.97850 = (mf)1.18606 + (embed)1.79244\n",
            "Epoch 87 (train)2.4s: train loss = 3.00392 = (mf)1.21191 + (embed)1.79201\n",
            "Epoch 88 (train)2.4s: train loss = 2.96397 = (mf)1.16949 + (embed)1.79448\n",
            "Epoch 89 (train)2.5s: train loss = 2.91801 = (mf)1.12476 + (embed)1.79325\n",
            "Epoch 90 (train)2.7s + (eval)0.6s: train loss = 2.95076 = (mf)1.15194 + (embed)1.79882, recall = 0.00824, ndcg = 0.13173\n",
            "Epoch 91 (train)2.4s: train loss = 2.94070 = (mf)1.14421 + (embed)1.79649\n",
            "Epoch 92 (train)2.3s: train loss = 2.93913 = (mf)1.13630 + (embed)1.80282\n",
            "Epoch 93 (train)2.3s: train loss = 2.93864 = (mf)1.13751 + (embed)1.80112\n",
            "Epoch 94 (train)2.9s: train loss = 2.95027 = (mf)1.14731 + (embed)1.80296\n",
            "Epoch 95 (train)2.4s + (eval)0.2s: train loss = 2.96229 = (mf)1.15210 + (embed)1.81019, recall = 0.00857, ndcg = 0.13858\n",
            "Epoch 96 (train)2.4s: train loss = 2.93511 = (mf)1.12945 + (embed)1.80565\n",
            "Epoch 97 (train)2.4s: train loss = 2.95193 = (mf)1.14611 + (embed)1.80582\n",
            "Epoch 98 (train)2.3s: train loss = 2.99769 = (mf)1.19397 + (embed)1.80372\n",
            "Epoch 99 (train)2.9s: train loss = 2.93530 = (mf)1.12839 + (embed)1.80691\n",
            "Epoch 100 (train)2.4s + (eval)0.3s: train loss = 2.98267 = (mf)1.17525 + (embed)1.80742, recall = 0.00967, ndcg = 0.12468\n",
            "Training finished in 257.10 seconds.\n",
            "Evaluation results for this combination: NDCG@10: 0.12468, Recall@10: 0.00967\n",
            "--- Trying combination: Epochs=100, TopK=10, LearningRate=0.5, Layers=5 ---\n",
            "Already normalize adjacency matrix (extended).\n",
            "Using xavier initialization for user, item, and genre embeddings.\n",
            "Epoch 1 (train)4.2s: train loss = 0.51074 = (mf)0.38219 + (embed)0.12855\n",
            "Epoch 2 (train)2.4s: train loss = 1.00536 = (mf)0.62651 + (embed)0.37886\n",
            "Epoch 3 (train)2.4s: train loss = 1.33659 = (mf)0.76683 + (embed)0.56976\n",
            "Epoch 4 (train)2.6s: train loss = 1.53704 = (mf)0.83864 + (embed)0.69840\n",
            "Epoch 5 (train)2.7s + (eval)1.4s: train loss = 1.62879 = (mf)0.83313 + (embed)0.79566, recall = 0.00709, ndcg = 0.13940\n",
            "Epoch 6 (train)2.4s: train loss = 1.76482 = (mf)0.88020 + (embed)0.88462\n",
            "Epoch 7 (train)2.4s: train loss = 1.85058 = (mf)0.89922 + (embed)0.95137\n",
            "Epoch 8 (train)2.5s: train loss = 1.90519 = (mf)0.89429 + (embed)1.01090\n",
            "Epoch 9 (train)2.8s: train loss = 1.95327 = (mf)0.89734 + (embed)1.05593\n",
            "Epoch 10 (train)2.4s + (eval)0.3s: train loss = 1.98085 = (mf)0.88598 + (embed)1.09487, recall = 0.00775, ndcg = 0.14373\n",
            "Epoch 11 (train)2.4s: train loss = 2.02743 = (mf)0.89454 + (embed)1.13288\n",
            "Epoch 12 (train)2.4s: train loss = 2.04862 = (mf)0.88900 + (embed)1.15962\n",
            "Epoch 13 (train)2.8s: train loss = 2.02753 = (mf)0.84932 + (embed)1.17822\n",
            "Epoch 14 (train)2.5s: train loss = 2.04410 = (mf)0.85484 + (embed)1.18926\n",
            "Epoch 15 (train)2.4s + (eval)0.2s: train loss = 2.09067 = (mf)0.88694 + (embed)1.20373, recall = 0.00677, ndcg = 0.12755\n",
            "Epoch 16 (train)2.4s: train loss = 2.11551 = (mf)0.89033 + (embed)1.22518\n",
            "Epoch 17 (train)2.4s: train loss = 2.06341 = (mf)0.82877 + (embed)1.23464\n",
            "Epoch 18 (train)2.9s: train loss = 2.06325 = (mf)0.83039 + (embed)1.23286\n",
            "Epoch 19 (train)2.4s: train loss = 2.08803 = (mf)0.84159 + (embed)1.24644\n",
            "Epoch 20 (train)2.4s + (eval)0.2s: train loss = 2.09076 = (mf)0.82587 + (embed)1.26489, recall = 0.00768, ndcg = 0.12827\n",
            "Epoch 21 (train)2.4s: train loss = 2.05608 = (mf)0.79213 + (embed)1.26395\n",
            "Epoch 22 (train)2.6s: train loss = 2.04963 = (mf)0.78137 + (embed)1.26826\n",
            "Epoch 23 (train)2.7s: train loss = 2.07721 = (mf)0.80828 + (embed)1.26893\n",
            "Epoch 24 (train)2.4s: train loss = 2.09678 = (mf)0.82260 + (embed)1.27417\n",
            "Epoch 25 (train)2.4s + (eval)0.6s: train loss = 2.03850 = (mf)0.76727 + (embed)1.27124, recall = 0.00718, ndcg = 0.09563\n",
            "Epoch 26 (train)2.4s: train loss = 2.03714 = (mf)0.76322 + (embed)1.27393\n",
            "Epoch 27 (train)2.9s: train loss = 2.05259 = (mf)0.77378 + (embed)1.27881\n",
            "Epoch 28 (train)2.4s: train loss = 2.03741 = (mf)0.75715 + (embed)1.28026\n",
            "Epoch 29 (train)2.4s: train loss = 2.07243 = (mf)0.78788 + (embed)1.28455\n",
            "Epoch 30 (train)2.4s + (eval)0.2s: train loss = 2.02316 = (mf)0.74331 + (embed)1.27985, recall = 0.00819, ndcg = 0.12805\n",
            "Epoch 31 (train)2.6s: train loss = 2.03786 = (mf)0.76365 + (embed)1.27422\n",
            "Epoch 32 (train)2.7s: train loss = 2.03860 = (mf)0.76433 + (embed)1.27428\n",
            "Epoch 33 (train)2.4s: train loss = 2.04874 = (mf)0.76787 + (embed)1.28087\n",
            "Epoch 34 (train)2.4s: train loss = 2.02559 = (mf)0.75773 + (embed)1.26787\n",
            "Epoch 35 (train)2.4s + (eval)0.2s: train loss = 2.07130 = (mf)0.80202 + (embed)1.26927, recall = 0.00781, ndcg = 0.08975\n",
            "Epoch 36 (train)2.9s: train loss = 2.01533 = (mf)0.73594 + (embed)1.27940\n",
            "Epoch 37 (train)2.4s: train loss = 2.01376 = (mf)0.73620 + (embed)1.27756\n",
            "Epoch 38 (train)2.4s: train loss = 2.03735 = (mf)0.75873 + (embed)1.27861\n",
            "Epoch 39 (train)2.4s: train loss = 2.02400 = (mf)0.74928 + (embed)1.27472\n",
            "Epoch 40 (train)2.4s + (eval)0.7s: train loss = 2.02760 = (mf)0.75661 + (embed)1.27099, recall = 0.00847, ndcg = 0.13531\n",
            "Epoch 41 (train)2.8s: train loss = 1.98373 = (mf)0.71530 + (embed)1.26842\n",
            "Epoch 42 (train)2.5s: train loss = 2.04015 = (mf)0.76961 + (embed)1.27055\n",
            "Epoch 43 (train)2.4s: train loss = 2.01435 = (mf)0.74382 + (embed)1.27053\n",
            "Epoch 44 (train)2.4s: train loss = 1.99972 = (mf)0.73296 + (embed)1.26676\n",
            "Epoch 45 (train)2.8s + (eval)0.4s: train loss = 2.01002 = (mf)0.74099 + (embed)1.26904, recall = 0.00630, ndcg = 0.11115\n",
            "Epoch 46 (train)2.6s: train loss = 2.01504 = (mf)0.74506 + (embed)1.26998\n",
            "Epoch 47 (train)2.5s: train loss = 2.03587 = (mf)0.75459 + (embed)1.28129\n",
            "Epoch 48 (train)2.4s: train loss = 2.05485 = (mf)0.76581 + (embed)1.28904\n",
            "Epoch 49 (train)2.4s: train loss = 2.03238 = (mf)0.74735 + (embed)1.28503\n",
            "Epoch 50 (train)3.0s + (eval)0.2s: train loss = 2.06202 = (mf)0.77860 + (embed)1.28342, recall = 0.00840, ndcg = 0.15237\n",
            "Epoch 51 (train)2.4s: train loss = 2.02608 = (mf)0.73657 + (embed)1.28950\n",
            "Epoch 52 (train)2.4s: train loss = 2.08132 = (mf)0.77846 + (embed)1.30287\n",
            "Epoch 53 (train)2.8s: train loss = 2.10597 = (mf)0.79854 + (embed)1.30743\n",
            "Epoch 54 (train)3.0s: train loss = 2.05896 = (mf)0.75256 + (embed)1.30640\n",
            "Epoch 55 (train)2.5s + (eval)0.6s: train loss = 2.02171 = (mf)0.72317 + (embed)1.29854, recall = 0.00696, ndcg = 0.09927\n",
            "Epoch 56 (train)2.4s: train loss = 2.03523 = (mf)0.73766 + (embed)1.29757\n",
            "Epoch 57 (train)2.4s: train loss = 2.04597 = (mf)0.75284 + (embed)1.29313\n",
            "Epoch 58 (train)2.5s: train loss = 2.02673 = (mf)0.73499 + (embed)1.29174\n",
            "Epoch 59 (train)2.9s: train loss = 2.07505 = (mf)0.78481 + (embed)1.29024\n",
            "Epoch 60 (train)2.5s + (eval)0.3s: train loss = 2.01561 = (mf)0.73038 + (embed)1.28523, recall = 0.00683, ndcg = 0.13150\n",
            "Epoch 61 (train)2.5s: train loss = 2.03552 = (mf)0.75659 + (embed)1.27893\n",
            "Epoch 62 (train)2.4s: train loss = 2.01078 = (mf)0.72883 + (embed)1.28195\n",
            "Epoch 63 (train)3.0s: train loss = 1.98566 = (mf)0.70992 + (embed)1.27573\n",
            "Epoch 64 (train)2.5s: train loss = 1.98908 = (mf)0.71998 + (embed)1.26910\n",
            "Epoch 65 (train)2.5s + (eval)0.2s: train loss = 2.02803 = (mf)0.75275 + (embed)1.27528, recall = 0.00710, ndcg = 0.13338\n",
            "Epoch 66 (train)2.5s: train loss = 2.02228 = (mf)0.73921 + (embed)1.28307\n",
            "Epoch 67 (train)2.5s: train loss = 1.98970 = (mf)0.70264 + (embed)1.28707\n",
            "Epoch 68 (train)2.9s: train loss = 2.05024 = (mf)0.75864 + (embed)1.29160\n",
            "Epoch 69 (train)2.5s: train loss = 2.02808 = (mf)0.74694 + (embed)1.28114\n",
            "Epoch 70 (train)2.4s + (eval)0.2s: train loss = 2.02612 = (mf)0.73558 + (embed)1.29054, recall = 0.00563, ndcg = 0.11240\n",
            "Epoch 71 (train)2.4s: train loss = 2.08692 = (mf)0.78696 + (embed)1.29996\n",
            "Epoch 72 (train)2.8s: train loss = 2.10489 = (mf)0.79483 + (embed)1.31006\n",
            "Epoch 73 (train)2.5s: train loss = 2.09374 = (mf)0.78125 + (embed)1.31249\n",
            "Epoch 74 (train)2.4s: train loss = 2.07384 = (mf)0.75676 + (embed)1.31708\n",
            "Epoch 75 (train)2.4s + (eval)0.6s: train loss = 2.09068 = (mf)0.77718 + (embed)1.31350, recall = 0.00676, ndcg = 0.08152\n",
            "Epoch 76 (train)2.4s: train loss = 2.03249 = (mf)0.72716 + (embed)1.30533\n",
            "Epoch 77 (train)2.9s: train loss = 2.06954 = (mf)0.76531 + (embed)1.30423\n",
            "Epoch 78 (train)2.4s: train loss = 2.08410 = (mf)0.77458 + (embed)1.30952\n",
            "Epoch 79 (train)2.4s: train loss = 2.05542 = (mf)0.75010 + (embed)1.30533\n",
            "Epoch 80 (train)2.4s + (eval)0.2s: train loss = 2.03281 = (mf)0.72399 + (embed)1.30883, recall = 0.00669, ndcg = 0.11449\n",
            "Epoch 81 (train)2.7s: train loss = 2.03461 = (mf)0.73005 + (embed)1.30456\n",
            "Epoch 82 (train)2.6s: train loss = 2.02400 = (mf)0.72372 + (embed)1.30028\n",
            "Epoch 83 (train)2.4s: train loss = 2.04005 = (mf)0.74172 + (embed)1.29833\n",
            "Epoch 84 (train)2.4s: train loss = 2.05293 = (mf)0.75332 + (embed)1.29960\n",
            "Epoch 85 (train)2.4s + (eval)0.3s: train loss = 2.01152 = (mf)0.71555 + (embed)1.29598, recall = 0.00818, ndcg = 0.12051\n",
            "Epoch 86 (train)2.9s: train loss = 2.06988 = (mf)0.76737 + (embed)1.30251\n",
            "Epoch 87 (train)2.4s: train loss = 2.01492 = (mf)0.71354 + (embed)1.30138\n",
            "Epoch 88 (train)2.4s: train loss = 2.01920 = (mf)0.71563 + (embed)1.30357\n",
            "Epoch 89 (train)2.4s: train loss = 2.04371 = (mf)0.74337 + (embed)1.30035\n",
            "Epoch 90 (train)2.5s + (eval)0.8s: train loss = 2.03200 = (mf)0.73745 + (embed)1.29455, recall = 0.00666, ndcg = 0.09791\n",
            "Epoch 91 (train)2.7s: train loss = 2.07999 = (mf)0.78216 + (embed)1.29782\n",
            "Epoch 92 (train)2.4s: train loss = 1.99379 = (mf)0.69953 + (embed)1.29426\n",
            "Epoch 93 (train)2.4s: train loss = 2.02639 = (mf)0.73546 + (embed)1.29093\n",
            "Epoch 94 (train)2.4s: train loss = 2.02444 = (mf)0.73448 + (embed)1.28996\n",
            "Epoch 95 (train)2.9s + (eval)0.2s: train loss = 2.02534 = (mf)0.74093 + (embed)1.28441, recall = 0.00739, ndcg = 0.11581\n",
            "Epoch 96 (train)2.4s: train loss = 2.01427 = (mf)0.73582 + (embed)1.27845\n",
            "Epoch 97 (train)2.4s: train loss = 2.02697 = (mf)0.73719 + (embed)1.28978\n",
            "Epoch 98 (train)2.4s: train loss = 2.01725 = (mf)0.72942 + (embed)1.28783\n",
            "Epoch 99 (train)2.4s: train loss = 2.02167 = (mf)0.73839 + (embed)1.28328\n",
            "Epoch 100 (train)2.9s + (eval)0.2s: train loss = 2.00047 = (mf)0.72318 + (embed)1.27729, recall = 0.00694, ndcg = 0.11827\n",
            "Training finished in 264.43 seconds.\n",
            "Evaluation results for this combination: NDCG@10: 0.11827, Recall@10: 0.00694\n",
            "--- Trying combination: Epochs=100, TopK=20, LearningRate=0.005, Layers=3 ---\n",
            "Already normalize adjacency matrix (extended).\n",
            "Using xavier initialization for user, item, and genre embeddings.\n",
            "Epoch 1 (train)4.5s: train loss = 0.29061 = (mf)0.29005 + (embed)0.00056\n",
            "Epoch 2 (train)2.4s: train loss = 0.17860 = (mf)0.17760 + (embed)0.00100\n",
            "Epoch 3 (train)2.3s: train loss = 0.14989 = (mf)0.14852 + (embed)0.00137\n",
            "Epoch 4 (train)2.3s: train loss = 0.13382 = (mf)0.13207 + (embed)0.00175\n",
            "Epoch 5 (train)2.7s + (eval)1.2s: train loss = 0.11835 = (mf)0.11622 + (embed)0.00213, recall = 0.01793, ndcg = 0.18005\n",
            "Epoch 6 (train)2.4s: train loss = 0.10743 = (mf)0.10489 + (embed)0.00254\n",
            "Epoch 7 (train)2.4s: train loss = 0.09565 = (mf)0.09269 + (embed)0.00296\n",
            "Epoch 8 (train)2.4s: train loss = 0.08518 = (mf)0.08179 + (embed)0.00339\n",
            "Epoch 9 (train)2.5s: train loss = 0.07809 = (mf)0.07426 + (embed)0.00383\n",
            "Epoch 10 (train)2.8s + (eval)0.2s: train loss = 0.07071 = (mf)0.06644 + (embed)0.00428, recall = 0.02343, ndcg = 0.23538\n",
            "Epoch 11 (train)2.4s: train loss = 0.06591 = (mf)0.06123 + (embed)0.00468\n",
            "Epoch 12 (train)2.4s: train loss = 0.06125 = (mf)0.05620 + (embed)0.00505\n",
            "Epoch 13 (train)2.3s: train loss = 0.05839 = (mf)0.05300 + (embed)0.00539\n",
            "Epoch 14 (train)2.6s: train loss = 0.05361 = (mf)0.04790 + (embed)0.00571\n",
            "Epoch 15 (train)2.5s + (eval)0.2s: train loss = 0.05191 = (mf)0.04591 + (embed)0.00600, recall = 0.02651, ndcg = 0.25586\n",
            "Epoch 16 (train)2.4s: train loss = 0.04936 = (mf)0.04309 + (embed)0.00627\n",
            "Epoch 17 (train)2.3s: train loss = 0.04659 = (mf)0.04007 + (embed)0.00653\n",
            "Epoch 18 (train)2.3s: train loss = 0.04568 = (mf)0.03892 + (embed)0.00676\n",
            "Epoch 19 (train)2.8s: train loss = 0.04344 = (mf)0.03646 + (embed)0.00698\n",
            "Epoch 20 (train)2.4s + (eval)0.6s: train loss = 0.04225 = (mf)0.03506 + (embed)0.00719, recall = 0.02670, ndcg = 0.26303\n",
            "Epoch 21 (train)2.3s: train loss = 0.04154 = (mf)0.03415 + (embed)0.00738\n",
            "Epoch 22 (train)2.3s: train loss = 0.03848 = (mf)0.03091 + (embed)0.00757\n",
            "Epoch 23 (train)2.4s: train loss = 0.03826 = (mf)0.03053 + (embed)0.00773\n",
            "Epoch 24 (train)2.8s: train loss = 0.03706 = (mf)0.02916 + (embed)0.00790\n",
            "Epoch 25 (train)2.3s + (eval)0.3s: train loss = 0.03540 = (mf)0.02735 + (embed)0.00805, recall = 0.02741, ndcg = 0.27000\n",
            "Epoch 26 (train)2.4s: train loss = 0.03531 = (mf)0.02714 + (embed)0.00817\n",
            "Epoch 27 (train)2.3s: train loss = 0.03382 = (mf)0.02553 + (embed)0.00829\n",
            "Epoch 28 (train)2.6s: train loss = 0.03291 = (mf)0.02448 + (embed)0.00843\n",
            "Epoch 29 (train)2.6s: train loss = 0.03311 = (mf)0.02457 + (embed)0.00854\n",
            "Epoch 30 (train)2.4s + (eval)0.3s: train loss = 0.03100 = (mf)0.02236 + (embed)0.00863, recall = 0.02916, ndcg = 0.26518\n",
            "Epoch 31 (train)2.3s: train loss = 0.03119 = (mf)0.02246 + (embed)0.00873\n",
            "Epoch 32 (train)2.3s: train loss = 0.03059 = (mf)0.02178 + (embed)0.00881\n",
            "Epoch 33 (train)2.9s: train loss = 0.02982 = (mf)0.02093 + (embed)0.00889\n",
            "Epoch 34 (train)2.4s: train loss = 0.02867 = (mf)0.01971 + (embed)0.00896\n",
            "Epoch 35 (train)2.3s + (eval)0.7s: train loss = 0.02906 = (mf)0.02003 + (embed)0.00903, recall = 0.02882, ndcg = 0.27416\n",
            "Epoch 36 (train)2.4s: train loss = 0.02949 = (mf)0.02038 + (embed)0.00910\n",
            "Epoch 37 (train)2.5s: train loss = 0.02779 = (mf)0.01863 + (embed)0.00916\n",
            "Epoch 38 (train)2.8s: train loss = 0.02793 = (mf)0.01870 + (embed)0.00923\n",
            "Epoch 39 (train)2.4s: train loss = 0.02779 = (mf)0.01852 + (embed)0.00927\n",
            "Epoch 40 (train)2.4s + (eval)0.2s: train loss = 0.02659 = (mf)0.01726 + (embed)0.00934, recall = 0.02972, ndcg = 0.26937\n",
            "Epoch 41 (train)2.4s: train loss = 0.02672 = (mf)0.01733 + (embed)0.00939\n",
            "Epoch 42 (train)2.8s: train loss = 0.02656 = (mf)0.01713 + (embed)0.00943\n",
            "Epoch 43 (train)3.2s: train loss = 0.02606 = (mf)0.01659 + (embed)0.00947\n",
            "Epoch 44 (train)2.4s: train loss = 0.02614 = (mf)0.01663 + (embed)0.00951\n",
            "Epoch 45 (train)2.4s + (eval)0.3s: train loss = 0.02538 = (mf)0.01581 + (embed)0.00957, recall = 0.02795, ndcg = 0.26398\n",
            "Epoch 46 (train)2.4s: train loss = 0.02470 = (mf)0.01510 + (embed)0.00960\n",
            "Epoch 47 (train)2.9s: train loss = 0.02500 = (mf)0.01536 + (embed)0.00964\n",
            "Epoch 48 (train)2.4s: train loss = 0.02452 = (mf)0.01484 + (embed)0.00968\n",
            "Epoch 49 (train)2.4s: train loss = 0.02430 = (mf)0.01457 + (embed)0.00973\n",
            "Epoch 50 (train)2.4s + (eval)0.7s: train loss = 0.02367 = (mf)0.01392 + (embed)0.00975, recall = 0.02820, ndcg = 0.26746\n",
            "Epoch 51 (train)2.7s: train loss = 0.02381 = (mf)0.01403 + (embed)0.00978\n",
            "Epoch 52 (train)2.6s: train loss = 0.02375 = (mf)0.01394 + (embed)0.00981\n",
            "Epoch 53 (train)2.3s: train loss = 0.02390 = (mf)0.01408 + (embed)0.00982\n",
            "Epoch 54 (train)2.4s: train loss = 0.02376 = (mf)0.01391 + (embed)0.00984\n",
            "Epoch 55 (train)2.3s + (eval)0.3s: train loss = 0.02289 = (mf)0.01301 + (embed)0.00988, recall = 0.02824, ndcg = 0.26783\n",
            "Epoch 56 (train)2.8s: train loss = 0.02301 = (mf)0.01312 + (embed)0.00989\n",
            "Epoch 57 (train)2.5s: train loss = 0.02294 = (mf)0.01302 + (embed)0.00991\n",
            "Epoch 58 (train)2.4s: train loss = 0.02287 = (mf)0.01293 + (embed)0.00994\n",
            "Epoch 59 (train)2.4s: train loss = 0.02236 = (mf)0.01241 + (embed)0.00995\n",
            "Epoch 60 (train)2.4s + (eval)0.2s: train loss = 0.02226 = (mf)0.01228 + (embed)0.00997, recall = 0.02854, ndcg = 0.27081\n",
            "Epoch 61 (train)2.9s: train loss = 0.02195 = (mf)0.01195 + (embed)0.01000\n",
            "Epoch 62 (train)2.4s: train loss = 0.02168 = (mf)0.01166 + (embed)0.01002\n",
            "Epoch 63 (train)2.4s: train loss = 0.02172 = (mf)0.01169 + (embed)0.01003\n",
            "Epoch 64 (train)2.4s: train loss = 0.02145 = (mf)0.01141 + (embed)0.01005\n",
            "Epoch 65 (train)2.5s + (eval)0.4s: train loss = 0.02129 = (mf)0.01124 + (embed)0.01005, recall = 0.02833, ndcg = 0.27092\n",
            "Epoch 66 (train)2.7s: train loss = 0.02155 = (mf)0.01149 + (embed)0.01006\n",
            "Epoch 67 (train)2.4s: train loss = 0.02132 = (mf)0.01125 + (embed)0.01007\n",
            "Epoch 68 (train)2.4s: train loss = 0.02114 = (mf)0.01106 + (embed)0.01008\n",
            "Epoch 69 (train)2.4s: train loss = 0.02093 = (mf)0.01082 + (embed)0.01011\n",
            "Epoch 70 (train)2.7s + (eval)0.8s: train loss = 0.02074 = (mf)0.01063 + (embed)0.01011, recall = 0.02843, ndcg = 0.26824\n",
            "Epoch 71 (train)2.4s: train loss = 0.02086 = (mf)0.01073 + (embed)0.01012\n",
            "Epoch 72 (train)2.4s: train loss = 0.02099 = (mf)0.01087 + (embed)0.01012\n",
            "Epoch 73 (train)2.4s: train loss = 0.02030 = (mf)0.01017 + (embed)0.01013\n",
            "Epoch 74 (train)2.4s: train loss = 0.02058 = (mf)0.01044 + (embed)0.01014\n",
            "Epoch 75 (train)2.9s + (eval)0.2s: train loss = 0.02015 = (mf)0.01000 + (embed)0.01015, recall = 0.02913, ndcg = 0.26581\n",
            "Epoch 76 (train)2.4s: train loss = 0.02033 = (mf)0.01017 + (embed)0.01016\n",
            "Epoch 77 (train)2.4s: train loss = 0.01996 = (mf)0.00979 + (embed)0.01018\n",
            "Epoch 78 (train)2.3s: train loss = 0.02015 = (mf)0.00997 + (embed)0.01018\n",
            "Epoch 79 (train)2.5s: train loss = 0.02004 = (mf)0.00984 + (embed)0.01020\n",
            "Epoch 80 (train)2.7s + (eval)0.3s: train loss = 0.01967 = (mf)0.00947 + (embed)0.01020, recall = 0.02852, ndcg = 0.27075\n",
            "Epoch 81 (train)2.4s: train loss = 0.01971 = (mf)0.00950 + (embed)0.01021\n",
            "Epoch 82 (train)2.3s: train loss = 0.01944 = (mf)0.00924 + (embed)0.01020\n",
            "Epoch 83 (train)2.3s: train loss = 0.01999 = (mf)0.00978 + (embed)0.01022\n",
            "Epoch 84 (train)2.7s: train loss = 0.01962 = (mf)0.00939 + (embed)0.01023\n",
            "Epoch 85 (train)2.5s + (eval)0.7s: train loss = 0.01949 = (mf)0.00926 + (embed)0.01024, recall = 0.02793, ndcg = 0.26305\n",
            "Epoch 86 (train)2.3s: train loss = 0.01983 = (mf)0.00959 + (embed)0.01024\n",
            "Epoch 87 (train)2.3s: train loss = 0.01948 = (mf)0.00924 + (embed)0.01024\n",
            "Epoch 88 (train)2.3s: train loss = 0.01935 = (mf)0.00910 + (embed)0.01025\n",
            "Epoch 89 (train)2.9s: train loss = 0.01946 = (mf)0.00920 + (embed)0.01026\n",
            "Epoch 90 (train)2.4s + (eval)0.2s: train loss = 0.01923 = (mf)0.00896 + (embed)0.01027, recall = 0.02859, ndcg = 0.26783\n",
            "Epoch 91 (train)2.3s: train loss = 0.01924 = (mf)0.00898 + (embed)0.01026\n",
            "Epoch 92 (train)2.3s: train loss = 0.01920 = (mf)0.00893 + (embed)0.01027\n",
            "Epoch 93 (train)2.5s: train loss = 0.01930 = (mf)0.00902 + (embed)0.01028\n",
            "Epoch 94 (train)2.7s: train loss = 0.01916 = (mf)0.00887 + (embed)0.01029\n",
            "Epoch 95 (train)2.3s + (eval)0.2s: train loss = 0.01880 = (mf)0.00851 + (embed)0.01029, recall = 0.02776, ndcg = 0.26820\n",
            "Epoch 96 (train)2.3s: train loss = 0.01923 = (mf)0.00893 + (embed)0.01029\n",
            "Epoch 97 (train)2.4s: train loss = 0.01852 = (mf)0.00821 + (embed)0.01031\n",
            "Epoch 98 (train)2.7s: train loss = 0.01883 = (mf)0.00850 + (embed)0.01033\n",
            "Epoch 99 (train)2.5s: train loss = 0.01846 = (mf)0.00814 + (embed)0.01032\n",
            "Epoch 100 (train)2.3s + (eval)0.7s: train loss = 0.01865 = (mf)0.00832 + (embed)0.01033, recall = 0.02788, ndcg = 0.26890\n",
            "Training finished in 258.04 seconds.\n",
            "Evaluation results for this combination: NDCG@20: 0.26890, Recall@20: 0.02788\n",
            "--- Trying combination: Epochs=100, TopK=20, LearningRate=0.005, Layers=4 ---\n",
            "Already normalize adjacency matrix (extended).\n",
            "Using xavier initialization for user, item, and genre embeddings.\n",
            "Epoch 1 (train)4.1s: train loss = 0.29621 = (mf)0.29563 + (embed)0.00058\n",
            "Epoch 2 (train)2.4s: train loss = 0.20175 = (mf)0.20074 + (embed)0.00101\n",
            "Epoch 3 (train)2.3s: train loss = 0.17515 = (mf)0.17370 + (embed)0.00145\n",
            "Epoch 4 (train)2.9s: train loss = 0.14946 = (mf)0.14750 + (embed)0.00196\n",
            "Epoch 5 (train)2.4s + (eval)1.1s: train loss = 0.13664 = (mf)0.13423 + (embed)0.00240, recall = 0.01643, ndcg = 0.17244\n",
            "Epoch 6 (train)2.5s: train loss = 0.12484 = (mf)0.12204 + (embed)0.00280\n",
            "Epoch 7 (train)2.4s: train loss = 0.11506 = (mf)0.11182 + (embed)0.00324\n",
            "Epoch 8 (train)2.9s: train loss = 0.10571 = (mf)0.10202 + (embed)0.00369\n",
            "Epoch 9 (train)2.4s: train loss = 0.09781 = (mf)0.09365 + (embed)0.00417\n",
            "Epoch 10 (train)2.4s + (eval)0.3s: train loss = 0.08959 = (mf)0.08496 + (embed)0.00463, recall = 0.02030, ndcg = 0.21485\n",
            "Epoch 11 (train)2.4s: train loss = 0.08323 = (mf)0.07812 + (embed)0.00511\n",
            "Epoch 12 (train)2.4s: train loss = 0.07735 = (mf)0.07178 + (embed)0.00557\n",
            "Epoch 13 (train)2.9s: train loss = 0.07365 = (mf)0.06765 + (embed)0.00600\n",
            "Epoch 14 (train)2.4s: train loss = 0.07034 = (mf)0.06395 + (embed)0.00639\n",
            "Epoch 15 (train)2.4s + (eval)0.6s: train loss = 0.06761 = (mf)0.06086 + (embed)0.00676, recall = 0.02470, ndcg = 0.23894\n",
            "Epoch 16 (train)2.4s: train loss = 0.06367 = (mf)0.05656 + (embed)0.00711\n",
            "Epoch 17 (train)2.8s: train loss = 0.06223 = (mf)0.05483 + (embed)0.00740\n",
            "Epoch 18 (train)2.5s: train loss = 0.05918 = (mf)0.05146 + (embed)0.00771\n",
            "Epoch 19 (train)2.3s: train loss = 0.05685 = (mf)0.04886 + (embed)0.00799\n",
            "Epoch 20 (train)2.3s + (eval)0.3s: train loss = 0.05640 = (mf)0.04816 + (embed)0.00825, recall = 0.02572, ndcg = 0.25866\n",
            "Epoch 21 (train)2.3s: train loss = 0.05370 = (mf)0.04522 + (embed)0.00848\n",
            "Epoch 22 (train)2.9s: train loss = 0.05205 = (mf)0.04332 + (embed)0.00873\n",
            "Epoch 23 (train)2.4s: train loss = 0.04962 = (mf)0.04066 + (embed)0.00896\n",
            "Epoch 24 (train)2.4s: train loss = 0.04817 = (mf)0.03900 + (embed)0.00917\n",
            "Epoch 25 (train)2.4s + (eval)0.3s: train loss = 0.04688 = (mf)0.03754 + (embed)0.00935, recall = 0.02666, ndcg = 0.25701\n",
            "Epoch 26 (train)2.4s: train loss = 0.04476 = (mf)0.03521 + (embed)0.00955\n",
            "Epoch 27 (train)2.8s: train loss = 0.04515 = (mf)0.03543 + (embed)0.00972\n",
            "Epoch 28 (train)2.3s: train loss = 0.04365 = (mf)0.03378 + (embed)0.00987\n",
            "Epoch 29 (train)2.3s: train loss = 0.04263 = (mf)0.03259 + (embed)0.01004\n",
            "Epoch 30 (train)2.3s + (eval)0.2s: train loss = 0.04129 = (mf)0.03112 + (embed)0.01017, recall = 0.02712, ndcg = 0.26391\n",
            "Epoch 31 (train)2.7s: train loss = 0.04147 = (mf)0.03117 + (embed)0.01030\n",
            "Epoch 32 (train)2.7s: train loss = 0.04072 = (mf)0.03030 + (embed)0.01042\n",
            "Epoch 33 (train)2.8s: train loss = 0.03977 = (mf)0.02924 + (embed)0.01052\n",
            "Epoch 34 (train)2.5s: train loss = 0.03911 = (mf)0.02849 + (embed)0.01062\n",
            "Epoch 35 (train)2.4s + (eval)0.8s: train loss = 0.03840 = (mf)0.02768 + (embed)0.01073, recall = 0.02850, ndcg = 0.27185\n",
            "Epoch 36 (train)2.9s: train loss = 0.03720 = (mf)0.02638 + (embed)0.01082\n",
            "Epoch 37 (train)2.4s: train loss = 0.03683 = (mf)0.02591 + (embed)0.01092\n",
            "Epoch 38 (train)2.4s: train loss = 0.03595 = (mf)0.02494 + (embed)0.01101\n",
            "Epoch 39 (train)2.3s: train loss = 0.03634 = (mf)0.02526 + (embed)0.01108\n",
            "Epoch 40 (train)2.6s + (eval)0.4s: train loss = 0.03561 = (mf)0.02446 + (embed)0.01115, recall = 0.02856, ndcg = 0.28436\n",
            "Epoch 41 (train)2.6s: train loss = 0.03510 = (mf)0.02389 + (embed)0.01121\n",
            "Epoch 42 (train)2.4s: train loss = 0.03389 = (mf)0.02259 + (embed)0.01130\n",
            "Epoch 43 (train)2.3s: train loss = 0.03406 = (mf)0.02270 + (embed)0.01136\n",
            "Epoch 44 (train)2.3s: train loss = 0.03388 = (mf)0.02246 + (embed)0.01141\n",
            "Epoch 45 (train)2.9s + (eval)0.2s: train loss = 0.03334 = (mf)0.02188 + (embed)0.01146, recall = 0.02891, ndcg = 0.28001\n",
            "Epoch 46 (train)2.5s: train loss = 0.03295 = (mf)0.02144 + (embed)0.01151\n",
            "Epoch 47 (train)2.4s: train loss = 0.03227 = (mf)0.02070 + (embed)0.01157\n",
            "Epoch 48 (train)2.4s: train loss = 0.03271 = (mf)0.02110 + (embed)0.01161\n",
            "Epoch 49 (train)2.4s: train loss = 0.03177 = (mf)0.02011 + (embed)0.01166\n",
            "Epoch 50 (train)2.9s + (eval)0.7s: train loss = 0.03191 = (mf)0.02019 + (embed)0.01172, recall = 0.02929, ndcg = 0.27382\n",
            "Epoch 51 (train)2.4s: train loss = 0.03113 = (mf)0.01937 + (embed)0.01176\n",
            "Epoch 52 (train)2.4s: train loss = 0.03088 = (mf)0.01909 + (embed)0.01179\n",
            "Epoch 53 (train)2.4s: train loss = 0.03096 = (mf)0.01912 + (embed)0.01185\n",
            "Epoch 54 (train)2.8s: train loss = 0.03048 = (mf)0.01861 + (embed)0.01187\n",
            "Epoch 55 (train)2.5s + (eval)0.3s: train loss = 0.03019 = (mf)0.01826 + (embed)0.01192, recall = 0.02840, ndcg = 0.27245\n",
            "Epoch 56 (train)2.4s: train loss = 0.03046 = (mf)0.01852 + (embed)0.01194\n",
            "Epoch 57 (train)2.4s: train loss = 0.03003 = (mf)0.01806 + (embed)0.01197\n",
            "Epoch 58 (train)2.4s: train loss = 0.02924 = (mf)0.01725 + (embed)0.01199\n",
            "Epoch 59 (train)2.9s: train loss = 0.02923 = (mf)0.01719 + (embed)0.01204\n",
            "Epoch 60 (train)2.4s + (eval)0.2s: train loss = 0.02918 = (mf)0.01711 + (embed)0.01207, recall = 0.02859, ndcg = 0.27315\n",
            "Epoch 61 (train)2.4s: train loss = 0.02887 = (mf)0.01677 + (embed)0.01210\n",
            "Epoch 62 (train)2.4s: train loss = 0.02881 = (mf)0.01671 + (embed)0.01210\n",
            "Epoch 63 (train)2.4s: train loss = 0.02807 = (mf)0.01594 + (embed)0.01213\n",
            "Epoch 64 (train)2.9s: train loss = 0.02822 = (mf)0.01606 + (embed)0.01217\n",
            "Epoch 65 (train)2.4s + (eval)0.3s: train loss = 0.02821 = (mf)0.01601 + (embed)0.01219, recall = 0.02976, ndcg = 0.27453\n",
            "Epoch 66 (train)2.4s: train loss = 0.02785 = (mf)0.01561 + (embed)0.01224\n",
            "Epoch 67 (train)2.4s: train loss = 0.02759 = (mf)0.01533 + (embed)0.01226\n",
            "Epoch 68 (train)2.7s: train loss = 0.02796 = (mf)0.01569 + (embed)0.01227\n",
            "Epoch 69 (train)2.6s: train loss = 0.02733 = (mf)0.01505 + (embed)0.01229\n",
            "Epoch 70 (train)2.4s + (eval)0.7s: train loss = 0.02736 = (mf)0.01505 + (embed)0.01231, recall = 0.02910, ndcg = 0.28176\n",
            "Epoch 71 (train)2.4s: train loss = 0.02701 = (mf)0.01467 + (embed)0.01234\n",
            "Epoch 72 (train)2.4s: train loss = 0.02696 = (mf)0.01462 + (embed)0.01235\n",
            "Epoch 73 (train)3.0s: train loss = 0.02688 = (mf)0.01451 + (embed)0.01236\n",
            "Epoch 74 (train)2.4s: train loss = 0.02690 = (mf)0.01450 + (embed)0.01240\n",
            "Epoch 75 (train)2.4s + (eval)0.3s: train loss = 0.02683 = (mf)0.01442 + (embed)0.01241, recall = 0.02951, ndcg = 0.27698\n",
            "Epoch 76 (train)2.4s: train loss = 0.02660 = (mf)0.01417 + (embed)0.01243\n",
            "Epoch 77 (train)2.7s: train loss = 0.02665 = (mf)0.01421 + (embed)0.01243\n",
            "Epoch 78 (train)2.7s: train loss = 0.02654 = (mf)0.01408 + (embed)0.01246\n",
            "Epoch 79 (train)2.4s: train loss = 0.02641 = (mf)0.01395 + (embed)0.01246\n",
            "Epoch 80 (train)2.3s + (eval)0.3s: train loss = 0.02607 = (mf)0.01359 + (embed)0.01249, recall = 0.02986, ndcg = 0.27866\n",
            "Epoch 81 (train)2.4s: train loss = 0.02573 = (mf)0.01321 + (embed)0.01252\n",
            "Epoch 82 (train)2.9s: train loss = 0.02600 = (mf)0.01346 + (embed)0.01254\n",
            "Epoch 83 (train)2.4s: train loss = 0.02577 = (mf)0.01322 + (embed)0.01254\n",
            "Epoch 84 (train)2.4s: train loss = 0.02587 = (mf)0.01331 + (embed)0.01256\n",
            "Epoch 85 (train)2.4s + (eval)0.7s: train loss = 0.02543 = (mf)0.01286 + (embed)0.01258, recall = 0.03005, ndcg = 0.27788\n",
            "Epoch 86 (train)2.5s: train loss = 0.02585 = (mf)0.01326 + (embed)0.01259\n",
            "Epoch 87 (train)2.8s: train loss = 0.02525 = (mf)0.01263 + (embed)0.01263\n",
            "Epoch 88 (train)2.4s: train loss = 0.02540 = (mf)0.01276 + (embed)0.01263\n",
            "Epoch 89 (train)2.4s: train loss = 0.02541 = (mf)0.01278 + (embed)0.01264\n",
            "Epoch 90 (train)2.3s + (eval)0.3s: train loss = 0.02481 = (mf)0.01215 + (embed)0.01266, recall = 0.02923, ndcg = 0.26877\n",
            "Epoch 91 (train)2.8s: train loss = 0.02525 = (mf)0.01257 + (embed)0.01267\n",
            "Epoch 92 (train)2.5s: train loss = 0.02511 = (mf)0.01242 + (embed)0.01269\n",
            "Epoch 93 (train)2.4s: train loss = 0.02508 = (mf)0.01237 + (embed)0.01271\n",
            "Epoch 94 (train)2.4s: train loss = 0.02478 = (mf)0.01206 + (embed)0.01273\n",
            "Epoch 95 (train)2.4s + (eval)0.2s: train loss = 0.02499 = (mf)0.01227 + (embed)0.01273, recall = 0.02827, ndcg = 0.26907\n",
            "Epoch 96 (train)2.9s: train loss = 0.02500 = (mf)0.01225 + (embed)0.01275\n",
            "Epoch 97 (train)2.4s: train loss = 0.02476 = (mf)0.01202 + (embed)0.01273\n",
            "Epoch 98 (train)2.4s: train loss = 0.02469 = (mf)0.01193 + (embed)0.01276\n",
            "Epoch 99 (train)2.4s: train loss = 0.02489 = (mf)0.01212 + (embed)0.01277\n",
            "Epoch 100 (train)2.3s + (eval)0.9s: train loss = 0.02424 = (mf)0.01144 + (embed)0.01280, recall = 0.02842, ndcg = 0.28062\n",
            "Training finished in 259.90 seconds.\n",
            "Evaluation results for this combination: NDCG@20: 0.28062, Recall@20: 0.02842\n",
            "--- Trying combination: Epochs=100, TopK=20, LearningRate=0.005, Layers=5 ---\n",
            "Already normalize adjacency matrix (extended).\n",
            "Using xavier initialization for user, item, and genre embeddings.\n",
            "Epoch 1 (train)4.8s: train loss = 0.30045 = (mf)0.29986 + (embed)0.00059\n",
            "Epoch 2 (train)2.5s: train loss = 0.21356 = (mf)0.21252 + (embed)0.00104\n",
            "Epoch 3 (train)2.4s: train loss = 0.20198 = (mf)0.20055 + (embed)0.00143\n",
            "Epoch 4 (train)2.4s: train loss = 0.18139 = (mf)0.17944 + (embed)0.00195\n",
            "Epoch 5 (train)2.4s + (eval)1.4s: train loss = 0.15855 = (mf)0.15598 + (embed)0.00257, recall = 0.01572, ndcg = 0.17056\n",
            "Epoch 6 (train)2.7s: train loss = 0.14117 = (mf)0.13799 + (embed)0.00318\n",
            "Epoch 7 (train)2.4s: train loss = 0.13398 = (mf)0.13030 + (embed)0.00368\n",
            "Epoch 8 (train)2.4s: train loss = 0.12374 = (mf)0.11963 + (embed)0.00411\n",
            "Epoch 9 (train)2.4s: train loss = 0.11724 = (mf)0.11265 + (embed)0.00459\n",
            "Epoch 10 (train)2.9s + (eval)0.3s: train loss = 0.10892 = (mf)0.10381 + (embed)0.00510, recall = 0.01824, ndcg = 0.19930\n",
            "Epoch 11 (train)2.5s: train loss = 0.10077 = (mf)0.09514 + (embed)0.00564\n",
            "Epoch 12 (train)2.4s: train loss = 0.09471 = (mf)0.08854 + (embed)0.00617\n",
            "Epoch 13 (train)2.5s: train loss = 0.08840 = (mf)0.08172 + (embed)0.00668\n",
            "Epoch 14 (train)2.5s: train loss = 0.08533 = (mf)0.07818 + (embed)0.00715\n",
            "Epoch 15 (train)2.9s + (eval)0.7s: train loss = 0.08151 = (mf)0.07390 + (embed)0.00760, recall = 0.02181, ndcg = 0.22995\n",
            "Epoch 16 (train)2.4s: train loss = 0.07743 = (mf)0.06942 + (embed)0.00801\n",
            "Epoch 17 (train)2.5s: train loss = 0.07501 = (mf)0.06662 + (embed)0.00839\n",
            "Epoch 18 (train)2.4s: train loss = 0.07232 = (mf)0.06358 + (embed)0.00874\n",
            "Epoch 19 (train)2.9s: train loss = 0.07052 = (mf)0.06148 + (embed)0.00905\n",
            "Epoch 20 (train)2.4s + (eval)0.3s: train loss = 0.06818 = (mf)0.05885 + (embed)0.00934, recall = 0.02357, ndcg = 0.25061\n",
            "Epoch 21 (train)2.4s: train loss = 0.06628 = (mf)0.05667 + (embed)0.00961\n",
            "Epoch 22 (train)2.7s: train loss = 0.06392 = (mf)0.05406 + (embed)0.00987\n",
            "Epoch 23 (train)2.9s: train loss = 0.06210 = (mf)0.05197 + (embed)0.01014\n",
            "Epoch 24 (train)2.7s: train loss = 0.06190 = (mf)0.05158 + (embed)0.01032\n",
            "Epoch 25 (train)2.4s + (eval)0.3s: train loss = 0.05835 = (mf)0.04782 + (embed)0.01053, recall = 0.02650, ndcg = 0.26417\n",
            "Epoch 26 (train)2.4s: train loss = 0.05843 = (mf)0.04770 + (embed)0.01073\n",
            "Epoch 27 (train)2.4s: train loss = 0.05685 = (mf)0.04593 + (embed)0.01092\n",
            "Epoch 28 (train)2.9s: train loss = 0.05575 = (mf)0.04462 + (embed)0.01113\n",
            "Epoch 29 (train)2.5s: train loss = 0.05458 = (mf)0.04327 + (embed)0.01131\n",
            "Epoch 30 (train)2.4s + (eval)0.2s: train loss = 0.05327 = (mf)0.04182 + (embed)0.01145, recall = 0.02677, ndcg = 0.26839\n",
            "Epoch 31 (train)2.4s: train loss = 0.05259 = (mf)0.04098 + (embed)0.01160\n",
            "Epoch 32 (train)2.6s: train loss = 0.05106 = (mf)0.03931 + (embed)0.01175\n",
            "Epoch 33 (train)2.8s: train loss = 0.04939 = (mf)0.03748 + (embed)0.01191\n",
            "Epoch 34 (train)2.4s: train loss = 0.04949 = (mf)0.03743 + (embed)0.01206\n",
            "Epoch 35 (train)2.5s + (eval)0.7s: train loss = 0.04868 = (mf)0.03650 + (embed)0.01217, recall = 0.02786, ndcg = 0.26958\n",
            "Epoch 36 (train)2.5s: train loss = 0.04793 = (mf)0.03562 + (embed)0.01231\n",
            "Epoch 37 (train)3.0s: train loss = 0.04625 = (mf)0.03385 + (embed)0.01240\n",
            "Epoch 38 (train)2.5s: train loss = 0.04649 = (mf)0.03397 + (embed)0.01252\n",
            "Epoch 39 (train)2.4s: train loss = 0.04630 = (mf)0.03366 + (embed)0.01264\n",
            "Epoch 40 (train)2.5s + (eval)0.3s: train loss = 0.04492 = (mf)0.03219 + (embed)0.01273, recall = 0.02745, ndcg = 0.27588\n",
            "Epoch 41 (train)2.6s: train loss = 0.04372 = (mf)0.03087 + (embed)0.01285\n",
            "Epoch 42 (train)2.8s: train loss = 0.04368 = (mf)0.03077 + (embed)0.01291\n",
            "Epoch 43 (train)2.4s: train loss = 0.04322 = (mf)0.03023 + (embed)0.01300\n",
            "Epoch 44 (train)2.4s: train loss = 0.04209 = (mf)0.02900 + (embed)0.01309\n",
            "Epoch 45 (train)2.4s + (eval)0.2s: train loss = 0.04198 = (mf)0.02881 + (embed)0.01317, recall = 0.02866, ndcg = 0.27808\n",
            "Epoch 46 (train)2.9s: train loss = 0.04133 = (mf)0.02810 + (embed)0.01323\n",
            "Epoch 47 (train)2.4s: train loss = 0.04100 = (mf)0.02770 + (embed)0.01331\n",
            "Epoch 48 (train)2.4s: train loss = 0.04102 = (mf)0.02763 + (embed)0.01339\n",
            "Epoch 49 (train)2.4s: train loss = 0.03981 = (mf)0.02636 + (embed)0.01345\n",
            "Epoch 50 (train)2.4s + (eval)0.9s: train loss = 0.03979 = (mf)0.02632 + (embed)0.01347, recall = 0.02831, ndcg = 0.27311\n",
            "Epoch 51 (train)2.7s: train loss = 0.03914 = (mf)0.02560 + (embed)0.01354\n",
            "Epoch 52 (train)2.4s: train loss = 0.03922 = (mf)0.02559 + (embed)0.01363\n",
            "Epoch 53 (train)2.4s: train loss = 0.03904 = (mf)0.02536 + (embed)0.01368\n",
            "Epoch 54 (train)2.4s: train loss = 0.03899 = (mf)0.02527 + (embed)0.01372\n",
            "Epoch 55 (train)2.9s + (eval)0.2s: train loss = 0.03869 = (mf)0.02491 + (embed)0.01378, recall = 0.02872, ndcg = 0.27992\n",
            "Epoch 56 (train)2.5s: train loss = 0.03717 = (mf)0.02334 + (embed)0.01383\n",
            "Epoch 57 (train)2.4s: train loss = 0.03664 = (mf)0.02272 + (embed)0.01391\n",
            "Epoch 58 (train)2.4s: train loss = 0.03698 = (mf)0.02304 + (embed)0.01394\n",
            "Epoch 59 (train)2.5s: train loss = 0.03658 = (mf)0.02259 + (embed)0.01399\n",
            "Epoch 60 (train)2.9s + (eval)0.3s: train loss = 0.03659 = (mf)0.02256 + (embed)0.01403, recall = 0.02978, ndcg = 0.28132\n",
            "Epoch 61 (train)2.4s: train loss = 0.03660 = (mf)0.02255 + (embed)0.01406\n",
            "Epoch 62 (train)2.4s: train loss = 0.03646 = (mf)0.02237 + (embed)0.01409\n",
            "Epoch 63 (train)2.4s: train loss = 0.03627 = (mf)0.02211 + (embed)0.01415\n",
            "Epoch 64 (train)2.8s: train loss = 0.03576 = (mf)0.02157 + (embed)0.01420\n",
            "Epoch 65 (train)2.6s + (eval)0.7s: train loss = 0.03566 = (mf)0.02141 + (embed)0.01425, recall = 0.02851, ndcg = 0.28306\n",
            "Epoch 66 (train)2.4s: train loss = 0.03516 = (mf)0.02086 + (embed)0.01429\n",
            "Epoch 67 (train)2.4s: train loss = 0.03537 = (mf)0.02104 + (embed)0.01432\n",
            "Epoch 68 (train)2.5s: train loss = 0.03478 = (mf)0.02042 + (embed)0.01436\n",
            "Epoch 69 (train)2.9s: train loss = 0.03406 = (mf)0.01966 + (embed)0.01440\n",
            "Epoch 70 (train)2.4s + (eval)0.3s: train loss = 0.03393 = (mf)0.01950 + (embed)0.01444, recall = 0.02825, ndcg = 0.27490\n",
            "Epoch 71 (train)2.4s: train loss = 0.03415 = (mf)0.01968 + (embed)0.01447\n",
            "Epoch 72 (train)2.4s: train loss = 0.03358 = (mf)0.01907 + (embed)0.01451\n",
            "Epoch 73 (train)2.8s: train loss = 0.03382 = (mf)0.01929 + (embed)0.01453\n",
            "Epoch 74 (train)2.6s: train loss = 0.03368 = (mf)0.01911 + (embed)0.01457\n",
            "Epoch 75 (train)2.4s + (eval)0.3s: train loss = 0.03367 = (mf)0.01908 + (embed)0.01459, recall = 0.02891, ndcg = 0.28136\n",
            "Epoch 76 (train)2.4s: train loss = 0.03313 = (mf)0.01851 + (embed)0.01462\n",
            "Epoch 77 (train)2.4s: train loss = 0.03290 = (mf)0.01822 + (embed)0.01468\n",
            "Epoch 78 (train)3.0s: train loss = 0.03255 = (mf)0.01785 + (embed)0.01470\n",
            "Epoch 79 (train)2.4s: train loss = 0.03315 = (mf)0.01842 + (embed)0.01473\n",
            "Epoch 80 (train)2.4s + (eval)0.3s: train loss = 0.03251 = (mf)0.01778 + (embed)0.01473, recall = 0.02860, ndcg = 0.28016\n",
            "Epoch 81 (train)2.4s: train loss = 0.03280 = (mf)0.01803 + (embed)0.01476\n",
            "Epoch 82 (train)2.7s: train loss = 0.03306 = (mf)0.01827 + (embed)0.01479\n",
            "Epoch 83 (train)2.7s: train loss = 0.03261 = (mf)0.01780 + (embed)0.01481\n",
            "Epoch 84 (train)2.4s: train loss = 0.03233 = (mf)0.01750 + (embed)0.01483\n",
            "Epoch 85 (train)2.4s + (eval)0.7s: train loss = 0.03199 = (mf)0.01715 + (embed)0.01484, recall = 0.02780, ndcg = 0.28340\n",
            "Epoch 86 (train)2.4s: train loss = 0.03176 = (mf)0.01688 + (embed)0.01489\n",
            "Epoch 87 (train)3.0s: train loss = 0.03213 = (mf)0.01722 + (embed)0.01491\n",
            "Epoch 88 (train)2.4s: train loss = 0.03150 = (mf)0.01657 + (embed)0.01493\n",
            "Epoch 89 (train)2.4s: train loss = 0.03111 = (mf)0.01613 + (embed)0.01498\n",
            "Epoch 90 (train)2.4s + (eval)0.3s: train loss = 0.03152 = (mf)0.01651 + (embed)0.01502, recall = 0.02887, ndcg = 0.28964\n",
            "Epoch 91 (train)2.7s: train loss = 0.03144 = (mf)0.01642 + (embed)0.01502\n",
            "Epoch 92 (train)2.7s: train loss = 0.03139 = (mf)0.01634 + (embed)0.01505\n",
            "Epoch 93 (train)2.4s: train loss = 0.03127 = (mf)0.01620 + (embed)0.01507\n",
            "Epoch 94 (train)2.4s: train loss = 0.03089 = (mf)0.01578 + (embed)0.01511\n",
            "Epoch 95 (train)2.4s + (eval)0.2s: train loss = 0.03098 = (mf)0.01585 + (embed)0.01513, recall = 0.02910, ndcg = 0.28982\n",
            "Epoch 96 (train)3.0s: train loss = 0.03079 = (mf)0.01562 + (embed)0.01517\n",
            "Epoch 97 (train)2.5s: train loss = 0.03076 = (mf)0.01558 + (embed)0.01518\n",
            "Epoch 98 (train)2.4s: train loss = 0.03097 = (mf)0.01575 + (embed)0.01522\n",
            "Epoch 99 (train)2.4s: train loss = 0.03047 = (mf)0.01523 + (embed)0.01524\n",
            "Epoch 100 (train)2.5s + (eval)0.9s: train loss = 0.03065 = (mf)0.01539 + (embed)0.01526, recall = 0.02896, ndcg = 0.29143\n",
            "Training finished in 266.15 seconds.\n",
            "Evaluation results for this combination: NDCG@20: 0.29143, Recall@20: 0.02896\n",
            "--- Trying combination: Epochs=100, TopK=20, LearningRate=0.05, Layers=3 ---\n",
            "Already normalize adjacency matrix (extended).\n",
            "Using xavier initialization for user, item, and genre embeddings.\n",
            "Epoch 1 (train)4.7s: train loss = 0.15325 = (mf)0.14998 + (embed)0.00327\n",
            "Epoch 2 (train)2.4s: train loss = 0.07045 = (mf)0.06261 + (embed)0.00784\n",
            "Epoch 3 (train)2.4s: train loss = 0.05470 = (mf)0.04355 + (embed)0.01115\n",
            "Epoch 4 (train)2.4s: train loss = 0.04937 = (mf)0.03587 + (embed)0.01349\n",
            "Epoch 5 (train)2.4s + (eval)1.5s: train loss = 0.04761 = (mf)0.03244 + (embed)0.01517, recall = 0.02135, ndcg = 0.19437\n",
            "Epoch 6 (train)2.6s: train loss = 0.04533 = (mf)0.02885 + (embed)0.01647\n",
            "Epoch 7 (train)2.4s: train loss = 0.04405 = (mf)0.02654 + (embed)0.01750\n",
            "Epoch 8 (train)2.4s: train loss = 0.04462 = (mf)0.02617 + (embed)0.01845\n",
            "Epoch 9 (train)2.4s: train loss = 0.04510 = (mf)0.02580 + (embed)0.01930\n",
            "Epoch 10 (train)3.6s + (eval)0.4s: train loss = 0.04536 = (mf)0.02526 + (embed)0.02009, recall = 0.02040, ndcg = 0.17066\n",
            "Epoch 11 (train)2.4s: train loss = 0.04593 = (mf)0.02508 + (embed)0.02085\n",
            "Epoch 12 (train)2.4s: train loss = 0.04640 = (mf)0.02477 + (embed)0.02164\n",
            "Epoch 13 (train)2.4s: train loss = 0.04531 = (mf)0.02318 + (embed)0.02213\n",
            "Epoch 14 (train)2.3s: train loss = 0.04772 = (mf)0.02497 + (embed)0.02275\n",
            "Epoch 15 (train)2.9s + (eval)0.7s: train loss = 0.04758 = (mf)0.02429 + (embed)0.02329, recall = 0.02027, ndcg = 0.18369\n",
            "Epoch 16 (train)2.5s: train loss = 0.04699 = (mf)0.02327 + (embed)0.02371\n",
            "Epoch 17 (train)2.4s: train loss = 0.04660 = (mf)0.02258 + (embed)0.02402\n",
            "Epoch 18 (train)2.3s: train loss = 0.04799 = (mf)0.02357 + (embed)0.02442\n",
            "Epoch 19 (train)2.6s: train loss = 0.04815 = (mf)0.02341 + (embed)0.02474\n",
            "Epoch 20 (train)2.7s + (eval)0.3s: train loss = 0.04789 = (mf)0.02278 + (embed)0.02511, recall = 0.01923, ndcg = 0.16278\n",
            "Epoch 21 (train)2.4s: train loss = 0.04810 = (mf)0.02268 + (embed)0.02542\n",
            "Epoch 22 (train)2.4s: train loss = 0.04793 = (mf)0.02225 + (embed)0.02568\n",
            "Epoch 23 (train)2.4s: train loss = 0.04883 = (mf)0.02298 + (embed)0.02586\n",
            "Epoch 24 (train)2.9s: train loss = 0.04897 = (mf)0.02282 + (embed)0.02614\n",
            "Epoch 25 (train)2.4s + (eval)0.3s: train loss = 0.04908 = (mf)0.02269 + (embed)0.02640, recall = 0.02006, ndcg = 0.15961\n",
            "Epoch 26 (train)2.4s: train loss = 0.04855 = (mf)0.02201 + (embed)0.02654\n",
            "Epoch 27 (train)2.4s: train loss = 0.04949 = (mf)0.02282 + (embed)0.02667\n",
            "Epoch 28 (train)2.4s: train loss = 0.04865 = (mf)0.02185 + (embed)0.02680\n",
            "Epoch 29 (train)2.9s: train loss = 0.04791 = (mf)0.02113 + (embed)0.02678\n",
            "Epoch 30 (train)2.4s + (eval)0.2s: train loss = 0.04837 = (mf)0.02149 + (embed)0.02688, recall = 0.02133, ndcg = 0.17012\n",
            "Epoch 31 (train)2.3s: train loss = 0.04734 = (mf)0.02035 + (embed)0.02699\n",
            "Epoch 32 (train)2.4s: train loss = 0.04775 = (mf)0.02074 + (embed)0.02702\n",
            "Epoch 33 (train)2.5s: train loss = 0.04838 = (mf)0.02119 + (embed)0.02719\n",
            "Epoch 34 (train)2.7s: train loss = 0.04781 = (mf)0.02051 + (embed)0.02730\n",
            "Epoch 35 (train)2.4s + (eval)0.7s: train loss = 0.04871 = (mf)0.02140 + (embed)0.02731, recall = 0.02063, ndcg = 0.16502\n",
            "Epoch 36 (train)2.4s: train loss = 0.04826 = (mf)0.02087 + (embed)0.02739\n",
            "Epoch 37 (train)2.4s: train loss = 0.04845 = (mf)0.02100 + (embed)0.02744\n",
            "Epoch 38 (train)2.9s: train loss = 0.04838 = (mf)0.02076 + (embed)0.02762\n",
            "Epoch 39 (train)2.4s: train loss = 0.04815 = (mf)0.02044 + (embed)0.02771\n",
            "Epoch 40 (train)2.4s + (eval)0.3s: train loss = 0.04787 = (mf)0.02016 + (embed)0.02771, recall = 0.01967, ndcg = 0.16762\n",
            "Epoch 41 (train)2.3s: train loss = 0.04800 = (mf)0.02023 + (embed)0.02777\n",
            "Epoch 42 (train)2.3s: train loss = 0.04707 = (mf)0.01924 + (embed)0.02782\n",
            "Epoch 43 (train)2.9s: train loss = 0.04763 = (mf)0.01968 + (embed)0.02795\n",
            "Epoch 44 (train)2.4s: train loss = 0.04851 = (mf)0.02062 + (embed)0.02790\n",
            "Epoch 45 (train)2.4s + (eval)0.3s: train loss = 0.04863 = (mf)0.02067 + (embed)0.02797, recall = 0.02131, ndcg = 0.17029\n",
            "Epoch 46 (train)2.4s: train loss = 0.04838 = (mf)0.02039 + (embed)0.02799\n",
            "Epoch 47 (train)2.6s: train loss = 0.04859 = (mf)0.02065 + (embed)0.02794\n",
            "Epoch 48 (train)2.7s: train loss = 0.04812 = (mf)0.02016 + (embed)0.02796\n",
            "Epoch 49 (train)2.4s: train loss = 0.04855 = (mf)0.02050 + (embed)0.02804\n",
            "Epoch 50 (train)2.4s + (eval)0.3s: train loss = 0.04915 = (mf)0.02100 + (embed)0.02814, recall = 0.01974, ndcg = 0.16377\n",
            "Epoch 51 (train)2.4s: train loss = 0.04875 = (mf)0.02060 + (embed)0.02815\n",
            "Epoch 52 (train)2.9s: train loss = 0.04863 = (mf)0.02040 + (embed)0.02823\n",
            "Epoch 53 (train)2.5s: train loss = 0.04866 = (mf)0.02033 + (embed)0.02833\n",
            "Epoch 54 (train)2.4s: train loss = 0.04823 = (mf)0.01992 + (embed)0.02832\n",
            "Epoch 55 (train)2.4s + (eval)0.7s: train loss = 0.04754 = (mf)0.01914 + (embed)0.02840, recall = 0.02109, ndcg = 0.16883\n",
            "Epoch 56 (train)2.6s: train loss = 0.04790 = (mf)0.01946 + (embed)0.02844\n",
            "Epoch 57 (train)2.8s: train loss = 0.04835 = (mf)0.01996 + (embed)0.02840\n",
            "Epoch 58 (train)2.4s: train loss = 0.04948 = (mf)0.02097 + (embed)0.02852\n",
            "Epoch 59 (train)2.4s: train loss = 0.04780 = (mf)0.01918 + (embed)0.02861\n",
            "Epoch 60 (train)2.3s + (eval)0.3s: train loss = 0.04754 = (mf)0.01897 + (embed)0.02857, recall = 0.02082, ndcg = 0.18070\n",
            "Epoch 61 (train)2.8s: train loss = 0.04778 = (mf)0.01928 + (embed)0.02850\n",
            "Epoch 62 (train)2.5s: train loss = 0.04849 = (mf)0.02004 + (embed)0.02845\n",
            "Epoch 63 (train)2.4s: train loss = 0.04815 = (mf)0.01971 + (embed)0.02845\n",
            "Epoch 64 (train)2.4s: train loss = 0.04868 = (mf)0.02035 + (embed)0.02833\n",
            "Epoch 65 (train)2.4s + (eval)0.2s: train loss = 0.04978 = (mf)0.02133 + (embed)0.02844, recall = 0.01860, ndcg = 0.17530\n",
            "Epoch 66 (train)2.9s: train loss = 0.04869 = (mf)0.02019 + (embed)0.02850\n",
            "Epoch 67 (train)2.4s: train loss = 0.05001 = (mf)0.02149 + (embed)0.02852\n",
            "Epoch 68 (train)2.4s: train loss = 0.04912 = (mf)0.02039 + (embed)0.02873\n",
            "Epoch 69 (train)2.3s: train loss = 0.04931 = (mf)0.02053 + (embed)0.02877\n",
            "Epoch 70 (train)2.4s + (eval)0.9s: train loss = 0.04789 = (mf)0.01923 + (embed)0.02865, recall = 0.01935, ndcg = 0.16216\n",
            "Epoch 71 (train)2.7s: train loss = 0.04934 = (mf)0.02067 + (embed)0.02867\n",
            "Epoch 72 (train)2.4s: train loss = 0.04829 = (mf)0.01956 + (embed)0.02873\n",
            "Epoch 73 (train)2.4s: train loss = 0.04750 = (mf)0.01890 + (embed)0.02860\n",
            "Epoch 74 (train)2.4s: train loss = 0.04826 = (mf)0.01968 + (embed)0.02858\n",
            "Epoch 75 (train)2.8s + (eval)0.4s: train loss = 0.04880 = (mf)0.02030 + (embed)0.02850, recall = 0.01871, ndcg = 0.15325\n",
            "Epoch 76 (train)2.4s: train loss = 0.04846 = (mf)0.01998 + (embed)0.02848\n",
            "Epoch 77 (train)2.4s: train loss = 0.04858 = (mf)0.02007 + (embed)0.02851\n",
            "Epoch 78 (train)2.4s: train loss = 0.04774 = (mf)0.01929 + (embed)0.02845\n",
            "Epoch 79 (train)2.3s: train loss = 0.04755 = (mf)0.01903 + (embed)0.02853\n",
            "Epoch 80 (train)2.9s + (eval)0.2s: train loss = 0.04668 = (mf)0.01827 + (embed)0.02842, recall = 0.01872, ndcg = 0.15019\n",
            "Epoch 81 (train)2.4s: train loss = 0.04785 = (mf)0.01945 + (embed)0.02841\n",
            "Epoch 82 (train)2.4s: train loss = 0.04766 = (mf)0.01925 + (embed)0.02841\n",
            "Epoch 83 (train)2.4s: train loss = 0.04662 = (mf)0.01822 + (embed)0.02840\n",
            "Epoch 84 (train)2.4s: train loss = 0.04728 = (mf)0.01889 + (embed)0.02839\n",
            "Epoch 85 (train)2.9s + (eval)0.2s: train loss = 0.04642 = (mf)0.01802 + (embed)0.02840, recall = 0.01886, ndcg = 0.17408\n",
            "Epoch 86 (train)2.4s: train loss = 0.04794 = (mf)0.01961 + (embed)0.02833\n",
            "Epoch 87 (train)2.4s: train loss = 0.04899 = (mf)0.02057 + (embed)0.02841\n",
            "Epoch 88 (train)2.3s: train loss = 0.04745 = (mf)0.01900 + (embed)0.02845\n",
            "Epoch 89 (train)2.6s: train loss = 0.04827 = (mf)0.01990 + (embed)0.02837\n",
            "Epoch 90 (train)2.6s + (eval)0.7s: train loss = 0.04820 = (mf)0.01977 + (embed)0.02843, recall = 0.01954, ndcg = 0.16645\n",
            "Epoch 91 (train)2.4s: train loss = 0.04839 = (mf)0.01996 + (embed)0.02844\n",
            "Epoch 92 (train)2.4s: train loss = 0.04722 = (mf)0.01875 + (embed)0.02847\n",
            "Epoch 93 (train)2.4s: train loss = 0.04834 = (mf)0.01982 + (embed)0.02852\n",
            "Epoch 94 (train)2.9s: train loss = 0.04847 = (mf)0.02001 + (embed)0.02846\n",
            "Epoch 95 (train)2.4s + (eval)0.3s: train loss = 0.04820 = (mf)0.01970 + (embed)0.02850, recall = 0.01919, ndcg = 0.16165\n",
            "Epoch 96 (train)2.4s: train loss = 0.04867 = (mf)0.02015 + (embed)0.02852\n",
            "Epoch 97 (train)2.4s: train loss = 0.04821 = (mf)0.01960 + (embed)0.02860\n",
            "Epoch 98 (train)2.4s: train loss = 0.04747 = (mf)0.01885 + (embed)0.02863\n",
            "Epoch 99 (train)2.9s: train loss = 0.04695 = (mf)0.01847 + (embed)0.02848\n",
            "Epoch 100 (train)2.4s + (eval)0.3s: train loss = 0.04632 = (mf)0.01797 + (embed)0.02835, recall = 0.01919, ndcg = 0.18145\n",
            "Training finished in 259.78 seconds.\n",
            "Evaluation results for this combination: NDCG@20: 0.18145, Recall@20: 0.01919\n",
            "--- Trying combination: Epochs=100, TopK=20, LearningRate=0.05, Layers=4 ---\n",
            "Already normalize adjacency matrix (extended).\n",
            "Using xavier initialization for user, item, and genre embeddings.\n",
            "Epoch 1 (train)4.2s: train loss = 0.17175 = (mf)0.16837 + (embed)0.00337\n",
            "Epoch 2 (train)2.4s: train loss = 0.08359 = (mf)0.07536 + (embed)0.00823\n",
            "Epoch 3 (train)2.4s: train loss = 0.06286 = (mf)0.05112 + (embed)0.01174\n",
            "Epoch 4 (train)3.0s: train loss = 0.05333 = (mf)0.03908 + (embed)0.01425\n",
            "Epoch 5 (train)2.4s + (eval)1.2s: train loss = 0.04896 = (mf)0.03296 + (embed)0.01600, recall = 0.02340, ndcg = 0.22492\n",
            "Epoch 6 (train)2.5s: train loss = 0.04671 = (mf)0.02931 + (embed)0.01740\n",
            "Epoch 7 (train)2.4s: train loss = 0.04518 = (mf)0.02672 + (embed)0.01846\n",
            "Epoch 8 (train)2.9s: train loss = 0.04352 = (mf)0.02422 + (embed)0.01929\n",
            "Epoch 9 (train)2.4s: train loss = 0.04302 = (mf)0.02309 + (embed)0.01993\n",
            "Epoch 10 (train)2.4s + (eval)0.2s: train loss = 0.04268 = (mf)0.02214 + (embed)0.02053, recall = 0.02109, ndcg = 0.21564\n",
            "Epoch 11 (train)2.4s: train loss = 0.04273 = (mf)0.02166 + (embed)0.02106\n",
            "Epoch 12 (train)2.4s: train loss = 0.04231 = (mf)0.02071 + (embed)0.02160\n",
            "Epoch 13 (train)2.9s: train loss = 0.04148 = (mf)0.01951 + (embed)0.02197\n",
            "Epoch 14 (train)2.4s: train loss = 0.04146 = (mf)0.01920 + (embed)0.02227\n",
            "Epoch 15 (train)2.4s + (eval)0.7s: train loss = 0.04105 = (mf)0.01846 + (embed)0.02258, recall = 0.02226, ndcg = 0.20482\n",
            "Epoch 16 (train)2.4s: train loss = 0.04185 = (mf)0.01890 + (embed)0.02295\n",
            "Epoch 17 (train)2.9s: train loss = 0.04138 = (mf)0.01819 + (embed)0.02319\n",
            "Epoch 18 (train)2.5s: train loss = 0.04110 = (mf)0.01766 + (embed)0.02343\n",
            "Epoch 19 (train)2.4s: train loss = 0.04179 = (mf)0.01810 + (embed)0.02369\n",
            "Epoch 20 (train)2.4s + (eval)0.2s: train loss = 0.04102 = (mf)0.01709 + (embed)0.02393, recall = 0.02332, ndcg = 0.20874\n",
            "Epoch 21 (train)2.4s: train loss = 0.04180 = (mf)0.01773 + (embed)0.02407\n",
            "Epoch 22 (train)2.9s: train loss = 0.04118 = (mf)0.01694 + (embed)0.02424\n",
            "Epoch 23 (train)2.4s: train loss = 0.04208 = (mf)0.01773 + (embed)0.02435\n",
            "Epoch 24 (train)2.4s: train loss = 0.04136 = (mf)0.01684 + (embed)0.02452\n",
            "Epoch 25 (train)2.4s + (eval)0.3s: train loss = 0.04253 = (mf)0.01791 + (embed)0.02462, recall = 0.02154, ndcg = 0.19139\n",
            "Epoch 26 (train)2.6s: train loss = 0.04207 = (mf)0.01737 + (embed)0.02470\n",
            "Epoch 27 (train)2.7s: train loss = 0.04072 = (mf)0.01600 + (embed)0.02472\n",
            "Epoch 28 (train)2.4s: train loss = 0.04192 = (mf)0.01715 + (embed)0.02477\n",
            "Epoch 29 (train)2.4s: train loss = 0.04071 = (mf)0.01581 + (embed)0.02489\n",
            "Epoch 30 (train)2.3s + (eval)0.3s: train loss = 0.04236 = (mf)0.01735 + (embed)0.02501, recall = 0.02112, ndcg = 0.18216\n",
            "Epoch 31 (train)3.0s: train loss = 0.04127 = (mf)0.01615 + (embed)0.02512\n",
            "Epoch 32 (train)2.5s: train loss = 0.04096 = (mf)0.01591 + (embed)0.02505\n",
            "Epoch 33 (train)2.4s: train loss = 0.04059 = (mf)0.01566 + (embed)0.02493\n",
            "Epoch 34 (train)2.5s: train loss = 0.04087 = (mf)0.01599 + (embed)0.02488\n",
            "Epoch 35 (train)2.5s + (eval)0.9s: train loss = 0.04065 = (mf)0.01578 + (embed)0.02487, recall = 0.02262, ndcg = 0.20115\n",
            "Epoch 36 (train)2.8s: train loss = 0.04026 = (mf)0.01538 + (embed)0.02487\n",
            "Epoch 37 (train)2.4s: train loss = 0.04088 = (mf)0.01586 + (embed)0.02502\n",
            "Epoch 38 (train)2.4s: train loss = 0.04159 = (mf)0.01652 + (embed)0.02507\n",
            "Epoch 39 (train)2.4s: train loss = 0.04157 = (mf)0.01647 + (embed)0.02510\n",
            "Epoch 40 (train)2.9s + (eval)0.3s: train loss = 0.04183 = (mf)0.01659 + (embed)0.02524, recall = 0.02232, ndcg = 0.20110\n",
            "Epoch 41 (train)2.5s: train loss = 0.04214 = (mf)0.01681 + (embed)0.02534\n",
            "Epoch 42 (train)2.4s: train loss = 0.04213 = (mf)0.01666 + (embed)0.02547\n",
            "Epoch 43 (train)2.4s: train loss = 0.04134 = (mf)0.01586 + (embed)0.02549\n",
            "Epoch 44 (train)2.4s: train loss = 0.04106 = (mf)0.01560 + (embed)0.02546\n",
            "Epoch 45 (train)2.9s + (eval)0.3s: train loss = 0.04116 = (mf)0.01563 + (embed)0.02553, recall = 0.02309, ndcg = 0.20746\n",
            "Epoch 46 (train)2.4s: train loss = 0.04165 = (mf)0.01615 + (embed)0.02550\n",
            "Epoch 47 (train)2.4s: train loss = 0.04059 = (mf)0.01508 + (embed)0.02551\n",
            "Epoch 48 (train)2.4s: train loss = 0.04109 = (mf)0.01560 + (embed)0.02549\n",
            "Epoch 49 (train)2.6s: train loss = 0.04091 = (mf)0.01550 + (embed)0.02540\n",
            "Epoch 50 (train)2.7s + (eval)0.2s: train loss = 0.04022 = (mf)0.01488 + (embed)0.02534, recall = 0.02528, ndcg = 0.19358\n",
            "Epoch 51 (train)2.4s: train loss = 0.04052 = (mf)0.01528 + (embed)0.02524\n",
            "Epoch 52 (train)2.4s: train loss = 0.04132 = (mf)0.01601 + (embed)0.02531\n",
            "Epoch 53 (train)2.4s: train loss = 0.03979 = (mf)0.01450 + (embed)0.02528\n",
            "Epoch 54 (train)2.9s: train loss = 0.04100 = (mf)0.01579 + (embed)0.02522\n",
            "Epoch 55 (train)2.4s + (eval)0.7s: train loss = 0.04151 = (mf)0.01619 + (embed)0.02532, recall = 0.02372, ndcg = 0.19163\n",
            "Epoch 56 (train)2.4s: train loss = 0.04056 = (mf)0.01514 + (embed)0.02542\n",
            "Epoch 57 (train)2.4s: train loss = 0.04104 = (mf)0.01566 + (embed)0.02537\n",
            "Epoch 58 (train)2.5s: train loss = 0.04031 = (mf)0.01493 + (embed)0.02537\n",
            "Epoch 59 (train)2.8s: train loss = 0.04089 = (mf)0.01540 + (embed)0.02550\n",
            "Epoch 60 (train)2.4s + (eval)0.2s: train loss = 0.04059 = (mf)0.01514 + (embed)0.02545, recall = 0.02327, ndcg = 0.20692\n",
            "Epoch 61 (train)2.4s: train loss = 0.03963 = (mf)0.01428 + (embed)0.02536\n",
            "Epoch 62 (train)2.4s: train loss = 0.04023 = (mf)0.01498 + (embed)0.02526\n",
            "Epoch 63 (train)2.9s: train loss = 0.03929 = (mf)0.01418 + (embed)0.02511\n",
            "Epoch 64 (train)2.5s: train loss = 0.03960 = (mf)0.01456 + (embed)0.02504\n",
            "Epoch 65 (train)2.4s + (eval)0.3s: train loss = 0.04038 = (mf)0.01521 + (embed)0.02517, recall = 0.02260, ndcg = 0.20623\n",
            "Epoch 66 (train)2.4s: train loss = 0.04031 = (mf)0.01515 + (embed)0.02516\n",
            "Epoch 67 (train)2.4s: train loss = 0.04080 = (mf)0.01560 + (embed)0.02520\n",
            "Epoch 68 (train)3.0s: train loss = 0.03971 = (mf)0.01451 + (embed)0.02520\n",
            "Epoch 69 (train)2.4s: train loss = 0.03952 = (mf)0.01439 + (embed)0.02513\n",
            "Epoch 70 (train)2.4s + (eval)0.7s: train loss = 0.04006 = (mf)0.01493 + (embed)0.02513, recall = 0.02237, ndcg = 0.19769\n",
            "Epoch 71 (train)2.5s: train loss = 0.04033 = (mf)0.01520 + (embed)0.02513\n",
            "Epoch 72 (train)2.8s: train loss = 0.04070 = (mf)0.01540 + (embed)0.02530\n",
            "Epoch 73 (train)2.5s: train loss = 0.04036 = (mf)0.01506 + (embed)0.02530\n",
            "Epoch 74 (train)2.4s: train loss = 0.04014 = (mf)0.01483 + (embed)0.02531\n",
            "Epoch 75 (train)2.4s + (eval)0.3s: train loss = 0.04011 = (mf)0.01483 + (embed)0.02527, recall = 0.02544, ndcg = 0.20550\n",
            "Epoch 76 (train)2.4s: train loss = 0.04120 = (mf)0.01592 + (embed)0.02528\n",
            "Epoch 77 (train)2.9s: train loss = 0.04029 = (mf)0.01487 + (embed)0.02542\n",
            "Epoch 78 (train)2.4s: train loss = 0.04003 = (mf)0.01463 + (embed)0.02541\n",
            "Epoch 79 (train)2.4s: train loss = 0.03985 = (mf)0.01450 + (embed)0.02535\n",
            "Epoch 80 (train)2.4s + (eval)0.3s: train loss = 0.03989 = (mf)0.01462 + (embed)0.02527, recall = 0.02269, ndcg = 0.19752\n",
            "Epoch 81 (train)2.6s: train loss = 0.04030 = (mf)0.01518 + (embed)0.02512\n",
            "Epoch 82 (train)2.8s: train loss = 0.04033 = (mf)0.01510 + (embed)0.02523\n",
            "Epoch 83 (train)2.4s: train loss = 0.04000 = (mf)0.01476 + (embed)0.02523\n",
            "Epoch 84 (train)2.4s: train loss = 0.04011 = (mf)0.01484 + (embed)0.02527\n",
            "Epoch 85 (train)2.4s + (eval)0.3s: train loss = 0.03995 = (mf)0.01469 + (embed)0.02526, recall = 0.02402, ndcg = 0.20854\n",
            "Epoch 86 (train)2.9s: train loss = 0.04072 = (mf)0.01539 + (embed)0.02534\n",
            "Epoch 87 (train)2.5s: train loss = 0.04052 = (mf)0.01515 + (embed)0.02537\n",
            "Epoch 88 (train)2.4s: train loss = 0.04030 = (mf)0.01491 + (embed)0.02538\n",
            "Epoch 89 (train)2.4s: train loss = 0.04018 = (mf)0.01485 + (embed)0.02532\n",
            "Epoch 90 (train)2.4s + (eval)0.9s: train loss = 0.04068 = (mf)0.01525 + (embed)0.02542, recall = 0.02303, ndcg = 0.20706\n",
            "Epoch 91 (train)3.7s: train loss = 0.04104 = (mf)0.01561 + (embed)0.02543\n",
            "Epoch 92 (train)2.4s: train loss = 0.03940 = (mf)0.01400 + (embed)0.02540\n",
            "Epoch 93 (train)2.4s: train loss = 0.04014 = (mf)0.01491 + (embed)0.02523\n",
            "Epoch 94 (train)2.4s: train loss = 0.04037 = (mf)0.01508 + (embed)0.02529\n",
            "Epoch 95 (train)2.6s + (eval)0.4s: train loss = 0.03920 = (mf)0.01394 + (embed)0.02526, recall = 0.02487, ndcg = 0.21395\n",
            "Epoch 96 (train)2.7s: train loss = 0.03956 = (mf)0.01433 + (embed)0.02523\n",
            "Epoch 97 (train)2.4s: train loss = 0.03998 = (mf)0.01482 + (embed)0.02516\n",
            "Epoch 98 (train)2.4s: train loss = 0.04011 = (mf)0.01486 + (embed)0.02525\n",
            "Epoch 99 (train)2.4s: train loss = 0.04054 = (mf)0.01524 + (embed)0.02530\n",
            "Epoch 100 (train)2.9s + (eval)0.2s: train loss = 0.03994 = (mf)0.01461 + (embed)0.02534, recall = 0.02396, ndcg = 0.20479\n",
            "Training finished in 262.93 seconds.\n",
            "Evaluation results for this combination: NDCG@20: 0.20479, Recall@20: 0.02396\n",
            "--- Trying combination: Epochs=100, TopK=20, LearningRate=0.05, Layers=5 ---\n",
            "Already normalize adjacency matrix (extended).\n",
            "Using xavier initialization for user, item, and genre embeddings.\n",
            "Epoch 1 (train)5.0s: train loss = 0.18006 = (mf)0.17646 + (embed)0.00360\n",
            "Epoch 2 (train)2.4s: train loss = 0.09444 = (mf)0.08546 + (embed)0.00898\n",
            "Epoch 3 (train)2.4s: train loss = 0.07100 = (mf)0.05795 + (embed)0.01305\n",
            "Epoch 4 (train)2.4s: train loss = 0.06044 = (mf)0.04464 + (embed)0.01580\n",
            "Epoch 5 (train)2.9s + (eval)1.6s: train loss = 0.05581 = (mf)0.03826 + (embed)0.01756, recall = 0.02452, ndcg = 0.21407\n",
            "Epoch 6 (train)2.6s: train loss = 0.05200 = (mf)0.03301 + (embed)0.01900\n",
            "Epoch 7 (train)2.4s: train loss = 0.04978 = (mf)0.02984 + (embed)0.01994\n",
            "Epoch 8 (train)2.4s: train loss = 0.04779 = (mf)0.02701 + (embed)0.02078\n",
            "Epoch 9 (train)2.9s: train loss = 0.04607 = (mf)0.02468 + (embed)0.02139\n",
            "Epoch 10 (train)2.5s + (eval)0.2s: train loss = 0.04549 = (mf)0.02358 + (embed)0.02191, recall = 0.02468, ndcg = 0.21940\n",
            "Epoch 11 (train)2.4s: train loss = 0.04458 = (mf)0.02222 + (embed)0.02236\n",
            "Epoch 12 (train)2.4s: train loss = 0.04440 = (mf)0.02165 + (embed)0.02275\n",
            "Epoch 13 (train)2.4s: train loss = 0.04444 = (mf)0.02130 + (embed)0.02314\n",
            "Epoch 14 (train)3.0s: train loss = 0.04361 = (mf)0.02023 + (embed)0.02338\n",
            "Epoch 15 (train)2.5s + (eval)0.3s: train loss = 0.04296 = (mf)0.01929 + (embed)0.02368, recall = 0.02635, ndcg = 0.22215\n",
            "Epoch 16 (train)2.5s: train loss = 0.04298 = (mf)0.01907 + (embed)0.02391\n",
            "Epoch 17 (train)2.4s: train loss = 0.04270 = (mf)0.01864 + (embed)0.02407\n",
            "Epoch 18 (train)2.9s: train loss = 0.04153 = (mf)0.01729 + (embed)0.02424\n",
            "Epoch 19 (train)2.6s: train loss = 0.04171 = (mf)0.01740 + (embed)0.02432\n",
            "Epoch 20 (train)2.4s + (eval)0.7s: train loss = 0.04199 = (mf)0.01746 + (embed)0.02453, recall = 0.02354, ndcg = 0.20153\n",
            "Epoch 21 (train)2.4s: train loss = 0.04210 = (mf)0.01740 + (embed)0.02470\n",
            "Epoch 22 (train)2.5s: train loss = 0.04145 = (mf)0.01658 + (embed)0.02487\n",
            "Epoch 23 (train)2.9s: train loss = 0.04167 = (mf)0.01676 + (embed)0.02492\n",
            "Epoch 24 (train)2.4s: train loss = 0.04107 = (mf)0.01609 + (embed)0.02498\n",
            "Epoch 25 (train)2.4s + (eval)0.2s: train loss = 0.04092 = (mf)0.01582 + (embed)0.02510, recall = 0.02492, ndcg = 0.21996\n",
            "Epoch 26 (train)2.5s: train loss = 0.04090 = (mf)0.01580 + (embed)0.02509\n",
            "Epoch 27 (train)2.9s: train loss = 0.04132 = (mf)0.01609 + (embed)0.02523\n",
            "Epoch 28 (train)2.5s: train loss = 0.04144 = (mf)0.01615 + (embed)0.02528\n",
            "Epoch 29 (train)2.4s: train loss = 0.04069 = (mf)0.01546 + (embed)0.02523\n",
            "Epoch 30 (train)2.4s + (eval)0.2s: train loss = 0.04055 = (mf)0.01522 + (embed)0.02533, recall = 0.02423, ndcg = 0.20132\n",
            "Epoch 31 (train)2.4s: train loss = 0.04115 = (mf)0.01579 + (embed)0.02536\n",
            "Epoch 32 (train)3.0s: train loss = 0.04130 = (mf)0.01586 + (embed)0.02544\n",
            "Epoch 33 (train)2.4s: train loss = 0.04157 = (mf)0.01605 + (embed)0.02552\n",
            "Epoch 34 (train)2.5s: train loss = 0.04097 = (mf)0.01537 + (embed)0.02559\n",
            "Epoch 35 (train)2.4s + (eval)0.2s: train loss = 0.04031 = (mf)0.01476 + (embed)0.02555, recall = 0.02516, ndcg = 0.22735\n",
            "Epoch 36 (train)2.8s: train loss = 0.04140 = (mf)0.01589 + (embed)0.02551\n",
            "Epoch 37 (train)2.6s: train loss = 0.04124 = (mf)0.01560 + (embed)0.02564\n",
            "Epoch 38 (train)2.4s: train loss = 0.04123 = (mf)0.01548 + (embed)0.02575\n",
            "Epoch 39 (train)2.5s: train loss = 0.04118 = (mf)0.01535 + (embed)0.02583\n",
            "Epoch 40 (train)2.5s + (eval)0.8s: train loss = 0.04071 = (mf)0.01489 + (embed)0.02582, recall = 0.02382, ndcg = 0.20211\n",
            "Epoch 41 (train)2.9s: train loss = 0.04057 = (mf)0.01483 + (embed)0.02574\n",
            "Epoch 42 (train)2.4s: train loss = 0.04072 = (mf)0.01502 + (embed)0.02570\n",
            "Epoch 43 (train)2.4s: train loss = 0.04034 = (mf)0.01472 + (embed)0.02562\n",
            "Epoch 44 (train)2.4s: train loss = 0.04099 = (mf)0.01534 + (embed)0.02566\n",
            "Epoch 45 (train)2.8s + (eval)0.4s: train loss = 0.04101 = (mf)0.01524 + (embed)0.02577, recall = 0.02450, ndcg = 0.21738\n",
            "Epoch 46 (train)2.5s: train loss = 0.04109 = (mf)0.01533 + (embed)0.02576\n",
            "Epoch 47 (train)2.4s: train loss = 0.04149 = (mf)0.01556 + (embed)0.02594\n",
            "Epoch 48 (train)2.4s: train loss = 0.04069 = (mf)0.01476 + (embed)0.02593\n",
            "Epoch 49 (train)2.5s: train loss = 0.04102 = (mf)0.01509 + (embed)0.02593\n",
            "Epoch 50 (train)3.0s + (eval)0.3s: train loss = 0.04079 = (mf)0.01491 + (embed)0.02588, recall = 0.02430, ndcg = 0.21835\n",
            "Epoch 51 (train)2.4s: train loss = 0.04017 = (mf)0.01433 + (embed)0.02584\n",
            "Epoch 52 (train)2.4s: train loss = 0.04100 = (mf)0.01524 + (embed)0.02577\n",
            "Epoch 53 (train)2.4s: train loss = 0.04088 = (mf)0.01491 + (embed)0.02596\n",
            "Epoch 54 (train)2.7s: train loss = 0.03977 = (mf)0.01395 + (embed)0.02582\n",
            "Epoch 55 (train)2.7s + (eval)0.7s: train loss = 0.04122 = (mf)0.01538 + (embed)0.02584, recall = 0.02452, ndcg = 0.22125\n",
            "Epoch 56 (train)2.5s: train loss = 0.04076 = (mf)0.01493 + (embed)0.02582\n",
            "Epoch 57 (train)2.4s: train loss = 0.04042 = (mf)0.01457 + (embed)0.02585\n",
            "Epoch 58 (train)2.4s: train loss = 0.04092 = (mf)0.01501 + (embed)0.02591\n",
            "Epoch 59 (train)3.0s: train loss = 0.04088 = (mf)0.01490 + (embed)0.02597\n",
            "Epoch 60 (train)2.4s + (eval)0.3s: train loss = 0.04078 = (mf)0.01493 + (embed)0.02584, recall = 0.02447, ndcg = 0.21926\n",
            "Epoch 61 (train)2.4s: train loss = 0.04025 = (mf)0.01445 + (embed)0.02581\n",
            "Epoch 62 (train)2.4s: train loss = 0.04012 = (mf)0.01439 + (embed)0.02573\n",
            "Epoch 63 (train)2.7s: train loss = 0.04017 = (mf)0.01445 + (embed)0.02571\n",
            "Epoch 64 (train)2.7s: train loss = 0.04059 = (mf)0.01487 + (embed)0.02572\n",
            "Epoch 65 (train)2.4s + (eval)0.3s: train loss = 0.04100 = (mf)0.01517 + (embed)0.02584, recall = 0.02335, ndcg = 0.20947\n",
            "Epoch 66 (train)2.4s: train loss = 0.04070 = (mf)0.01477 + (embed)0.02593\n",
            "Epoch 67 (train)2.4s: train loss = 0.04112 = (mf)0.01516 + (embed)0.02596\n",
            "Epoch 68 (train)3.0s: train loss = 0.04099 = (mf)0.01496 + (embed)0.02602\n",
            "Epoch 69 (train)2.5s: train loss = 0.04065 = (mf)0.01466 + (embed)0.02599\n",
            "Epoch 70 (train)2.4s + (eval)0.3s: train loss = 0.04056 = (mf)0.01465 + (embed)0.02592, recall = 0.02327, ndcg = 0.21068\n",
            "Epoch 71 (train)2.4s: train loss = 0.04039 = (mf)0.01453 + (embed)0.02586\n",
            "Epoch 72 (train)2.7s: train loss = 0.04032 = (mf)0.01443 + (embed)0.02589\n",
            "Epoch 73 (train)2.8s: train loss = 0.04017 = (mf)0.01441 + (embed)0.02576\n",
            "Epoch 74 (train)2.4s: train loss = 0.04116 = (mf)0.01533 + (embed)0.02583\n",
            "Epoch 75 (train)2.4s + (eval)0.7s: train loss = 0.04080 = (mf)0.01482 + (embed)0.02597, recall = 0.02502, ndcg = 0.20370\n",
            "Epoch 76 (train)3.1s: train loss = 0.04048 = (mf)0.01454 + (embed)0.02595\n",
            "Epoch 77 (train)2.9s: train loss = 0.04031 = (mf)0.01449 + (embed)0.02582\n",
            "Epoch 78 (train)2.5s: train loss = 0.04072 = (mf)0.01488 + (embed)0.02584\n",
            "Epoch 79 (train)2.4s: train loss = 0.04009 = (mf)0.01427 + (embed)0.02582\n",
            "Epoch 80 (train)2.5s + (eval)0.2s: train loss = 0.04035 = (mf)0.01459 + (embed)0.02576, recall = 0.02438, ndcg = 0.21483\n",
            "Epoch 81 (train)2.9s: train loss = 0.04016 = (mf)0.01442 + (embed)0.02574\n",
            "Epoch 82 (train)2.5s: train loss = 0.04023 = (mf)0.01455 + (embed)0.02568\n",
            "Epoch 83 (train)2.4s: train loss = 0.04095 = (mf)0.01516 + (embed)0.02579\n",
            "Epoch 84 (train)2.5s: train loss = 0.04029 = (mf)0.01445 + (embed)0.02584\n",
            "Epoch 85 (train)2.5s + (eval)0.3s: train loss = 0.04074 = (mf)0.01478 + (embed)0.02595, recall = 0.02467, ndcg = 0.21540\n",
            "Epoch 86 (train)2.9s: train loss = 0.04041 = (mf)0.01454 + (embed)0.02587\n",
            "Epoch 87 (train)2.4s: train loss = 0.04096 = (mf)0.01502 + (embed)0.02593\n",
            "Epoch 88 (train)2.4s: train loss = 0.04039 = (mf)0.01445 + (embed)0.02593\n",
            "Epoch 89 (train)2.5s: train loss = 0.03986 = (mf)0.01403 + (embed)0.02583\n",
            "Epoch 90 (train)2.7s + (eval)0.4s: train loss = 0.04011 = (mf)0.01439 + (embed)0.02572, recall = 0.02466, ndcg = 0.21688\n",
            "Epoch 91 (train)2.6s: train loss = 0.04022 = (mf)0.01448 + (embed)0.02574\n",
            "Epoch 92 (train)2.4s: train loss = 0.04035 = (mf)0.01458 + (embed)0.02577\n",
            "Epoch 93 (train)2.4s: train loss = 0.04007 = (mf)0.01434 + (embed)0.02573\n",
            "Epoch 94 (train)2.4s: train loss = 0.04065 = (mf)0.01487 + (embed)0.02577\n",
            "Epoch 95 (train)3.0s + (eval)0.7s: train loss = 0.04020 = (mf)0.01444 + (embed)0.02575, recall = 0.02360, ndcg = 0.20501\n",
            "Epoch 96 (train)2.5s: train loss = 0.04021 = (mf)0.01452 + (embed)0.02570\n",
            "Epoch 97 (train)2.4s: train loss = 0.03979 = (mf)0.01402 + (embed)0.02577\n",
            "Epoch 98 (train)2.4s: train loss = 0.04027 = (mf)0.01459 + (embed)0.02567\n",
            "Epoch 99 (train)2.8s: train loss = 0.04065 = (mf)0.01487 + (embed)0.02578\n",
            "Epoch 100 (train)2.6s + (eval)0.2s: train loss = 0.04071 = (mf)0.01490 + (embed)0.02582, recall = 0.02466, ndcg = 0.22897\n",
            "Training finished in 268.13 seconds.\n",
            "Evaluation results for this combination: NDCG@20: 0.22897, Recall@20: 0.02466\n",
            "--- Trying combination: Epochs=100, TopK=20, LearningRate=0.5, Layers=3 ---\n",
            "Already normalize adjacency matrix (extended).\n",
            "Using xavier initialization for user, item, and genre embeddings.\n",
            "Epoch 1 (train)4.2s: train loss = 0.91382 = (mf)0.74298 + (embed)0.17084\n",
            "Epoch 2 (train)2.4s: train loss = 1.94073 = (mf)1.44611 + (embed)0.49462\n",
            "Epoch 3 (train)2.4s: train loss = 2.76601 = (mf)1.99170 + (embed)0.77431\n",
            "Epoch 4 (train)2.5s: train loss = 3.20154 = (mf)2.21108 + (embed)0.99046\n",
            "Epoch 5 (train)2.8s + (eval)1.2s: train loss = 3.45725 = (mf)2.29458 + (embed)1.16268, recall = 0.01438, ndcg = 0.15404\n",
            "Epoch 6 (train)2.4s: train loss = 3.75867 = (mf)2.45913 + (embed)1.29954\n",
            "Epoch 7 (train)2.3s: train loss = 3.88799 = (mf)2.45608 + (embed)1.43191\n",
            "Epoch 8 (train)2.4s: train loss = 4.10898 = (mf)2.56494 + (embed)1.54404\n",
            "Epoch 9 (train)2.9s: train loss = 4.24243 = (mf)2.59418 + (embed)1.64825\n",
            "Epoch 10 (train)2.4s + (eval)0.7s: train loss = 4.34998 = (mf)2.61134 + (embed)1.73864, recall = 0.01452, ndcg = 0.12713\n",
            "Epoch 11 (train)2.4s: train loss = 4.36296 = (mf)2.54654 + (embed)1.81642\n",
            "Epoch 12 (train)2.4s: train loss = 4.49904 = (mf)2.61685 + (embed)1.88218\n",
            "Epoch 13 (train)2.6s: train loss = 4.57527 = (mf)2.63167 + (embed)1.94360\n",
            "Epoch 14 (train)2.7s: train loss = 4.49746 = (mf)2.50369 + (embed)1.99376\n",
            "Epoch 15 (train)2.4s + (eval)0.2s: train loss = 4.72270 = (mf)2.67915 + (embed)2.04355, recall = 0.01485, ndcg = 0.14379\n",
            "Epoch 16 (train)2.4s: train loss = 4.68896 = (mf)2.59001 + (embed)2.09896\n",
            "Epoch 17 (train)2.3s: train loss = 4.75951 = (mf)2.61960 + (embed)2.13991\n",
            "Epoch 18 (train)2.8s: train loss = 4.84096 = (mf)2.64681 + (embed)2.19415\n",
            "Epoch 19 (train)2.4s: train loss = 4.75738 = (mf)2.52457 + (embed)2.23281\n",
            "Epoch 20 (train)2.4s + (eval)0.3s: train loss = 4.86459 = (mf)2.58965 + (embed)2.27494, recall = 0.01278, ndcg = 0.13453\n",
            "Epoch 21 (train)2.4s: train loss = 4.70954 = (mf)2.40400 + (embed)2.30554\n",
            "Epoch 22 (train)2.4s: train loss = 4.81072 = (mf)2.47812 + (embed)2.33260\n",
            "Epoch 23 (train)2.9s: train loss = 4.74618 = (mf)2.39030 + (embed)2.35589\n",
            "Epoch 24 (train)2.4s: train loss = 4.85389 = (mf)2.47610 + (embed)2.37779\n",
            "Epoch 25 (train)2.4s + (eval)0.7s: train loss = 4.81733 = (mf)2.41374 + (embed)2.40360, recall = 0.01352, ndcg = 0.11551\n",
            "Epoch 26 (train)2.4s: train loss = 4.76502 = (mf)2.34021 + (embed)2.42481\n",
            "Epoch 27 (train)2.7s: train loss = 4.90456 = (mf)2.46011 + (embed)2.44445\n",
            "Epoch 28 (train)2.6s: train loss = 4.85595 = (mf)2.38787 + (embed)2.46808\n",
            "Epoch 29 (train)2.3s: train loss = 4.91991 = (mf)2.42872 + (embed)2.49118\n",
            "Epoch 30 (train)2.4s + (eval)0.3s: train loss = 4.78965 = (mf)2.28157 + (embed)2.50807, recall = 0.01192, ndcg = 0.11046\n",
            "Epoch 31 (train)2.4s: train loss = 4.75549 = (mf)2.23933 + (embed)2.51615\n",
            "Epoch 32 (train)2.9s: train loss = 4.84981 = (mf)2.32814 + (embed)2.52168\n",
            "Epoch 33 (train)2.4s: train loss = 4.78500 = (mf)2.24201 + (embed)2.54299\n",
            "Epoch 34 (train)2.4s: train loss = 4.81613 = (mf)2.26610 + (embed)2.55004\n",
            "Epoch 35 (train)2.3s + (eval)0.2s: train loss = 4.85192 = (mf)2.28810 + (embed)2.56382, recall = 0.01287, ndcg = 0.12344\n",
            "Epoch 36 (train)2.4s: train loss = 4.80028 = (mf)2.22921 + (embed)2.57107\n",
            "Epoch 37 (train)2.9s: train loss = 4.80822 = (mf)2.22588 + (embed)2.58234\n",
            "Epoch 38 (train)2.4s: train loss = 4.84096 = (mf)2.24239 + (embed)2.59857\n",
            "Epoch 39 (train)2.4s: train loss = 4.93070 = (mf)2.32604 + (embed)2.60465\n",
            "Epoch 40 (train)2.4s + (eval)0.3s: train loss = 4.82715 = (mf)2.21551 + (embed)2.61163, recall = 0.01291, ndcg = 0.13530\n",
            "Epoch 41 (train)2.5s: train loss = 4.90396 = (mf)2.28452 + (embed)2.61944\n",
            "Epoch 42 (train)2.7s: train loss = 4.91621 = (mf)2.27932 + (embed)2.63689\n",
            "Epoch 43 (train)2.4s: train loss = 4.88163 = (mf)2.22752 + (embed)2.65410\n",
            "Epoch 44 (train)2.4s: train loss = 4.99322 = (mf)2.32082 + (embed)2.67240\n",
            "Epoch 45 (train)2.4s + (eval)0.7s: train loss = 4.95430 = (mf)2.27062 + (embed)2.68368, recall = 0.01676, ndcg = 0.13735\n",
            "Epoch 46 (train)2.9s: train loss = 4.90666 = (mf)2.21804 + (embed)2.68862\n",
            "Epoch 47 (train)2.4s: train loss = 4.95278 = (mf)2.26786 + (embed)2.68492\n",
            "Epoch 48 (train)2.4s: train loss = 4.86654 = (mf)2.18457 + (embed)2.68198\n",
            "Epoch 49 (train)2.4s: train loss = 4.76774 = (mf)2.08937 + (embed)2.67837\n",
            "Epoch 50 (train)2.4s + (eval)0.4s: train loss = 4.91390 = (mf)2.23883 + (embed)2.67508, recall = 0.01325, ndcg = 0.11813\n",
            "Epoch 51 (train)2.8s: train loss = 4.78356 = (mf)2.11436 + (embed)2.66920\n",
            "Epoch 52 (train)2.4s: train loss = 4.81900 = (mf)2.14816 + (embed)2.67084\n",
            "Epoch 53 (train)2.3s: train loss = 4.93235 = (mf)2.26013 + (embed)2.67223\n",
            "Epoch 54 (train)2.3s: train loss = 4.86087 = (mf)2.17995 + (embed)2.68093\n",
            "Epoch 55 (train)2.6s + (eval)0.4s: train loss = 4.87509 = (mf)2.19337 + (embed)2.68172, recall = 0.01594, ndcg = 0.13436\n",
            "Epoch 56 (train)2.6s: train loss = 4.88534 = (mf)2.19424 + (embed)2.69111\n",
            "Epoch 57 (train)2.4s: train loss = 4.79540 = (mf)2.10254 + (embed)2.69287\n",
            "Epoch 58 (train)2.3s: train loss = 4.91021 = (mf)2.20554 + (embed)2.70466\n",
            "Epoch 59 (train)2.3s: train loss = 4.92655 = (mf)2.22322 + (embed)2.70333\n",
            "Epoch 60 (train)2.8s + (eval)0.7s: train loss = 4.87002 = (mf)2.16710 + (embed)2.70292, recall = 0.01263, ndcg = 0.11167\n",
            "Epoch 61 (train)2.4s: train loss = 4.84044 = (mf)2.12570 + (embed)2.71474\n",
            "Epoch 62 (train)2.4s: train loss = 5.03347 = (mf)2.31885 + (embed)2.71462\n",
            "Epoch 63 (train)2.4s: train loss = 5.02014 = (mf)2.29446 + (embed)2.72569\n",
            "Epoch 64 (train)3.0s: train loss = 4.89692 = (mf)2.16536 + (embed)2.73156\n",
            "Epoch 65 (train)2.8s + (eval)0.3s: train loss = 4.91797 = (mf)2.18820 + (embed)2.72977, recall = 0.01300, ndcg = 0.10217\n",
            "Epoch 66 (train)2.4s: train loss = 4.88858 = (mf)2.15934 + (embed)2.72924\n",
            "Epoch 67 (train)2.4s: train loss = 4.98582 = (mf)2.25773 + (embed)2.72809\n",
            "Epoch 68 (train)2.3s: train loss = 4.87388 = (mf)2.13611 + (embed)2.73777\n",
            "Epoch 69 (train)2.7s: train loss = 4.90124 = (mf)2.16480 + (embed)2.73644\n",
            "Epoch 70 (train)2.5s + (eval)0.3s: train loss = 4.81373 = (mf)2.07681 + (embed)2.73692, recall = 0.01402, ndcg = 0.12459\n",
            "Epoch 71 (train)2.4s: train loss = 4.93772 = (mf)2.20922 + (embed)2.72850\n",
            "Epoch 72 (train)2.3s: train loss = 4.98613 = (mf)2.25435 + (embed)2.73178\n",
            "Epoch 73 (train)2.4s: train loss = 4.93062 = (mf)2.19186 + (embed)2.73876\n",
            "Epoch 74 (train)2.9s: train loss = 4.75804 = (mf)2.01265 + (embed)2.74540\n",
            "Epoch 75 (train)2.4s + (eval)0.3s: train loss = 4.82037 = (mf)2.07116 + (embed)2.74921, recall = 0.01300, ndcg = 0.12277\n",
            "Epoch 76 (train)2.4s: train loss = 4.95290 = (mf)2.20122 + (embed)2.75167\n",
            "Epoch 77 (train)2.3s: train loss = 4.92777 = (mf)2.17115 + (embed)2.75662\n",
            "Epoch 78 (train)2.4s: train loss = 4.92418 = (mf)2.16575 + (embed)2.75844\n",
            "Epoch 79 (train)2.9s: train loss = 4.92015 = (mf)2.15016 + (embed)2.76999\n",
            "Epoch 80 (train)2.4s + (eval)0.7s: train loss = 4.89489 = (mf)2.12888 + (embed)2.76601, recall = 0.01456, ndcg = 0.12304\n",
            "Epoch 81 (train)2.4s: train loss = 5.05214 = (mf)2.28954 + (embed)2.76260\n",
            "Epoch 82 (train)2.3s: train loss = 4.96004 = (mf)2.19129 + (embed)2.76875\n",
            "Epoch 83 (train)2.7s: train loss = 4.85608 = (mf)2.08960 + (embed)2.76647\n",
            "Epoch 84 (train)2.5s: train loss = 4.98960 = (mf)2.22350 + (embed)2.76609\n",
            "Epoch 85 (train)2.4s + (eval)0.3s: train loss = 4.85624 = (mf)2.08661 + (embed)2.76963, recall = 0.01370, ndcg = 0.12802\n",
            "Epoch 86 (train)2.4s: train loss = 4.81321 = (mf)2.05020 + (embed)2.76301\n",
            "Epoch 87 (train)2.3s: train loss = 4.85523 = (mf)2.09427 + (embed)2.76095\n",
            "Epoch 88 (train)2.9s: train loss = 4.84572 = (mf)2.07404 + (embed)2.77168\n",
            "Epoch 89 (train)2.4s: train loss = 4.85862 = (mf)2.08930 + (embed)2.76931\n",
            "Epoch 90 (train)2.4s + (eval)0.3s: train loss = 4.91413 = (mf)2.14210 + (embed)2.77203, recall = 0.01314, ndcg = 0.10523\n",
            "Epoch 91 (train)2.4s: train loss = 4.85004 = (mf)2.07196 + (embed)2.77809\n",
            "Epoch 92 (train)2.3s: train loss = 4.90452 = (mf)2.13006 + (embed)2.77446\n",
            "Epoch 93 (train)2.9s: train loss = 5.02975 = (mf)2.23745 + (embed)2.79231\n",
            "Epoch 94 (train)2.4s: train loss = 4.95625 = (mf)2.16578 + (embed)2.79047\n",
            "Epoch 95 (train)2.4s + (eval)0.7s: train loss = 5.12006 = (mf)2.33015 + (embed)2.78991, recall = 0.01399, ndcg = 0.12107\n",
            "Epoch 96 (train)2.4s: train loss = 4.97529 = (mf)2.18685 + (embed)2.78845\n",
            "Epoch 97 (train)2.7s: train loss = 4.91661 = (mf)2.13908 + (embed)2.77753\n",
            "Epoch 98 (train)2.6s: train loss = 4.93353 = (mf)2.15128 + (embed)2.78225\n",
            "Epoch 99 (train)2.4s: train loss = 4.84094 = (mf)2.04873 + (embed)2.79221\n",
            "Epoch 100 (train)2.3s + (eval)0.3s: train loss = 4.91431 = (mf)2.12872 + (embed)2.78559, recall = 0.01505, ndcg = 0.13426\n",
            "Training finished in 258.61 seconds.\n",
            "Evaluation results for this combination: NDCG@20: 0.13426, Recall@20: 0.01505\n",
            "--- Trying combination: Epochs=100, TopK=20, LearningRate=0.5, Layers=4 ---\n",
            "Already normalize adjacency matrix (extended).\n",
            "Using xavier initialization for user, item, and genre embeddings.\n",
            "Epoch 1 (train)4.3s: train loss = 0.67086 = (mf)0.52243 + (embed)0.14843\n",
            "Epoch 2 (train)2.7s: train loss = 1.32503 = (mf)0.89141 + (embed)0.43362\n",
            "Epoch 3 (train)2.6s: train loss = 1.67091 = (mf)1.02945 + (embed)0.64147\n",
            "Epoch 4 (train)2.4s: train loss = 2.00442 = (mf)1.20045 + (embed)0.80397\n",
            "Epoch 5 (train)2.4s + (eval)1.2s: train loss = 2.30923 = (mf)1.36595 + (embed)0.94328, recall = 0.01062, ndcg = 0.11657\n",
            "Epoch 6 (train)2.4s: train loss = 2.40709 = (mf)1.35235 + (embed)1.05473\n",
            "Epoch 7 (train)2.8s: train loss = 2.53198 = (mf)1.38626 + (embed)1.14571\n",
            "Epoch 8 (train)2.4s: train loss = 2.61274 = (mf)1.39189 + (embed)1.22086\n",
            "Epoch 9 (train)2.4s: train loss = 2.64352 = (mf)1.35262 + (embed)1.29090\n",
            "Epoch 10 (train)2.4s + (eval)0.7s: train loss = 2.78947 = (mf)1.43385 + (embed)1.35561, recall = 0.01539, ndcg = 0.13855\n",
            "Epoch 11 (train)3.0s: train loss = 2.84784 = (mf)1.44355 + (embed)1.40429\n",
            "Epoch 12 (train)2.4s: train loss = 2.86003 = (mf)1.41785 + (embed)1.44218\n",
            "Epoch 13 (train)2.4s: train loss = 2.87177 = (mf)1.39086 + (embed)1.48091\n",
            "Epoch 14 (train)2.4s: train loss = 2.93402 = (mf)1.41936 + (embed)1.51466\n",
            "Epoch 15 (train)2.4s + (eval)0.2s: train loss = 2.83966 = (mf)1.29755 + (embed)1.54211, recall = 0.01449, ndcg = 0.13979\n",
            "Epoch 16 (train)3.0s: train loss = 2.88039 = (mf)1.32086 + (embed)1.55953\n",
            "Epoch 17 (train)2.4s: train loss = 2.93758 = (mf)1.35744 + (embed)1.58014\n",
            "Epoch 18 (train)2.4s: train loss = 2.95990 = (mf)1.35293 + (embed)1.60697\n",
            "Epoch 19 (train)2.4s: train loss = 2.98714 = (mf)1.35970 + (embed)1.62744\n",
            "Epoch 20 (train)2.6s + (eval)0.4s: train loss = 2.97954 = (mf)1.32733 + (embed)1.65221, recall = 0.01424, ndcg = 0.13101\n",
            "Epoch 21 (train)2.7s: train loss = 2.85876 = (mf)1.19177 + (embed)1.66698\n",
            "Epoch 22 (train)2.4s: train loss = 3.06031 = (mf)1.37480 + (embed)1.68551\n",
            "Epoch 23 (train)2.4s: train loss = 2.97047 = (mf)1.27220 + (embed)1.69827\n",
            "Epoch 24 (train)2.4s: train loss = 2.93239 = (mf)1.22986 + (embed)1.70254\n",
            "Epoch 25 (train)3.0s + (eval)0.3s: train loss = 2.98693 = (mf)1.27944 + (embed)1.70749, recall = 0.01290, ndcg = 0.10398\n",
            "Epoch 26 (train)2.5s: train loss = 2.96225 = (mf)1.24501 + (embed)1.71724\n",
            "Epoch 27 (train)2.5s: train loss = 2.98103 = (mf)1.26187 + (embed)1.71916\n",
            "Epoch 28 (train)2.4s: train loss = 2.92573 = (mf)1.20106 + (embed)1.72467\n",
            "Epoch 29 (train)2.5s: train loss = 2.91971 = (mf)1.18842 + (embed)1.73129\n",
            "Epoch 30 (train)2.9s + (eval)0.7s: train loss = 2.89512 = (mf)1.15586 + (embed)1.73926, recall = 0.01269, ndcg = 0.12722\n",
            "Epoch 31 (train)2.4s: train loss = 2.96591 = (mf)1.22090 + (embed)1.74501\n",
            "Epoch 32 (train)2.4s: train loss = 2.93898 = (mf)1.19502 + (embed)1.74396\n",
            "Epoch 33 (train)2.4s: train loss = 2.93874 = (mf)1.19206 + (embed)1.74669\n",
            "Epoch 34 (train)2.9s: train loss = 2.87820 = (mf)1.13017 + (embed)1.74803\n",
            "Epoch 35 (train)2.4s + (eval)0.2s: train loss = 2.94128 = (mf)1.18580 + (embed)1.75547, recall = 0.01389, ndcg = 0.11821\n",
            "Epoch 36 (train)2.4s: train loss = 2.98429 = (mf)1.22111 + (embed)1.76319\n",
            "Epoch 37 (train)2.4s: train loss = 2.96645 = (mf)1.20248 + (embed)1.76398\n",
            "Epoch 38 (train)2.4s: train loss = 2.95341 = (mf)1.19149 + (embed)1.76191\n",
            "Epoch 39 (train)3.0s: train loss = 2.92032 = (mf)1.14763 + (embed)1.77269\n",
            "Epoch 40 (train)2.4s + (eval)0.3s: train loss = 3.01050 = (mf)1.24808 + (embed)1.76242, recall = 0.01345, ndcg = 0.11144\n",
            "Epoch 41 (train)2.4s: train loss = 2.97348 = (mf)1.20820 + (embed)1.76527\n",
            "Epoch 42 (train)2.4s: train loss = 2.98832 = (mf)1.22535 + (embed)1.76296\n",
            "Epoch 43 (train)2.6s: train loss = 2.98556 = (mf)1.22199 + (embed)1.76357\n",
            "Epoch 44 (train)2.7s: train loss = 2.94853 = (mf)1.18375 + (embed)1.76478\n",
            "Epoch 45 (train)2.4s + (eval)0.3s: train loss = 2.98514 = (mf)1.21791 + (embed)1.76723, recall = 0.01428, ndcg = 0.13129\n",
            "Epoch 46 (train)2.4s: train loss = 2.99322 = (mf)1.21677 + (embed)1.77645\n",
            "Epoch 47 (train)2.4s: train loss = 3.03148 = (mf)1.25199 + (embed)1.77948\n",
            "Epoch 48 (train)2.9s: train loss = 2.97448 = (mf)1.19622 + (embed)1.77826\n",
            "Epoch 49 (train)2.5s: train loss = 2.95884 = (mf)1.17947 + (embed)1.77936\n",
            "Epoch 50 (train)2.4s + (eval)0.7s: train loss = 2.92375 = (mf)1.14069 + (embed)1.78306, recall = 0.01419, ndcg = 0.13471\n",
            "Epoch 51 (train)2.9s: train loss = 3.00787 = (mf)1.21666 + (embed)1.79121\n",
            "Epoch 52 (train)2.8s: train loss = 2.98923 = (mf)1.19509 + (embed)1.79414\n",
            "Epoch 53 (train)2.5s: train loss = 2.96443 = (mf)1.17652 + (embed)1.78792\n",
            "Epoch 54 (train)2.4s: train loss = 2.89967 = (mf)1.12086 + (embed)1.77880\n",
            "Epoch 55 (train)2.4s + (eval)0.2s: train loss = 2.97546 = (mf)1.19006 + (embed)1.78540, recall = 0.01290, ndcg = 0.11410\n",
            "Epoch 56 (train)2.4s: train loss = 2.95022 = (mf)1.16723 + (embed)1.78299\n",
            "Epoch 57 (train)2.9s: train loss = 2.92540 = (mf)1.14557 + (embed)1.77983\n",
            "Epoch 58 (train)2.4s: train loss = 2.97742 = (mf)1.19444 + (embed)1.78298\n",
            "Epoch 59 (train)2.4s: train loss = 2.87313 = (mf)1.09743 + (embed)1.77570\n",
            "Epoch 60 (train)2.4s + (eval)0.3s: train loss = 2.95699 = (mf)1.18040 + (embed)1.77659, recall = 0.01222, ndcg = 0.11217\n",
            "Epoch 61 (train)2.6s: train loss = 2.98101 = (mf)1.18583 + (embed)1.79519\n",
            "Epoch 62 (train)2.8s: train loss = 2.90481 = (mf)1.11802 + (embed)1.78679\n",
            "Epoch 63 (train)2.4s: train loss = 2.98102 = (mf)1.20301 + (embed)1.77801\n",
            "Epoch 64 (train)2.4s: train loss = 2.99770 = (mf)1.22121 + (embed)1.77650\n",
            "Epoch 65 (train)2.3s + (eval)0.7s: train loss = 2.93649 = (mf)1.15926 + (embed)1.77723, recall = 0.01101, ndcg = 0.11340\n",
            "Epoch 66 (train)3.0s: train loss = 2.93435 = (mf)1.15256 + (embed)1.78178\n",
            "Epoch 67 (train)2.4s: train loss = 2.97086 = (mf)1.18152 + (embed)1.78934\n",
            "Epoch 68 (train)2.4s: train loss = 2.99875 = (mf)1.20563 + (embed)1.79312\n",
            "Epoch 69 (train)2.4s: train loss = 2.95011 = (mf)1.15144 + (embed)1.79867\n",
            "Epoch 70 (train)2.4s + (eval)0.4s: train loss = 2.89604 = (mf)1.10533 + (embed)1.79071, recall = 0.01413, ndcg = 0.11404\n",
            "Epoch 71 (train)2.9s: train loss = 2.93307 = (mf)1.14300 + (embed)1.79007\n",
            "Epoch 72 (train)2.4s: train loss = 3.00609 = (mf)1.21708 + (embed)1.78901\n",
            "Epoch 73 (train)2.3s: train loss = 3.00552 = (mf)1.20566 + (embed)1.79986\n",
            "Epoch 74 (train)2.4s: train loss = 2.95648 = (mf)1.15410 + (embed)1.80238\n",
            "Epoch 75 (train)2.7s + (eval)0.4s: train loss = 3.01472 = (mf)1.20741 + (embed)1.80732, recall = 0.01528, ndcg = 0.12959\n",
            "Epoch 76 (train)2.5s: train loss = 2.91665 = (mf)1.11028 + (embed)1.80636\n",
            "Epoch 77 (train)2.4s: train loss = 3.04276 = (mf)1.24195 + (embed)1.80081\n",
            "Epoch 78 (train)2.4s: train loss = 2.91885 = (mf)1.12084 + (embed)1.79801\n",
            "Epoch 79 (train)2.4s: train loss = 2.92031 = (mf)1.12993 + (embed)1.79038\n",
            "Epoch 80 (train)2.9s + (eval)0.3s: train loss = 2.98456 = (mf)1.19705 + (embed)1.78751, recall = 0.01408, ndcg = 0.12013\n",
            "Epoch 81 (train)2.4s: train loss = 3.00192 = (mf)1.21107 + (embed)1.79085\n",
            "Epoch 82 (train)2.4s: train loss = 3.00345 = (mf)1.21331 + (embed)1.79014\n",
            "Epoch 83 (train)2.4s: train loss = 2.99539 = (mf)1.19136 + (embed)1.80403\n",
            "Epoch 84 (train)2.5s: train loss = 2.96334 = (mf)1.15790 + (embed)1.80544\n",
            "Epoch 85 (train)2.9s + (eval)0.7s: train loss = 2.95653 = (mf)1.15634 + (embed)1.80019, recall = 0.01394, ndcg = 0.12690\n",
            "Epoch 86 (train)2.4s: train loss = 2.94438 = (mf)1.14388 + (embed)1.80049\n",
            "Epoch 87 (train)2.4s: train loss = 2.96084 = (mf)1.16937 + (embed)1.79147\n",
            "Epoch 88 (train)2.4s: train loss = 2.87644 = (mf)1.09299 + (embed)1.78345\n",
            "Epoch 89 (train)2.9s: train loss = 2.87668 = (mf)1.09640 + (embed)1.78028\n",
            "Epoch 90 (train)2.4s + (eval)0.3s: train loss = 2.88895 = (mf)1.10880 + (embed)1.78015, recall = 0.01405, ndcg = 0.13154\n",
            "Epoch 91 (train)2.4s: train loss = 2.94511 = (mf)1.16206 + (embed)1.78305\n",
            "Epoch 92 (train)2.4s: train loss = 2.89806 = (mf)1.10846 + (embed)1.78960\n",
            "Epoch 93 (train)2.4s: train loss = 2.96945 = (mf)1.17611 + (embed)1.79334\n",
            "Epoch 94 (train)2.9s: train loss = 2.88841 = (mf)1.09603 + (embed)1.79238\n",
            "Epoch 95 (train)2.4s + (eval)0.2s: train loss = 2.98364 = (mf)1.19036 + (embed)1.79328, recall = 0.01446, ndcg = 0.12879\n",
            "Epoch 96 (train)2.5s: train loss = 2.95109 = (mf)1.15957 + (embed)1.79152\n",
            "Epoch 97 (train)2.4s: train loss = 2.92252 = (mf)1.12304 + (embed)1.79948\n",
            "Epoch 98 (train)2.7s: train loss = 2.88018 = (mf)1.08900 + (embed)1.79119\n",
            "Epoch 99 (train)2.7s: train loss = 2.93454 = (mf)1.14486 + (embed)1.78968\n",
            "Epoch 100 (train)2.4s + (eval)0.7s: train loss = 2.87210 = (mf)1.08181 + (embed)1.79029, recall = 0.01419, ndcg = 0.13551\n",
            "Training finished in 262.67 seconds.\n",
            "Evaluation results for this combination: NDCG@20: 0.13551, Recall@20: 0.01419\n",
            "--- Trying combination: Epochs=100, TopK=20, LearningRate=0.5, Layers=5 ---\n",
            "Already normalize adjacency matrix (extended).\n",
            "Using xavier initialization for user, item, and genre embeddings.\n",
            "Epoch 1 (train)4.5s: train loss = 0.50652 = (mf)0.38310 + (embed)0.12342\n",
            "Epoch 2 (train)2.5s: train loss = 0.99166 = (mf)0.61131 + (embed)0.38035\n",
            "Epoch 3 (train)2.9s: train loss = 1.30535 = (mf)0.73787 + (embed)0.56748\n",
            "Epoch 4 (train)2.5s: train loss = 1.52527 = (mf)0.81855 + (embed)0.70672\n",
            "Epoch 5 (train)2.4s + (eval)1.2s: train loss = 1.69421 = (mf)0.88075 + (embed)0.81345, recall = 0.01299, ndcg = 0.12298\n",
            "Epoch 6 (train)2.4s: train loss = 1.78524 = (mf)0.88859 + (embed)0.89665\n",
            "Epoch 7 (train)2.9s: train loss = 1.83047 = (mf)0.87350 + (embed)0.95697\n",
            "Epoch 8 (train)2.5s: train loss = 1.90936 = (mf)0.89968 + (embed)1.00968\n",
            "Epoch 9 (train)2.5s: train loss = 1.99233 = (mf)0.93558 + (embed)1.05675\n",
            "Epoch 10 (train)2.4s + (eval)0.3s: train loss = 2.02426 = (mf)0.92290 + (embed)1.10136, recall = 0.01178, ndcg = 0.10617\n",
            "Epoch 11 (train)2.5s: train loss = 2.05532 = (mf)0.92980 + (embed)1.12551\n",
            "Epoch 12 (train)2.9s: train loss = 2.06378 = (mf)0.90697 + (embed)1.15681\n",
            "Epoch 13 (train)2.4s: train loss = 2.09813 = (mf)0.92009 + (embed)1.17804\n",
            "Epoch 14 (train)2.4s: train loss = 2.05253 = (mf)0.85899 + (embed)1.19354\n",
            "Epoch 15 (train)2.4s + (eval)0.3s: train loss = 2.09098 = (mf)0.88116 + (embed)1.20983, recall = 0.01263, ndcg = 0.11672\n",
            "Epoch 16 (train)2.8s: train loss = 2.07954 = (mf)0.85963 + (embed)1.21991\n",
            "Epoch 17 (train)2.6s: train loss = 2.05223 = (mf)0.82178 + (embed)1.23045\n",
            "Epoch 18 (train)2.4s: train loss = 2.03515 = (mf)0.79461 + (embed)1.24054\n",
            "Epoch 19 (train)2.4s: train loss = 2.05002 = (mf)0.80223 + (embed)1.24779\n",
            "Epoch 20 (train)2.4s + (eval)0.7s: train loss = 2.03083 = (mf)0.77923 + (embed)1.25160, recall = 0.01172, ndcg = 0.10863\n",
            "Epoch 21 (train)2.9s: train loss = 2.06287 = (mf)0.80759 + (embed)1.25528\n",
            "Epoch 22 (train)2.4s: train loss = 2.04788 = (mf)0.78908 + (embed)1.25879\n",
            "Epoch 23 (train)2.4s: train loss = 2.05786 = (mf)0.80082 + (embed)1.25704\n",
            "Epoch 24 (train)2.5s: train loss = 2.07474 = (mf)0.81183 + (embed)1.26291\n",
            "Epoch 25 (train)2.7s + (eval)0.4s: train loss = 2.00843 = (mf)0.75677 + (embed)1.25166, recall = 0.01273, ndcg = 0.11352\n",
            "Epoch 26 (train)2.6s: train loss = 2.03490 = (mf)0.76852 + (embed)1.26639\n",
            "Epoch 27 (train)2.4s: train loss = 2.03982 = (mf)0.77287 + (embed)1.26695\n",
            "Epoch 28 (train)2.4s: train loss = 2.05857 = (mf)0.79184 + (embed)1.26673\n",
            "Epoch 29 (train)2.4s: train loss = 2.03110 = (mf)0.76165 + (embed)1.26945\n",
            "Epoch 30 (train)3.0s + (eval)0.2s: train loss = 2.03880 = (mf)0.76632 + (embed)1.27248, recall = 0.01158, ndcg = 0.09724\n",
            "Epoch 31 (train)2.5s: train loss = 2.05054 = (mf)0.77485 + (embed)1.27569\n",
            "Epoch 32 (train)2.4s: train loss = 2.10779 = (mf)0.82689 + (embed)1.28089\n",
            "Epoch 33 (train)2.4s: train loss = 2.07678 = (mf)0.79294 + (embed)1.28384\n",
            "Epoch 34 (train)2.6s: train loss = 2.07110 = (mf)0.78739 + (embed)1.28371\n",
            "Epoch 35 (train)2.8s + (eval)0.7s: train loss = 2.08347 = (mf)0.79645 + (embed)1.28702, recall = 0.01065, ndcg = 0.09571\n",
            "Epoch 36 (train)2.5s: train loss = 2.08134 = (mf)0.78087 + (embed)1.30046\n",
            "Epoch 37 (train)2.8s: train loss = 2.05477 = (mf)0.75356 + (embed)1.30121\n",
            "Epoch 38 (train)2.7s: train loss = 2.04200 = (mf)0.74194 + (embed)1.30006\n",
            "Epoch 39 (train)2.9s: train loss = 2.05837 = (mf)0.76073 + (embed)1.29764\n",
            "Epoch 40 (train)2.4s + (eval)0.2s: train loss = 2.06787 = (mf)0.77789 + (embed)1.28999, recall = 0.01393, ndcg = 0.11936\n",
            "Epoch 41 (train)2.5s: train loss = 2.03113 = (mf)0.73513 + (embed)1.29600\n",
            "Epoch 42 (train)2.4s: train loss = 2.06006 = (mf)0.76027 + (embed)1.29979\n",
            "Epoch 43 (train)2.8s: train loss = 2.05366 = (mf)0.75725 + (embed)1.29642\n",
            "Epoch 44 (train)2.5s: train loss = 2.01840 = (mf)0.72428 + (embed)1.29412\n",
            "Epoch 45 (train)2.4s + (eval)0.2s: train loss = 2.03800 = (mf)0.74879 + (embed)1.28922, recall = 0.01179, ndcg = 0.10188\n",
            "Epoch 46 (train)2.5s: train loss = 2.01446 = (mf)0.72355 + (embed)1.29091\n",
            "Epoch 47 (train)2.5s: train loss = 2.02159 = (mf)0.73478 + (embed)1.28681\n",
            "Epoch 48 (train)2.9s: train loss = 1.98724 = (mf)0.71022 + (embed)1.27702\n",
            "Epoch 49 (train)2.4s: train loss = 2.01935 = (mf)0.74180 + (embed)1.27756\n",
            "Epoch 50 (train)2.5s + (eval)0.3s: train loss = 2.04768 = (mf)0.76204 + (embed)1.28563, recall = 0.01498, ndcg = 0.12148\n",
            "Epoch 51 (train)2.4s: train loss = 2.05071 = (mf)0.76454 + (embed)1.28617\n",
            "Epoch 52 (train)2.7s: train loss = 1.99720 = (mf)0.71557 + (embed)1.28162\n",
            "Epoch 53 (train)2.7s: train loss = 2.00897 = (mf)0.72796 + (embed)1.28101\n",
            "Epoch 54 (train)2.4s: train loss = 2.07319 = (mf)0.79241 + (embed)1.28078\n",
            "Epoch 55 (train)2.5s + (eval)0.7s: train loss = 2.00886 = (mf)0.72582 + (embed)1.28304, recall = 0.01556, ndcg = 0.12745\n",
            "Epoch 56 (train)2.4s: train loss = 2.04469 = (mf)0.76032 + (embed)1.28437\n",
            "Epoch 57 (train)3.0s: train loss = 2.04776 = (mf)0.75917 + (embed)1.28859\n",
            "Epoch 58 (train)2.4s: train loss = 2.05800 = (mf)0.76238 + (embed)1.29562\n",
            "Epoch 59 (train)2.4s: train loss = 2.02433 = (mf)0.72783 + (embed)1.29649\n",
            "Epoch 60 (train)2.4s + (eval)0.3s: train loss = 2.07814 = (mf)0.78000 + (embed)1.29813, recall = 0.01099, ndcg = 0.09986\n",
            "Epoch 61 (train)2.8s: train loss = 2.04012 = (mf)0.74148 + (embed)1.29864\n",
            "Epoch 62 (train)2.6s: train loss = 2.02486 = (mf)0.72393 + (embed)1.30093\n",
            "Epoch 63 (train)2.4s: train loss = 2.03886 = (mf)0.73862 + (embed)1.30024\n",
            "Epoch 64 (train)2.4s: train loss = 2.06263 = (mf)0.75968 + (embed)1.30294\n",
            "Epoch 65 (train)2.4s + (eval)0.3s: train loss = 2.00531 = (mf)0.70876 + (embed)1.29655, recall = 0.01394, ndcg = 0.11309\n",
            "Epoch 66 (train)3.0s: train loss = 2.00369 = (mf)0.71265 + (embed)1.29105\n",
            "Epoch 67 (train)2.5s: train loss = 1.98796 = (mf)0.70133 + (embed)1.28663\n",
            "Epoch 68 (train)2.4s: train loss = 1.99087 = (mf)0.71387 + (embed)1.27700\n",
            "Epoch 69 (train)2.4s: train loss = 2.02809 = (mf)0.74679 + (embed)1.28130\n",
            "Epoch 70 (train)2.6s + (eval)0.4s: train loss = 2.01598 = (mf)0.72869 + (embed)1.28729, recall = 0.01353, ndcg = 0.10708\n",
            "Epoch 71 (train)2.7s: train loss = 2.04935 = (mf)0.74958 + (embed)1.29977\n",
            "Epoch 72 (train)2.4s: train loss = 2.09720 = (mf)0.79588 + (embed)1.30132\n",
            "Epoch 73 (train)2.5s: train loss = 2.02171 = (mf)0.71847 + (embed)1.30324\n",
            "Epoch 74 (train)2.4s: train loss = 2.01659 = (mf)0.71682 + (embed)1.29976\n",
            "Epoch 75 (train)2.9s + (eval)0.7s: train loss = 2.09819 = (mf)0.79666 + (embed)1.30153, recall = 0.01191, ndcg = 0.11399\n",
            "Epoch 76 (train)2.5s: train loss = 2.05524 = (mf)0.75439 + (embed)1.30085\n",
            "Epoch 77 (train)2.4s: train loss = 2.02494 = (mf)0.72893 + (embed)1.29601\n",
            "Epoch 78 (train)2.4s: train loss = 2.02801 = (mf)0.73410 + (embed)1.29391\n",
            "Epoch 79 (train)2.6s: train loss = 2.01116 = (mf)0.72133 + (embed)1.28984\n",
            "Epoch 80 (train)2.8s + (eval)0.2s: train loss = 2.06317 = (mf)0.77372 + (embed)1.28945, recall = 0.01209, ndcg = 0.11358\n",
            "Epoch 81 (train)2.4s: train loss = 2.07045 = (mf)0.77596 + (embed)1.29449\n",
            "Epoch 82 (train)2.4s: train loss = 2.02507 = (mf)0.73127 + (embed)1.29379\n",
            "Epoch 83 (train)2.4s: train loss = 2.05010 = (mf)0.76153 + (embed)1.28857\n",
            "Epoch 84 (train)3.0s: train loss = 2.03496 = (mf)0.73699 + (embed)1.29797\n",
            "Epoch 85 (train)2.5s + (eval)0.2s: train loss = 2.06152 = (mf)0.76022 + (embed)1.30130, recall = 0.01164, ndcg = 0.10486\n",
            "Epoch 86 (train)2.4s: train loss = 2.07469 = (mf)0.76324 + (embed)1.31145\n",
            "Epoch 87 (train)2.4s: train loss = 2.04052 = (mf)0.73180 + (embed)1.30873\n",
            "Epoch 88 (train)2.5s: train loss = 1.97844 = (mf)0.68308 + (embed)1.29536\n",
            "Epoch 89 (train)2.9s: train loss = 2.01808 = (mf)0.73088 + (embed)1.28721\n",
            "Epoch 90 (train)2.4s + (eval)0.7s: train loss = 2.04087 = (mf)0.74485 + (embed)1.29602, recall = 0.01369, ndcg = 0.13126\n",
            "Epoch 91 (train)2.4s: train loss = 2.02336 = (mf)0.72986 + (embed)1.29351\n",
            "Epoch 92 (train)2.4s: train loss = 2.02980 = (mf)0.73559 + (embed)1.29421\n",
            "Epoch 93 (train)3.0s: train loss = 2.02715 = (mf)0.73179 + (embed)1.29535\n",
            "Epoch 94 (train)2.5s: train loss = 2.02782 = (mf)0.73424 + (embed)1.29359\n",
            "Epoch 95 (train)2.4s + (eval)0.3s: train loss = 1.99642 = (mf)0.70419 + (embed)1.29223, recall = 0.01314, ndcg = 0.10834\n",
            "Epoch 96 (train)2.4s: train loss = 1.99370 = (mf)0.71066 + (embed)1.28304\n",
            "Epoch 97 (train)2.5s: train loss = 1.98669 = (mf)0.70162 + (embed)1.28508\n",
            "Epoch 98 (train)2.9s: train loss = 2.02418 = (mf)0.74140 + (embed)1.28279\n",
            "Epoch 99 (train)2.4s: train loss = 2.00048 = (mf)0.71476 + (embed)1.28572\n",
            "Epoch 100 (train)2.4s + (eval)0.3s: train loss = 2.06433 = (mf)0.77735 + (embed)1.28699, recall = 0.01161, ndcg = 0.10858\n",
            "Training finished in 266.55 seconds.\n",
            "Evaluation results for this combination: NDCG@20: 0.10858, Recall@20: 0.01161\n",
            "--- Trying combination: Epochs=100, TopK=50, LearningRate=0.005, Layers=3 ---\n",
            "Already normalize adjacency matrix (extended).\n",
            "Using xavier initialization for user, item, and genre embeddings.\n",
            "Epoch 1 (train)4.3s: train loss = 0.28932 = (mf)0.28875 + (embed)0.00057\n",
            "Epoch 2 (train)2.6s: train loss = 0.17218 = (mf)0.17113 + (embed)0.00105\n",
            "Epoch 3 (train)2.7s: train loss = 0.14410 = (mf)0.14264 + (embed)0.00147\n",
            "Epoch 4 (train)2.4s: train loss = 0.12713 = (mf)0.12529 + (embed)0.00184\n",
            "Epoch 5 (train)2.4s + (eval)1.3s: train loss = 0.11394 = (mf)0.11174 + (embed)0.00220, recall = 0.03127, ndcg = 0.14539\n",
            "Epoch 6 (train)2.4s: train loss = 0.10456 = (mf)0.10201 + (embed)0.00255\n",
            "Epoch 7 (train)2.9s: train loss = 0.09448 = (mf)0.09155 + (embed)0.00293\n",
            "Epoch 8 (train)2.4s: train loss = 0.08675 = (mf)0.08342 + (embed)0.00333\n",
            "Epoch 9 (train)2.4s: train loss = 0.07840 = (mf)0.07463 + (embed)0.00377\n",
            "Epoch 10 (train)2.4s + (eval)0.7s: train loss = 0.07135 = (mf)0.06717 + (embed)0.00418, recall = 0.03733, ndcg = 0.17564\n",
            "Epoch 11 (train)2.9s: train loss = 0.06643 = (mf)0.06185 + (embed)0.00458\n",
            "Epoch 12 (train)2.5s: train loss = 0.06179 = (mf)0.05682 + (embed)0.00497\n",
            "Epoch 13 (train)2.4s: train loss = 0.05839 = (mf)0.05309 + (embed)0.00530\n",
            "Epoch 14 (train)2.4s: train loss = 0.05472 = (mf)0.04908 + (embed)0.00564\n",
            "Epoch 15 (train)2.3s + (eval)0.3s: train loss = 0.05178 = (mf)0.04583 + (embed)0.00596, recall = 0.04001, ndcg = 0.18522\n",
            "Epoch 16 (train)2.9s: train loss = 0.04965 = (mf)0.04342 + (embed)0.00623\n",
            "Epoch 17 (train)2.4s: train loss = 0.04683 = (mf)0.04033 + (embed)0.00649\n",
            "Epoch 18 (train)2.4s: train loss = 0.04525 = (mf)0.03851 + (embed)0.00674\n",
            "Epoch 19 (train)2.4s: train loss = 0.04318 = (mf)0.03620 + (embed)0.00698\n",
            "Epoch 20 (train)2.5s + (eval)0.4s: train loss = 0.04208 = (mf)0.03488 + (embed)0.00720, recall = 0.04276, ndcg = 0.19405\n",
            "Epoch 21 (train)2.7s: train loss = 0.03952 = (mf)0.03212 + (embed)0.00740\n",
            "Epoch 22 (train)2.4s: train loss = 0.03953 = (mf)0.03197 + (embed)0.00757\n",
            "Epoch 23 (train)2.4s: train loss = 0.03775 = (mf)0.03001 + (embed)0.00775\n",
            "Epoch 24 (train)2.9s: train loss = 0.03652 = (mf)0.02859 + (embed)0.00793\n",
            "Epoch 25 (train)3.0s + (eval)0.7s: train loss = 0.03605 = (mf)0.02798 + (embed)0.00807, recall = 0.04251, ndcg = 0.19552\n",
            "Epoch 26 (train)2.4s: train loss = 0.03461 = (mf)0.02639 + (embed)0.00822\n",
            "Epoch 27 (train)2.4s: train loss = 0.03361 = (mf)0.02526 + (embed)0.00834\n",
            "Epoch 28 (train)2.4s: train loss = 0.03335 = (mf)0.02488 + (embed)0.00847\n",
            "Epoch 29 (train)2.7s: train loss = 0.03224 = (mf)0.02366 + (embed)0.00859\n",
            "Epoch 30 (train)2.6s + (eval)0.3s: train loss = 0.03102 = (mf)0.02234 + (embed)0.00869, recall = 0.04403, ndcg = 0.20277\n",
            "Epoch 31 (train)2.4s: train loss = 0.03134 = (mf)0.02255 + (embed)0.00878\n",
            "Epoch 32 (train)2.4s: train loss = 0.03021 = (mf)0.02133 + (embed)0.00888\n",
            "Epoch 33 (train)2.4s: train loss = 0.02963 = (mf)0.02068 + (embed)0.00895\n",
            "Epoch 34 (train)2.9s: train loss = 0.02949 = (mf)0.02047 + (embed)0.00902\n",
            "Epoch 35 (train)2.4s + (eval)0.3s: train loss = 0.02784 = (mf)0.01874 + (embed)0.00911, recall = 0.04254, ndcg = 0.19822\n",
            "Epoch 36 (train)2.4s: train loss = 0.02841 = (mf)0.01923 + (embed)0.00918\n",
            "Epoch 37 (train)2.4s: train loss = 0.02838 = (mf)0.01914 + (embed)0.00924\n",
            "Epoch 38 (train)2.4s: train loss = 0.02763 = (mf)0.01833 + (embed)0.00930\n",
            "Epoch 39 (train)2.9s: train loss = 0.02698 = (mf)0.01764 + (embed)0.00934\n",
            "Epoch 40 (train)2.4s + (eval)0.3s: train loss = 0.02684 = (mf)0.01743 + (embed)0.00941, recall = 0.04309, ndcg = 0.20452\n",
            "Epoch 41 (train)2.4s: train loss = 0.02604 = (mf)0.01659 + (embed)0.00945\n",
            "Epoch 42 (train)2.4s: train loss = 0.02608 = (mf)0.01658 + (embed)0.00950\n",
            "Epoch 43 (train)2.6s: train loss = 0.02592 = (mf)0.01636 + (embed)0.00956\n",
            "Epoch 44 (train)2.6s: train loss = 0.02574 = (mf)0.01615 + (embed)0.00959\n",
            "Epoch 45 (train)2.4s + (eval)0.7s: train loss = 0.02519 = (mf)0.01557 + (embed)0.00962, recall = 0.04391, ndcg = 0.20395\n",
            "Epoch 46 (train)2.4s: train loss = 0.02466 = (mf)0.01500 + (embed)0.00965\n",
            "Epoch 47 (train)2.4s: train loss = 0.02456 = (mf)0.01487 + (embed)0.00969\n",
            "Epoch 48 (train)2.9s: train loss = 0.02441 = (mf)0.01469 + (embed)0.00972\n",
            "Epoch 49 (train)2.4s: train loss = 0.02384 = (mf)0.01410 + (embed)0.00974\n",
            "Epoch 50 (train)2.4s + (eval)0.3s: train loss = 0.02340 = (mf)0.01363 + (embed)0.00977, recall = 0.04457, ndcg = 0.20734\n",
            "Epoch 51 (train)2.4s: train loss = 0.02332 = (mf)0.01351 + (embed)0.00981\n",
            "Epoch 52 (train)2.5s: train loss = 0.02308 = (mf)0.01323 + (embed)0.00985\n",
            "Epoch 53 (train)2.8s: train loss = 0.02306 = (mf)0.01319 + (embed)0.00987\n",
            "Epoch 54 (train)2.4s: train loss = 0.02299 = (mf)0.01311 + (embed)0.00988\n",
            "Epoch 55 (train)2.3s + (eval)0.3s: train loss = 0.02316 = (mf)0.01326 + (embed)0.00990, recall = 0.04451, ndcg = 0.20424\n",
            "Epoch 56 (train)2.3s: train loss = 0.02293 = (mf)0.01300 + (embed)0.00993\n",
            "Epoch 57 (train)2.8s: train loss = 0.02228 = (mf)0.01233 + (embed)0.00996\n",
            "Epoch 58 (train)2.6s: train loss = 0.02229 = (mf)0.01231 + (embed)0.00997\n",
            "Epoch 59 (train)2.4s: train loss = 0.02243 = (mf)0.01244 + (embed)0.00999\n",
            "Epoch 60 (train)2.4s + (eval)0.3s: train loss = 0.02208 = (mf)0.01206 + (embed)0.01002, recall = 0.04502, ndcg = 0.20858\n",
            "Epoch 61 (train)2.4s: train loss = 0.02185 = (mf)0.01184 + (embed)0.01002\n",
            "Epoch 62 (train)2.9s: train loss = 0.02160 = (mf)0.01156 + (embed)0.01004\n",
            "Epoch 63 (train)2.4s: train loss = 0.02195 = (mf)0.01190 + (embed)0.01005\n",
            "Epoch 64 (train)2.4s: train loss = 0.02150 = (mf)0.01144 + (embed)0.01006\n",
            "Epoch 65 (train)2.4s + (eval)0.7s: train loss = 0.02148 = (mf)0.01141 + (embed)0.01007, recall = 0.04528, ndcg = 0.20614\n",
            "Epoch 66 (train)2.6s: train loss = 0.02105 = (mf)0.01098 + (embed)0.01007\n",
            "Epoch 67 (train)2.7s: train loss = 0.02114 = (mf)0.01105 + (embed)0.01010\n",
            "Epoch 68 (train)2.4s: train loss = 0.02137 = (mf)0.01126 + (embed)0.01011\n",
            "Epoch 69 (train)2.4s: train loss = 0.02119 = (mf)0.01106 + (embed)0.01012\n",
            "Epoch 70 (train)2.4s + (eval)0.3s: train loss = 0.02046 = (mf)0.01032 + (embed)0.01014, recall = 0.04584, ndcg = 0.20924\n",
            "Epoch 71 (train)2.9s: train loss = 0.02081 = (mf)0.01067 + (embed)0.01014\n",
            "Epoch 72 (train)2.5s: train loss = 0.02062 = (mf)0.01046 + (embed)0.01016\n",
            "Epoch 73 (train)2.4s: train loss = 0.02073 = (mf)0.01057 + (embed)0.01017\n",
            "Epoch 74 (train)2.3s: train loss = 0.02031 = (mf)0.01014 + (embed)0.01017\n",
            "Epoch 75 (train)2.4s + (eval)0.3s: train loss = 0.01984 = (mf)0.00966 + (embed)0.01018, recall = 0.04483, ndcg = 0.20564\n",
            "Epoch 76 (train)2.9s: train loss = 0.02015 = (mf)0.00994 + (embed)0.01021\n",
            "Epoch 77 (train)2.4s: train loss = 0.02027 = (mf)0.01007 + (embed)0.01020\n",
            "Epoch 78 (train)2.4s: train loss = 0.02004 = (mf)0.00983 + (embed)0.01021\n",
            "Epoch 79 (train)2.4s: train loss = 0.01990 = (mf)0.00968 + (embed)0.01022\n",
            "Epoch 80 (train)2.4s + (eval)1.0s: train loss = 0.01983 = (mf)0.00960 + (embed)0.01022, recall = 0.04511, ndcg = 0.20369\n",
            "Epoch 81 (train)2.6s: train loss = 0.01983 = (mf)0.00960 + (embed)0.01023\n",
            "Epoch 82 (train)2.4s: train loss = 0.01956 = (mf)0.00931 + (embed)0.01024\n",
            "Epoch 83 (train)2.4s: train loss = 0.01977 = (mf)0.00951 + (embed)0.01026\n",
            "Epoch 84 (train)2.4s: train loss = 0.01926 = (mf)0.00901 + (embed)0.01025\n",
            "Epoch 85 (train)2.9s + (eval)0.3s: train loss = 0.01951 = (mf)0.00925 + (embed)0.01026, recall = 0.04536, ndcg = 0.20653\n",
            "Epoch 86 (train)2.4s: train loss = 0.01942 = (mf)0.00915 + (embed)0.01027\n",
            "Epoch 87 (train)2.4s: train loss = 0.01924 = (mf)0.00896 + (embed)0.01028\n",
            "Epoch 88 (train)2.4s: train loss = 0.01943 = (mf)0.00916 + (embed)0.01027\n",
            "Epoch 89 (train)2.4s: train loss = 0.01961 = (mf)0.00932 + (embed)0.01028\n",
            "Epoch 90 (train)2.9s + (eval)0.3s: train loss = 0.01915 = (mf)0.00887 + (embed)0.01029, recall = 0.04535, ndcg = 0.20812\n",
            "Epoch 91 (train)2.4s: train loss = 0.01923 = (mf)0.00893 + (embed)0.01030\n",
            "Epoch 92 (train)2.4s: train loss = 0.01901 = (mf)0.00870 + (embed)0.01031\n",
            "Epoch 93 (train)2.4s: train loss = 0.01935 = (mf)0.00904 + (embed)0.01031\n",
            "Epoch 94 (train)2.5s: train loss = 0.01886 = (mf)0.00853 + (embed)0.01033\n",
            "Epoch 95 (train)2.7s + (eval)0.3s: train loss = 0.01914 = (mf)0.00882 + (embed)0.01032, recall = 0.04472, ndcg = 0.19988\n",
            "Epoch 96 (train)2.4s: train loss = 0.01885 = (mf)0.00851 + (embed)0.01034\n",
            "Epoch 97 (train)2.4s: train loss = 0.01891 = (mf)0.00857 + (embed)0.01034\n",
            "Epoch 98 (train)2.4s: train loss = 0.01879 = (mf)0.00844 + (embed)0.01035\n",
            "Epoch 99 (train)2.8s: train loss = 0.01854 = (mf)0.00818 + (embed)0.01036\n",
            "Epoch 100 (train)2.5s + (eval)0.7s: train loss = 0.01880 = (mf)0.00844 + (embed)0.01036, recall = 0.04451, ndcg = 0.20278\n",
            "Training finished in 261.48 seconds.\n",
            "Evaluation results for this combination: NDCG@50: 0.20278, Recall@50: 0.04451\n",
            "--- Trying combination: Epochs=100, TopK=50, LearningRate=0.005, Layers=4 ---\n",
            "Already normalize adjacency matrix (extended).\n",
            "Using xavier initialization for user, item, and genre embeddings.\n",
            "Epoch 1 (train)4.5s: train loss = 0.29529 = (mf)0.29472 + (embed)0.00058\n",
            "Epoch 2 (train)2.3s: train loss = 0.20443 = (mf)0.20344 + (embed)0.00100\n",
            "Epoch 3 (train)2.4s: train loss = 0.18407 = (mf)0.18270 + (embed)0.00137\n",
            "Epoch 4 (train)2.9s: train loss = 0.15555 = (mf)0.15366 + (embed)0.00189\n",
            "Epoch 5 (train)2.4s + (eval)1.3s: train loss = 0.13657 = (mf)0.13417 + (embed)0.00240, recall = 0.02854, ndcg = 0.13089\n",
            "Epoch 6 (train)2.5s: train loss = 0.12740 = (mf)0.12458 + (embed)0.00282\n",
            "Epoch 7 (train)2.4s: train loss = 0.11589 = (mf)0.11265 + (embed)0.00324\n",
            "Epoch 8 (train)2.9s: train loss = 0.10810 = (mf)0.10440 + (embed)0.00370\n",
            "Epoch 9 (train)2.4s: train loss = 0.09697 = (mf)0.09280 + (embed)0.00418\n",
            "Epoch 10 (train)2.4s + (eval)0.4s: train loss = 0.09016 = (mf)0.08550 + (embed)0.00466, recall = 0.03431, ndcg = 0.16415\n",
            "Epoch 11 (train)2.9s: train loss = 0.08368 = (mf)0.07853 + (embed)0.00515\n",
            "Epoch 12 (train)2.7s: train loss = 0.07916 = (mf)0.07354 + (embed)0.00563\n",
            "Epoch 13 (train)2.7s: train loss = 0.07422 = (mf)0.06814 + (embed)0.00608\n",
            "Epoch 14 (train)2.4s: train loss = 0.07024 = (mf)0.06378 + (embed)0.00647\n",
            "Epoch 15 (train)2.4s + (eval)0.7s: train loss = 0.06745 = (mf)0.06062 + (embed)0.00683, recall = 0.03914, ndcg = 0.18251\n",
            "Epoch 16 (train)2.4s: train loss = 0.06401 = (mf)0.05686 + (embed)0.00715\n",
            "Epoch 17 (train)2.9s: train loss = 0.06219 = (mf)0.05473 + (embed)0.00746\n",
            "Epoch 18 (train)2.4s: train loss = 0.05957 = (mf)0.05183 + (embed)0.00774\n",
            "Epoch 19 (train)2.3s: train loss = 0.05820 = (mf)0.05017 + (embed)0.00803\n",
            "Epoch 20 (train)2.3s + (eval)0.3s: train loss = 0.05636 = (mf)0.04809 + (embed)0.00827, recall = 0.04117, ndcg = 0.18763\n",
            "Epoch 21 (train)2.5s: train loss = 0.05318 = (mf)0.04468 + (embed)0.00851\n",
            "Epoch 22 (train)2.8s: train loss = 0.05219 = (mf)0.04345 + (embed)0.00874\n",
            "Epoch 23 (train)2.4s: train loss = 0.04969 = (mf)0.04072 + (embed)0.00898\n",
            "Epoch 24 (train)2.4s: train loss = 0.04860 = (mf)0.03941 + (embed)0.00918\n",
            "Epoch 25 (train)2.4s + (eval)0.3s: train loss = 0.04684 = (mf)0.03746 + (embed)0.00938, recall = 0.04180, ndcg = 0.19338\n",
            "Epoch 26 (train)3.0s: train loss = 0.04577 = (mf)0.03622 + (embed)0.00955\n",
            "Epoch 27 (train)2.5s: train loss = 0.04541 = (mf)0.03569 + (embed)0.00973\n",
            "Epoch 28 (train)2.5s: train loss = 0.04399 = (mf)0.03413 + (embed)0.00986\n",
            "Epoch 29 (train)2.4s: train loss = 0.04374 = (mf)0.03373 + (embed)0.01001\n",
            "Epoch 30 (train)2.3s + (eval)0.3s: train loss = 0.04196 = (mf)0.03183 + (embed)0.01013, recall = 0.04142, ndcg = 0.19865\n",
            "Epoch 31 (train)2.9s: train loss = 0.04058 = (mf)0.03031 + (embed)0.01027\n",
            "Epoch 32 (train)2.4s: train loss = 0.04043 = (mf)0.03007 + (embed)0.01037\n",
            "Epoch 33 (train)2.4s: train loss = 0.03979 = (mf)0.02928 + (embed)0.01051\n",
            "Epoch 34 (train)2.4s: train loss = 0.03870 = (mf)0.02809 + (embed)0.01061\n",
            "Epoch 35 (train)2.6s + (eval)1.0s: train loss = 0.03919 = (mf)0.02849 + (embed)0.01070, recall = 0.04217, ndcg = 0.19753\n",
            "Epoch 36 (train)2.5s: train loss = 0.03822 = (mf)0.02742 + (embed)0.01080\n",
            "Epoch 37 (train)2.4s: train loss = 0.03747 = (mf)0.02658 + (embed)0.01088\n",
            "Epoch 38 (train)2.4s: train loss = 0.03663 = (mf)0.02566 + (embed)0.01097\n",
            "Epoch 39 (train)2.4s: train loss = 0.03558 = (mf)0.02450 + (embed)0.01108\n",
            "Epoch 40 (train)2.9s + (eval)0.3s: train loss = 0.03483 = (mf)0.02365 + (embed)0.01118, recall = 0.04374, ndcg = 0.20197\n",
            "Epoch 41 (train)2.4s: train loss = 0.03540 = (mf)0.02415 + (embed)0.01125\n",
            "Epoch 42 (train)2.3s: train loss = 0.03436 = (mf)0.02305 + (embed)0.01131\n",
            "Epoch 43 (train)2.4s: train loss = 0.03414 = (mf)0.02277 + (embed)0.01137\n",
            "Epoch 44 (train)2.5s: train loss = 0.03407 = (mf)0.02264 + (embed)0.01143\n",
            "Epoch 45 (train)2.8s + (eval)0.3s: train loss = 0.03387 = (mf)0.02239 + (embed)0.01148, recall = 0.04317, ndcg = 0.20291\n",
            "Epoch 46 (train)2.4s: train loss = 0.03312 = (mf)0.02160 + (embed)0.01153\n",
            "Epoch 47 (train)2.4s: train loss = 0.03256 = (mf)0.02098 + (embed)0.01158\n",
            "Epoch 48 (train)2.4s: train loss = 0.03237 = (mf)0.02074 + (embed)0.01164\n",
            "Epoch 49 (train)2.8s: train loss = 0.03221 = (mf)0.02053 + (embed)0.01168\n",
            "Epoch 50 (train)2.5s + (eval)0.3s: train loss = 0.03226 = (mf)0.02055 + (embed)0.01172, recall = 0.04385, ndcg = 0.20465\n",
            "Epoch 51 (train)2.4s: train loss = 0.03124 = (mf)0.01949 + (embed)0.01175\n",
            "Epoch 52 (train)2.4s: train loss = 0.03131 = (mf)0.01950 + (embed)0.01181\n",
            "Epoch 53 (train)2.4s: train loss = 0.03094 = (mf)0.01909 + (embed)0.01185\n",
            "Epoch 54 (train)2.9s: train loss = 0.03054 = (mf)0.01865 + (embed)0.01189\n",
            "Epoch 55 (train)2.4s + (eval)0.7s: train loss = 0.03052 = (mf)0.01859 + (embed)0.01192, recall = 0.04294, ndcg = 0.20301\n",
            "Epoch 56 (train)2.5s: train loss = 0.03028 = (mf)0.01833 + (embed)0.01195\n",
            "Epoch 57 (train)2.4s: train loss = 0.02970 = (mf)0.01772 + (embed)0.01197\n",
            "Epoch 58 (train)2.8s: train loss = 0.02952 = (mf)0.01751 + (embed)0.01201\n",
            "Epoch 59 (train)2.6s: train loss = 0.02913 = (mf)0.01707 + (embed)0.01206\n",
            "Epoch 60 (train)2.4s + (eval)0.3s: train loss = 0.02936 = (mf)0.01727 + (embed)0.01209, recall = 0.04446, ndcg = 0.20192\n",
            "Epoch 61 (train)2.4s: train loss = 0.02918 = (mf)0.01705 + (embed)0.01213\n",
            "Epoch 62 (train)2.4s: train loss = 0.02861 = (mf)0.01648 + (embed)0.01214\n",
            "Epoch 63 (train)2.9s: train loss = 0.02858 = (mf)0.01641 + (embed)0.01217\n",
            "Epoch 64 (train)2.4s: train loss = 0.02820 = (mf)0.01599 + (embed)0.01221\n",
            "Epoch 65 (train)2.4s + (eval)0.3s: train loss = 0.02779 = (mf)0.01554 + (embed)0.01225, recall = 0.04456, ndcg = 0.20574\n",
            "Epoch 66 (train)2.4s: train loss = 0.02778 = (mf)0.01550 + (embed)0.01228\n",
            "Epoch 67 (train)2.6s: train loss = 0.02781 = (mf)0.01553 + (embed)0.01228\n",
            "Epoch 68 (train)2.8s: train loss = 0.02804 = (mf)0.01574 + (embed)0.01229\n",
            "Epoch 69 (train)2.4s: train loss = 0.02768 = (mf)0.01535 + (embed)0.01232\n",
            "Epoch 70 (train)2.4s + (eval)0.3s: train loss = 0.02670 = (mf)0.01434 + (embed)0.01236, recall = 0.04480, ndcg = 0.19864\n",
            "Epoch 71 (train)2.4s: train loss = 0.02668 = (mf)0.01430 + (embed)0.01238\n",
            "Epoch 72 (train)2.9s: train loss = 0.02665 = (mf)0.01424 + (embed)0.01241\n",
            "Epoch 73 (train)2.4s: train loss = 0.02679 = (mf)0.01436 + (embed)0.01243\n",
            "Epoch 74 (train)2.4s: train loss = 0.02659 = (mf)0.01417 + (embed)0.01242\n",
            "Epoch 75 (train)2.4s + (eval)0.7s: train loss = 0.02675 = (mf)0.01429 + (embed)0.01246, recall = 0.04630, ndcg = 0.20457\n",
            "Epoch 76 (train)2.6s: train loss = 0.02662 = (mf)0.01414 + (embed)0.01248\n",
            "Epoch 77 (train)2.8s: train loss = 0.02639 = (mf)0.01388 + (embed)0.01250\n",
            "Epoch 78 (train)2.4s: train loss = 0.02638 = (mf)0.01387 + (embed)0.01251\n",
            "Epoch 79 (train)2.4s: train loss = 0.02583 = (mf)0.01331 + (embed)0.01252\n",
            "Epoch 80 (train)2.4s + (eval)0.3s: train loss = 0.02619 = (mf)0.01364 + (embed)0.01255, recall = 0.04521, ndcg = 0.19917\n",
            "Epoch 81 (train)2.9s: train loss = 0.02571 = (mf)0.01315 + (embed)0.01256\n",
            "Epoch 82 (train)2.4s: train loss = 0.02562 = (mf)0.01304 + (embed)0.01258\n",
            "Epoch 83 (train)2.4s: train loss = 0.02585 = (mf)0.01324 + (embed)0.01261\n",
            "Epoch 84 (train)2.4s: train loss = 0.02567 = (mf)0.01304 + (embed)0.01263\n",
            "Epoch 85 (train)2.4s + (eval)0.3s: train loss = 0.02557 = (mf)0.01294 + (embed)0.01263, recall = 0.04519, ndcg = 0.20216\n",
            "Epoch 86 (train)3.0s: train loss = 0.02569 = (mf)0.01303 + (embed)0.01266\n",
            "Epoch 87 (train)2.4s: train loss = 0.02559 = (mf)0.01291 + (embed)0.01268\n",
            "Epoch 88 (train)2.4s: train loss = 0.02529 = (mf)0.01260 + (embed)0.01269\n",
            "Epoch 89 (train)2.4s: train loss = 0.02515 = (mf)0.01244 + (embed)0.01271\n",
            "Epoch 90 (train)2.5s + (eval)0.4s: train loss = 0.02514 = (mf)0.01241 + (embed)0.01273, recall = 0.04544, ndcg = 0.20196\n",
            "Epoch 91 (train)2.7s: train loss = 0.02492 = (mf)0.01219 + (embed)0.01273\n",
            "Epoch 92 (train)2.4s: train loss = 0.02498 = (mf)0.01224 + (embed)0.01274\n",
            "Epoch 93 (train)2.4s: train loss = 0.02453 = (mf)0.01178 + (embed)0.01276\n",
            "Epoch 94 (train)2.4s: train loss = 0.02483 = (mf)0.01207 + (embed)0.01276\n",
            "Epoch 95 (train)2.9s + (eval)0.8s: train loss = 0.02493 = (mf)0.01215 + (embed)0.01278, recall = 0.04562, ndcg = 0.20314\n",
            "Epoch 96 (train)2.5s: train loss = 0.02478 = (mf)0.01199 + (embed)0.01279\n",
            "Epoch 97 (train)2.4s: train loss = 0.02483 = (mf)0.01202 + (embed)0.01281\n",
            "Epoch 98 (train)2.4s: train loss = 0.02408 = (mf)0.01127 + (embed)0.01281\n",
            "Epoch 99 (train)2.4s: train loss = 0.02448 = (mf)0.01165 + (embed)0.01283\n",
            "Epoch 100 (train)2.9s + (eval)0.3s: train loss = 0.02443 = (mf)0.01158 + (embed)0.01285, recall = 0.04507, ndcg = 0.20450\n",
            "Training finished in 263.22 seconds.\n",
            "Evaluation results for this combination: NDCG@50: 0.20450, Recall@50: 0.04507\n",
            "--- Trying combination: Epochs=100, TopK=50, LearningRate=0.005, Layers=5 ---\n",
            "Already normalize adjacency matrix (extended).\n",
            "Using xavier initialization for user, item, and genre embeddings.\n",
            "Epoch 1 (train)4.4s: train loss = 0.30034 = (mf)0.29975 + (embed)0.00059\n",
            "Epoch 2 (train)2.5s: train loss = 0.21214 = (mf)0.21109 + (embed)0.00105\n",
            "Epoch 3 (train)2.4s: train loss = 0.18937 = (mf)0.18786 + (embed)0.00152\n",
            "Epoch 4 (train)2.9s: train loss = 0.16823 = (mf)0.16618 + (embed)0.00205\n",
            "Epoch 5 (train)2.6s + (eval)1.3s: train loss = 0.15289 = (mf)0.15033 + (embed)0.00256, recall = 0.02654, ndcg = 0.13040\n",
            "Epoch 6 (train)2.5s: train loss = 0.14199 = (mf)0.13897 + (embed)0.00302\n",
            "Epoch 7 (train)2.4s: train loss = 0.13590 = (mf)0.13243 + (embed)0.00347\n",
            "Epoch 8 (train)2.8s: train loss = 0.12676 = (mf)0.12282 + (embed)0.00394\n",
            "Epoch 9 (train)2.6s: train loss = 0.11667 = (mf)0.11220 + (embed)0.00447\n",
            "Epoch 10 (train)2.5s + (eval)0.7s: train loss = 0.10879 = (mf)0.10376 + (embed)0.00503, recall = 0.03199, ndcg = 0.15108\n",
            "Epoch 11 (train)2.4s: train loss = 0.10120 = (mf)0.09556 + (embed)0.00563\n",
            "Epoch 12 (train)2.5s: train loss = 0.09333 = (mf)0.08713 + (embed)0.00620\n",
            "Epoch 13 (train)3.0s: train loss = 0.08919 = (mf)0.08243 + (embed)0.00675\n",
            "Epoch 14 (train)2.4s: train loss = 0.08369 = (mf)0.07643 + (embed)0.00727\n",
            "Epoch 15 (train)2.4s + (eval)0.3s: train loss = 0.08025 = (mf)0.07253 + (embed)0.00772, recall = 0.03706, ndcg = 0.17318\n",
            "Epoch 16 (train)2.4s: train loss = 0.07658 = (mf)0.06841 + (embed)0.00816\n",
            "Epoch 17 (train)2.9s: train loss = 0.07317 = (mf)0.06462 + (embed)0.00855\n",
            "Epoch 18 (train)2.6s: train loss = 0.07058 = (mf)0.06166 + (embed)0.00891\n",
            "Epoch 19 (train)2.4s: train loss = 0.06928 = (mf)0.06005 + (embed)0.00923\n",
            "Epoch 20 (train)2.4s + (eval)0.3s: train loss = 0.06709 = (mf)0.05754 + (embed)0.00955, recall = 0.03900, ndcg = 0.18393\n",
            "Epoch 21 (train)2.4s: train loss = 0.06410 = (mf)0.05426 + (embed)0.00984\n",
            "Epoch 22 (train)3.0s: train loss = 0.06335 = (mf)0.05323 + (embed)0.01011\n",
            "Epoch 23 (train)2.5s: train loss = 0.06114 = (mf)0.05080 + (embed)0.01034\n",
            "Epoch 24 (train)2.5s: train loss = 0.05933 = (mf)0.04872 + (embed)0.01061\n",
            "Epoch 25 (train)2.4s + (eval)0.3s: train loss = 0.05857 = (mf)0.04776 + (embed)0.01081, recall = 0.04096, ndcg = 0.18824\n",
            "Epoch 26 (train)2.8s: train loss = 0.05639 = (mf)0.04538 + (embed)0.01101\n",
            "Epoch 27 (train)2.6s: train loss = 0.05575 = (mf)0.04454 + (embed)0.01121\n",
            "Epoch 28 (train)2.4s: train loss = 0.05468 = (mf)0.04329 + (embed)0.01138\n",
            "Epoch 29 (train)2.4s: train loss = 0.05284 = (mf)0.04127 + (embed)0.01157\n",
            "Epoch 30 (train)2.4s + (eval)0.8s: train loss = 0.05266 = (mf)0.04091 + (embed)0.01175, recall = 0.04181, ndcg = 0.19207\n",
            "Epoch 31 (train)2.9s: train loss = 0.05047 = (mf)0.03859 + (embed)0.01188\n",
            "Epoch 32 (train)2.5s: train loss = 0.04967 = (mf)0.03762 + (embed)0.01205\n",
            "Epoch 33 (train)2.4s: train loss = 0.04887 = (mf)0.03669 + (embed)0.01217\n",
            "Epoch 34 (train)2.4s: train loss = 0.04881 = (mf)0.03652 + (embed)0.01229\n",
            "Epoch 35 (train)2.8s + (eval)0.4s: train loss = 0.04717 = (mf)0.03472 + (embed)0.01244, recall = 0.04322, ndcg = 0.19984\n",
            "Epoch 36 (train)2.6s: train loss = 0.04721 = (mf)0.03464 + (embed)0.01257\n",
            "Epoch 37 (train)2.4s: train loss = 0.04511 = (mf)0.03242 + (embed)0.01269\n",
            "Epoch 38 (train)2.5s: train loss = 0.04566 = (mf)0.03289 + (embed)0.01278\n",
            "Epoch 39 (train)2.5s: train loss = 0.04430 = (mf)0.03143 + (embed)0.01287\n",
            "Epoch 40 (train)3.0s + (eval)0.3s: train loss = 0.04390 = (mf)0.03093 + (embed)0.01297, recall = 0.04333, ndcg = 0.20025\n",
            "Epoch 41 (train)2.4s: train loss = 0.04307 = (mf)0.03004 + (embed)0.01303\n",
            "Epoch 42 (train)2.5s: train loss = 0.04243 = (mf)0.02931 + (embed)0.01312\n",
            "Epoch 43 (train)2.4s: train loss = 0.04202 = (mf)0.02881 + (embed)0.01321\n",
            "Epoch 44 (train)2.7s: train loss = 0.04182 = (mf)0.02852 + (embed)0.01330\n",
            "Epoch 45 (train)2.7s + (eval)0.3s: train loss = 0.04137 = (mf)0.02797 + (embed)0.01340, recall = 0.04426, ndcg = 0.20339\n",
            "Epoch 46 (train)2.4s: train loss = 0.04023 = (mf)0.02676 + (embed)0.01347\n",
            "Epoch 47 (train)2.5s: train loss = 0.04012 = (mf)0.02661 + (embed)0.01351\n",
            "Epoch 48 (train)2.4s: train loss = 0.03985 = (mf)0.02626 + (embed)0.01359\n",
            "Epoch 49 (train)3.0s: train loss = 0.03977 = (mf)0.02612 + (embed)0.01365\n",
            "Epoch 50 (train)2.5s + (eval)0.7s: train loss = 0.03915 = (mf)0.02546 + (embed)0.01369, recall = 0.04501, ndcg = 0.20720\n",
            "Epoch 51 (train)2.5s: train loss = 0.03896 = (mf)0.02521 + (embed)0.01376\n",
            "Epoch 52 (train)2.5s: train loss = 0.03869 = (mf)0.02487 + (embed)0.01382\n",
            "Epoch 53 (train)2.8s: train loss = 0.03744 = (mf)0.02355 + (embed)0.01389\n",
            "Epoch 54 (train)2.6s: train loss = 0.03792 = (mf)0.02400 + (embed)0.01392\n",
            "Epoch 55 (train)2.5s + (eval)0.3s: train loss = 0.03791 = (mf)0.02394 + (embed)0.01396, recall = 0.04468, ndcg = 0.20863\n",
            "Epoch 56 (train)2.4s: train loss = 0.03668 = (mf)0.02267 + (embed)0.01401\n",
            "Epoch 57 (train)2.4s: train loss = 0.03636 = (mf)0.02231 + (embed)0.01405\n",
            "Epoch 58 (train)3.0s: train loss = 0.03687 = (mf)0.02278 + (embed)0.01410\n",
            "Epoch 59 (train)2.4s: train loss = 0.03599 = (mf)0.02186 + (embed)0.01413\n",
            "Epoch 60 (train)2.4s + (eval)0.3s: train loss = 0.03569 = (mf)0.02150 + (embed)0.01419, recall = 0.04474, ndcg = 0.20956\n",
            "Epoch 61 (train)2.5s: train loss = 0.03559 = (mf)0.02136 + (embed)0.01423\n",
            "Epoch 62 (train)2.8s: train loss = 0.03522 = (mf)0.02095 + (embed)0.01427\n",
            "Epoch 63 (train)2.7s: train loss = 0.03575 = (mf)0.02144 + (embed)0.01430\n",
            "Epoch 64 (train)2.4s: train loss = 0.03497 = (mf)0.02062 + (embed)0.01435\n",
            "Epoch 65 (train)2.4s + (eval)0.3s: train loss = 0.03483 = (mf)0.02044 + (embed)0.01440, recall = 0.04497, ndcg = 0.21079\n",
            "Epoch 66 (train)2.4s: train loss = 0.03468 = (mf)0.02025 + (embed)0.01443\n",
            "Epoch 67 (train)3.0s: train loss = 0.03425 = (mf)0.01978 + (embed)0.01447\n",
            "Epoch 68 (train)2.4s: train loss = 0.03432 = (mf)0.01980 + (embed)0.01451\n",
            "Epoch 69 (train)2.5s: train loss = 0.03393 = (mf)0.01937 + (embed)0.01456\n",
            "Epoch 70 (train)2.4s + (eval)0.7s: train loss = 0.03372 = (mf)0.01917 + (embed)0.01456, recall = 0.04478, ndcg = 0.20825\n",
            "Epoch 71 (train)2.8s: train loss = 0.03398 = (mf)0.01936 + (embed)0.01461\n",
            "Epoch 72 (train)2.6s: train loss = 0.03336 = (mf)0.01871 + (embed)0.01465\n",
            "Epoch 73 (train)2.4s: train loss = 0.03344 = (mf)0.01877 + (embed)0.01467\n",
            "Epoch 74 (train)2.4s: train loss = 0.03347 = (mf)0.01876 + (embed)0.01471\n",
            "Epoch 75 (train)2.4s + (eval)0.3s: train loss = 0.03266 = (mf)0.01793 + (embed)0.01473, recall = 0.04450, ndcg = 0.20401\n",
            "Epoch 76 (train)3.0s: train loss = 0.03288 = (mf)0.01809 + (embed)0.01478\n",
            "Epoch 77 (train)2.5s: train loss = 0.03254 = (mf)0.01776 + (embed)0.01478\n",
            "Epoch 78 (train)2.4s: train loss = 0.03237 = (mf)0.01756 + (embed)0.01482\n",
            "Epoch 79 (train)2.4s: train loss = 0.03221 = (mf)0.01737 + (embed)0.01484\n",
            "Epoch 80 (train)2.7s + (eval)0.4s: train loss = 0.03207 = (mf)0.01721 + (embed)0.01486, recall = 0.04516, ndcg = 0.20628\n",
            "Epoch 81 (train)2.7s: train loss = 0.03243 = (mf)0.01754 + (embed)0.01489\n",
            "Epoch 82 (train)2.4s: train loss = 0.03239 = (mf)0.01746 + (embed)0.01493\n",
            "Epoch 83 (train)2.4s: train loss = 0.03202 = (mf)0.01706 + (embed)0.01497\n",
            "Epoch 84 (train)2.4s: train loss = 0.03130 = (mf)0.01633 + (embed)0.01497\n",
            "Epoch 85 (train)3.0s + (eval)0.7s: train loss = 0.03146 = (mf)0.01648 + (embed)0.01498, recall = 0.04513, ndcg = 0.20462\n",
            "Epoch 86 (train)2.9s: train loss = 0.03162 = (mf)0.01660 + (embed)0.01502\n",
            "Epoch 87 (train)2.6s: train loss = 0.03184 = (mf)0.01683 + (embed)0.01501\n",
            "Epoch 88 (train)2.4s: train loss = 0.03124 = (mf)0.01621 + (embed)0.01503\n",
            "Epoch 89 (train)2.9s: train loss = 0.03101 = (mf)0.01596 + (embed)0.01506\n",
            "Epoch 90 (train)2.4s + (eval)0.3s: train loss = 0.03118 = (mf)0.01607 + (embed)0.01511, recall = 0.04587, ndcg = 0.20464\n",
            "Epoch 91 (train)2.5s: train loss = 0.03123 = (mf)0.01612 + (embed)0.01511\n",
            "Epoch 92 (train)2.5s: train loss = 0.03139 = (mf)0.01624 + (embed)0.01515\n",
            "Epoch 93 (train)2.5s: train loss = 0.03122 = (mf)0.01603 + (embed)0.01519\n",
            "Epoch 94 (train)2.9s: train loss = 0.03120 = (mf)0.01601 + (embed)0.01520\n",
            "Epoch 95 (train)2.4s + (eval)0.3s: train loss = 0.03083 = (mf)0.01561 + (embed)0.01523, recall = 0.04573, ndcg = 0.21215\n",
            "Epoch 96 (train)2.5s: train loss = 0.03066 = (mf)0.01541 + (embed)0.01524\n",
            "Epoch 97 (train)2.4s: train loss = 0.03052 = (mf)0.01526 + (embed)0.01526\n",
            "Epoch 98 (train)2.8s: train loss = 0.03043 = (mf)0.01513 + (embed)0.01530\n",
            "Epoch 99 (train)2.5s: train loss = 0.03023 = (mf)0.01493 + (embed)0.01530\n",
            "Epoch 100 (train)2.4s + (eval)0.3s: train loss = 0.03052 = (mf)0.01520 + (embed)0.01532, recall = 0.04473, ndcg = 0.20591\n",
            "Training finished in 267.96 seconds.\n",
            "Evaluation results for this combination: NDCG@50: 0.20591, Recall@50: 0.04473\n",
            "--- Trying combination: Epochs=100, TopK=50, LearningRate=0.05, Layers=3 ---\n",
            "Already normalize adjacency matrix (extended).\n",
            "Using xavier initialization for user, item, and genre embeddings.\n",
            "Epoch 1 (train)4.5s: train loss = 0.15825 = (mf)0.15504 + (embed)0.00321\n",
            "Epoch 2 (train)2.4s: train loss = 0.07107 = (mf)0.06317 + (embed)0.00790\n",
            "Epoch 3 (train)2.9s: train loss = 0.05604 = (mf)0.04488 + (embed)0.01116\n",
            "Epoch 4 (train)2.4s: train loss = 0.04876 = (mf)0.03533 + (embed)0.01343\n",
            "Epoch 5 (train)2.3s + (eval)1.8s: train loss = 0.04724 = (mf)0.03209 + (embed)0.01515, recall = 0.03569, ndcg = 0.14868\n",
            "Epoch 6 (train)2.4s: train loss = 0.04754 = (mf)0.03099 + (embed)0.01655\n",
            "Epoch 7 (train)2.9s: train loss = 0.04581 = (mf)0.02805 + (embed)0.01776\n",
            "Epoch 8 (train)2.4s: train loss = 0.04768 = (mf)0.02886 + (embed)0.01883\n",
            "Epoch 9 (train)2.4s: train loss = 0.04614 = (mf)0.02646 + (embed)0.01967\n",
            "Epoch 10 (train)2.4s + (eval)0.3s: train loss = 0.04733 = (mf)0.02683 + (embed)0.02050, recall = 0.03263, ndcg = 0.12889\n",
            "Epoch 11 (train)2.7s: train loss = 0.04817 = (mf)0.02696 + (embed)0.02122\n",
            "Epoch 12 (train)2.7s: train loss = 0.04821 = (mf)0.02626 + (embed)0.02195\n",
            "Epoch 13 (train)2.4s: train loss = 0.04721 = (mf)0.02479 + (embed)0.02242\n",
            "Epoch 14 (train)2.4s: train loss = 0.04864 = (mf)0.02562 + (embed)0.02302\n",
            "Epoch 15 (train)2.4s + (eval)0.3s: train loss = 0.04808 = (mf)0.02460 + (embed)0.02348, recall = 0.03225, ndcg = 0.12749\n",
            "Epoch 16 (train)2.9s: train loss = 0.04716 = (mf)0.02326 + (embed)0.02390\n",
            "Epoch 17 (train)2.4s: train loss = 0.04769 = (mf)0.02351 + (embed)0.02418\n",
            "Epoch 18 (train)2.4s: train loss = 0.04849 = (mf)0.02394 + (embed)0.02455\n",
            "Epoch 19 (train)2.4s: train loss = 0.04873 = (mf)0.02388 + (embed)0.02485\n",
            "Epoch 20 (train)2.4s + (eval)0.4s: train loss = 0.04873 = (mf)0.02362 + (embed)0.02512, recall = 0.03298, ndcg = 0.12890\n",
            "Epoch 21 (train)2.8s: train loss = 0.04883 = (mf)0.02348 + (embed)0.02535\n",
            "Epoch 22 (train)2.4s: train loss = 0.04707 = (mf)0.02141 + (embed)0.02566\n",
            "Epoch 23 (train)2.4s: train loss = 0.04780 = (mf)0.02193 + (embed)0.02587\n",
            "Epoch 24 (train)2.4s: train loss = 0.04863 = (mf)0.02256 + (embed)0.02607\n",
            "Epoch 25 (train)2.7s + (eval)0.9s: train loss = 0.04864 = (mf)0.02226 + (embed)0.02638, recall = 0.03289, ndcg = 0.12802\n",
            "Epoch 26 (train)2.4s: train loss = 0.04880 = (mf)0.02215 + (embed)0.02665\n",
            "Epoch 27 (train)2.4s: train loss = 0.04896 = (mf)0.02223 + (embed)0.02673\n",
            "Epoch 28 (train)2.4s: train loss = 0.04978 = (mf)0.02286 + (embed)0.02692\n",
            "Epoch 29 (train)2.4s: train loss = 0.04857 = (mf)0.02150 + (embed)0.02707\n",
            "Epoch 30 (train)2.9s + (eval)0.3s: train loss = 0.04798 = (mf)0.02078 + (embed)0.02721, recall = 0.03046, ndcg = 0.12651\n",
            "Epoch 31 (train)2.4s: train loss = 0.04838 = (mf)0.02097 + (embed)0.02740\n",
            "Epoch 32 (train)2.4s: train loss = 0.04727 = (mf)0.01985 + (embed)0.02742\n",
            "Epoch 33 (train)2.4s: train loss = 0.04909 = (mf)0.02162 + (embed)0.02747\n",
            "Epoch 34 (train)2.7s: train loss = 0.04724 = (mf)0.01968 + (embed)0.02755\n",
            "Epoch 35 (train)2.7s + (eval)0.3s: train loss = 0.04821 = (mf)0.02068 + (embed)0.02753, recall = 0.03191, ndcg = 0.13347\n",
            "Epoch 36 (train)2.4s: train loss = 0.04890 = (mf)0.02120 + (embed)0.02770\n",
            "Epoch 37 (train)2.4s: train loss = 0.04744 = (mf)0.01961 + (embed)0.02784\n",
            "Epoch 38 (train)2.4s: train loss = 0.04826 = (mf)0.02044 + (embed)0.02783\n",
            "Epoch 39 (train)2.9s: train loss = 0.04795 = (mf)0.02011 + (embed)0.02785\n",
            "Epoch 40 (train)2.4s + (eval)0.3s: train loss = 0.04835 = (mf)0.02044 + (embed)0.02792, recall = 0.03196, ndcg = 0.12973\n",
            "Epoch 41 (train)2.4s: train loss = 0.04871 = (mf)0.02066 + (embed)0.02804\n",
            "Epoch 42 (train)2.4s: train loss = 0.04877 = (mf)0.02077 + (embed)0.02800\n",
            "Epoch 43 (train)2.4s: train loss = 0.04798 = (mf)0.02001 + (embed)0.02797\n",
            "Epoch 44 (train)2.9s: train loss = 0.04848 = (mf)0.02052 + (embed)0.02797\n",
            "Epoch 45 (train)2.4s + (eval)0.7s: train loss = 0.04781 = (mf)0.01987 + (embed)0.02794, recall = 0.03315, ndcg = 0.13738\n",
            "Epoch 46 (train)2.4s: train loss = 0.04772 = (mf)0.01971 + (embed)0.02802\n",
            "Epoch 47 (train)2.4s: train loss = 0.04737 = (mf)0.01938 + (embed)0.02799\n",
            "Epoch 48 (train)2.9s: train loss = 0.04812 = (mf)0.02009 + (embed)0.02804\n",
            "Epoch 49 (train)2.4s: train loss = 0.04746 = (mf)0.01940 + (embed)0.02806\n",
            "Epoch 50 (train)2.4s + (eval)0.3s: train loss = 0.04787 = (mf)0.01981 + (embed)0.02807, recall = 0.03417, ndcg = 0.14094\n",
            "Epoch 51 (train)2.4s: train loss = 0.04938 = (mf)0.02133 + (embed)0.02804\n",
            "Epoch 52 (train)2.4s: train loss = 0.04852 = (mf)0.02036 + (embed)0.02816\n",
            "Epoch 53 (train)2.9s: train loss = 0.04827 = (mf)0.01996 + (embed)0.02831\n",
            "Epoch 54 (train)2.4s: train loss = 0.04846 = (mf)0.02019 + (embed)0.02827\n",
            "Epoch 55 (train)2.4s + (eval)0.3s: train loss = 0.04757 = (mf)0.01933 + (embed)0.02824, recall = 0.03169, ndcg = 0.12499\n",
            "Epoch 56 (train)2.4s: train loss = 0.04830 = (mf)0.02004 + (embed)0.02826\n",
            "Epoch 57 (train)2.6s: train loss = 0.04717 = (mf)0.01885 + (embed)0.02832\n",
            "Epoch 58 (train)2.7s: train loss = 0.04857 = (mf)0.02033 + (embed)0.02825\n",
            "Epoch 59 (train)2.4s: train loss = 0.04728 = (mf)0.01908 + (embed)0.02820\n",
            "Epoch 60 (train)2.4s + (eval)0.3s: train loss = 0.04747 = (mf)0.01927 + (embed)0.02820, recall = 0.03209, ndcg = 0.11852\n",
            "Epoch 61 (train)2.4s: train loss = 0.04797 = (mf)0.01976 + (embed)0.02821\n",
            "Epoch 62 (train)2.9s: train loss = 0.04797 = (mf)0.01974 + (embed)0.02823\n",
            "Epoch 63 (train)2.4s: train loss = 0.04757 = (mf)0.01941 + (embed)0.02816\n",
            "Epoch 64 (train)2.4s: train loss = 0.04808 = (mf)0.01989 + (embed)0.02819\n",
            "Epoch 65 (train)2.4s + (eval)0.7s: train loss = 0.04708 = (mf)0.01891 + (embed)0.02817, recall = 0.03205, ndcg = 0.11831\n",
            "Epoch 66 (train)2.6s: train loss = 0.04743 = (mf)0.01921 + (embed)0.02822\n",
            "Epoch 67 (train)2.8s: train loss = 0.04868 = (mf)0.02037 + (embed)0.02831\n",
            "Epoch 68 (train)2.4s: train loss = 0.04733 = (mf)0.01902 + (embed)0.02831\n",
            "Epoch 69 (train)2.4s: train loss = 0.04680 = (mf)0.01851 + (embed)0.02829\n",
            "Epoch 70 (train)2.4s + (eval)0.3s: train loss = 0.04765 = (mf)0.01943 + (embed)0.02822, recall = 0.03172, ndcg = 0.12495\n",
            "Epoch 71 (train)2.9s: train loss = 0.04727 = (mf)0.01915 + (embed)0.02813\n",
            "Epoch 72 (train)2.6s: train loss = 0.04767 = (mf)0.01950 + (embed)0.02817\n",
            "Epoch 73 (train)2.8s: train loss = 0.04728 = (mf)0.01911 + (embed)0.02817\n",
            "Epoch 74 (train)2.4s: train loss = 0.04776 = (mf)0.01961 + (embed)0.02815\n",
            "Epoch 75 (train)2.5s + (eval)0.4s: train loss = 0.04867 = (mf)0.02036 + (embed)0.02830, recall = 0.03324, ndcg = 0.12847\n",
            "Epoch 76 (train)2.8s: train loss = 0.04750 = (mf)0.01913 + (embed)0.02837\n",
            "Epoch 77 (train)2.4s: train loss = 0.04785 = (mf)0.01957 + (embed)0.02828\n",
            "Epoch 78 (train)2.4s: train loss = 0.04776 = (mf)0.01943 + (embed)0.02833\n",
            "Epoch 79 (train)2.4s: train loss = 0.04759 = (mf)0.01932 + (embed)0.02827\n",
            "Epoch 80 (train)2.7s + (eval)0.4s: train loss = 0.04767 = (mf)0.01937 + (embed)0.02830, recall = 0.03005, ndcg = 0.12572\n",
            "Epoch 81 (train)2.5s: train loss = 0.04766 = (mf)0.01935 + (embed)0.02831\n",
            "Epoch 82 (train)2.4s: train loss = 0.04829 = (mf)0.01995 + (embed)0.02834\n",
            "Epoch 83 (train)2.4s: train loss = 0.04850 = (mf)0.02012 + (embed)0.02838\n",
            "Epoch 84 (train)2.4s: train loss = 0.04828 = (mf)0.01997 + (embed)0.02831\n",
            "Epoch 85 (train)2.9s + (eval)0.7s: train loss = 0.04710 = (mf)0.01888 + (embed)0.02822, recall = 0.03234, ndcg = 0.12819\n",
            "Epoch 86 (train)2.4s: train loss = 0.04843 = (mf)0.02015 + (embed)0.02828\n",
            "Epoch 87 (train)2.4s: train loss = 0.04877 = (mf)0.02037 + (embed)0.02840\n",
            "Epoch 88 (train)2.4s: train loss = 0.04910 = (mf)0.02063 + (embed)0.02847\n",
            "Epoch 89 (train)2.7s: train loss = 0.04801 = (mf)0.01954 + (embed)0.02847\n",
            "Epoch 90 (train)2.6s + (eval)0.3s: train loss = 0.04857 = (mf)0.02006 + (embed)0.02851, recall = 0.03318, ndcg = 0.13290\n",
            "Epoch 91 (train)2.4s: train loss = 0.04933 = (mf)0.02072 + (embed)0.02861\n",
            "Epoch 92 (train)2.4s: train loss = 0.04911 = (mf)0.02054 + (embed)0.02857\n",
            "Epoch 93 (train)2.4s: train loss = 0.04700 = (mf)0.01844 + (embed)0.02857\n",
            "Epoch 94 (train)2.9s: train loss = 0.04679 = (mf)0.01836 + (embed)0.02843\n",
            "Epoch 95 (train)2.4s + (eval)0.3s: train loss = 0.04780 = (mf)0.01943 + (embed)0.02837, recall = 0.03272, ndcg = 0.13029\n",
            "Epoch 96 (train)2.4s: train loss = 0.04716 = (mf)0.01877 + (embed)0.02839\n",
            "Epoch 97 (train)2.4s: train loss = 0.04726 = (mf)0.01895 + (embed)0.02831\n",
            "Epoch 98 (train)2.4s: train loss = 0.04841 = (mf)0.02002 + (embed)0.02839\n",
            "Epoch 99 (train)2.8s: train loss = 0.04837 = (mf)0.02001 + (embed)0.02836\n",
            "Epoch 100 (train)2.4s + (eval)0.8s: train loss = 0.04763 = (mf)0.01920 + (embed)0.02842, recall = 0.03190, ndcg = 0.12880\n",
            "Training finished in 263.69 seconds.\n",
            "Evaluation results for this combination: NDCG@50: 0.12880, Recall@50: 0.03190\n",
            "--- Trying combination: Epochs=100, TopK=50, LearningRate=0.05, Layers=4 ---\n",
            "Already normalize adjacency matrix (extended).\n",
            "Using xavier initialization for user, item, and genre embeddings.\n",
            "Epoch 1 (train)4.5s: train loss = 0.17257 = (mf)0.16928 + (embed)0.00328\n",
            "Epoch 2 (train)2.4s: train loss = 0.08178 = (mf)0.07356 + (embed)0.00822\n",
            "Epoch 3 (train)2.9s: train loss = 0.06076 = (mf)0.04885 + (embed)0.01191\n",
            "Epoch 4 (train)2.4s: train loss = 0.05309 = (mf)0.03861 + (embed)0.01448\n",
            "Epoch 5 (train)2.4s + (eval)1.3s: train loss = 0.04727 = (mf)0.03105 + (embed)0.01623, recall = 0.03908, ndcg = 0.15925\n",
            "Epoch 6 (train)2.6s: train loss = 0.04692 = (mf)0.02942 + (embed)0.01750\n",
            "Epoch 7 (train)3.0s: train loss = 0.04528 = (mf)0.02669 + (embed)0.01860\n",
            "Epoch 8 (train)2.4s: train loss = 0.04463 = (mf)0.02518 + (embed)0.01945\n",
            "Epoch 9 (train)2.4s: train loss = 0.04357 = (mf)0.02336 + (embed)0.02021\n",
            "Epoch 10 (train)2.4s + (eval)0.3s: train loss = 0.04306 = (mf)0.02223 + (embed)0.02083, recall = 0.03695, ndcg = 0.15735\n",
            "Epoch 11 (train)2.5s: train loss = 0.04224 = (mf)0.02101 + (embed)0.02122\n",
            "Epoch 12 (train)2.9s: train loss = 0.04253 = (mf)0.02085 + (embed)0.02168\n",
            "Epoch 13 (train)2.4s: train loss = 0.04173 = (mf)0.01969 + (embed)0.02204\n",
            "Epoch 14 (train)2.4s: train loss = 0.04160 = (mf)0.01919 + (embed)0.02242\n",
            "Epoch 15 (train)2.4s + (eval)0.3s: train loss = 0.04062 = (mf)0.01804 + (embed)0.02258, recall = 0.03730, ndcg = 0.15787\n",
            "Epoch 16 (train)2.8s: train loss = 0.04174 = (mf)0.01898 + (embed)0.02276\n",
            "Epoch 17 (train)2.6s: train loss = 0.04022 = (mf)0.01723 + (embed)0.02300\n",
            "Epoch 18 (train)2.4s: train loss = 0.04185 = (mf)0.01860 + (embed)0.02324\n",
            "Epoch 19 (train)2.4s: train loss = 0.04035 = (mf)0.01684 + (embed)0.02351\n",
            "Epoch 20 (train)2.4s + (eval)0.8s: train loss = 0.04082 = (mf)0.01727 + (embed)0.02355, recall = 0.03641, ndcg = 0.14820\n",
            "Epoch 21 (train)3.0s: train loss = 0.04094 = (mf)0.01717 + (embed)0.02376\n",
            "Epoch 22 (train)2.4s: train loss = 0.04132 = (mf)0.01731 + (embed)0.02401\n",
            "Epoch 23 (train)2.4s: train loss = 0.04072 = (mf)0.01660 + (embed)0.02412\n",
            "Epoch 24 (train)2.4s: train loss = 0.04046 = (mf)0.01624 + (embed)0.02421\n",
            "Epoch 25 (train)2.7s + (eval)0.4s: train loss = 0.04079 = (mf)0.01663 + (embed)0.02415, recall = 0.03776, ndcg = 0.15493\n",
            "Epoch 26 (train)2.6s: train loss = 0.04104 = (mf)0.01677 + (embed)0.02427\n",
            "Epoch 27 (train)2.4s: train loss = 0.04090 = (mf)0.01649 + (embed)0.02441\n",
            "Epoch 28 (train)2.4s: train loss = 0.04102 = (mf)0.01659 + (embed)0.02443\n",
            "Epoch 29 (train)2.4s: train loss = 0.04061 = (mf)0.01605 + (embed)0.02456\n",
            "Epoch 30 (train)2.9s + (eval)0.3s: train loss = 0.04012 = (mf)0.01554 + (embed)0.02458, recall = 0.03637, ndcg = 0.14677\n",
            "Epoch 31 (train)2.5s: train loss = 0.04043 = (mf)0.01584 + (embed)0.02459\n",
            "Epoch 32 (train)2.5s: train loss = 0.04101 = (mf)0.01639 + (embed)0.02462\n",
            "Epoch 33 (train)2.4s: train loss = 0.04124 = (mf)0.01649 + (embed)0.02475\n",
            "Epoch 34 (train)2.7s: train loss = 0.04062 = (mf)0.01568 + (embed)0.02494\n",
            "Epoch 35 (train)2.8s + (eval)0.3s: train loss = 0.04076 = (mf)0.01585 + (embed)0.02491, recall = 0.03742, ndcg = 0.16104\n",
            "Epoch 36 (train)2.4s: train loss = 0.04092 = (mf)0.01596 + (embed)0.02496\n",
            "Epoch 37 (train)2.4s: train loss = 0.04093 = (mf)0.01599 + (embed)0.02494\n",
            "Epoch 38 (train)2.4s: train loss = 0.04071 = (mf)0.01582 + (embed)0.02489\n",
            "Epoch 39 (train)2.9s: train loss = 0.04079 = (mf)0.01583 + (embed)0.02496\n",
            "Epoch 40 (train)2.4s + (eval)0.7s: train loss = 0.04141 = (mf)0.01632 + (embed)0.02509, recall = 0.03509, ndcg = 0.14793\n",
            "Epoch 41 (train)2.4s: train loss = 0.04096 = (mf)0.01572 + (embed)0.02525\n",
            "Epoch 42 (train)2.4s: train loss = 0.04029 = (mf)0.01510 + (embed)0.02519\n",
            "Epoch 43 (train)2.6s: train loss = 0.04013 = (mf)0.01499 + (embed)0.02515\n",
            "Epoch 44 (train)2.8s: train loss = 0.04044 = (mf)0.01526 + (embed)0.02518\n",
            "Epoch 45 (train)2.4s + (eval)0.3s: train loss = 0.04010 = (mf)0.01502 + (embed)0.02508, recall = 0.03892, ndcg = 0.16318\n",
            "Epoch 46 (train)2.5s: train loss = 0.04032 = (mf)0.01537 + (embed)0.02494\n",
            "Epoch 47 (train)2.4s: train loss = 0.04063 = (mf)0.01557 + (embed)0.02506\n",
            "Epoch 48 (train)2.9s: train loss = 0.04022 = (mf)0.01515 + (embed)0.02508\n",
            "Epoch 49 (train)2.4s: train loss = 0.04034 = (mf)0.01538 + (embed)0.02497\n",
            "Epoch 50 (train)2.4s + (eval)0.3s: train loss = 0.03977 = (mf)0.01486 + (embed)0.02491, recall = 0.03653, ndcg = 0.15934\n",
            "Epoch 51 (train)2.4s: train loss = 0.04030 = (mf)0.01534 + (embed)0.02496\n",
            "Epoch 52 (train)2.4s: train loss = 0.04098 = (mf)0.01583 + (embed)0.02515\n",
            "Epoch 53 (train)2.9s: train loss = 0.04130 = (mf)0.01610 + (embed)0.02520\n",
            "Epoch 54 (train)2.4s: train loss = 0.04113 = (mf)0.01584 + (embed)0.02528\n",
            "Epoch 55 (train)2.4s + (eval)0.8s: train loss = 0.04053 = (mf)0.01528 + (embed)0.02525, recall = 0.03649, ndcg = 0.15442\n",
            "Epoch 56 (train)2.5s: train loss = 0.04009 = (mf)0.01489 + (embed)0.02520\n",
            "Epoch 57 (train)2.9s: train loss = 0.04047 = (mf)0.01532 + (embed)0.02515\n",
            "Epoch 58 (train)3.0s: train loss = 0.03913 = (mf)0.01396 + (embed)0.02517\n",
            "Epoch 59 (train)2.4s: train loss = 0.03923 = (mf)0.01424 + (embed)0.02498\n",
            "Epoch 60 (train)2.4s + (eval)0.3s: train loss = 0.03911 = (mf)0.01432 + (embed)0.02479, recall = 0.03844, ndcg = 0.16059\n",
            "Epoch 61 (train)2.7s: train loss = 0.03960 = (mf)0.01477 + (embed)0.02482\n",
            "Epoch 62 (train)2.8s: train loss = 0.03976 = (mf)0.01480 + (embed)0.02497\n",
            "Epoch 63 (train)2.4s: train loss = 0.04002 = (mf)0.01497 + (embed)0.02504\n",
            "Epoch 64 (train)2.4s: train loss = 0.04021 = (mf)0.01515 + (embed)0.02507\n",
            "Epoch 65 (train)2.4s + (eval)0.3s: train loss = 0.03961 = (mf)0.01454 + (embed)0.02506, recall = 0.03779, ndcg = 0.15256\n",
            "Epoch 66 (train)2.9s: train loss = 0.04046 = (mf)0.01540 + (embed)0.02505\n",
            "Epoch 67 (train)2.5s: train loss = 0.04021 = (mf)0.01517 + (embed)0.02504\n",
            "Epoch 68 (train)2.4s: train loss = 0.03961 = (mf)0.01458 + (embed)0.02503\n",
            "Epoch 69 (train)2.4s: train loss = 0.04022 = (mf)0.01522 + (embed)0.02499\n",
            "Epoch 70 (train)2.4s + (eval)0.4s: train loss = 0.03845 = (mf)0.01350 + (embed)0.02495, recall = 0.03612, ndcg = 0.15335\n",
            "Epoch 71 (train)2.9s: train loss = 0.03964 = (mf)0.01467 + (embed)0.02497\n",
            "Epoch 72 (train)2.4s: train loss = 0.03992 = (mf)0.01495 + (embed)0.02496\n",
            "Epoch 73 (train)2.4s: train loss = 0.04006 = (mf)0.01507 + (embed)0.02499\n",
            "Epoch 74 (train)2.4s: train loss = 0.03907 = (mf)0.01412 + (embed)0.02495\n",
            "Epoch 75 (train)2.8s + (eval)0.9s: train loss = 0.04010 = (mf)0.01515 + (embed)0.02495, recall = 0.03750, ndcg = 0.14857\n",
            "Epoch 76 (train)2.5s: train loss = 0.03947 = (mf)0.01446 + (embed)0.02501\n",
            "Epoch 77 (train)2.4s: train loss = 0.03983 = (mf)0.01475 + (embed)0.02508\n",
            "Epoch 78 (train)2.5s: train loss = 0.04046 = (mf)0.01536 + (embed)0.02510\n",
            "Epoch 79 (train)2.5s: train loss = 0.03949 = (mf)0.01430 + (embed)0.02519\n",
            "Epoch 80 (train)2.9s + (eval)0.3s: train loss = 0.04050 = (mf)0.01536 + (embed)0.02514, recall = 0.03690, ndcg = 0.14971\n",
            "Epoch 81 (train)2.4s: train loss = 0.03995 = (mf)0.01479 + (embed)0.02516\n",
            "Epoch 82 (train)2.4s: train loss = 0.04047 = (mf)0.01527 + (embed)0.02520\n",
            "Epoch 83 (train)2.4s: train loss = 0.03984 = (mf)0.01464 + (embed)0.02520\n",
            "Epoch 84 (train)2.9s: train loss = 0.03958 = (mf)0.01436 + (embed)0.02522\n",
            "Epoch 85 (train)2.5s + (eval)0.3s: train loss = 0.03996 = (mf)0.01477 + (embed)0.02519, recall = 0.03737, ndcg = 0.15241\n",
            "Epoch 86 (train)2.4s: train loss = 0.03976 = (mf)0.01457 + (embed)0.02520\n",
            "Epoch 87 (train)2.4s: train loss = 0.03990 = (mf)0.01473 + (embed)0.02516\n",
            "Epoch 88 (train)2.4s: train loss = 0.04052 = (mf)0.01529 + (embed)0.02524\n",
            "Epoch 89 (train)2.9s: train loss = 0.04045 = (mf)0.01516 + (embed)0.02529\n",
            "Epoch 90 (train)2.4s + (eval)0.3s: train loss = 0.04042 = (mf)0.01510 + (embed)0.02532, recall = 0.03766, ndcg = 0.16317\n",
            "Epoch 91 (train)2.4s: train loss = 0.03994 = (mf)0.01464 + (embed)0.02529\n",
            "Epoch 92 (train)2.4s: train loss = 0.04026 = (mf)0.01502 + (embed)0.02524\n",
            "Epoch 93 (train)2.6s: train loss = 0.04034 = (mf)0.01507 + (embed)0.02526\n",
            "Epoch 94 (train)2.7s: train loss = 0.03998 = (mf)0.01478 + (embed)0.02520\n",
            "Epoch 95 (train)2.4s + (eval)0.8s: train loss = 0.04046 = (mf)0.01527 + (embed)0.02519, recall = 0.03662, ndcg = 0.15181\n",
            "Epoch 96 (train)2.4s: train loss = 0.03975 = (mf)0.01464 + (embed)0.02511\n",
            "Epoch 97 (train)2.4s: train loss = 0.04047 = (mf)0.01531 + (embed)0.02516\n",
            "Epoch 98 (train)2.9s: train loss = 0.04045 = (mf)0.01519 + (embed)0.02526\n",
            "Epoch 99 (train)2.4s: train loss = 0.04072 = (mf)0.01552 + (embed)0.02519\n",
            "Epoch 100 (train)2.4s + (eval)0.3s: train loss = 0.04028 = (mf)0.01505 + (embed)0.02523, recall = 0.03817, ndcg = 0.16229\n",
            "Training finished in 265.71 seconds.\n",
            "Evaluation results for this combination: NDCG@50: 0.16229, Recall@50: 0.03817\n",
            "--- Trying combination: Epochs=100, TopK=50, LearningRate=0.05, Layers=5 ---\n",
            "Already normalize adjacency matrix (extended).\n",
            "Using xavier initialization for user, item, and genre embeddings.\n",
            "Epoch 1 (train)4.6s: train loss = 0.18416 = (mf)0.18060 + (embed)0.00356\n",
            "Epoch 2 (train)2.9s: train loss = 0.09445 = (mf)0.08554 + (embed)0.00891\n",
            "Epoch 3 (train)2.6s: train loss = 0.07369 = (mf)0.06089 + (embed)0.01281\n",
            "Epoch 4 (train)2.4s: train loss = 0.06212 = (mf)0.04653 + (embed)0.01558\n",
            "Epoch 5 (train)2.4s + (eval)1.4s: train loss = 0.05536 = (mf)0.03781 + (embed)0.01755, recall = 0.03811, ndcg = 0.17089\n",
            "Epoch 6 (train)3.0s: train loss = 0.05232 = (mf)0.03337 + (embed)0.01896\n",
            "Epoch 7 (train)2.7s: train loss = 0.04963 = (mf)0.02958 + (embed)0.02005\n",
            "Epoch 8 (train)2.4s: train loss = 0.04817 = (mf)0.02727 + (embed)0.02091\n",
            "Epoch 9 (train)2.5s: train loss = 0.04653 = (mf)0.02503 + (embed)0.02150\n",
            "Epoch 10 (train)2.5s + (eval)0.3s: train loss = 0.04584 = (mf)0.02381 + (embed)0.02202, recall = 0.03921, ndcg = 0.16792\n",
            "Epoch 11 (train)3.0s: train loss = 0.04521 = (mf)0.02267 + (embed)0.02254\n",
            "Epoch 12 (train)2.4s: train loss = 0.04387 = (mf)0.02096 + (embed)0.02291\n",
            "Epoch 13 (train)2.4s: train loss = 0.04344 = (mf)0.02021 + (embed)0.02323\n",
            "Epoch 14 (train)2.4s: train loss = 0.04335 = (mf)0.01987 + (embed)0.02348\n",
            "Epoch 15 (train)2.7s + (eval)1.0s: train loss = 0.04348 = (mf)0.01974 + (embed)0.02374, recall = 0.03833, ndcg = 0.16849\n",
            "Epoch 16 (train)2.5s: train loss = 0.04197 = (mf)0.01797 + (embed)0.02400\n",
            "Epoch 17 (train)2.4s: train loss = 0.04235 = (mf)0.01825 + (embed)0.02410\n",
            "Epoch 18 (train)2.5s: train loss = 0.04225 = (mf)0.01788 + (embed)0.02436\n",
            "Epoch 19 (train)2.5s: train loss = 0.04197 = (mf)0.01755 + (embed)0.02442\n",
            "Epoch 20 (train)3.0s + (eval)0.3s: train loss = 0.04223 = (mf)0.01768 + (embed)0.02454, recall = 0.04032, ndcg = 0.16928\n",
            "Epoch 21 (train)2.5s: train loss = 0.04179 = (mf)0.01714 + (embed)0.02465\n",
            "Epoch 22 (train)2.4s: train loss = 0.04169 = (mf)0.01691 + (embed)0.02478\n",
            "Epoch 23 (train)2.4s: train loss = 0.04166 = (mf)0.01678 + (embed)0.02488\n",
            "Epoch 24 (train)2.8s: train loss = 0.04174 = (mf)0.01676 + (embed)0.02498\n",
            "Epoch 25 (train)2.6s + (eval)0.3s: train loss = 0.04143 = (mf)0.01629 + (embed)0.02514, recall = 0.03980, ndcg = 0.17506\n",
            "Epoch 26 (train)2.4s: train loss = 0.04178 = (mf)0.01650 + (embed)0.02528\n",
            "Epoch 27 (train)2.4s: train loss = 0.04131 = (mf)0.01584 + (embed)0.02547\n",
            "Epoch 28 (train)2.5s: train loss = 0.04160 = (mf)0.01612 + (embed)0.02548\n",
            "Epoch 29 (train)3.0s: train loss = 0.04130 = (mf)0.01577 + (embed)0.02553\n",
            "Epoch 30 (train)2.5s + (eval)0.3s: train loss = 0.04147 = (mf)0.01589 + (embed)0.02559, recall = 0.03985, ndcg = 0.17703\n",
            "Epoch 31 (train)2.4s: train loss = 0.04153 = (mf)0.01596 + (embed)0.02557\n",
            "Epoch 32 (train)2.4s: train loss = 0.04051 = (mf)0.01495 + (embed)0.02557\n",
            "Epoch 33 (train)2.8s: train loss = 0.04071 = (mf)0.01522 + (embed)0.02549\n",
            "Epoch 34 (train)2.6s: train loss = 0.04131 = (mf)0.01573 + (embed)0.02558\n",
            "Epoch 35 (train)2.4s + (eval)0.8s: train loss = 0.04023 = (mf)0.01469 + (embed)0.02554, recall = 0.03866, ndcg = 0.16973\n",
            "Epoch 36 (train)2.5s: train loss = 0.04141 = (mf)0.01578 + (embed)0.02563\n",
            "Epoch 37 (train)2.5s: train loss = 0.04107 = (mf)0.01542 + (embed)0.02565\n",
            "Epoch 38 (train)2.9s: train loss = 0.04056 = (mf)0.01489 + (embed)0.02567\n",
            "Epoch 39 (train)2.4s: train loss = 0.04138 = (mf)0.01568 + (embed)0.02571\n",
            "Epoch 40 (train)2.4s + (eval)0.3s: train loss = 0.04103 = (mf)0.01528 + (embed)0.02574, recall = 0.03929, ndcg = 0.16683\n",
            "Epoch 41 (train)2.5s: train loss = 0.04109 = (mf)0.01530 + (embed)0.02579\n",
            "Epoch 42 (train)3.1s: train loss = 0.04093 = (mf)0.01515 + (embed)0.02578\n",
            "Epoch 43 (train)3.1s: train loss = 0.04112 = (mf)0.01527 + (embed)0.02585\n",
            "Epoch 44 (train)2.5s: train loss = 0.04078 = (mf)0.01496 + (embed)0.02582\n",
            "Epoch 45 (train)2.4s + (eval)0.3s: train loss = 0.04114 = (mf)0.01530 + (embed)0.02584, recall = 0.04104, ndcg = 0.17063\n",
            "Epoch 46 (train)2.5s: train loss = 0.04107 = (mf)0.01527 + (embed)0.02580\n",
            "Epoch 47 (train)3.0s: train loss = 0.04100 = (mf)0.01511 + (embed)0.02588\n",
            "Epoch 48 (train)2.5s: train loss = 0.04124 = (mf)0.01520 + (embed)0.02604\n",
            "Epoch 49 (train)2.4s: train loss = 0.04088 = (mf)0.01492 + (embed)0.02596\n",
            "Epoch 50 (train)2.5s + (eval)0.3s: train loss = 0.04150 = (mf)0.01549 + (embed)0.02601, recall = 0.04152, ndcg = 0.17069\n",
            "Epoch 51 (train)2.9s: train loss = 0.04095 = (mf)0.01486 + (embed)0.02610\n",
            "Epoch 52 (train)2.6s: train loss = 0.04092 = (mf)0.01490 + (embed)0.02602\n",
            "Epoch 53 (train)2.5s: train loss = 0.04063 = (mf)0.01463 + (embed)0.02600\n",
            "Epoch 54 (train)2.4s: train loss = 0.04063 = (mf)0.01476 + (embed)0.02587\n",
            "Epoch 55 (train)2.4s + (eval)0.9s: train loss = 0.04151 = (mf)0.01552 + (embed)0.02599, recall = 0.03887, ndcg = 0.16878\n",
            "Epoch 56 (train)2.8s: train loss = 0.04102 = (mf)0.01503 + (embed)0.02600\n",
            "Epoch 57 (train)2.4s: train loss = 0.04069 = (mf)0.01471 + (embed)0.02598\n",
            "Epoch 58 (train)2.4s: train loss = 0.04095 = (mf)0.01496 + (embed)0.02600\n",
            "Epoch 59 (train)2.4s: train loss = 0.04070 = (mf)0.01472 + (embed)0.02598\n",
            "Epoch 60 (train)2.9s + (eval)0.4s: train loss = 0.03992 = (mf)0.01411 + (embed)0.02581, recall = 0.03921, ndcg = 0.16937\n",
            "Epoch 61 (train)2.5s: train loss = 0.04031 = (mf)0.01462 + (embed)0.02569\n",
            "Epoch 62 (train)2.4s: train loss = 0.04030 = (mf)0.01459 + (embed)0.02571\n",
            "Epoch 63 (train)2.4s: train loss = 0.04056 = (mf)0.01475 + (embed)0.02582\n",
            "Epoch 64 (train)2.5s: train loss = 0.04103 = (mf)0.01519 + (embed)0.02584\n",
            "Epoch 65 (train)3.0s + (eval)0.3s: train loss = 0.04066 = (mf)0.01476 + (embed)0.02591, recall = 0.04045, ndcg = 0.16979\n",
            "Epoch 66 (train)2.5s: train loss = 0.04084 = (mf)0.01494 + (embed)0.02590\n",
            "Epoch 67 (train)2.5s: train loss = 0.04068 = (mf)0.01477 + (embed)0.02591\n",
            "Epoch 68 (train)2.5s: train loss = 0.04098 = (mf)0.01503 + (embed)0.02594\n",
            "Epoch 69 (train)2.8s: train loss = 0.04119 = (mf)0.01525 + (embed)0.02595\n",
            "Epoch 70 (train)2.6s + (eval)0.3s: train loss = 0.04134 = (mf)0.01523 + (embed)0.02611, recall = 0.03839, ndcg = 0.16070\n",
            "Epoch 71 (train)2.4s: train loss = 0.04063 = (mf)0.01459 + (embed)0.02605\n",
            "Epoch 72 (train)2.5s: train loss = 0.04059 = (mf)0.01454 + (embed)0.02605\n",
            "Epoch 73 (train)2.5s: train loss = 0.04053 = (mf)0.01451 + (embed)0.02602\n",
            "Epoch 74 (train)3.0s: train loss = 0.04065 = (mf)0.01470 + (embed)0.02595\n",
            "Epoch 75 (train)2.4s + (eval)0.8s: train loss = 0.04101 = (mf)0.01509 + (embed)0.02592, recall = 0.03998, ndcg = 0.17053\n",
            "Epoch 76 (train)2.5s: train loss = 0.04035 = (mf)0.01445 + (embed)0.02590\n",
            "Epoch 77 (train)2.5s: train loss = 0.04069 = (mf)0.01476 + (embed)0.02593\n",
            "Epoch 78 (train)2.9s: train loss = 0.04034 = (mf)0.01440 + (embed)0.02594\n",
            "Epoch 79 (train)2.5s: train loss = 0.04089 = (mf)0.01495 + (embed)0.02594\n",
            "Epoch 80 (train)2.4s + (eval)0.3s: train loss = 0.04005 = (mf)0.01415 + (embed)0.02590, recall = 0.04050, ndcg = 0.17142\n",
            "Epoch 81 (train)2.5s: train loss = 0.04090 = (mf)0.01503 + (embed)0.02587\n",
            "Epoch 82 (train)2.5s: train loss = 0.04054 = (mf)0.01464 + (embed)0.02590\n",
            "Epoch 83 (train)2.9s: train loss = 0.04071 = (mf)0.01481 + (embed)0.02590\n",
            "Epoch 84 (train)2.4s: train loss = 0.04073 = (mf)0.01490 + (embed)0.02583\n",
            "Epoch 85 (train)2.4s + (eval)0.3s: train loss = 0.04029 = (mf)0.01452 + (embed)0.02577, recall = 0.03742, ndcg = 0.16419\n",
            "Epoch 86 (train)2.4s: train loss = 0.04101 = (mf)0.01514 + (embed)0.02586\n",
            "Epoch 87 (train)2.9s: train loss = 0.04075 = (mf)0.01482 + (embed)0.02594\n",
            "Epoch 88 (train)2.5s: train loss = 0.04014 = (mf)0.01418 + (embed)0.02596\n",
            "Epoch 89 (train)2.5s: train loss = 0.04058 = (mf)0.01464 + (embed)0.02594\n",
            "Epoch 90 (train)2.5s + (eval)0.3s: train loss = 0.04022 = (mf)0.01435 + (embed)0.02588, recall = 0.04140, ndcg = 0.16888\n",
            "Epoch 91 (train)2.5s: train loss = 0.04023 = (mf)0.01434 + (embed)0.02589\n",
            "Epoch 92 (train)3.0s: train loss = 0.04063 = (mf)0.01479 + (embed)0.02585\n",
            "Epoch 93 (train)2.4s: train loss = 0.04045 = (mf)0.01459 + (embed)0.02586\n",
            "Epoch 94 (train)2.4s: train loss = 0.04005 = (mf)0.01412 + (embed)0.02593\n",
            "Epoch 95 (train)2.4s + (eval)0.7s: train loss = 0.04038 = (mf)0.01445 + (embed)0.02592, recall = 0.03949, ndcg = 0.17263\n",
            "Epoch 96 (train)3.0s: train loss = 0.04033 = (mf)0.01444 + (embed)0.02590\n",
            "Epoch 97 (train)2.4s: train loss = 0.04008 = (mf)0.01422 + (embed)0.02586\n",
            "Epoch 98 (train)2.5s: train loss = 0.03955 = (mf)0.01379 + (embed)0.02575\n",
            "Epoch 99 (train)2.5s: train loss = 0.04060 = (mf)0.01480 + (embed)0.02580\n",
            "Epoch 100 (train)2.4s + (eval)0.4s: train loss = 0.03992 = (mf)0.01412 + (embed)0.02580, recall = 0.03960, ndcg = 0.17841\n",
            "Training finished in 269.19 seconds.\n",
            "Evaluation results for this combination: NDCG@50: 0.17841, Recall@50: 0.03960\n",
            "--- Trying combination: Epochs=100, TopK=50, LearningRate=0.5, Layers=3 ---\n",
            "Already normalize adjacency matrix (extended).\n",
            "Using xavier initialization for user, item, and genre embeddings.\n",
            "Epoch 1 (train)5.1s: train loss = 0.97887 = (mf)0.80887 + (embed)0.16999\n",
            "Epoch 2 (train)2.4s: train loss = 1.94655 = (mf)1.45204 + (embed)0.49450\n",
            "Epoch 3 (train)2.4s: train loss = 2.61012 = (mf)1.85658 + (embed)0.75353\n",
            "Epoch 4 (train)2.3s: train loss = 3.08181 = (mf)2.11733 + (embed)0.96449\n",
            "Epoch 5 (train)2.9s + (eval)1.4s: train loss = 3.37897 = (mf)2.23846 + (embed)1.14052, recall = 0.02710, ndcg = 0.11484\n",
            "Epoch 6 (train)2.5s: train loss = 3.67725 = (mf)2.39436 + (embed)1.28289\n",
            "Epoch 7 (train)2.4s: train loss = 3.84537 = (mf)2.43411 + (embed)1.41126\n",
            "Epoch 8 (train)2.4s: train loss = 4.07912 = (mf)2.56085 + (embed)1.51827\n",
            "Epoch 9 (train)2.7s: train loss = 4.12914 = (mf)2.50213 + (embed)1.62701\n",
            "Epoch 10 (train)2.6s + (eval)0.3s: train loss = 4.20537 = (mf)2.49846 + (embed)1.70691, recall = 0.02397, ndcg = 0.10454\n",
            "Epoch 11 (train)2.4s: train loss = 4.25976 = (mf)2.47899 + (embed)1.78076\n",
            "Epoch 12 (train)2.4s: train loss = 4.17467 = (mf)2.32789 + (embed)1.84678\n",
            "Epoch 13 (train)2.4s: train loss = 4.41230 = (mf)2.49657 + (embed)1.91573\n",
            "Epoch 14 (train)2.9s: train loss = 4.49457 = (mf)2.52042 + (embed)1.97415\n",
            "Epoch 15 (train)2.4s + (eval)0.8s: train loss = 4.57954 = (mf)2.54141 + (embed)2.03813, recall = 0.02389, ndcg = 0.10542\n",
            "Epoch 16 (train)2.4s: train loss = 4.41372 = (mf)2.32679 + (embed)2.08693\n",
            "Epoch 17 (train)2.4s: train loss = 4.61388 = (mf)2.48673 + (embed)2.12716\n",
            "Epoch 18 (train)2.6s: train loss = 4.65520 = (mf)2.48726 + (embed)2.16794\n",
            "Epoch 19 (train)2.7s: train loss = 4.67739 = (mf)2.46342 + (embed)2.21397\n",
            "Epoch 20 (train)2.4s + (eval)0.3s: train loss = 4.65478 = (mf)2.40626 + (embed)2.24852, recall = 0.02306, ndcg = 0.10492\n",
            "Epoch 21 (train)2.4s: train loss = 4.64116 = (mf)2.36039 + (embed)2.28077\n",
            "Epoch 22 (train)2.4s: train loss = 4.71704 = (mf)2.41065 + (embed)2.30639\n",
            "Epoch 23 (train)2.9s: train loss = 4.71675 = (mf)2.38008 + (embed)2.33667\n",
            "Epoch 24 (train)2.4s: train loss = 4.68350 = (mf)2.33138 + (embed)2.35211\n",
            "Epoch 25 (train)2.4s + (eval)0.3s: train loss = 4.75392 = (mf)2.38031 + (embed)2.37361, recall = 0.02525, ndcg = 0.10515\n",
            "Epoch 26 (train)2.4s: train loss = 4.84861 = (mf)2.45813 + (embed)2.39047\n",
            "Epoch 27 (train)2.9s: train loss = 4.86488 = (mf)2.44323 + (embed)2.42165\n",
            "Epoch 28 (train)3.0s: train loss = 4.85779 = (mf)2.40586 + (embed)2.45193\n",
            "Epoch 29 (train)2.4s: train loss = 4.77533 = (mf)2.30690 + (embed)2.46842\n",
            "Epoch 30 (train)2.4s + (eval)0.8s: train loss = 4.94109 = (mf)2.45928 + (embed)2.48181, recall = 0.02235, ndcg = 0.09411\n",
            "Epoch 31 (train)2.4s: train loss = 4.89796 = (mf)2.40003 + (embed)2.49793\n",
            "Epoch 32 (train)2.9s: train loss = 4.85973 = (mf)2.33914 + (embed)2.52059\n",
            "Epoch 33 (train)2.4s: train loss = 4.80048 = (mf)2.26846 + (embed)2.53202\n",
            "Epoch 34 (train)2.4s: train loss = 4.85674 = (mf)2.31330 + (embed)2.54344\n",
            "Epoch 35 (train)2.4s + (eval)0.3s: train loss = 4.83998 = (mf)2.27714 + (embed)2.56284, recall = 0.02708, ndcg = 0.10599\n",
            "Epoch 36 (train)2.4s: train loss = 4.89931 = (mf)2.33658 + (embed)2.56272\n",
            "Epoch 37 (train)2.9s: train loss = 4.75326 = (mf)2.17510 + (embed)2.57816\n",
            "Epoch 38 (train)2.4s: train loss = 4.83978 = (mf)2.25559 + (embed)2.58419\n",
            "Epoch 39 (train)2.4s: train loss = 4.87504 = (mf)2.29635 + (embed)2.57869\n",
            "Epoch 40 (train)2.4s + (eval)0.3s: train loss = 4.71275 = (mf)2.12945 + (embed)2.58331, recall = 0.02476, ndcg = 0.09639\n",
            "Epoch 41 (train)2.6s: train loss = 4.71904 = (mf)2.12791 + (embed)2.59113\n",
            "Epoch 42 (train)2.7s: train loss = 4.88536 = (mf)2.28388 + (embed)2.60148\n",
            "Epoch 43 (train)2.4s: train loss = 4.80438 = (mf)2.18394 + (embed)2.62043\n",
            "Epoch 44 (train)2.4s: train loss = 4.86691 = (mf)2.24364 + (embed)2.62327\n",
            "Epoch 45 (train)2.4s + (eval)0.3s: train loss = 4.84689 = (mf)2.22025 + (embed)2.62664, recall = 0.02604, ndcg = 0.10003\n",
            "Epoch 46 (train)2.9s: train loss = 4.73201 = (mf)2.09937 + (embed)2.63264\n",
            "Epoch 47 (train)2.4s: train loss = 4.90136 = (mf)2.25971 + (embed)2.64166\n",
            "Epoch 48 (train)2.4s: train loss = 4.83366 = (mf)2.18441 + (embed)2.64925\n",
            "Epoch 49 (train)2.4s: train loss = 4.91420 = (mf)2.25491 + (embed)2.65929\n",
            "Epoch 50 (train)2.3s + (eval)0.3s: train loss = 4.80121 = (mf)2.13458 + (embed)2.66663, recall = 0.02580, ndcg = 0.10249\n",
            "Epoch 51 (train)3.0s: train loss = 4.82929 = (mf)2.15864 + (embed)2.67064\n",
            "Epoch 52 (train)2.4s: train loss = 4.85736 = (mf)2.18854 + (embed)2.66882\n",
            "Epoch 53 (train)2.4s: train loss = 4.86213 = (mf)2.18764 + (embed)2.67449\n",
            "Epoch 54 (train)2.4s: train loss = 4.93492 = (mf)2.26476 + (embed)2.67016\n",
            "Epoch 55 (train)2.5s + (eval)1.0s: train loss = 4.96246 = (mf)2.28492 + (embed)2.67754, recall = 0.02822, ndcg = 0.11344\n",
            "Epoch 56 (train)2.6s: train loss = 5.02944 = (mf)2.34549 + (embed)2.68395\n",
            "Epoch 57 (train)2.4s: train loss = 4.95201 = (mf)2.26338 + (embed)2.68864\n",
            "Epoch 58 (train)2.4s: train loss = 4.91464 = (mf)2.22007 + (embed)2.69457\n",
            "Epoch 59 (train)2.4s: train loss = 4.87355 = (mf)2.17219 + (embed)2.70136\n",
            "Epoch 60 (train)2.9s + (eval)0.3s: train loss = 5.05047 = (mf)2.33687 + (embed)2.71359, recall = 0.02719, ndcg = 0.10560\n",
            "Epoch 61 (train)2.4s: train loss = 4.81368 = (mf)2.10553 + (embed)2.70815\n",
            "Epoch 62 (train)2.4s: train loss = 4.95346 = (mf)2.24326 + (embed)2.71020\n",
            "Epoch 63 (train)2.4s: train loss = 4.95069 = (mf)2.23817 + (embed)2.71252\n",
            "Epoch 64 (train)2.4s: train loss = 4.91592 = (mf)2.19926 + (embed)2.71666\n",
            "Epoch 65 (train)2.9s + (eval)0.3s: train loss = 4.96916 = (mf)2.23870 + (embed)2.73046, recall = 0.02856, ndcg = 0.11599\n",
            "Epoch 66 (train)2.4s: train loss = 4.86454 = (mf)2.13499 + (embed)2.72956\n",
            "Epoch 67 (train)2.4s: train loss = 4.88583 = (mf)2.16528 + (embed)2.72056\n",
            "Epoch 68 (train)2.4s: train loss = 4.75328 = (mf)2.02972 + (embed)2.72356\n",
            "Epoch 69 (train)2.6s: train loss = 4.73762 = (mf)2.00965 + (embed)2.72798\n",
            "Epoch 70 (train)2.6s + (eval)0.8s: train loss = 4.93341 = (mf)2.19953 + (embed)2.73388, recall = 0.02652, ndcg = 0.10233\n",
            "Epoch 71 (train)2.4s: train loss = 4.83872 = (mf)2.10591 + (embed)2.73281\n",
            "Epoch 72 (train)2.4s: train loss = 4.89972 = (mf)2.15913 + (embed)2.74060\n",
            "Epoch 73 (train)2.3s: train loss = 4.82457 = (mf)2.08210 + (embed)2.74247\n",
            "Epoch 74 (train)2.9s: train loss = 4.76787 = (mf)2.02101 + (embed)2.74686\n",
            "Epoch 75 (train)2.4s + (eval)0.3s: train loss = 4.75439 = (mf)2.02322 + (embed)2.73118, recall = 0.02550, ndcg = 0.10808\n",
            "Epoch 76 (train)2.4s: train loss = 4.83376 = (mf)2.10489 + (embed)2.72886\n",
            "Epoch 77 (train)2.4s: train loss = 4.79814 = (mf)2.07387 + (embed)2.72426\n",
            "Epoch 78 (train)2.5s: train loss = 4.80326 = (mf)2.06974 + (embed)2.73352\n",
            "Epoch 79 (train)2.8s: train loss = 4.93646 = (mf)2.20198 + (embed)2.73448\n",
            "Epoch 80 (train)2.4s + (eval)0.3s: train loss = 4.88668 = (mf)2.15884 + (embed)2.72784, recall = 0.02486, ndcg = 0.09922\n",
            "Epoch 81 (train)2.4s: train loss = 4.86747 = (mf)2.14607 + (embed)2.72140\n",
            "Epoch 82 (train)2.3s: train loss = 4.93547 = (mf)2.21119 + (embed)2.72428\n",
            "Epoch 83 (train)2.7s: train loss = 4.99649 = (mf)2.26227 + (embed)2.73421\n",
            "Epoch 84 (train)2.6s: train loss = 4.77836 = (mf)2.04146 + (embed)2.73690\n",
            "Epoch 85 (train)2.4s + (eval)0.3s: train loss = 4.72785 = (mf)1.99219 + (embed)2.73566, recall = 0.02613, ndcg = 0.10112\n",
            "Epoch 86 (train)2.4s: train loss = 4.82929 = (mf)2.09266 + (embed)2.73663\n",
            "Epoch 87 (train)2.4s: train loss = 4.87919 = (mf)2.13574 + (embed)2.74345\n",
            "Epoch 88 (train)2.9s: train loss = 4.84428 = (mf)2.11089 + (embed)2.73340\n",
            "Epoch 89 (train)2.4s: train loss = 4.74388 = (mf)2.00374 + (embed)2.74014\n",
            "Epoch 90 (train)2.3s + (eval)0.8s: train loss = 4.87344 = (mf)2.12230 + (embed)2.75114, recall = 0.02575, ndcg = 0.10911\n",
            "Epoch 91 (train)2.4s: train loss = 4.74889 = (mf)1.99321 + (embed)2.75568\n",
            "Epoch 92 (train)2.5s: train loss = 4.83874 = (mf)2.08511 + (embed)2.75362\n",
            "Epoch 93 (train)2.8s: train loss = 4.83408 = (mf)2.08678 + (embed)2.74730\n",
            "Epoch 94 (train)2.4s: train loss = 4.69706 = (mf)1.95606 + (embed)2.74101\n",
            "Epoch 95 (train)2.3s + (eval)0.3s: train loss = 4.80568 = (mf)2.05802 + (embed)2.74767, recall = 0.02680, ndcg = 0.10467\n",
            "Epoch 96 (train)2.3s: train loss = 4.76876 = (mf)2.02473 + (embed)2.74403\n",
            "Epoch 97 (train)2.7s: train loss = 4.84388 = (mf)2.09505 + (embed)2.74883\n",
            "Epoch 98 (train)2.6s: train loss = 4.92727 = (mf)2.16334 + (embed)2.76393\n",
            "Epoch 99 (train)2.4s: train loss = 4.95820 = (mf)2.18394 + (embed)2.77427\n",
            "Epoch 100 (train)2.4s + (eval)0.3s: train loss = 4.92623 = (mf)2.14777 + (embed)2.77846, recall = 0.02636, ndcg = 0.10045\n",
            "Training finished in 261.37 seconds.\n",
            "Evaluation results for this combination: NDCG@50: 0.10045, Recall@50: 0.02636\n",
            "--- Trying combination: Epochs=100, TopK=50, LearningRate=0.5, Layers=4 ---\n",
            "Already normalize adjacency matrix (extended).\n",
            "Using xavier initialization for user, item, and genre embeddings.\n",
            "Epoch 1 (train)4.8s: train loss = 0.65010 = (mf)0.50023 + (embed)0.14986\n",
            "Epoch 2 (train)2.8s: train loss = 1.33280 = (mf)0.89254 + (embed)0.44026\n",
            "Epoch 3 (train)2.4s: train loss = 1.69237 = (mf)1.03918 + (embed)0.65319\n",
            "Epoch 4 (train)2.4s: train loss = 2.06753 = (mf)1.24058 + (embed)0.82695\n",
            "Epoch 5 (train)2.4s + (eval)1.5s: train loss = 2.31384 = (mf)1.34148 + (embed)0.97237, recall = 0.02454, ndcg = 0.11453\n",
            "Epoch 6 (train)3.1s: train loss = 2.48070 = (mf)1.40447 + (embed)1.07623\n",
            "Epoch 7 (train)2.4s: train loss = 2.53525 = (mf)1.36955 + (embed)1.16570\n",
            "Epoch 8 (train)2.4s: train loss = 2.68836 = (mf)1.44557 + (embed)1.24280\n",
            "Epoch 9 (train)2.4s: train loss = 2.79971 = (mf)1.49182 + (embed)1.30789\n",
            "Epoch 10 (train)2.7s + (eval)0.9s: train loss = 2.79865 = (mf)1.44500 + (embed)1.35365, recall = 0.02109, ndcg = 0.09738\n",
            "Epoch 11 (train)2.5s: train loss = 2.83338 = (mf)1.42755 + (embed)1.40583\n",
            "Epoch 12 (train)2.4s: train loss = 2.83684 = (mf)1.39406 + (embed)1.44277\n",
            "Epoch 13 (train)2.4s: train loss = 2.85254 = (mf)1.36923 + (embed)1.48331\n",
            "Epoch 14 (train)2.9s: train loss = 2.91475 = (mf)1.39510 + (embed)1.51965\n",
            "Epoch 15 (train)3.2s + (eval)0.3s: train loss = 2.91291 = (mf)1.36292 + (embed)1.54999, recall = 0.02521, ndcg = 0.09857\n",
            "Epoch 16 (train)2.4s: train loss = 2.92538 = (mf)1.35707 + (embed)1.56831\n",
            "Epoch 17 (train)2.4s: train loss = 2.95670 = (mf)1.36855 + (embed)1.58815\n",
            "Epoch 18 (train)2.4s: train loss = 2.95940 = (mf)1.34860 + (embed)1.61081\n",
            "Epoch 19 (train)2.8s: train loss = 2.95459 = (mf)1.32400 + (embed)1.63059\n",
            "Epoch 20 (train)2.5s + (eval)0.3s: train loss = 2.97835 = (mf)1.32912 + (embed)1.64924, recall = 0.02533, ndcg = 0.10964\n",
            "Epoch 21 (train)2.4s: train loss = 2.97724 = (mf)1.31478 + (embed)1.66246\n",
            "Epoch 22 (train)2.4s: train loss = 2.95946 = (mf)1.27687 + (embed)1.68259\n",
            "Epoch 23 (train)2.4s: train loss = 2.95229 = (mf)1.26452 + (embed)1.68778\n",
            "Epoch 24 (train)3.0s: train loss = 2.98328 = (mf)1.29337 + (embed)1.68991\n",
            "Epoch 25 (train)2.4s + (eval)0.3s: train loss = 2.99803 = (mf)1.28941 + (embed)1.70862, recall = 0.02725, ndcg = 0.10672\n",
            "Epoch 26 (train)2.4s: train loss = 2.96270 = (mf)1.25153 + (embed)1.71117\n",
            "Epoch 27 (train)2.4s: train loss = 2.94570 = (mf)1.23091 + (embed)1.71479\n",
            "Epoch 28 (train)2.7s: train loss = 2.91785 = (mf)1.19889 + (embed)1.71897\n",
            "Epoch 29 (train)2.6s: train loss = 2.96845 = (mf)1.24491 + (embed)1.72354\n",
            "Epoch 30 (train)2.4s + (eval)0.3s: train loss = 2.91627 = (mf)1.18394 + (embed)1.73233, recall = 0.02724, ndcg = 0.11036\n",
            "Epoch 31 (train)2.3s: train loss = 3.01512 = (mf)1.27279 + (embed)1.74233\n",
            "Epoch 32 (train)2.4s: train loss = 3.02040 = (mf)1.27561 + (embed)1.74479\n",
            "Epoch 33 (train)2.9s: train loss = 2.98814 = (mf)1.23399 + (embed)1.75416\n",
            "Epoch 34 (train)2.4s: train loss = 3.07116 = (mf)1.31948 + (embed)1.75167\n",
            "Epoch 35 (train)2.4s + (eval)0.8s: train loss = 2.96722 = (mf)1.21023 + (embed)1.75699, recall = 0.02329, ndcg = 0.10081\n",
            "Epoch 36 (train)2.6s: train loss = 2.98133 = (mf)1.22250 + (embed)1.75883\n",
            "Epoch 37 (train)2.7s: train loss = 2.97629 = (mf)1.21210 + (embed)1.76419\n",
            "Epoch 38 (train)2.8s: train loss = 2.94753 = (mf)1.18660 + (embed)1.76093\n",
            "Epoch 39 (train)2.5s: train loss = 2.85560 = (mf)1.10066 + (embed)1.75494\n",
            "Epoch 40 (train)2.4s + (eval)0.3s: train loss = 2.97798 = (mf)1.21764 + (embed)1.76035, recall = 0.02567, ndcg = 0.10475\n",
            "Epoch 41 (train)2.5s: train loss = 2.98236 = (mf)1.21709 + (embed)1.76528\n",
            "Epoch 42 (train)3.0s: train loss = 2.86258 = (mf)1.09917 + (embed)1.76341\n",
            "Epoch 43 (train)2.4s: train loss = 2.90245 = (mf)1.14353 + (embed)1.75891\n",
            "Epoch 44 (train)2.4s: train loss = 2.97029 = (mf)1.19648 + (embed)1.77381\n",
            "Epoch 45 (train)2.4s + (eval)0.3s: train loss = 3.02353 = (mf)1.25052 + (embed)1.77301, recall = 0.02703, ndcg = 0.10615\n",
            "Epoch 46 (train)2.7s: train loss = 2.98325 = (mf)1.20813 + (embed)1.77512\n",
            "Epoch 47 (train)2.7s: train loss = 2.92129 = (mf)1.14873 + (embed)1.77256\n",
            "Epoch 48 (train)2.4s: train loss = 2.96243 = (mf)1.18656 + (embed)1.77586\n",
            "Epoch 49 (train)2.4s: train loss = 2.93162 = (mf)1.15523 + (embed)1.77640\n",
            "Epoch 50 (train)2.4s + (eval)0.8s: train loss = 2.95346 = (mf)1.17892 + (embed)1.77454, recall = 0.02810, ndcg = 0.11001\n",
            "Epoch 51 (train)3.1s: train loss = 2.93515 = (mf)1.16214 + (embed)1.77301\n",
            "Epoch 52 (train)2.4s: train loss = 2.95325 = (mf)1.18139 + (embed)1.77186\n",
            "Epoch 53 (train)2.4s: train loss = 2.97816 = (mf)1.19931 + (embed)1.77885\n",
            "Epoch 54 (train)2.4s: train loss = 2.90967 = (mf)1.12720 + (embed)1.78247\n",
            "Epoch 55 (train)2.6s + (eval)0.5s: train loss = 3.00202 = (mf)1.22356 + (embed)1.77847, recall = 0.02738, ndcg = 0.11474\n",
            "Epoch 56 (train)2.7s: train loss = 2.88793 = (mf)1.11514 + (embed)1.77279\n",
            "Epoch 57 (train)2.4s: train loss = 2.96387 = (mf)1.18314 + (embed)1.78072\n",
            "Epoch 58 (train)2.4s: train loss = 2.97548 = (mf)1.19318 + (embed)1.78230\n",
            "Epoch 59 (train)2.4s: train loss = 2.92830 = (mf)1.15082 + (embed)1.77749\n",
            "Epoch 60 (train)2.9s + (eval)0.3s: train loss = 3.00220 = (mf)1.22159 + (embed)1.78060, recall = 0.02380, ndcg = 0.09910\n",
            "Epoch 61 (train)2.5s: train loss = 2.92864 = (mf)1.15352 + (embed)1.77512\n",
            "Epoch 62 (train)2.4s: train loss = 2.93442 = (mf)1.15606 + (embed)1.77835\n",
            "Epoch 63 (train)2.4s: train loss = 3.02181 = (mf)1.23177 + (embed)1.79003\n",
            "Epoch 64 (train)2.4s: train loss = 2.92237 = (mf)1.13321 + (embed)1.78916\n",
            "Epoch 65 (train)2.9s + (eval)0.3s: train loss = 2.95030 = (mf)1.16478 + (embed)1.78552, recall = 0.02453, ndcg = 0.10396\n",
            "Epoch 66 (train)2.4s: train loss = 2.97647 = (mf)1.19085 + (embed)1.78562\n",
            "Epoch 67 (train)2.4s: train loss = 2.91349 = (mf)1.11482 + (embed)1.79867\n",
            "Epoch 68 (train)2.4s: train loss = 3.01551 = (mf)1.22896 + (embed)1.78655\n",
            "Epoch 69 (train)2.7s: train loss = 2.95087 = (mf)1.15674 + (embed)1.79413\n",
            "Epoch 70 (train)2.6s + (eval)0.8s: train loss = 2.88387 = (mf)1.09597 + (embed)1.78790, recall = 0.02431, ndcg = 0.09849\n",
            "Epoch 71 (train)2.4s: train loss = 2.95697 = (mf)1.18020 + (embed)1.77677\n",
            "Epoch 72 (train)2.4s: train loss = 2.96569 = (mf)1.18843 + (embed)1.77725\n",
            "Epoch 73 (train)2.4s: train loss = 2.97257 = (mf)1.17827 + (embed)1.79430\n",
            "Epoch 74 (train)2.9s: train loss = 2.98050 = (mf)1.18542 + (embed)1.79509\n",
            "Epoch 75 (train)2.4s + (eval)0.3s: train loss = 2.98042 = (mf)1.17941 + (embed)1.80101, recall = 0.02514, ndcg = 0.09919\n",
            "Epoch 76 (train)2.4s: train loss = 2.97028 = (mf)1.17154 + (embed)1.79874\n",
            "Epoch 77 (train)2.4s: train loss = 2.99656 = (mf)1.20205 + (embed)1.79451\n",
            "Epoch 78 (train)2.7s: train loss = 2.90917 = (mf)1.12395 + (embed)1.78522\n",
            "Epoch 79 (train)2.6s: train loss = 2.95565 = (mf)1.16524 + (embed)1.79041\n",
            "Epoch 80 (train)2.4s + (eval)0.3s: train loss = 3.03811 = (mf)1.23246 + (embed)1.80565, recall = 0.02358, ndcg = 0.09709\n",
            "Epoch 81 (train)2.4s: train loss = 2.95633 = (mf)1.15066 + (embed)1.80567\n",
            "Epoch 82 (train)2.4s: train loss = 2.96238 = (mf)1.16189 + (embed)1.80050\n",
            "Epoch 83 (train)2.9s: train loss = 2.95517 = (mf)1.16563 + (embed)1.78955\n",
            "Epoch 84 (train)2.5s: train loss = 2.89384 = (mf)1.10446 + (embed)1.78938\n",
            "Epoch 85 (train)2.4s + (eval)0.3s: train loss = 2.94996 = (mf)1.16386 + (embed)1.78610, recall = 0.02671, ndcg = 0.10430\n",
            "Epoch 86 (train)2.5s: train loss = 2.95231 = (mf)1.15924 + (embed)1.79306\n",
            "Epoch 87 (train)2.7s: train loss = 2.94225 = (mf)1.14924 + (embed)1.79301\n",
            "Epoch 88 (train)2.7s: train loss = 2.96719 = (mf)1.17376 + (embed)1.79344\n",
            "Epoch 89 (train)2.4s: train loss = 2.94436 = (mf)1.14667 + (embed)1.79769\n",
            "Epoch 90 (train)2.4s + (eval)0.3s: train loss = 2.91968 = (mf)1.13110 + (embed)1.78858, recall = 0.02244, ndcg = 0.09317\n",
            "Epoch 91 (train)2.4s: train loss = 3.00579 = (mf)1.21116 + (embed)1.79463\n",
            "Epoch 92 (train)2.9s: train loss = 2.96123 = (mf)1.16203 + (embed)1.79920\n",
            "Epoch 93 (train)2.5s: train loss = 2.94964 = (mf)1.15216 + (embed)1.79748\n",
            "Epoch 94 (train)2.4s: train loss = 2.94568 = (mf)1.15395 + (embed)1.79173\n",
            "Epoch 95 (train)2.4s + (eval)0.8s: train loss = 2.98304 = (mf)1.19222 + (embed)1.79082, recall = 0.02249, ndcg = 0.08419\n",
            "Epoch 96 (train)2.7s: train loss = 2.92716 = (mf)1.13688 + (embed)1.79029\n",
            "Epoch 97 (train)2.8s: train loss = 2.98103 = (mf)1.18272 + (embed)1.79831\n",
            "Epoch 98 (train)2.4s: train loss = 2.94463 = (mf)1.13850 + (embed)1.80613\n",
            "Epoch 99 (train)2.4s: train loss = 2.95091 = (mf)1.14929 + (embed)1.80162\n",
            "Epoch 100 (train)2.4s + (eval)0.3s: train loss = 3.01393 = (mf)1.20454 + (embed)1.80939, recall = 0.02439, ndcg = 0.09081\n",
            "Training finished in 266.35 seconds.\n",
            "Evaluation results for this combination: NDCG@50: 0.09081, Recall@50: 0.02439\n",
            "--- Trying combination: Epochs=100, TopK=50, LearningRate=0.5, Layers=5 ---\n",
            "Already normalize adjacency matrix (extended).\n",
            "Using xavier initialization for user, item, and genre embeddings.\n",
            "Epoch 1 (train)6.2s: train loss = 0.45815 = (mf)0.33428 + (embed)0.12387\n",
            "Epoch 2 (train)2.5s: train loss = 0.94888 = (mf)0.57627 + (embed)0.37261\n",
            "Epoch 3 (train)2.5s: train loss = 1.29164 = (mf)0.72450 + (embed)0.56715\n",
            "Epoch 4 (train)2.4s: train loss = 1.55069 = (mf)0.83430 + (embed)0.71639\n",
            "Epoch 5 (train)2.9s + (eval)1.5s: train loss = 1.74026 = (mf)0.91996 + (embed)0.82030, recall = 0.02060, ndcg = 0.08572\n",
            "Epoch 6 (train)2.6s: train loss = 1.88394 = (mf)0.97480 + (embed)0.90913\n",
            "Epoch 7 (train)2.5s: train loss = 1.93288 = (mf)0.94658 + (embed)0.98630\n",
            "Epoch 8 (train)2.4s: train loss = 1.96978 = (mf)0.94351 + (embed)1.02627\n",
            "Epoch 9 (train)2.9s: train loss = 2.01961 = (mf)0.95493 + (embed)1.06468\n",
            "Epoch 10 (train)2.6s + (eval)0.8s: train loss = 2.01230 = (mf)0.91231 + (embed)1.09999, recall = 0.02153, ndcg = 0.09594\n",
            "Epoch 11 (train)2.5s: train loss = 2.06568 = (mf)0.93463 + (embed)1.13105\n",
            "Epoch 12 (train)2.5s: train loss = 2.06173 = (mf)0.90616 + (embed)1.15557\n",
            "Epoch 13 (train)2.7s: train loss = 2.10136 = (mf)0.92900 + (embed)1.17237\n",
            "Epoch 14 (train)2.8s: train loss = 2.09663 = (mf)0.90277 + (embed)1.19387\n",
            "Epoch 15 (train)2.4s + (eval)0.3s: train loss = 2.08191 = (mf)0.87544 + (embed)1.20647, recall = 0.02450, ndcg = 0.10646\n",
            "Epoch 16 (train)2.4s: train loss = 2.05038 = (mf)0.83195 + (embed)1.21843\n",
            "Epoch 17 (train)2.5s: train loss = 2.07540 = (mf)0.85273 + (embed)1.22268\n",
            "Epoch 18 (train)2.9s: train loss = 2.06094 = (mf)0.83106 + (embed)1.22989\n",
            "Epoch 19 (train)2.5s: train loss = 2.10410 = (mf)0.86773 + (embed)1.23637\n",
            "Epoch 20 (train)2.4s + (eval)0.3s: train loss = 2.10961 = (mf)0.86133 + (embed)1.24828, recall = 0.02330, ndcg = 0.09339\n",
            "Epoch 21 (train)2.4s: train loss = 2.05270 = (mf)0.79429 + (embed)1.25841\n",
            "Epoch 22 (train)2.5s: train loss = 2.05159 = (mf)0.79022 + (embed)1.26137\n",
            "Epoch 23 (train)2.9s: train loss = 2.04732 = (mf)0.77368 + (embed)1.27364\n",
            "Epoch 24 (train)2.5s: train loss = 2.01783 = (mf)0.75557 + (embed)1.26226\n",
            "Epoch 25 (train)2.5s + (eval)0.3s: train loss = 2.05586 = (mf)0.79167 + (embed)1.26419, recall = 0.02376, ndcg = 0.08897\n",
            "Epoch 26 (train)2.5s: train loss = 2.03702 = (mf)0.76646 + (embed)1.27057\n",
            "Epoch 27 (train)2.9s: train loss = 2.01669 = (mf)0.74693 + (embed)1.26976\n",
            "Epoch 28 (train)2.5s: train loss = 2.03104 = (mf)0.76140 + (embed)1.26964\n",
            "Epoch 29 (train)2.4s: train loss = 2.07948 = (mf)0.79990 + (embed)1.27958\n",
            "Epoch 30 (train)2.5s + (eval)0.7s: train loss = 2.06531 = (mf)0.78572 + (embed)1.27959, recall = 0.02511, ndcg = 0.09853\n",
            "Epoch 31 (train)2.7s: train loss = 2.03305 = (mf)0.76066 + (embed)1.27239\n",
            "Epoch 32 (train)2.8s: train loss = 2.03290 = (mf)0.75806 + (embed)1.27484\n",
            "Epoch 33 (train)2.4s: train loss = 2.03985 = (mf)0.76528 + (embed)1.27457\n",
            "Epoch 34 (train)2.4s: train loss = 2.03405 = (mf)0.75256 + (embed)1.28149\n",
            "Epoch 35 (train)2.5s + (eval)0.3s: train loss = 2.06346 = (mf)0.78037 + (embed)1.28310, recall = 0.02542, ndcg = 0.09169\n",
            "Epoch 36 (train)3.0s: train loss = 2.07341 = (mf)0.78490 + (embed)1.28851\n",
            "Epoch 37 (train)2.5s: train loss = 2.05320 = (mf)0.76662 + (embed)1.28659\n",
            "Epoch 38 (train)2.4s: train loss = 2.01254 = (mf)0.73262 + (embed)1.27992\n",
            "Epoch 39 (train)2.4s: train loss = 2.03923 = (mf)0.75594 + (embed)1.28329\n",
            "Epoch 40 (train)2.5s + (eval)0.4s: train loss = 2.00501 = (mf)0.72149 + (embed)1.28351, recall = 0.02436, ndcg = 0.08785\n",
            "Epoch 41 (train)2.8s: train loss = 2.02075 = (mf)0.73996 + (embed)1.28079\n",
            "Epoch 42 (train)2.5s: train loss = 2.03957 = (mf)0.76108 + (embed)1.27849\n",
            "Epoch 43 (train)2.4s: train loss = 1.99072 = (mf)0.71099 + (embed)1.27974\n",
            "Epoch 44 (train)2.4s: train loss = 2.05956 = (mf)0.77848 + (embed)1.28108\n",
            "Epoch 45 (train)2.9s + (eval)0.3s: train loss = 2.05391 = (mf)0.76888 + (embed)1.28502, recall = 0.02125, ndcg = 0.08668\n",
            "Epoch 46 (train)2.5s: train loss = 1.99771 = (mf)0.71262 + (embed)1.28508\n",
            "Epoch 47 (train)2.5s: train loss = 2.02340 = (mf)0.74253 + (embed)1.28087\n",
            "Epoch 48 (train)2.5s: train loss = 2.01211 = (mf)0.73103 + (embed)1.28109\n",
            "Epoch 49 (train)2.5s: train loss = 2.01080 = (mf)0.72734 + (embed)1.28347\n",
            "Epoch 50 (train)2.9s + (eval)0.8s: train loss = 2.04531 = (mf)0.75261 + (embed)1.29270, recall = 0.02414, ndcg = 0.09002\n",
            "Epoch 51 (train)2.4s: train loss = 2.05922 = (mf)0.75835 + (embed)1.30087\n",
            "Epoch 52 (train)2.4s: train loss = 2.07295 = (mf)0.77227 + (embed)1.30068\n",
            "Epoch 53 (train)2.4s: train loss = 2.06211 = (mf)0.77165 + (embed)1.29046\n",
            "Epoch 54 (train)3.0s: train loss = 2.03221 = (mf)0.74238 + (embed)1.28984\n",
            "Epoch 55 (train)2.4s + (eval)0.3s: train loss = 2.03690 = (mf)0.74639 + (embed)1.29051, recall = 0.02516, ndcg = 0.09115\n",
            "Epoch 56 (train)2.4s: train loss = 2.06839 = (mf)0.76840 + (embed)1.29999\n",
            "Epoch 57 (train)2.5s: train loss = 2.07887 = (mf)0.77365 + (embed)1.30522\n",
            "Epoch 58 (train)2.6s: train loss = 2.04778 = (mf)0.75274 + (embed)1.29504\n",
            "Epoch 59 (train)2.8s: train loss = 2.03897 = (mf)0.73849 + (embed)1.30048\n",
            "Epoch 60 (train)2.4s + (eval)0.3s: train loss = 2.06419 = (mf)0.75962 + (embed)1.30457, recall = 0.02337, ndcg = 0.08628\n",
            "Epoch 61 (train)2.5s: train loss = 2.01610 = (mf)0.72760 + (embed)1.28851\n",
            "Epoch 62 (train)2.4s: train loss = 2.00330 = (mf)0.72148 + (embed)1.28181\n",
            "Epoch 63 (train)3.0s: train loss = 2.00746 = (mf)0.72439 + (embed)1.28306\n",
            "Epoch 64 (train)2.4s: train loss = 2.00159 = (mf)0.72453 + (embed)1.27706\n",
            "Epoch 65 (train)2.5s + (eval)0.3s: train loss = 2.00138 = (mf)0.72683 + (embed)1.27454, recall = 0.02556, ndcg = 0.10136\n",
            "Epoch 66 (train)2.4s: train loss = 2.03976 = (mf)0.76425 + (embed)1.27552\n",
            "Epoch 67 (train)2.5s: train loss = 2.03100 = (mf)0.75369 + (embed)1.27731\n",
            "Epoch 68 (train)2.8s: train loss = 2.00251 = (mf)0.72350 + (embed)1.27901\n",
            "Epoch 69 (train)2.5s: train loss = 2.01823 = (mf)0.73512 + (embed)1.28312\n",
            "Epoch 70 (train)2.5s + (eval)0.8s: train loss = 2.06342 = (mf)0.77968 + (embed)1.28374, recall = 0.02476, ndcg = 0.09006\n",
            "Epoch 71 (train)2.5s: train loss = 2.03875 = (mf)0.75375 + (embed)1.28500\n",
            "Epoch 72 (train)3.0s: train loss = 2.06844 = (mf)0.77782 + (embed)1.29062\n",
            "Epoch 73 (train)2.4s: train loss = 2.05298 = (mf)0.76277 + (embed)1.29021\n",
            "Epoch 74 (train)2.4s: train loss = 2.06507 = (mf)0.77887 + (embed)1.28620\n",
            "Epoch 75 (train)2.5s + (eval)0.3s: train loss = 2.04624 = (mf)0.75748 + (embed)1.28876, recall = 0.02358, ndcg = 0.07994\n",
            "Epoch 76 (train)2.6s: train loss = 2.00512 = (mf)0.71764 + (embed)1.28748\n",
            "Epoch 77 (train)2.8s: train loss = 2.06435 = (mf)0.77475 + (embed)1.28960\n",
            "Epoch 78 (train)2.4s: train loss = 2.02661 = (mf)0.73972 + (embed)1.28689\n",
            "Epoch 79 (train)2.4s: train loss = 2.01312 = (mf)0.71917 + (embed)1.29396\n",
            "Epoch 80 (train)2.5s + (eval)0.3s: train loss = 2.02974 = (mf)0.73903 + (embed)1.29070, recall = 0.02447, ndcg = 0.09289\n",
            "Epoch 81 (train)3.0s: train loss = 2.04123 = (mf)0.75057 + (embed)1.29066\n",
            "Epoch 82 (train)2.5s: train loss = 2.07045 = (mf)0.77954 + (embed)1.29091\n",
            "Epoch 83 (train)2.4s: train loss = 2.04098 = (mf)0.74686 + (embed)1.29412\n",
            "Epoch 84 (train)2.5s: train loss = 2.00423 = (mf)0.71283 + (embed)1.29140\n",
            "Epoch 85 (train)2.5s + (eval)0.4s: train loss = 2.06140 = (mf)0.76266 + (embed)1.29874, recall = 0.02594, ndcg = 0.09842\n",
            "Epoch 86 (train)2.8s: train loss = 2.07480 = (mf)0.76739 + (embed)1.30740\n",
            "Epoch 87 (train)2.4s: train loss = 2.05573 = (mf)0.74859 + (embed)1.30714\n",
            "Epoch 88 (train)2.5s: train loss = 2.02322 = (mf)0.71906 + (embed)1.30416\n",
            "Epoch 89 (train)2.4s: train loss = 2.05356 = (mf)0.75464 + (embed)1.29892\n",
            "Epoch 90 (train)3.4s + (eval)0.5s: train loss = 2.11868 = (mf)0.80896 + (embed)1.30972, recall = 0.02761, ndcg = 0.09945\n",
            "Epoch 91 (train)2.7s: train loss = 2.06749 = (mf)0.75260 + (embed)1.31489\n",
            "Epoch 92 (train)2.5s: train loss = 2.02798 = (mf)0.71561 + (embed)1.31237\n",
            "Epoch 93 (train)2.5s: train loss = 2.05301 = (mf)0.74978 + (embed)1.30323\n",
            "Epoch 94 (train)2.4s: train loss = 2.03042 = (mf)0.72411 + (embed)1.30630\n",
            "Epoch 95 (train)3.0s + (eval)0.8s: train loss = 1.98585 = (mf)0.69062 + (embed)1.29522, recall = 0.02457, ndcg = 0.10273\n",
            "Epoch 96 (train)2.4s: train loss = 2.02531 = (mf)0.73231 + (embed)1.29300\n",
            "Epoch 97 (train)2.5s: train loss = 2.01989 = (mf)0.72480 + (embed)1.29509\n",
            "Epoch 98 (train)2.4s: train loss = 2.02720 = (mf)0.73121 + (embed)1.29598\n",
            "Epoch 99 (train)3.0s: train loss = 2.02302 = (mf)0.72554 + (embed)1.29747\n",
            "Epoch 100 (train)2.5s + (eval)0.3s: train loss = 2.06851 = (mf)0.76909 + (embed)1.29942, recall = 0.02400, ndcg = 0.09608\n",
            "Training finished in 270.95 seconds.\n",
            "Evaluation results for this combination: NDCG@50: 0.09608, Recall@50: 0.02400\n",
            "\n",
            "===== Hyperparameter Tuning Summary =====\n",
            "Epochs=25_TopK=10_LR=0.005_Layers=3: NDCG=0.33641, Recall=0.01717, TrainTime=61.81s\n",
            "Epochs=25_TopK=10_LR=0.005_Layers=4: NDCG=0.32024, Recall=0.01709, TrainTime=62.53s\n",
            "Epochs=25_TopK=10_LR=0.005_Layers=5: NDCG=0.31419, Recall=0.01622, TrainTime=73.87s\n",
            "Epochs=25_TopK=10_LR=0.05_Layers=3: NDCG=0.17760, Recall=0.01261, TrainTime=63.04s\n",
            "Epochs=25_TopK=10_LR=0.05_Layers=4: NDCG=0.26699, Recall=0.01612, TrainTime=62.73s\n",
            "Epochs=25_TopK=10_LR=0.05_Layers=5: NDCG=0.29646, Recall=0.01681, TrainTime=65.54s\n",
            "Epochs=25_TopK=10_LR=0.5_Layers=3: NDCG=0.12884, Recall=0.00839, TrainTime=63.25s\n",
            "Epochs=25_TopK=10_LR=0.5_Layers=4: NDCG=0.13808, Recall=0.00792, TrainTime=63.70s\n",
            "Epochs=25_TopK=10_LR=0.5_Layers=5: NDCG=0.13142, Recall=0.00764, TrainTime=64.98s\n",
            "Epochs=25_TopK=20_LR=0.005_Layers=3: NDCG=0.25783, Recall=0.02740, TrainTime=62.58s\n",
            "Epochs=25_TopK=20_LR=0.005_Layers=4: NDCG=0.26116, Recall=0.02681, TrainTime=64.93s\n",
            "Epochs=25_TopK=20_LR=0.005_Layers=5: NDCG=0.25813, Recall=0.02562, TrainTime=64.82s\n",
            "Epochs=25_TopK=20_LR=0.05_Layers=3: NDCG=0.17009, Recall=0.01954, TrainTime=63.17s\n",
            "Epochs=25_TopK=20_LR=0.05_Layers=4: NDCG=0.19025, Recall=0.02163, TrainTime=63.38s\n",
            "Epochs=25_TopK=20_LR=0.05_Layers=5: NDCG=0.23419, Recall=0.02494, TrainTime=66.50s\n",
            "Epochs=25_TopK=20_LR=0.5_Layers=3: NDCG=0.11914, Recall=0.01575, TrainTime=64.14s\n",
            "Epochs=25_TopK=20_LR=0.5_Layers=4: NDCG=0.11350, Recall=0.01375, TrainTime=63.69s\n",
            "Epochs=25_TopK=20_LR=0.5_Layers=5: NDCG=0.11134, Recall=0.01323, TrainTime=65.73s\n",
            "Epochs=25_TopK=50_LR=0.005_Layers=3: NDCG=0.19784, Recall=0.04369, TrainTime=64.71s\n",
            "Epochs=25_TopK=50_LR=0.005_Layers=4: NDCG=0.19692, Recall=0.04297, TrainTime=64.28s\n",
            "Epochs=25_TopK=50_LR=0.005_Layers=5: NDCG=0.19430, Recall=0.04122, TrainTime=66.10s\n",
            "Epochs=25_TopK=50_LR=0.05_Layers=3: NDCG=0.14033, Recall=0.03391, TrainTime=63.76s\n",
            "Epochs=25_TopK=50_LR=0.05_Layers=4: NDCG=0.15149, Recall=0.03717, TrainTime=65.88s\n",
            "Epochs=25_TopK=50_LR=0.05_Layers=5: NDCG=0.17156, Recall=0.03816, TrainTime=66.52s\n",
            "Epochs=25_TopK=50_LR=0.5_Layers=3: NDCG=0.10913, Recall=0.02615, TrainTime=64.21s\n",
            "Epochs=25_TopK=50_LR=0.5_Layers=4: NDCG=0.10652, Recall=0.02706, TrainTime=65.27s\n",
            "Epochs=25_TopK=50_LR=0.5_Layers=5: NDCG=0.09074, Recall=0.02351, TrainTime=66.57s\n",
            "Epochs=50_TopK=10_LR=0.005_Layers=3: NDCG=0.32248, Recall=0.01845, TrainTime=127.53s\n",
            "Epochs=50_TopK=10_LR=0.005_Layers=4: NDCG=0.34805, Recall=0.01888, TrainTime=129.69s\n",
            "Epochs=50_TopK=10_LR=0.005_Layers=5: NDCG=0.33220, Recall=0.01697, TrainTime=131.42s\n",
            "Epochs=50_TopK=10_LR=0.05_Layers=3: NDCG=0.16477, Recall=0.01117, TrainTime=128.54s\n",
            "Epochs=50_TopK=10_LR=0.05_Layers=4: NDCG=0.26262, Recall=0.01687, TrainTime=129.04s\n",
            "Epochs=50_TopK=10_LR=0.05_Layers=5: NDCG=0.27662, Recall=0.01529, TrainTime=133.52s\n",
            "Epochs=50_TopK=10_LR=0.5_Layers=3: NDCG=0.10829, Recall=0.00642, TrainTime=131.52s\n",
            "Epochs=50_TopK=10_LR=0.5_Layers=4: NDCG=0.10869, Recall=0.00652, TrainTime=129.90s\n",
            "Epochs=50_TopK=10_LR=0.5_Layers=5: NDCG=0.12479, Recall=0.00539, TrainTime=132.54s\n",
            "Epochs=50_TopK=20_LR=0.005_Layers=3: NDCG=0.26899, Recall=0.02830, TrainTime=127.58s\n",
            "Epochs=50_TopK=20_LR=0.005_Layers=4: NDCG=0.28421, Recall=0.02939, TrainTime=130.48s\n",
            "Epochs=50_TopK=20_LR=0.005_Layers=5: NDCG=0.27080, Recall=0.02708, TrainTime=132.65s\n",
            "Epochs=50_TopK=20_LR=0.05_Layers=3: NDCG=0.16285, Recall=0.02056, TrainTime=128.63s\n",
            "Epochs=50_TopK=20_LR=0.05_Layers=4: NDCG=0.18292, Recall=0.02196, TrainTime=128.53s\n",
            "Epochs=50_TopK=20_LR=0.05_Layers=5: NDCG=0.19911, Recall=0.02453, TrainTime=131.81s\n",
            "Epochs=50_TopK=20_LR=0.5_Layers=3: NDCG=0.12021, Recall=0.01539, TrainTime=127.34s\n",
            "Epochs=50_TopK=20_LR=0.5_Layers=4: NDCG=0.11273, Recall=0.01331, TrainTime=128.44s\n",
            "Epochs=50_TopK=20_LR=0.5_Layers=5: NDCG=0.10913, Recall=0.01249, TrainTime=131.48s\n",
            "Epochs=50_TopK=50_LR=0.005_Layers=3: NDCG=0.19755, Recall=0.04489, TrainTime=129.13s\n",
            "Epochs=50_TopK=50_LR=0.005_Layers=4: NDCG=0.20497, Recall=0.04447, TrainTime=127.90s\n",
            "Epochs=50_TopK=50_LR=0.005_Layers=5: NDCG=0.20526, Recall=0.04478, TrainTime=132.98s\n",
            "Epochs=50_TopK=50_LR=0.05_Layers=3: NDCG=0.12232, Recall=0.03212, TrainTime=128.40s\n",
            "Epochs=50_TopK=50_LR=0.05_Layers=4: NDCG=0.15918, Recall=0.03741, TrainTime=129.85s\n",
            "Epochs=50_TopK=50_LR=0.05_Layers=5: NDCG=0.17138, Recall=0.03934, TrainTime=133.29s\n",
            "Epochs=50_TopK=50_LR=0.5_Layers=3: NDCG=0.10409, Recall=0.02587, TrainTime=128.55s\n",
            "Epochs=50_TopK=50_LR=0.5_Layers=4: NDCG=0.10676, Recall=0.02563, TrainTime=130.92s\n",
            "Epochs=50_TopK=50_LR=0.5_Layers=5: NDCG=0.09145, Recall=0.02344, TrainTime=132.50s\n",
            "Epochs=100_TopK=10_LR=0.005_Layers=3: NDCG=0.33238, Recall=0.01891, TrainTime=254.33s\n",
            "Epochs=100_TopK=10_LR=0.005_Layers=4: NDCG=0.35791, Recall=0.01816, TrainTime=257.44s\n",
            "Epochs=100_TopK=10_LR=0.005_Layers=5: NDCG=0.36099, Recall=0.01932, TrainTime=263.78s\n",
            "Epochs=100_TopK=10_LR=0.05_Layers=3: NDCG=0.19209, Recall=0.01175, TrainTime=257.19s\n",
            "Epochs=100_TopK=10_LR=0.05_Layers=4: NDCG=0.23508, Recall=0.01541, TrainTime=258.56s\n",
            "Epochs=100_TopK=10_LR=0.05_Layers=5: NDCG=0.26240, Recall=0.01547, TrainTime=265.00s\n",
            "Epochs=100_TopK=10_LR=0.5_Layers=3: NDCG=0.13569, Recall=0.00728, TrainTime=255.85s\n",
            "Epochs=100_TopK=10_LR=0.5_Layers=4: NDCG=0.12468, Recall=0.00967, TrainTime=257.10s\n",
            "Epochs=100_TopK=10_LR=0.5_Layers=5: NDCG=0.11827, Recall=0.00694, TrainTime=264.43s\n",
            "Epochs=100_TopK=20_LR=0.005_Layers=3: NDCG=0.26890, Recall=0.02788, TrainTime=258.04s\n",
            "Epochs=100_TopK=20_LR=0.005_Layers=4: NDCG=0.28062, Recall=0.02842, TrainTime=259.90s\n",
            "Epochs=100_TopK=20_LR=0.005_Layers=5: NDCG=0.29143, Recall=0.02896, TrainTime=266.15s\n",
            "Epochs=100_TopK=20_LR=0.05_Layers=3: NDCG=0.18145, Recall=0.01919, TrainTime=259.78s\n",
            "Epochs=100_TopK=20_LR=0.05_Layers=4: NDCG=0.20479, Recall=0.02396, TrainTime=262.93s\n",
            "Epochs=100_TopK=20_LR=0.05_Layers=5: NDCG=0.22897, Recall=0.02466, TrainTime=268.13s\n",
            "Epochs=100_TopK=20_LR=0.5_Layers=3: NDCG=0.13426, Recall=0.01505, TrainTime=258.61s\n",
            "Epochs=100_TopK=20_LR=0.5_Layers=4: NDCG=0.13551, Recall=0.01419, TrainTime=262.67s\n",
            "Epochs=100_TopK=20_LR=0.5_Layers=5: NDCG=0.10858, Recall=0.01161, TrainTime=266.55s\n",
            "Epochs=100_TopK=50_LR=0.005_Layers=3: NDCG=0.20278, Recall=0.04451, TrainTime=261.48s\n",
            "Epochs=100_TopK=50_LR=0.005_Layers=4: NDCG=0.20450, Recall=0.04507, TrainTime=263.22s\n",
            "Epochs=100_TopK=50_LR=0.005_Layers=5: NDCG=0.20591, Recall=0.04473, TrainTime=267.96s\n",
            "Epochs=100_TopK=50_LR=0.05_Layers=3: NDCG=0.12880, Recall=0.03190, TrainTime=263.69s\n",
            "Epochs=100_TopK=50_LR=0.05_Layers=4: NDCG=0.16229, Recall=0.03817, TrainTime=265.71s\n",
            "Epochs=100_TopK=50_LR=0.05_Layers=5: NDCG=0.17841, Recall=0.03960, TrainTime=269.19s\n",
            "Epochs=100_TopK=50_LR=0.5_Layers=3: NDCG=0.10045, Recall=0.02636, TrainTime=261.37s\n",
            "Epochs=100_TopK=50_LR=0.5_Layers=4: NDCG=0.09081, Recall=0.02439, TrainTime=266.35s\n",
            "Epochs=100_TopK=50_LR=0.5_Layers=5: NDCG=0.09608, Recall=0.02400, TrainTime=270.95s\n",
            "\n",
            "Best combination based on NDCG: Epochs=100_TopK=10_LR=0.005_Layers=5\n",
            "NDCG: 0.36099\n",
            "Recall: 0.01932\n"
          ]
        }
      ]
    }
  ]
}